[
  {
    "title": "Modular Docs - Mojo language basics",
    "url": "https://docs.modular.com/mojo/manual/basics/index.html#language-basics",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nLanguage basics\nSyntax and semantics\nFunctions\nVariables\nFunction arguments and returns\nStructures\nPython integration\nNext steps\nMojo language basics\n\nMojo is a powerful programming language that‚Äôs primarily designed for high-performance systems programming, so it has a lot in common with other systems languages like Rust and C++. Yet, Mojo is also designed to become a superset of Python, so a lot of language features and concepts you might know from Python translate nicely to Mojo.\n\nFor example, if you‚Äôre in a REPL environment or Jupyter notebook (like this document), you can run top-level code just like Python:\n\nprint(\"Hello Mojo!\")\nHello Mojo!\n\nYou don‚Äôt normally see that with other systems programming languages.\n\nMojo preserves Python‚Äôs dynamic features and language syntax, and it even allows you to import and run code from Python packages. However, it‚Äôs important to know that Mojo is an entirely new language, not just a new implementation of Python with syntax sugar. Mojo takes the Python language to a whole new level, with systems programming features, strong type-checking, memory safety, next-generation compiler technologies, and more. Yet, it‚Äôs still designed to be a simple language that‚Äôs useful for general-purpose programming.\n\nThis page provides a gentle introduction to the Mojo language, and requires only a little programming experience. So let‚Äôs get started!\n\nIf you‚Äôre an experienced systems programmer and want a deep dive into the language, check out the Mojo programming manual.\n\nLanguage basics\n\nFirst and foremost, Mojo is a compiled language and a lot of its performance and memory-safety features are derived from that fact. Mojo code can be ahead-of-time (AOT) or just-in-time (JIT) compiled.\n\nLike other compiled languages, Mojo programs (.mojo or .üî• files) require a main() function as the entry point to the program. For example:\n\nfn main():\n    var x: Int = 1\n    x += 1\n    print(x)\n\nIf you know Python, you might have expected the function name to be def main() instead of fn main(). Both actually work in Mojo, but using fn behaves a bit differently, as we‚Äôll discuss below.\n\nOf course, if you‚Äôre building a Mojo module (an API library), not a Mojo program, then your file doesn‚Äôt need a main() function (because it will be imported by other programs that do have one).\n\nNote: When you‚Äôre writing code in a .mojo/.üî• file, you can‚Äôt run top-level code as shown on this page‚Äîall code in a Mojo program or module must be encased in a function or struct. However, top-level code does work in a REPL or Jupyter notebook (such as the notebook for this page).\n\nNow let‚Äôs explain the code in this main() function.\n\nSyntax and semantics\n\nThis is simple: Mojo supports (or will support) all of Python‚Äôs syntax and semantics. If you‚Äôre not familiar with Python syntax, there are a ton of great resources online that can teach you.\n\nFor example, like Python, Mojo uses line breaks and indentation to define code blocks (not curly braces), and Mojo supports all of Python‚Äôs control-flow syntax such as if conditions and for loops.\n\nHowever, Mojo is still a work in progress, so there are some things from Python that aren‚Äôt implemented in Mojo yet (see the Mojo roadmap). All the missing Python features will arrive in time, but Mojo already includes many features and capabilities beyond what‚Äôs available in Python.\n\nAs such, the following sections will focus on some of the language features that are unique to Mojo (compared to Python).\n\nFunctions\n\nMojo functions can be declared with either fn (shown above) or def (as in Python). The fn declaration enforces strongly-typed and memory-safe behaviors, while def provides Python-style dynamic behaviors.\n\nBoth fn and def functions have their value, and it‚Äôs important that you learn them both. However, for the purposes of this introduction, we‚Äôre going to focus on fn functions only. For much more detail about both, see the programming manual.\n\nIn the following sections, you‚Äôll learn how fn functions enforce strongly-typed and memory-safe behaviors in your code.\n\nVariables\n\nYou can declare variables (such as x in the above main() function) with var to create a mutable value, or with let to create an immutable value.\n\nIf you change var to let in the main() function above and run it, you‚Äôll get a compiler error like this:\n\nerror: Expression [15]:7:5: expression must be mutable for in-place operator destination\n    x += 1\n    ^\n\nThat‚Äôs because let makes the value immutable, so you can‚Äôt increment it.\n\nAnd if you delete var completely, you‚Äôll get an error because fn functions require explicit variable declarations (unlike Python-style def functions).\n\nFinally, notice that the x variable has an explicit Int type specification. Declaring the type is not required for variables in fn, but it is desirable sometimes. If you omit it, Mojo infers the type, as shown here:\n\nfn do_math():\n    let x: Int = 1\n    let y = 2\n    print(x + y)\n\ndo_math()\n3\nFunction arguments and returns\n\nAlthough types aren‚Äôt required for variables declared in the function body, they are required for arguments and return values for an fn function.\n\nFor example, here‚Äôs how to declare Int as the type for function arguments and the return value:\n\nfn add(x: Int, y: Int) -> Int:\n    return x + y\n\nz = add(1, 2)\nprint(z)\n3\nOptional arguments and keyword arguments\n\nYou can also specify argument default values (also known as optional arguments), and pass values with keyword argument names. For example:\n\nfn pow(base: Int, exp: Int = 2) -> Int:\n    return base ** exp\n\n# Uses default value for `exp`\nz = pow(3)\nprint(z)\n\n# Uses keyword argument names (with order reversed)\nz = pow(exp=3, base=2)\nprint(z)\n9\n8\n\nNote: Mojo currently includes only partial support for keyword arguments, so some features such as keyword-only arguments and variadic keyword arguments (e.g.¬†**kwargs) are not supported yet.\n\nArgument mutability and ownership\n\nMojo supports full value semantics and enforces memory safety with a robust value ownership model (similar to the Rust borrow checker). Essentially, that means Mojo allows you to share references to values (instead of making a copy every time you pass a value to a function), but doing so requires that you follow Mojo‚Äôs ownership rules (to ensure memory safety) as described in this section.\n\nNotice that, above, add() doesn‚Äôt modify x or y, it only reads the values. In fact, as written, the function cannot modify them because fn arguments are immutable references by default. This ensures memory safety (no surprise changes to the data) while also avoiding a copy (which could be a performance hit).\n\nIn terms of argument conventions, this is called ‚Äúborrowing,‚Äù and although it‚Äôs the default for fn functions, you can make it explicit with the borrowed declaration like this (this behaves exactly the same as the add() above):\n\nfn add(borrowed x: Int, borrowed y: Int) -> Int:\n    return x + y\n\nIf you want the arguments to be mutable, you need to declare each argument convention as inout. This means that changes made to the arguments inside the function are visible outside the function.\n\nFor example, this function is able to modify the original variables:\n\nfn add_inout(inout x: Int, inout y: Int) -> Int:\n    x += 1\n    y += 1\n    return x + y\n\nvar a = 1\nvar b = 2\nc = add_inout(a, b)\nprint(a)\nprint(b)\nprint(c)\n2\n3\n5\n\nAnother option is to declare the argument as owned, which provides the function full ownership of the value (it‚Äôs mutable and guaranteed unique). This way, the function can modify the value and not worry about affecting variables outside the function. For example:\n\nfn set_fire(owned text: String) -> String:\n    text += \"üî•\"\n    return text\n\nfn mojo():\n    let a: String = \"mojo\"\n    let b = set_fire(a)\n    print(a)\n    print(b)\n\nmojo()\nmojo\nmojoüî•\n\nIn this case, Mojo makes a copy of a and passes it as the text argument. The original a string is still alive and well.\n\nHowever, if you want to give the function ownership of the value and do not want to make a copy (which can be an expensive operation for some types), then you can add the ^ ‚Äútransfer‚Äù operator when you pass a to the function. The transfer operator effectively destroys the local variable name‚Äîany attempt to call upon it later causes a compiler error.\n\nTry it above by changing the call to set_fire() to look like this:\n\n    let b = set_fire(a^)\n\nYou‚Äôll now get an error because the transfer operator effectively destroys the a variable, so when the following print() function tries to use a, that variable isn‚Äôt initialized anymore.\n\nIf you delete print(a), then it works fine.\n\nThese argument conventions are designed to provide systems programmers with total control for memory optimizations while ensuring safe access and timely deallocations‚Äîthe Mojo compiler ensures that no two variables have mutable access to the same value at the same time, and the lifetime of each value is well-defined to strictly prevent any memory errors such as ‚Äúuse-after-free‚Äù and ‚Äúdouble-free.‚Äù\n\nNote: Currently, Mojo always makes a copy when a function returns a value.\n\nStructures\n\nYou can build high-level abstractions for types (or ‚Äúobjects‚Äù) in a struct. A struct in Mojo is similar to a class in Python: they both support methods, fields, operator overloading, decorators for metaprogramming, etc. However, Mojo structs are completely static‚Äîthey are bound at compile-time, so they do not allow dynamic dispatch or any runtime changes to the structure. (Mojo will also support classes in the future.)\n\nFor example, here‚Äôs a basic struct:\n\nstruct MyPair:\n    var first: Int\n    var second: Int\n\n    fn __init__(inout self, first: Int, second: Int):\n        self.first = first\n        self.second = second\n    \n    fn dump(self):\n        print(self.first, self.second)\n\nAnd here‚Äôs how you can use it:\n\nlet mine = MyPair(2, 4)\nmine.dump()\n2 4\n\nIf you‚Äôre familiar with Python, then the __init__() method and the self argument should be familiar to you. If you‚Äôre not familiar with Python, then notice that, when we call dump(), we don‚Äôt actually pass a value for the self argument. The value for self is automatically provided with the current instance of the struct (it‚Äôs used similar to the this name used in some other languages to refer to the current instance of the object/type).\n\nFor much more detail about structs and other special methods like __init__() (also known as ‚Äúdunder‚Äù methods), see the programming manual.\n\nPython integration\n\nAlthough Mojo is still a work in progress and is not a full superset of Python yet, we‚Äôve built a mechanism to import Python modules as-is, so you can leverage existing Python code right away. Under the hood, this mechanism uses the CPython interpreter to run Python code, and thus it works seamlessly with all Python modules today.\n\nFor example, here‚Äôs how you can import and use NumPy (you must have Python numpy installed):\n\nfrom python import Python\n\nlet np = Python.import_module(\"numpy\")\n\nar = np.arange(15).reshape(3, 5)\nprint(ar)\nprint(ar.shape)\n[[ 0  1  2  3  4]\n [ 5  6  7  8  9]\n [10 11 12 13 14]]\n(3, 5)\n\nNote: Mojo is not a feature-complete superset of Python yet. So, you can‚Äôt always copy Python code and run it in Mojo. For more details on our plans, please refer to the Mojo roadmap and sharp edges.\n\nCaution: When you install Mojo, the installer searches your system for a version of Python to use with Mojo, and adds the path to the modular.cfg config file. If you change your Python version or switch virtual environments, Mojo will then be looking at the wrong Python library, which can cause problems such as errors when you import Python packages (Mojo says only An error occurred in Python‚Äîthis is a separate known issue). The current solution is to override Mojo‚Äôs path to the Python library, using the MOJO_PYTHON_LIBRARY environment variable. For instructions on how to find and set this path, see this related issue.\n\nNext steps\n\nWe hope this page covered enough of the basics to get you started. It‚Äôs intentionally brief, so if you want more detail about any of the topics touched upon here, check out the Mojo programming manual.\n\nIf you want to package your code as a library, read about Mojo modules and packages.\n\nIf you want to explore some Mojo code, check out our code examples on GitHub.\n\nTo see all the available Mojo APIs, check out the Mojo standard library reference.\n\nNote: The Mojo SDK is still in early development. Some things are still rough, but you can expect constant changes and improvements to both the language and tools. Please see the known issues and report any other issues on GitHub.\n\nHello, world!\nModules and packages\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - Get started with Mojoüî•",
    "url": "https://docs.modular.com/mojo/manual/get-started/index.html#get-the-mojo-sdk",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nGet the Mojo SDK\nSystem requirements\nInstall Mojo\nUpdate Mojo\nUpdate the Modular CLI\nDevelop in the Mojo Playground\nGet started with Mojoüî•\n\nMojo is now available for local development!\n\nDownload Now\n\nThe Mojo SDK is currently available for Ubuntu Linux systems and macOS systems running on Apple silicon. Support for Windows is coming soon. You can also develop from Windows or Intel macOS using a container or remote Linux system. Alternatively, you can also experiment with Mojo using our web-based Mojo Playground.\n\nGet the Mojo SDK\n\nThe Mojo SDK includes everything you need for local Mojo development, including the Mojo standard library and the Mojo command-line interface (CLI). The Mojo CLI can start a REPL programming environment, compile and run Mojo source files, format source files, and more.\n\nWe‚Äôve also published a Mojo extension for Visual Studio Code to provide a first-class developer experience with features like code completion, quick fixes, and hover help for Mojo APIs.\n\nSystem requirements\n\nTo use the Mojo SDK, you need a system that meets these specifications:\n\nLinux:\n\nUbuntu 20.04/22.04 LTS\nx86-64 CPU (with SSE4.2 or newer) and a minimum of 8 GiB memory\nPython 3.8 - 3.11\ng++ or clang++ C++ compiler\n\nMac:\n\nApple silicon (M1 or M2 processor)\nmacOS Monterey (12) or later\nPython 3.8 - 3.11\nCommand-line tools for Xcode, or Xcode\n\nSupport for Windows will be added in a future release.\n\nInstall Mojo\n\nThe Mojo SDK is available through the Modular CLI tool, which works like a package manager to install and update Mojo. Use the following link to log into the Modular developer console, where you can get the Modular CLI and then install Mojo:\n\nDownload Now\n\nThen get started with Hello, world!\n\nNote: To help us improve Mojo, we collect some basic system information and crash reports. Learn more.\n\nUpdate Mojo\n\nMojo is a work in progress and we will release regular updates to the Mojo language and SDK tools. For information about each release, see the Mojo changelog.\n\nTo check your current Mojo version, use the --version option:\n\nmojo --version\n\nTo update to the latest Mojo version, use the modular update command:\n\nmodular update mojo\nUpdate the Modular CLI\n\nWe may also release updates to the modular tool. Run the following commands to update the CLI on your system.\n\nLinux:\n\nsudo apt update\n\nsudo apt install modular\n\nMac:\n\nbrew update\n\nbrew upgrade modular\nDevelop in the Mojo Playground\n\nInstead of downloading the Mojo SDK, you can also experiment with Mojo in our hosted Jupyter notebook environment called Mojo Playground. This is a hosted version of JupyterLab that‚Äôs running our latest Mojo kernel.\n\nTo get access, just log in to the Mojo Playground here.\n\nWhat to expect\n\nThe Mojo Playground is a JupyterHub environment in which you get a private volume associated with your account, so you can create your own notebooks and they‚Äôll be saved across sessions.\n\nWe‚Äôve included a handful of notebooks to show you Mojo basics and demonstrate its capabilities.\n\nThe number of vCPU cores available in your cloud instance may vary, so baseline performance is not representative of the language. However, as you will see in the included Matmul.ipynb notebook, Mojo‚Äôs relative performance over Python is significant.\n\nThere might be some bugs. Please report issues and feedback on GitHub.\n\nTips\n\nIf you want to keep any edits to the included notebooks, rename the notebook files. These files will reset upon any server refresh or update, sorry. So if you rename the files, your changes will be safe.\n\nYou can use %%python at the top of a notebook cell and write normal Python code. Variables, functions, and imports defined in a Python cell are available for access in subsequent Mojo cells.\n\nCaveats\n\nDid we mention that the included notebooks will lose your changes?\nRename the files if you want to save your changes.\n\nThe Mojo environment does not have network access, so you cannot install other tools or Python packages. However, we‚Äôve included a variety of popular Python packages, such as numpy, pandas, and matplotlib (see how to import Python modules).\n\nRedefining implicit variables is not supported (variables without a let or var in front). If you‚Äôd like to redefine a variable across notebook cells, you must introduce the variable with var (let variables are immutable).\n\nYou can‚Äôt use global variables inside functions‚Äîthey‚Äôre only visible to other global variables.\n\nFor a longer list of things that don‚Äôt work yet or have pain-points, see the Mojo roadmap and sharp edges.\n\nHello, world!\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - Mojo language basics",
    "url": "https://docs.modular.com/mojo/manual/basics/index.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nLanguage basics\nSyntax and semantics\nFunctions\nVariables\nFunction arguments and returns\nStructures\nPython integration\nNext steps\nMojo language basics\n\nMojo is a powerful programming language that‚Äôs primarily designed for high-performance systems programming, so it has a lot in common with other systems languages like Rust and C++. Yet, Mojo is also designed to become a superset of Python, so a lot of language features and concepts you might know from Python translate nicely to Mojo.\n\nFor example, if you‚Äôre in a REPL environment or Jupyter notebook (like this document), you can run top-level code just like Python:\n\nprint(\"Hello Mojo!\")\nHello Mojo!\n\nYou don‚Äôt normally see that with other systems programming languages.\n\nMojo preserves Python‚Äôs dynamic features and language syntax, and it even allows you to import and run code from Python packages. However, it‚Äôs important to know that Mojo is an entirely new language, not just a new implementation of Python with syntax sugar. Mojo takes the Python language to a whole new level, with systems programming features, strong type-checking, memory safety, next-generation compiler technologies, and more. Yet, it‚Äôs still designed to be a simple language that‚Äôs useful for general-purpose programming.\n\nThis page provides a gentle introduction to the Mojo language, and requires only a little programming experience. So let‚Äôs get started!\n\nIf you‚Äôre an experienced systems programmer and want a deep dive into the language, check out the Mojo programming manual.\n\nLanguage basics\n\nFirst and foremost, Mojo is a compiled language and a lot of its performance and memory-safety features are derived from that fact. Mojo code can be ahead-of-time (AOT) or just-in-time (JIT) compiled.\n\nLike other compiled languages, Mojo programs (.mojo or .üî• files) require a main() function as the entry point to the program. For example:\n\nfn main():\n    var x: Int = 1\n    x += 1\n    print(x)\n\nIf you know Python, you might have expected the function name to be def main() instead of fn main(). Both actually work in Mojo, but using fn behaves a bit differently, as we‚Äôll discuss below.\n\nOf course, if you‚Äôre building a Mojo module (an API library), not a Mojo program, then your file doesn‚Äôt need a main() function (because it will be imported by other programs that do have one).\n\nNote: When you‚Äôre writing code in a .mojo/.üî• file, you can‚Äôt run top-level code as shown on this page‚Äîall code in a Mojo program or module must be encased in a function or struct. However, top-level code does work in a REPL or Jupyter notebook (such as the notebook for this page).\n\nNow let‚Äôs explain the code in this main() function.\n\nSyntax and semantics\n\nThis is simple: Mojo supports (or will support) all of Python‚Äôs syntax and semantics. If you‚Äôre not familiar with Python syntax, there are a ton of great resources online that can teach you.\n\nFor example, like Python, Mojo uses line breaks and indentation to define code blocks (not curly braces), and Mojo supports all of Python‚Äôs control-flow syntax such as if conditions and for loops.\n\nHowever, Mojo is still a work in progress, so there are some things from Python that aren‚Äôt implemented in Mojo yet (see the Mojo roadmap). All the missing Python features will arrive in time, but Mojo already includes many features and capabilities beyond what‚Äôs available in Python.\n\nAs such, the following sections will focus on some of the language features that are unique to Mojo (compared to Python).\n\nFunctions\n\nMojo functions can be declared with either fn (shown above) or def (as in Python). The fn declaration enforces strongly-typed and memory-safe behaviors, while def provides Python-style dynamic behaviors.\n\nBoth fn and def functions have their value, and it‚Äôs important that you learn them both. However, for the purposes of this introduction, we‚Äôre going to focus on fn functions only. For much more detail about both, see the programming manual.\n\nIn the following sections, you‚Äôll learn how fn functions enforce strongly-typed and memory-safe behaviors in your code.\n\nVariables\n\nYou can declare variables (such as x in the above main() function) with var to create a mutable value, or with let to create an immutable value.\n\nIf you change var to let in the main() function above and run it, you‚Äôll get a compiler error like this:\n\nerror: Expression [15]:7:5: expression must be mutable for in-place operator destination\n    x += 1\n    ^\n\nThat‚Äôs because let makes the value immutable, so you can‚Äôt increment it.\n\nAnd if you delete var completely, you‚Äôll get an error because fn functions require explicit variable declarations (unlike Python-style def functions).\n\nFinally, notice that the x variable has an explicit Int type specification. Declaring the type is not required for variables in fn, but it is desirable sometimes. If you omit it, Mojo infers the type, as shown here:\n\nfn do_math():\n    let x: Int = 1\n    let y = 2\n    print(x + y)\n\ndo_math()\n3\nFunction arguments and returns\n\nAlthough types aren‚Äôt required for variables declared in the function body, they are required for arguments and return values for an fn function.\n\nFor example, here‚Äôs how to declare Int as the type for function arguments and the return value:\n\nfn add(x: Int, y: Int) -> Int:\n    return x + y\n\nz = add(1, 2)\nprint(z)\n3\nOptional arguments and keyword arguments\n\nYou can also specify argument default values (also known as optional arguments), and pass values with keyword argument names. For example:\n\nfn pow(base: Int, exp: Int = 2) -> Int:\n    return base ** exp\n\n# Uses default value for `exp`\nz = pow(3)\nprint(z)\n\n# Uses keyword argument names (with order reversed)\nz = pow(exp=3, base=2)\nprint(z)\n9\n8\n\nNote: Mojo currently includes only partial support for keyword arguments, so some features such as keyword-only arguments and variadic keyword arguments (e.g.¬†**kwargs) are not supported yet.\n\nArgument mutability and ownership\n\nMojo supports full value semantics and enforces memory safety with a robust value ownership model (similar to the Rust borrow checker). Essentially, that means Mojo allows you to share references to values (instead of making a copy every time you pass a value to a function), but doing so requires that you follow Mojo‚Äôs ownership rules (to ensure memory safety) as described in this section.\n\nNotice that, above, add() doesn‚Äôt modify x or y, it only reads the values. In fact, as written, the function cannot modify them because fn arguments are immutable references by default. This ensures memory safety (no surprise changes to the data) while also avoiding a copy (which could be a performance hit).\n\nIn terms of argument conventions, this is called ‚Äúborrowing,‚Äù and although it‚Äôs the default for fn functions, you can make it explicit with the borrowed declaration like this (this behaves exactly the same as the add() above):\n\nfn add(borrowed x: Int, borrowed y: Int) -> Int:\n    return x + y\n\nIf you want the arguments to be mutable, you need to declare each argument convention as inout. This means that changes made to the arguments inside the function are visible outside the function.\n\nFor example, this function is able to modify the original variables:\n\nfn add_inout(inout x: Int, inout y: Int) -> Int:\n    x += 1\n    y += 1\n    return x + y\n\nvar a = 1\nvar b = 2\nc = add_inout(a, b)\nprint(a)\nprint(b)\nprint(c)\n2\n3\n5\n\nAnother option is to declare the argument as owned, which provides the function full ownership of the value (it‚Äôs mutable and guaranteed unique). This way, the function can modify the value and not worry about affecting variables outside the function. For example:\n\nfn set_fire(owned text: String) -> String:\n    text += \"üî•\"\n    return text\n\nfn mojo():\n    let a: String = \"mojo\"\n    let b = set_fire(a)\n    print(a)\n    print(b)\n\nmojo()\nmojo\nmojoüî•\n\nIn this case, Mojo makes a copy of a and passes it as the text argument. The original a string is still alive and well.\n\nHowever, if you want to give the function ownership of the value and do not want to make a copy (which can be an expensive operation for some types), then you can add the ^ ‚Äútransfer‚Äù operator when you pass a to the function. The transfer operator effectively destroys the local variable name‚Äîany attempt to call upon it later causes a compiler error.\n\nTry it above by changing the call to set_fire() to look like this:\n\n    let b = set_fire(a^)\n\nYou‚Äôll now get an error because the transfer operator effectively destroys the a variable, so when the following print() function tries to use a, that variable isn‚Äôt initialized anymore.\n\nIf you delete print(a), then it works fine.\n\nThese argument conventions are designed to provide systems programmers with total control for memory optimizations while ensuring safe access and timely deallocations‚Äîthe Mojo compiler ensures that no two variables have mutable access to the same value at the same time, and the lifetime of each value is well-defined to strictly prevent any memory errors such as ‚Äúuse-after-free‚Äù and ‚Äúdouble-free.‚Äù\n\nNote: Currently, Mojo always makes a copy when a function returns a value.\n\nStructures\n\nYou can build high-level abstractions for types (or ‚Äúobjects‚Äù) in a struct. A struct in Mojo is similar to a class in Python: they both support methods, fields, operator overloading, decorators for metaprogramming, etc. However, Mojo structs are completely static‚Äîthey are bound at compile-time, so they do not allow dynamic dispatch or any runtime changes to the structure. (Mojo will also support classes in the future.)\n\nFor example, here‚Äôs a basic struct:\n\nstruct MyPair:\n    var first: Int\n    var second: Int\n\n    fn __init__(inout self, first: Int, second: Int):\n        self.first = first\n        self.second = second\n    \n    fn dump(self):\n        print(self.first, self.second)\n\nAnd here‚Äôs how you can use it:\n\nlet mine = MyPair(2, 4)\nmine.dump()\n2 4\n\nIf you‚Äôre familiar with Python, then the __init__() method and the self argument should be familiar to you. If you‚Äôre not familiar with Python, then notice that, when we call dump(), we don‚Äôt actually pass a value for the self argument. The value for self is automatically provided with the current instance of the struct (it‚Äôs used similar to the this name used in some other languages to refer to the current instance of the object/type).\n\nFor much more detail about structs and other special methods like __init__() (also known as ‚Äúdunder‚Äù methods), see the programming manual.\n\nPython integration\n\nAlthough Mojo is still a work in progress and is not a full superset of Python yet, we‚Äôve built a mechanism to import Python modules as-is, so you can leverage existing Python code right away. Under the hood, this mechanism uses the CPython interpreter to run Python code, and thus it works seamlessly with all Python modules today.\n\nFor example, here‚Äôs how you can import and use NumPy (you must have Python numpy installed):\n\nfrom python import Python\n\nlet np = Python.import_module(\"numpy\")\n\nar = np.arange(15).reshape(3, 5)\nprint(ar)\nprint(ar.shape)\n[[ 0  1  2  3  4]\n [ 5  6  7  8  9]\n [10 11 12 13 14]]\n(3, 5)\n\nNote: Mojo is not a feature-complete superset of Python yet. So, you can‚Äôt always copy Python code and run it in Mojo. For more details on our plans, please refer to the Mojo roadmap and sharp edges.\n\nCaution: When you install Mojo, the installer searches your system for a version of Python to use with Mojo, and adds the path to the modular.cfg config file. If you change your Python version or switch virtual environments, Mojo will then be looking at the wrong Python library, which can cause problems such as errors when you import Python packages (Mojo says only An error occurred in Python‚Äîthis is a separate known issue). The current solution is to override Mojo‚Äôs path to the Python library, using the MOJO_PYTHON_LIBRARY environment variable. For instructions on how to find and set this path, see this related issue.\n\nNext steps\n\nWe hope this page covered enough of the basics to get you started. It‚Äôs intentionally brief, so if you want more detail about any of the topics touched upon here, check out the Mojo programming manual.\n\nIf you want to package your code as a library, read about Mojo modules and packages.\n\nIf you want to explore some Mojo code, check out our code examples on GitHub.\n\nTo see all the available Mojo APIs, check out the Mojo standard library reference.\n\nNote: The Mojo SDK is still in early development. Some things are still rough, but you can expect constant changes and improvements to both the language and tools. Please see the known issues and report any other issues on GitHub.\n\nHello, world!\nModules and packages\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - Get started with Mojoüî•",
    "url": "https://docs.modular.com/mojo/manual/get-started/index.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nGet the Mojo SDK\nSystem requirements\nInstall Mojo\nUpdate Mojo\nUpdate the Modular CLI\nDevelop in the Mojo Playground\nGet started with Mojoüî•\n\nMojo is now available for local development!\n\nDownload Now\n\nThe Mojo SDK is currently available for Ubuntu Linux systems and macOS systems running on Apple silicon. Support for Windows is coming soon. You can also develop from Windows or Intel macOS using a container or remote Linux system. Alternatively, you can also experiment with Mojo using our web-based Mojo Playground.\n\nGet the Mojo SDK\n\nThe Mojo SDK includes everything you need for local Mojo development, including the Mojo standard library and the Mojo command-line interface (CLI). The Mojo CLI can start a REPL programming environment, compile and run Mojo source files, format source files, and more.\n\nWe‚Äôve also published a Mojo extension for Visual Studio Code to provide a first-class developer experience with features like code completion, quick fixes, and hover help for Mojo APIs.\n\nSystem requirements\n\nTo use the Mojo SDK, you need a system that meets these specifications:\n\nLinux:\n\nUbuntu 20.04/22.04 LTS\nx86-64 CPU (with SSE4.2 or newer) and a minimum of 8 GiB memory\nPython 3.8 - 3.11\ng++ or clang++ C++ compiler\n\nMac:\n\nApple silicon (M1 or M2 processor)\nmacOS Monterey (12) or later\nPython 3.8 - 3.11\nCommand-line tools for Xcode, or Xcode\n\nSupport for Windows will be added in a future release.\n\nInstall Mojo\n\nThe Mojo SDK is available through the Modular CLI tool, which works like a package manager to install and update Mojo. Use the following link to log into the Modular developer console, where you can get the Modular CLI and then install Mojo:\n\nDownload Now\n\nThen get started with Hello, world!\n\nNote: To help us improve Mojo, we collect some basic system information and crash reports. Learn more.\n\nUpdate Mojo\n\nMojo is a work in progress and we will release regular updates to the Mojo language and SDK tools. For information about each release, see the Mojo changelog.\n\nTo check your current Mojo version, use the --version option:\n\nmojo --version\n\nTo update to the latest Mojo version, use the modular update command:\n\nmodular update mojo\nUpdate the Modular CLI\n\nWe may also release updates to the modular tool. Run the following commands to update the CLI on your system.\n\nLinux:\n\nsudo apt update\n\nsudo apt install modular\n\nMac:\n\nbrew update\n\nbrew upgrade modular\nDevelop in the Mojo Playground\n\nInstead of downloading the Mojo SDK, you can also experiment with Mojo in our hosted Jupyter notebook environment called Mojo Playground. This is a hosted version of JupyterLab that‚Äôs running our latest Mojo kernel.\n\nTo get access, just log in to the Mojo Playground here.\n\nWhat to expect\n\nThe Mojo Playground is a JupyterHub environment in which you get a private volume associated with your account, so you can create your own notebooks and they‚Äôll be saved across sessions.\n\nWe‚Äôve included a handful of notebooks to show you Mojo basics and demonstrate its capabilities.\n\nThe number of vCPU cores available in your cloud instance may vary, so baseline performance is not representative of the language. However, as you will see in the included Matmul.ipynb notebook, Mojo‚Äôs relative performance over Python is significant.\n\nThere might be some bugs. Please report issues and feedback on GitHub.\n\nTips\n\nIf you want to keep any edits to the included notebooks, rename the notebook files. These files will reset upon any server refresh or update, sorry. So if you rename the files, your changes will be safe.\n\nYou can use %%python at the top of a notebook cell and write normal Python code. Variables, functions, and imports defined in a Python cell are available for access in subsequent Mojo cells.\n\nCaveats\n\nDid we mention that the included notebooks will lose your changes?\nRename the files if you want to save your changes.\n\nThe Mojo environment does not have network access, so you cannot install other tools or Python packages. However, we‚Äôve included a variety of popular Python packages, such as numpy, pandas, and matplotlib (see how to import Python modules).\n\nRedefining implicit variables is not supported (variables without a let or var in front). If you‚Äôd like to redefine a variable across notebook cells, you must introduce the variable with var (let variables are immutable).\n\nYou can‚Äôt use global variables inside functions‚Äîthey‚Äôre only visible to other global variables.\n\nFor a longer list of things that don‚Äôt work yet or have pain-points, see the Mojo roadmap and sharp edges.\n\nHello, world!\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - Mojoüî• FAQ",
    "url": "https://docs.modular.com/mojo/faq.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nMotivation\nWhy did you build Mojo?\nWhy is it called Mojo?\nWhy does mojo have the üî• file extension?\nWhat problems does Mojo solve that no other language can?\nWhat kind of developers will benefit the most from Mojo?\nWhy build upon Python?\nWhy not enhance CPython (the major Python implementation) instead?\nWhy not enhance another Python implementation (like Codon, PyPy, etc)?\nWhy not make Julia better?\nFunctionality\nPerformance\nMojo SDK\nVersioning & compatibility\nMojo Playground\nOpen Source\nCommunity\nMojoüî• FAQ\n\nWe tried to anticipate your questions about Mojo on this page. If this page doesn‚Äôt answer all your questions, also check out our Mojo community channels.\n\nMotivation\nWhy did you build Mojo?\n\nWe built Mojo to solve an internal challenge at Modular, and we are using it extensively in our systems such as our AI Engine. As a result, we are extremely committed to its long term success and are investing heavily in it. Our overall mission is to unify AI software and we can‚Äôt do that without a unified language that can scale across the AI infrastructure stack. That said, we don‚Äôt plan to stop at AI‚Äîthe north star is for Mojo to support the whole gamut of general-purpose programming over time. For a longer answer, read Why Mojo.\n\nWhy is it called Mojo?\n\nMojo means ‚Äúa magical charm‚Äù or ‚Äúmagical powers.‚Äù We thought this was a fitting name for a language that brings magical powers to Python, including unlocking an innovative programming model for accelerators and other heterogeneous systems pervasive in AI today.\n\nWhy does mojo have the üî• file extension?\n\nWe paired Mojo with fire emoji üî• as a fun visual way to impart onto users that Mojo empowers them to get their Mojo on‚Äîto develop faster and more efficiently than ever before. We also believe that the world can handle a unicode extension at this point, but you can also just use the .mojo extension. :)\n\nWhat problems does Mojo solve that no other language can?\n\nMojo combines the usability of Python with the systems programming features it‚Äôs missing. We are guided more by pragmatism than novelty, but Mojo‚Äôs use of MLIR allows it to scale to new exotic hardware types and domains in a way that other languages haven‚Äôt demonstrated (for an example of Mojo talking directly to MLIR, see our low-level IR in Mojo notebook). It also includes autotuning, and has caching and distributed compilation built into its core. We also believe Mojo has a good chance of unifying hybrid packages in the broader Python community.\n\nWhat kind of developers will benefit the most from Mojo?\n\nMojo‚Äôs initial focus is to bring programmability back to AI, enabling AI developers to customize and get the most out of their hardware. As such, Mojo will primarily benefit researchers and other engineers looking to write high-performance AI operations. Over time, Mojo will become much more interesting to the general Python community as it grows to be a superset of Python. We hope this will help lift the vast Python library ecosystem and empower more traditional systems developers that use C, C++, Rust, etc.\n\nWhy build upon Python?\n\nEffectively, all AI research and model development happens in Python today, and there‚Äôs a good reason for this! Python is a powerful high-level language with clean, simple syntax and a massive ecosystem of libraries. It‚Äôs also one of the world‚Äôs most popular programming languages, and we want to help it become even better. At Modular, one of our core principles is meeting customers where they are‚Äîour goal is not to further fragment the AI landscape but to unify and simplify AI development workflows.\n\nWhy not enhance CPython (the major Python implementation) instead?\n\nWe‚Äôre thrilled to see a big push to improve CPython by the existing community, but our goals for Mojo (such as to deploy onto GPUs and other accelerators) need a fundamentally different architecture and compiler approach underlying it. CPython is a significant part of our compatibility approach and powers our Python interoperability.\n\nWhy not enhance another Python implementation (like Codon, PyPy, etc)?\n\nCodon and PyPy aim to improve performance compared to CPython, but Mojo‚Äôs goals are much deeper than this. Our objective isn‚Äôt just to create ‚Äúa faster Python,‚Äù but to enable a whole new layer of systems programming that includes direct access to accelerated hardware, as outlined in Why Mojo. Our technical implementation approach is also very different, for example, we are not relying on heroic compiler and JIT technologies to ‚Äúdevirtualize‚Äù Python.\n\nFurthermore, solving big challenges for the computing industry is hard and requires a fundamental rethinking of the compiler and runtime infrastructure. This drove us to build an entirely new approach and we‚Äôre willing to put in the time required to do it properly (see our blog post about building a next-generation AI platform), rather than tweaking an existing system that would only solve a small part of the problem.\n\nWhy not make Julia better?\n\nWe think Julia is a great language and it has a wonderful community, but Mojo is completely different. While Julia and Mojo might share some goals and look similar as an easy-to-use and high-performance alternative to Python, we‚Äôre taking a completely different approach to building Mojo. Notably, Mojo is Python-first and doesn‚Äôt require existing Python developers to learn a new syntax.\n\nMojo also has a bunch of technical advancements compared to Julia, simply because Mojo is newer and we‚Äôve been able to learn from Julia (and from Swift, Rust, C++ and many others that came before us). For example, Mojo takes a different approach to memory ownership and memory management, it scales down to smaller envelopes, and is designed with AI and MLIR-first principles (though Mojo is not only for AI).\n\nThat said, we also believe there‚Äôs plenty of room for many languages and this isn‚Äôt an OR proposition. If you use and love Julia, that‚Äôs great! We‚Äôd love for you to try Mojo and if you find it useful, then that‚Äôs great too.\n\nFunctionality\nWhere can I learn more about Mojo‚Äôs features?\n\nThe best place to start is the Mojo programming manual, which is very long, but it covers all the features we support today. And if you want to see what features are coming in the future, take a look at the roadmap.\n\nWhat does it mean that Mojo is designed for MLIR?\n\nMLIR provides a flexible infrastructure for building compilers. It‚Äôs based upon layers of intermediate representations (IRs) that allow for progressive lowering of any code for any hardware, and it has been widely adopted by the hardware accelerator industry since its first release. Although you can use MLIR to create a flexible and powerful compiler for any programming language, Mojo is the world‚Äôs first language to be built from the ground up with MLIR design principles. This means that Mojo not only offers high-performance compilation for heterogeneous hardware, but it also provides direct programming support for the MLIR intermediate representations. For a simple example of Mojo talking directly to MLIR, see our low-level IR in Mojo notebook.\n\nIs Mojo only for AI or can it be used for other stuff?\n\nMojo is a general purpose programming language. We use Mojo at Modular to develop AI algorithms, but as we grow Mojo into a superset of Python, you can use it for other things like HPC, data transformations, writing pre/post processing operations, and much more. For examples of how Mojo can be used for other general programming tasks, see our Mojo examples.\n\nIs Mojo interpreted or compiled?\n\nMojo supports both just-in-time (JIT) and ahead-of-time (AOT) compilation. In either a REPL environment or Jupyter notebook, Mojo is JIT‚Äôd.¬†However, for AI deployment, it‚Äôs important that Mojo also supports AOT compilation instead of having to JIT compile everything. You can compile your Mojo programs using the mojo CLI.\n\nHow does Mojo compare to Triton Lang?\n\nTriton Lang is a specialized programming model for one type of accelerator, whereas Mojo is a more general language that will support more architectures over time and includes a debugger, a full tool suite, etc. For more about embedded domain-specific languages (EDSLs) like Triton, read the ‚ÄúEmbedded DSLs in Python‚Äù section of Why Mojo.\n\nHow does Mojo help with PyTorch and TensorFlow acceleration?\n\nMojo is a general purpose programming language, so it has no specific implementations for ML training or serving, although we use Mojo as part of the overall Modular AI stack. The Modular AI Engine, for example, supports deployment of PyTorch and TensorFlow models, while Mojo is the language we use to write the engine‚Äôs in-house kernels.\n\nDoes Mojo support distributed execution?\n\nNot alone. You will need to leverage the Modular AI Engine for that. Mojo is one component of the Modular stack that makes it easier for you to author highly performant, portable kernels, but you‚Äôll also need a runtime (or ‚ÄúOS‚Äù) that supports graph level transformations and heterogeneous compute.\n\nWill Mojo support web deployment (such as Wasm or WebGPU)?\n\nWe haven‚Äôt prioritized this functionality yet, but there‚Äôs no reason Mojo can‚Äôt support it.\n\nHow do I convert Python programs or libraries to Mojo?\n\nMojo is still early and not yet a Python superset, so only simple programs can be brought over as-is with no code changes. We will continue investing in this and build migration tools as the language matures.\n\nWhat about interoperability with other languages like C/C++?\n\nYes, we want to enable developers to port code from languages other than Python to Mojo as well. We expect that due to Mojo‚Äôs similarity to the C/C++ type systems, migrating code from C/C++ should work well and it‚Äôs in our roadmap.\n\nHow does Mojo support hardware lowering?\n\nMojo leverages LLVM-level dialects for the hardware targets it supports, and it uses other MLIR-based code-generation backends where applicable. This also means that Mojo is easily extensible to any hardware backend. For more information, read about our vision for pluggable hardware.\n\nHow does Mojo autotuning work?\n\nFor details about what autotuning capabilities we support so far, check out the programming manual. But stay tuned for more details!\n\nWho writes the software to add more hardware support for Mojo?\n\nMojo provides all the language functionality necessary for anyone to extend hardware support. As such, we expect hardware vendors and community members will contribute additional hardware support in the future. We‚Äôll share more details about opening access to Mojo in the future, but in the meantime, you can read more about our hardware extensibility vision.\n\nHow does Mojo provide a 35,000x speed-up over Python?\n\nModern CPUs are surprisingly complex and diverse, but Mojo enables systems-level optimizations and flexibility that unlock the features of any device in a way that Python cannot. So the hardware matters for this sort of benchmark, and for the Mandelbrot benchmarks we show in our launch keynote, we ran them on an AWS r7iz.metal-16xl machine.\n\nFor lots more information, check out our 3-part blog post series about how Mojo gets a 35,000x speedup over Python.\n\nBy the way, all the kernels that power the Modular AI Engine are written in Mojo. We also compared our matrix multiplication implementation to other state-of-the-art implementations that are usually written in assembly. To see the results, see our blog post about unified matrix multiplication.\n\nPerformance\nMojo‚Äôs matmul performance in the notebook doesn‚Äôt seem that great. What‚Äôs going on?\n\nThe Mojo Matmul notebook uses matrix multiplication to show off some Mojo features in a scenario that you would never attempt in pure Python. So that implementation is like a ‚Äútoy‚Äù matmul implementation and it doesn‚Äôt measure up to the state of the art.\n\nPlus, if you‚Äôre using the Mojo Playground, that VM environment is not set up for stable performance evaluation. Modular has a separate matmul implementation written in Mojo (and used by the Modular AI Engine) that is not available with this release, but you can read about it in this blog post.\n\nAre there any AI related performance benchmarks for Mojo?\n\nIt‚Äôs important to remember that Mojo is a general-purpose programming language, and any AI-related benchmarks will rely heavily upon other framework components. For example, our in-house kernels for the Modular AI Engine are all written in Mojo and you can learn more about our kernel performance in our matrix multiplication blog post. For details about our end-to-end model performance relative to the latest releases of TensorFlow and PyTorch, check out our performance dashboard.\n\nMojo SDK\nHow can I get access to the SDK?\n\nYou can get the Mojo SDK here!\n\nIs the Mojo Playground still available?\n\nYes, you can get access today to the Mojo Playground, a hosted set of Mojo-supported Jupyter notebooks.\n\nWhat are the license terms for the SDK?\n\nPlease read the Mojo SDK License Terms.\n\nWhat does the Mojo SDK ship with?\n\nThe Mojo SDK includes the Mojo standard library and mojo command-line tool, which provides a REPL similar to the python command, along with build, run, package, doc and format commands. We‚Äôve also published a Mojo language extension for VS Code.\n\nWhat operating systems are supported?\n\nCurrently, we support Ubuntu Linux 20.04/22.04 (64-bit x86) and macOS (Apple silicon). Support for Windows will follow. Until then, you have several options:\n\nWindows users can use Windows Subsystem for Linux version 2 (WSL 2) running a supported Linix distribution.\nIntel Mac users can use a Docker container running a supported Linux distribution.\nUsers on any system can install the SDK on a remote machine running a supported Linux distribution.\nIs there IDE Integration?\n\nYes, we‚Äôve published an official Mojo language extension for VS Code.\n\nThe extension supports various features including syntax highlighting, code completion, formatting, hover, etc. It works seamlessly with remote-ssh and dev containers to enable remote development in Mojo.\n\nDoes the Mojo SDK collect telemetry?\n\nYes, in combination with the Modular CLI tool, the Mojo SDK collects some basic system information and crash reports that enable us to identify, analyze, and prioritize Mojo issues.\n\nMojo is still in its early days, and this telemetry is crucial to help us quickly identify problems and improve Mojo. Without this telemetry, we would have to rely on user-submitted bug reports, and in our decades of building developer products, we know that most people don‚Äôt bother. Plus, a lot of product issues are not easily identified by users or quantifiable with individual bug reports. The telemetry provides us the insights we need to build Mojo into a premier developer product.\n\nOf course, if you don‚Äôt want to share this information with us, you can easily opt-out of all telemetry, using the modular CLI. To stop sharing system information, run this:\n\nmodular config-set telemetry.enabled=false\n\nTo stop sharing crash reports, run this:\n\nmodular config-set crash_reporting.enabled=false\n\nVersioning & compatibility\nWhat‚Äôs the Mojo versioning strategy?\n\nMojo is still in early development and not at a 1.0 version yet. It‚Äôs still missing many foundational features, but please take a look at our roadmap to understand where things are headed. As such, the language is evolving rapidly and source stability is not guaranteed.\n\nHow often will you be releasing new versions of Mojo?\n\nMojo development is moving fast and we are regularly releasing updates. Please join the Mojo Discord channel for notifications and sign up for our newsletter for more coarse-grain updates.\n\nMojo Playground\nWhat sort of computer is backing each instance in the Mojo Playground?\n\nThe Mojo Playground runs on a fleet of AWS EC2 C6i (c6i.8xlarge) instances that is divided among active users. Due to the shared nature of the system, the number of vCPU cores provided to your session may vary. We guarantee 1 vCPU core per session, but that may increase when the total number of active users is low.\n\nEach user also has a dedicated volume in which you can save your own files that persist across sessions.\n\nOpen Source\nWill Mojo be open-sourced?\n\nOver time we expect to open-source core parts of Mojo, such as the standard library. However, Mojo is still young, so we will continue to incubate it within Modular until more of its internal architecture is fleshed out. We don‚Äôt have an established plan for open-sourcing yet.\n\nWhy not develop Mojo in the open from the beginning?\n\nMojo is a big project and has several architectural differences from previous languages. We believe a tight-knit group of engineers with a common vision can move faster than a community effort. This development approach is also well-established from other projects that are now open source (such as LLVM, Clang, Swift, MLIR, etc.).\n\nCommunity\nWhere can I ask more questions or share feedback?\n\nIf you have questions about upcoming features or have suggestions for the language, be sure you first read the Mojo roadmap, which provides important information about our current priorities and links to our GitHub channels where you can report issues and discuss new features.\n\nTo get in touch with the Mojo team and developer community, use the resources on our Mojo community page.\n\nCan I share Mojo code from the Mojo Playground?\n\nYes! You‚Äôre welcome and encouraged to share your Mojo code any way you like. We‚Äôve added a feature in the Mojo Playground to make this easier, and you can learn more in the Mojo Playground by opening the help directory in the file browser.\n\nHowever, the Mojo SDK is also now available, so you can also share .mojo source files and .ipynb notebooks to run locally!\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - Get started with Mojoüî•",
    "url": "https://docs.modular.com/mojo/manual/get-started/index.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nGet the Mojo SDK\nSystem requirements\nInstall Mojo\nUpdate Mojo\nUpdate the Modular CLI\nDevelop in the Mojo Playground\nGet started with Mojoüî•\n\nMojo is now available for local development!\n\nDownload Now\n\nThe Mojo SDK is currently available for Ubuntu Linux systems and macOS systems running on Apple silicon. Support for Windows is coming soon. You can also develop from Windows or Intel macOS using a container or remote Linux system. Alternatively, you can also experiment with Mojo using our web-based Mojo Playground.\n\nGet the Mojo SDK\n\nThe Mojo SDK includes everything you need for local Mojo development, including the Mojo standard library and the Mojo command-line interface (CLI). The Mojo CLI can start a REPL programming environment, compile and run Mojo source files, format source files, and more.\n\nWe‚Äôve also published a Mojo extension for Visual Studio Code to provide a first-class developer experience with features like code completion, quick fixes, and hover help for Mojo APIs.\n\nSystem requirements\n\nTo use the Mojo SDK, you need a system that meets these specifications:\n\nLinux:\n\nUbuntu 20.04/22.04 LTS\nx86-64 CPU (with SSE4.2 or newer) and a minimum of 8 GiB memory\nPython 3.8 - 3.11\ng++ or clang++ C++ compiler\n\nMac:\n\nApple silicon (M1 or M2 processor)\nmacOS Monterey (12) or later\nPython 3.8 - 3.11\nCommand-line tools for Xcode, or Xcode\n\nSupport for Windows will be added in a future release.\n\nInstall Mojo\n\nThe Mojo SDK is available through the Modular CLI tool, which works like a package manager to install and update Mojo. Use the following link to log into the Modular developer console, where you can get the Modular CLI and then install Mojo:\n\nDownload Now\n\nThen get started with Hello, world!\n\nNote: To help us improve Mojo, we collect some basic system information and crash reports. Learn more.\n\nUpdate Mojo\n\nMojo is a work in progress and we will release regular updates to the Mojo language and SDK tools. For information about each release, see the Mojo changelog.\n\nTo check your current Mojo version, use the --version option:\n\nmojo --version\n\nTo update to the latest Mojo version, use the modular update command:\n\nmodular update mojo\nUpdate the Modular CLI\n\nWe may also release updates to the modular tool. Run the following commands to update the CLI on your system.\n\nLinux:\n\nsudo apt update\n\nsudo apt install modular\n\nMac:\n\nbrew update\n\nbrew upgrade modular\nDevelop in the Mojo Playground\n\nInstead of downloading the Mojo SDK, you can also experiment with Mojo in our hosted Jupyter notebook environment called Mojo Playground. This is a hosted version of JupyterLab that‚Äôs running our latest Mojo kernel.\n\nTo get access, just log in to the Mojo Playground here.\n\nWhat to expect\n\nThe Mojo Playground is a JupyterHub environment in which you get a private volume associated with your account, so you can create your own notebooks and they‚Äôll be saved across sessions.\n\nWe‚Äôve included a handful of notebooks to show you Mojo basics and demonstrate its capabilities.\n\nThe number of vCPU cores available in your cloud instance may vary, so baseline performance is not representative of the language. However, as you will see in the included Matmul.ipynb notebook, Mojo‚Äôs relative performance over Python is significant.\n\nThere might be some bugs. Please report issues and feedback on GitHub.\n\nTips\n\nIf you want to keep any edits to the included notebooks, rename the notebook files. These files will reset upon any server refresh or update, sorry. So if you rename the files, your changes will be safe.\n\nYou can use %%python at the top of a notebook cell and write normal Python code. Variables, functions, and imports defined in a Python cell are available for access in subsequent Mojo cells.\n\nCaveats\n\nDid we mention that the included notebooks will lose your changes?\nRename the files if you want to save your changes.\n\nThe Mojo environment does not have network access, so you cannot install other tools or Python packages. However, we‚Äôve included a variety of popular Python packages, such as numpy, pandas, and matplotlib (see how to import Python modules).\n\nRedefining implicit variables is not supported (variables without a let or var in front). If you‚Äôd like to redefine a variable across notebook cells, you must introduce the variable with var (let variables are immutable).\n\nYou can‚Äôt use global variables inside functions‚Äîthey‚Äôre only visible to other global variables.\n\nFor a longer list of things that don‚Äôt work yet or have pain-points, see the Mojo roadmap and sharp edges.\n\nHello, world!\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - Mojoüî• community",
    "url": "https://docs.modular.com/mojo/community.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nMojoüî• community\n\nMojo is still very young, but we believe an active community and a strong feedback pipeline is key to its success.\n\nWe‚Äôd love to hear from you through the following community channels.\n\n\n\n\n Ask a question\n\nSee existing GitHub Discussion posts, ask new questions, and share your ideas.\n\nThis is a forum for ideas and questions, moderated by the Modular team.\n\n Report an issue\n\nReport bugs or other issues with the Mojo SDK or Mojo Playground.\n\nBefore reporting an issue, see the Mojo roadmap & sharp edges.\n\n Chat on Discord\n\nJoin our realtime chat on Discord to discuss the Mojo language and tools with the community.\n\nThis is a community space where you can chat with other Mojo developers in realtime.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - Mojoüî• changelog",
    "url": "https://docs.modular.com/mojo/changelog.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nUpdate Mojo\nv0.5.0 (2023-11-2)\nv0.4.0 for Mac (2023-10-19)\nv0.4.0 (2023-10-05)\nv0.3.1 (2023-09-28)\nv0.3.0 (2023-09-21)\nv0.2.1 (2023-09-07)\nAugust 2023\nJuly 2023\nJune 2023\nMay 2023\nApril 2023\nMarch 2023\nFebruary 2023\nJanuary 2023\nDecember 2022\nNovember 2022\nOctober 2022\nSeptember 2022\nMojoüî• changelog\n\nThis is a running list of significant changes for the Mojo language and tools. It doesn‚Äôt include all internal implementation changes.\n\nUpdate Mojo\n\nIf you don‚Äôt have Mojo yet, see the get started guide.\n\nTo see your current Mojo version, run this:\n\nmojo --version\n\nTo update Mojo to the latest release, run this:\n\nmodular update mojo\n\nHowever, if your current version is 0.3.0 or lower, you‚Äôll need these additional commands:\n\nsudo apt-get update\nsudo apt-get install modular\nmodular clean\nmodular install mojo\nv0.5.0 (2023-11-2)\n‚≠êÔ∏è New\n\nThe SIMD type now defaults to the architectural SIMD width of the type. This means you can write SIMD[DType.float32] which is equivalent to SIMD[DType.float32, simdwidthof[DType.float32]()].\n\nThe SIMD type now contains a join() function that allows you to concatenate two SIMD values together and produce a new SIMD value.\n\nMojo now supports compile-time keyword parameters, in addition to existing support for keyword arguments. For example:\n\nfn foo[a: Int, b: Int = 42]():\n  print(a, \"+\", b)\n\nfoo[a=5]()        # prints '5 + 42'\nfoo[a=7, b=13]()  # prints '7 + 13'\nfoo[b=20, a=6]()  # prints '6 + 20'\n\nKeyword parameters are also supported in structs:\n\nstruct KwParamStruct[a: Int, msg: String = \"üî•mojoüî•\"]:\n    fn __init__(inout self):\n        print(msg, a)\n\nfn use_kw_params():\n    KwParamStruct[a=42]()               # prints 'üî•mojoüî• 42'\n    KwParamStruct[5, msg=\"hello\"]()     # prints 'hello 5'\n    KwParamStruct[msg=\"hello\", a=42]()  # prints 'hello 42'\n\nFor more detail, see the programming manual.\n\nFor the time being, the following notable limitations apply:\n\nKeyword-only parameters are not supported yet:\n\nfn baz[*args: Int, b: Int](): pass  # fails\nfn baz[a: Int, *, b: Int](): pass  # fails\n\n(The analogous keyword-only arguments in Python are described in PEP 3102.)\n\nVariadic keyword parameters are not supported yet:\n\nfn baz[a: Int, **kwargs: Int](): pass  # fails\n\nMojo now supports ‚Äúautomatic‚Äù parameterization of functions. What this means is that if a function argument type is parametric but has no bound parameters, they are automatically added as input parameters on the function. This works with existing features to allow you to write parametric functions with less boilerplate.\n\n@value\nstruct Thing[x: Int, y: Int]:\n    pass\n\nfn foo(v: Thing):\n    print(v.x)\n    print(v.y)\n\nfn main():\n    let v = Thing[2, 3]()\n    foo(v)\n\nHowever, partial autoparameterization is not supported yet:\n\nfn foo(v: Thing[y=7]):  # Partially bound type not allowed yet.\n    ...\n\nKeyword argument passing is supported when invoking __getitem__ using the bracket syntax:\n\n@value\nstruct MyStruct:\n  fn __getitem__(self, x: Int, y: Int, z: Int) -> Int:\n    return x * y + z\n\nMyStruct()[z=7, x=3, y=5]  # returns 22\n\nHowever, keyword argument passing to __setitem__ using the bracket syntax is not supported yet:\n\n@value\nstruct OtherStruct:\n    fn __setitem__(self, x: Int, y: Int): pass\n\nOtherStruct()[x=1] = 4  # fails\n\nFunction argument input parameters can now be referenced within the signature of the function:\n\nfn foo(x: SIMD, y: SIMD[x.type, x.size]):\n    pass\n\nThe benchmark module has been simplified and improved so you can now run:\n\nimport benchmark\nfrom time import sleep\n\nfn sleeper():\n    sleep(.01)\n\nfn main():\n    let report = benchmark.run[sleeper]()\n    print(report.mean())\n\nIt no longer requires a capturing fn so can benchmark functions outside the same scope.\n\nYou can print a report with:\n\nreport.print()\n---------------------\nBenchmark Report (s)\n---------------------\nMean: 0.012314264957264957\nTotal: 1.440769\nIters: 117\nWarmup Mean: 0.0119335\nWarmup Total: 0.023866999999999999\nWarmup Iters: 2\nFastest Mean: 0.012227958333333334\nSlowest Mean: 0.012442699999999999\n\nUnits for all functions default to seconds, but can be changed with:\n\nfrom benchmark import Unit\n\nreport.print[Unit.ms]()\n\nMojo now supports struct parameter deduction (a.k.a. class template argument deduction, or CTAD) for partially bound types. Struct parameter deduction is also possible from static methods. For example:\n\n@value\nstruct Thing[v: Int]: pass\n\nstruct CtadStructWithDefault[a: Int, b: Int, c: Int = 8]:\n    fn __init__(inout self, x: Thing[a]):\n        print(\"hello\", a, b, c)\n\n    @staticmethod\n    fn foo(x: Thing[a]):\n        print(\"üî•\", a, b, c)\n\n    _ = CtadStructWithDefault[b=7](Thing[6]())  # prints 'hello 6 7 8'\n    CtadStructWithDefault[b=7].foo(Thing[6]())  # prints 'üî• 6 7 8'\n\nTensor has new fromfile() and tofile() methods to save and load as bytes from a file.\n\nThe built-in print() function now works on the Tensor type.\n\nTensorShape and TensorSpec now have constructors that take DynamicVector[Int] and StaticIntTuple to initialize shapes.\n\nThe String type now has the count() and find() methods to enable counting the number of occurrences or finding the offset index of a substring in a string.\n\nThe String type now has a replace() method which allows you to replace a substring with another string.\n\nü¶ã Changed\n\nVariadicList and VariadicListMem moved under builtins, and no longer need to be imported.\n\nVariadic arguments are now automatically projected into a VariadicList or VariadicListMem inside the function body. This allows for more flexibility in using var args. For example:\n\n  fn print_ints(*nums: Int):\n      let len = len(nums)\n      for i in range(len):\n          print(nums[i])\n      print(len)\n\nThe parameters for InlinedFixedVector have been switched. The parameters are now [type, size] instead of [size, type]. The InlinedFixedVector now has a default size which means that one can just use InlinedFixedVector as InlinedFixedVector[Float32] and the default size is used.\n\nwrite_file() method in Buffer and NDBuffer is renamed to tofile() to match the Python naming.\n\nMojo will now utilize all available cores across all NUMA sockets on the host machine by default. The prior default behavior was to use all the cores on the first socket.\n\n‚ùå Removed\nThe math.numerics module is now private, because its types (FPUtils and FlushDenormals) should not be used externally.\nüõ†Ô∏è Fixed\n#532 - Compiler optimizing while True loop away\n#760 - Compilation error: ‚Äòhlcf.for.yield‚Äô op specifies 0 branch inputs but target expected 1 along control-flow edge from here\n#849 - The Tensor type is now initialized with zeros at construction time.\n#912 - Invalid load for __get_address_as_lvalue.\n#916 - Parser crash when specifying default values for inout arguments.\n#943 - Mojo hangs if you use continue in the nested loop\n#957 - Parser crash when a function call with variadic arguments of a memory-only type is evaluated at compile time.\n#990 - Fixes rounding issue with floor division with negative numerator.\n#1018 - In some cases the sort function was returning invalid results. This release fixes some of these corner cases.\n#1010 - Initializing tensor in alias declaration results in crash.\n#1110 - The time.now() function now returns nanoseconds across all operating systems.\n#1115 - cannot load non-register passable type into SSA register.\nv0.4.0 for Mac (2023-10-19)\nüî• Legendary\n\nMojo for Mac!\n\nThe Mojo SDK now works on macOS (Apple silicon). This is the same version previously released for Linux. Get the latest version of the SDK for your Mac system:\n\nDownload Now!\n\nv0.4.0 (2023-10-05)\n‚≠êÔ∏è New\n\nMojo now supports default parameter values. For example:\n\nfn foo[a: Int = 3, msg: StringLiteral = \"woof\"]():\n    print(msg, a)\n\nfn main():\n    foo()  # prints 'woof 3'\n    foo[5]()  # prints 'woof 5'\n    foo[7, \"meow\"]()  # prints 'meow 7'\n\nInferred parameter values take precedence over defaults:\n\n@value\nstruct Bar[v: Int]:\n    pass\n\nfn foo[a: Int = 42, msg: StringLiteral = \"quack\"](bar: Bar[a]):\n    print(msg, a)\n\nfn main():\n    foo(Bar[9]())  # prints 'quack 9'\n\nStructs also support default parameters:\n\n@value\nstruct DefaultParams[msg: StringLiteral = \"woof\"]:\n    alias message = msg\n\nfn main():\n    print(DefaultParams[]().message)  # prints 'woof'\n    print(DefaultParams[\"meow\"]().message)  # prints 'meow'\n\nThe new file module adds basic file I/O support. You can now write:\n\nvar f = open(\"my_file.txt\", \"r\")\nprint(f.read())\nf.close()\n\nor\n\nwith open(\"my_file.txt\", \"r\") as f:\n    print(f.read())\n\nMojo now allows context managers to support an __enter__ method without implementing support for an __exit__ method, enabling idioms like this:\n\n# This context manager consumes itself and returns it as the value.\nfn __enter__(owned self) -> Self:\n    return self^\n\nHere Mojo cannot invoke a noop __exit__ method because the context manager is consumed by the __enter__ method. This can be used for types (like file descriptors) that are traditionally used with with statements, even though Mojo‚Äôs guaranteed early destruction doesn‚Äôt require that.\n\nA very basic version of pathlib has been implemented in Mojo. The module will be improved to achieve functional parity with Python in the next few releases.\n\nThe memory.unsafe module now contains a bitcast function. This is a low-level operation that enables bitcasting between pointers and scalars.\n\nThe input parameters of a parametric type can now be directly accessed as attribute references on the type or variables of the type. For example:\n\n@value\nstruct Thing[param: Int]:\n    pass\n\nfn main():\n    print(Thing[2].param) # prints '2'\n    let x = Thing[9]()\n    print(x.param) # prints '9'\n\nInput parameters on values can even be accessed in parameter contexts. For example:\n\nfn foo[value: Int]():\n    print(value)\n\nlet y = Thing[12]()\nalias constant = y.param + 4\nfoo[constant]() # prints '16'\n\nThe Mojo REPL now supports code completion. Press Tab while typing to query potential completion results.\n\nError messages from Python are now exposed in Mojo. For example the following should print No module named 'my_uninstalled_module':\n\nfn main():\n    try:\n        let my_module = Python.import_module(\"my_uninstalled_module\")\n    except e:\n        print(e)\n\nError messages can now store dynamic messages. For example, the following should print ‚ÄúFailed on: Hello‚Äù\n\nfn foo(x:String) raises:\n    raise Error(\"Failed on: \" + x)\n\nfn main():\n    try:\n        foo(\"Hello\")\n    except e:\n        print(e)\nü¶ã Changed\n\nWe have improved and simplified the parallelize function. The function now elides some overhead by caching the Mojo parallel runtime.\n\nThe Mojo REPL and Jupyter environments no longer implicitly expose Python, PythonObject, or Pointer. These symbols must now be imported explicitly, for example:\n\nfrom python import Python\nfrom python.object import PythonObject\nfrom memory.unsafe import Pointer\n\nThe syntax for specifying attributes with the __mlir_op prefix have changed to mimic Python‚Äôs keyword argument passing syntax. That is, = should be used instead of :, e.g.:\n\n# Old syntax, now fails.\n__mlir_op.`index.bool.constant`[value : __mlir_attr.`false`]()\n# New syntax.\n__mlir_op.`index.bool.constant`[value=__mlir_attr.`false`]()\n\nYou can now print the Error object directly. The message() method has been removed.\n\nüõ†Ô∏è Fixed\n#794 - Parser crash when using the in operator.\n#936 - The Int constructor now accepts other Int instances.\n#921 - Better error message when running mojo on a module with no main function.\n#556 - UInt64s are now printed correctly.\n#804 - Emit error instead of crashing when passing variadic arguments of unsupported types.\n#833 - Parser crash when assigning module value.\n#752 - Parser crash when calling async def.\n#711 - The overload resolution logic now correctly prioritizes instance methods over static methods (if candidates are an equally good match otherwise), and no longer crashed if a static method has a Self type as its first argument.\n#859 - Fix confusing error and documentation of the rebind builtin.\n#753 - Direct use of LLVM dialect produces strange errors in the compiler.\n#926 - Fixes an issue that occured when a function with a return type of StringRef raised an error. When the function raised an error, it incorrectly returned the string value of that error.\n#536 - Report More information on python exception.\nv0.3.1 (2023-09-28)\n\nOur first-ever patch release of the Mojo SDK is here! Release v0.3.1 includes primarily installation-related fixes. If you‚Äôve had trouble installing the previous versions of the SDK, this release may be for you.\n\nüõ†Ô∏è Fixed\n#538 - Installation hangs during the testing phase. This issue occurs on machines with a low number of CPU cores, such as free AWS EC2 instances and GitHub Codespaces.\n#590 - Installation fails with a ‚Äúfailed to run python‚Äù message.\n#672 - Language server hangs on code completion. Related to #538, this occurs on machines with a low number of CPU cores.\n#913 - In the REPL and Jupyter notebooks, inline comments were being parsed incorrectly.\nv0.3.0 (2023-09-21)\n\nThere‚Äôs more Mojo to love in this, the second release of the Mojo SDK! This release includes new features, an API change, and bug fixes.\n\nThere‚Äôs also an updated version of the Mojo extension for VS Code.\n\n‚≠êÔ∏è New\n\nMojo now has partial support for passing keyword arguments to functions and methods. For example the following should work:\n\nfn foo(a: Int, b: Int = 3) -> Int:\n    return a * b\n\nfn main():\n    print(foo(6, b=7))  # prints '42'\n    print(foo(a=6, b=7))  # prints '42'\n    print(foo(b=7, a=6))  # prints '42'\n\nParameters can also be inferred from keyword arguments, for example:\n\nfn bar[A: AnyType, B: AnyType](a: A, b: B):\n    print(\"Hello üî•\")\n\nfn bar[B: AnyType](a: StringLiteral, b: B):\n    print(a)\n\nfn main():\n    bar(1, 2)  # prints `Hello üî•`\n    bar(b=2, a=\"Yay!\")  # prints `Yay!`\n\nFor the time being, the following notable limitations apply:\n\nKeyword-only arguments are not supported:\n\nfn baz(*args: Int, b: Int): pass  # fails\nfn baz(a: Int, *, b: Int): pass  # fails\n\n(Keyword-only arguments are described in PEP 3102.)\n\nVariadic keyword arguments are not supported:\n\nfn baz(a: Int, **kwargs: Int): pass  # fails\n\nMojo now supports the @nonmaterializable decorator. The purpose is to mark data types that should only exist in the parameter domain. To use it, a struct is decorated with @nonmaterializable(TargetType). Any time the nonmaterializable type is converted from the parameter domain, it is automatically converted to TargetType. A nonmaterializable struct should have all of its methods annotated as @always_inline, and must be computable in the parameter domain. In the following example, the NmStruct type can be added in the parameter domain, but are converted to HasBool when materialized.\n\n@value\n@register_passable(\"trivial\")\nstruct HasBool:\n  var x: Bool\n  fn __init__(x: Bool) -> Self:\n    return Self {x: x}\n  @always_inline(\"nodebug\")\n  fn __init__(nms: NmStruct) -> Self:\n    return Self {x: True if (nms.x == 77) else False}\n\n@value\n@nonmaterializable(HasBool)\n@register_passable(\"trivial\")\nstruct NmStruct:\n  var x: Int\n  @always_inline(\"nodebug\")\n  fn __add__(self: Self, rhs: Self) -> Self:\n    return NmStruct(self.x + rhs.x)\n\nalias stillNmStruct = NmStruct(1) + NmStruct(2)\n# When materializing to a run-time variable, it is automatically converted,\n# even without a type annotation.\nlet convertedToHasBool = stillNmStruct\n\nMojo integer literals now produce the IntLiteral infinite precision integer type when used in the parameter domain. IntLiteral is materialized to the Int type for runtime computation, but intermediate computations at compile time, using supported operators, can now exceed the bit width of the Int type.\n\nThe Mojo Language Server now supports top-level code completions, enabling completion when typing a reference to a variable, type, etc. This resolves #679.\n\nThe Mojo REPL now colorizes the resultant variables to help distinguish input expressions from the output variables.\n\nü¶ã Changed\n\nMojo allows types to implement two forms of move constructors, one that is invoked when the lifetime of one value ends, and one that is invoked if the compiler cannot prove that. These were previously both named __moveinit__, with the following two signatures:\n\nfn __moveinit__(inout self, owned existing: Self): ...\nfn __moveinit__(inout self, inout existing: Self): ...\n\nWe‚Äôve changed the second form to get its own name to make it more clear that these are two separate operations: the second has been renamed to __takeinit__:\n\nfn __moveinit__(inout self, owned existing: Self): ...\nfn __takeinit__(inout self, inout existing: Self): ...\n\nThe name is intended to connote that the operation takes the conceptual value from the source (without destroying it) unlike the first one which ‚Äúmoves‚Äù a value from one location to another.\n\nThe Error type in Mojo has changed. Instead of extracting the error message using error.value you will now extract the error message using error.message().\n\nFor more information, see Unique ‚Äúmove-only‚Äù types in the Mojo docs.\n\nüõ†Ô∏è Fixed\n#503 - Improve error message for failure lowering kgen.param.constant.\n#554 - Alias of static tuple fails to expand.\n#500 - Call expansion failed due to verifier error.\n#422 - Incorrect comment detection in multiline strings.\n#729 - Improve messaging on how to exit the REPL.\n#756 - Fix initialization errors of the VS Code extension.\n#575 - Build LLDB/REPL with libedit for a nicer editing experience in the terminal.\nv0.2.1 (2023-09-07)\n\nThe first versioned release of Mojo! üî•\n\nAll earlier releases were considered version 0.1.\n\nüî• Legendary\n\nFirst release of the Mojo SDK!\n\nYou can now develop with Mojo locally. The Mojo SDK is currently available for Ubuntu Linux systems, and support for Windows and macOS is coming soon. You can still develop from a Windows or Mac computer using a container or remote Linux system.\n\nThe Mojo SDK includes the Mojo standard library and the Mojo command-line interface (CLI), which allows you to run, compile, and package Mojo code. It also provides a REPL programming environment.\n\nGet the Mojo SDK!\n\nFirst release of the Mojo extension for VS Code.\n\nThis provides essential Mojo language features in Visual Studio Code, such as code completion, code quick fixes, docs tooltips, and more. Even when developing on a remote system, using VS Code with this extension provides a native-like IDE experience.\n\n‚≠êÔ∏è New\n\nA new clobber_memory function has been added to the benchmark module. The clobber memory function tells the system to flush all memory operations at the specified program point. This allows you to benchmark operations without the compiler reordering memory operations.\n\nA new keep function has been added to the benchmark module. The keep function tries to tell the compiler not to optimize the variable away if not used. This allows you to avoid compiler‚Äôs dead code elimination mechanism, with a low footprint side effect.\n\nNew shift_right and shift_left functions have been added to the simd module. They shift the elements in a SIMD vector right/left, filling elements with zeros as needed.\n\nA new cumsum function has been added to the reduction module that computes the cumulative sum (also known as scan) of input elements.\n\nMojo Jupyter kernel now supports code completion.\n\nü¶ã Changed\nExtends rotate_bits_left, rotate_left, rotate_bits_right, and rotate_right to operate on Int values. The ordering of parameters has also been changed to enable type inference. Now it‚Äôs possible to write rotate_right[shift_val](simd_val) and have the dtype and simd_width inferred from the argument. This addresses Issue #528.\nüõ†Ô∏è Fixed\n\nFixed a bug causing the parser to crash when the with statement was written without a colon. This addresses Issue #529.\n\nIncorrect imports no longer crash when there are other errors at the top level of a module. This fixes Issue #531.\n\nAugust 2023\n2023-08-24\nFixed issue where the with expr as x statement within fn behaved as if it were in a def, binding x with function scope instead of using lexical scope.\n‚≠êÔ∏è New\n\nMajor refactoring of the standard library to enable packaging and better import ergonomics:\n\nThe packages are built as binaries to improve startup speed.\nPackage and module names are now lowercase to align with the Python style.\nModules have been moved to better reflect the purpose of the underlying functions (e.g.¬†Pointer is now within the unsafe module in the memory package).\nThe following modules are now included as built-ins: SIMD, DType, IO, Object, and String. This means it‚Äôs no longer necessary to explicitly import these modules. Instead, these modules will be implicitly imported for the user. Private methods within the module are still accessible using the builtin.module_name._private_method import syntax.\nNew math package has been added to contain the bit, math, numerics, and polynomial modules. The contents of the math.math module are re-exported into the math package.\n\nMojo now supports using memory-only types in parameter expressions and as function or type parameters:\n\n@value\nstruct IntPair:\n    var first: Int\n    var second: Int\n\nfn add_them[value: IntPair]() -> Int:\n    return value.first + value.second\n\nfn main():\n    print(add_them[IntPair(1, 2)]()) # prints '3'\n\nIn addition, Mojo supports evaluating code that uses heap-allocated memory at compile-time and materializing compile-time values with heap-allocated memory into dynamic values:\n\nfn fillVector(lowerBound: Int, upperBound: Int, step: Int) -> DynamicVector[Int]:\n    var result = DynamicVector[Int]()\n    for i in range(lowerBound, upperBound, step):\n        result.push_back(i)\n    return result\n\nfn main():\n    alias values = fillVector(5, 23, 7)\n    for i in range(0, values.__len__()):\n        print(values[i]) # prints '5', '12', and then '19'\nü¶ã Changed\n\ndef main():, without the explicit None type, can now be used to define the entry point to a Mojo program.\n\nThe assert_param function has been renamed to constrained and is now a built-in function.\n\nThe print function now works on Complex values.\n\nüõ†Ô∏è Fixed\nFixed issues with print formatting for DType.uint16 and DType.int16.\nIssue #499 - Two new rotate_right and rotate_left functions have been added to the SIMD module.\nIssue #429 - You can now construct a Bool from a SIMD type whose element-type is DType.bool.\nIssue #350 - Confusing Matrix implementation\nIssue #349 - Missing load_tr in struct Matrix\nIssue #501 - Missing syntax error messages in Python expressions.\n2023-08-09\nü¶ã Changed\n\nThe ref and mutref identifiers are now treated as keywords, which means they cannot be used as variable, attribute, or function names. These keywords are used by the ‚Äúlifetimes‚Äù features, which is still in development. We can consider renaming these (as well as other related keywords) when the development work gels, support is enabled in public Mojo builds, and when we have experience using them.\n\nThe argument handling in def functions has changed: previously, they had special behavior that involved mutable copies in the callee. Now, we have a simple rule, which is that def argument default to the owned convention (fn arguments still default to the borrowed convention).\n\nThis change is mostly an internal cleanup and simplification of the compiler and argument model, but does enable one niche use-case: you can now pass non-copyable types to def arguments by transferring ownership of a value into the def call. Before, that would not be possible because the copy was made on the callee side, not the caller‚Äôs side. This also allows the explicit use of the borrowed keyword with a def that wants to opt-in to that behavior.\n\n2023-08-03\n‚≠êÔ∏è New\n\nA new Tensor type has been introduced. This tensor type manages its own data (unlike NDBuffer and Buffer which are just views). Therefore, the tensor type performs its own allocation and free. Here is a simple example of using the tensor type to represent an RGB image and convert it to grayscale:\n\nfrom tensor import Tensor, TensorShape\nfrom utils.index import Index\nfrom random import rand\n\nlet height = 256\nlet width = 256\nlet channels = 3\n\n# Create the tensor of dimensions height, width, channels and fill with\n# random value.\nlet image = rand[DType.float32](height, width, channels)\n\n# Declare the grayscale image.\nvar gray_scale_image = Tensor[DType.float32](height, width)\n\n# Perform the RGB to grayscale transform.\nfor y in range(height):\n  for x in range(width):\n    let r = image[y,x,0]\n    let g = image[y,x,1]\n    let b = image[y,x,2]\n    gray_scale_image[Index(y,x)] = 0.299 * r + 0.587 * g + 0.114 * b\nüõ†Ô∏è Fixed\nIssue #53 - Int now implements true division with the / operator. Similar to Python, this returns a 64-bit floating point number. The corresponding in-place operator, /=, has the same semantics as //=.\nJuly 2023\n2023-07-26\n‚≠êÔ∏è New\n\nTypes that define both __getitem__ and __setitem__ (i.e.¬†where sub-scripting instances creates computed LValues) can now be indexed in parameter expressions.\n\nUnroll decorator for loops with constant bounds and steps:\n\n@unroll: Fully unroll a loop.\n\n@unroll(n): Unroll a loop by factor of n, where n is a positive integer.\n\nUnroll decorator requires loop bounds and iteration step to be compiler time constant value, otherwise unrolling will fail with compilation error. This also doesn‚Äôt make loop induction variable a parameter.\n\n  # Fully unroll the loop.\n  @unroll\n  for i in range(5):\n    print(i)\n\n  # Unroll the loop by a factor of 4 (with remainder iterations of 2).\n  @unroll(4)\n  for i in range(10):\n    print(i)\n\nThe Mojo REPL now prints the values of variables defined in the REPL. There is full support for scalars and structs. Non-scalar SIMD vectors are not supported at this time.\n\nüõ†Ô∏è Fixed\n\nIssue #437 - Range can now be instantiated with a PythonObject.\n\nIssue #288 - Python strings can now be safely copied.\n\n2023-07-20\n‚≠êÔ∏è New\n\nMojo now includes a Limits module, which contains functions to get the max and min values representable by a type, as requested in Issue #51. The following functions moved from Math to Limits: inf(), neginf(), isinf(), isfinite().\n\nMojo decorators are now distinguished between ‚Äúsignature‚Äù and ‚Äúbody‚Äù decorators and are ordered. Signature decorators, like @register_passable and @parameter, modify the type of declaration before the body is parsed. Body decorators, like @value, modify the body of declaration after it is fully parsed. Due to ordering, a signature decorator cannot be applied after a body decorator. That means the following is now invalid:\n\n@register_passable # error: cannot apply signature decorator after a body one!\n@value\nstruct Foo:\n  pass\n\nGlobal variables can now be exported in Mojo compiled archives, using the @export decorator. Exported global variables are public symbols in compiled archives and use the variable name as its linkage name, by default. A custom linkage name can be specified with @export(\"new_name\"). This does not affect variable names in Mojo code.\n\nMojo now supports packages! A Mojo package is defined by placing an __init__.mojo or __init__.üî• within a directory. Other files in the same directory form modules within the package (this works exactly like it does in Python). Example:\n\nmain.üî•\nmy_package/\n  __init__.üî•\n  module.üî•\n  my_other_package/\n    __init__.üî•\n    stuff.üî•\n# main.üî•\nfrom my_package.module import some_function\nfrom my_package.my_other_package.stuff import SomeType\n\nfn main():\n    var x: SomeType = some_function()\n\nMojo now supports direct module and package imports! Modules and packages can be imported and bound to names. Module and package elements, like functions, types, global variables, and other modules, can be accessed using attribute references, like my_module.foo. Note that modules lack runtime representations, meaning module references cannot be instantiated.\n\nimport builtin.io as io\nimport SIMD\n\nio.print(\"hello world\")\nvar x: SIMD.Float32 = 1.2\nü¶ã Changed\n\nReverted the feature from 2023-02-13 that allowed unqualified struct members. Use the Self keyword to conveniently access struct members with bound parameters instead. This was required to fix Issue #260.\n\nUpdated the RayTracing notebook: added step 5 to create specular lighting for more realistic images and step 6 to add a background image.\n\nüõ†Ô∏è Fixed\nIssue #260 - Definitions inside structs no longer shadow definitions outside of struct definitions.\n2023-07-12\n‚≠êÔ∏è New\n\nMojo now has support for global variables! This enables var and let declaration at the top-level scope in Mojo files. Global variable initializers are run when code modules are loaded by the platform according to the order of dependencies between global variables, and their destructors are called in the reverse order.\n\nThe Mojo programming manual is now written as a Jupyter notebook, and available in its entirety in the Mojo Playground (programming-manual.ipynb). (Previously, HelloMojo.ipynb included most of the same material, but it was not up-to-date.)\n\nAs a result, we‚Äôve also re-written HelloMojo.ipynb to be much shorter and provide a more gentle first-user experience.\n\nCoroutine module documentation is now available. Coroutines form the basis of Mojo‚Äôs support for asynchronous execution. Calls to async fns can be stored into a Coroutine, from which they can be resumed, awaited upon, and have their results retrieved upon completion.\n\nü¶ã Changed\nsimd_bit_width in the TargetInfo module has been renamed to simdbitwidth to better align with simdwidthof, bitwidthof, etc.\nüõ†Ô∏è Fixed\n\nThe walrus operator now works in if/while statements without parentheses, e.g.¬†if x := function():.\n\nIssue #428 - The FloatLiteral and SIMD types now support conversion to Int via the to_int or __int__ method calls. The behavior matches that of Python, which rounds towards zero.\n\n2023-07-05\n‚≠êÔ∏è New\nTuple expressions now work without parentheses. For example, a, b = b, a works as you‚Äôd expect in Python.\nChained assignments (e.g.¬†a = b = 42) and the walrus operator (e.g. some_function(b := 17)) are now supported.\nü¶ã Changed\n\nThe simd_width and dtype_simd_width functions in the TargetInfo module have been renamed to simdwidthof.\n\nThe dtype_ prefix has been dropped from alignof, sizeof, and bitwidthof. You can now use these functions (e.g.¬†alignof) with any argument type, including DType.\n\nThe inf, neginf, nan, isinf, isfinite, and isnan functions were moved from the Numerics module to the Math module, to better align with Python‚Äôs library structure.\n\nüõ†Ô∏è Fixed\n\nIssue #253 - Issue when accessing a struct member alias without providing parameters.\n\nIssue #404 - The docs now use snake_case for variable names, which more closely conforms to Python‚Äôs style.\n\nIssue #379 - Tuple limitations have been addressed and multiple return values are now supported, even without parentheses.\n\nIssue #347 - Tuples no longer require parentheses.\n\nIssue #320 - Python objects are now traversable via for loops.\n\nJune 2023\n2023-06-29\n‚≠êÔ∏è New\nYou can now share .ipynb notebook files in Mojo Playground. Just save a file in the shared directory, and then right-click the file and select Copy Sharable link. To open a shared notebook, you must already have access to Mojo Playground; when you open a shared notebook, click Import at the top of the notebook to save your own copy. For more details about this feature, see the instructions inside the help directory, in the Mojo Playground file browser.\nü¶ã Changed\nThe unroll2() and unroll3() functions in the Functional module have been renamed to overload the unroll() function. These functions unroll 2D and 3D loops and unroll() can determine the intent based on the number of input parameters.\nüõ†Ô∏è Fixed\n\nIssue #229 - Issue when throwing an exception from __init__ before all fields are initialized.\n\nIssue #74 - Struct definition with recursive reference crashes.\n\nIssue #285 - The TargetInfo module now includes is_little_endian() and is_big_endian() to check if the target host uses either little or big endian.\n\nIssue #254 - Parameter name shadowing in nested scopes is now handled correctly.\n\n2023-06-21\n‚≠êÔ∏è New\n\nAdded support for overloading on parameter signature. For example, it is now possible to write the following:\n\nfn foo[a: Int](x: Int):\n    pass\n\nfn foo[a: Int, b: Int](x: Int):\n    pass\n\nFor details on the overload resolution logic, see the programming manual.\n\nA new cost_of() function has been added to Autotune. This meta-function must be invoked at compile time, and it returns the number of MLIR operations in a function (at a certain stage in compilation), which can be used to build basic heuristics in higher-order generators.\n\nfrom autotune import cost_of\n\nfn generator[f: fn(Int) -> Int]() -> Int:\n    @parameter\n    if cost_of[fn(Int) -> Int, f]() < 10:\n        return f()\n    else:\n        # Do something else for slower functions...\n\nAdded a new example notebook with a basic Ray Tracing algorithm.\n\nü¶ã Changed\nThe constrained_msg() in the Assert module has been renamed to constrained().\nüõ†Ô∏è Fixed\n\nOverloads marked with @adaptive now correctly handle signatures that differ only in declared parameter names, e.g.¬†the following now works correctly:\n\n@adaptive\nfn foobar[w: Int, T: DType]() -> SIMD[T, w]: ...\n\n@adaptive\nfn foobar[w: Int, S: DType]() -> SIMD[S, w]: ...\n\nIssue #219 - Issue when redefining a function and a struct defined in the same cell.\n\nIssue #355 - The loop order in the Matmul notebook for Python and naive mojo have been reordered for consistency. The loop order now follows (M, K, N) ordering.\n\nIssue #309 - Use snake case naming within the testing package and move the asserts out of the TestSuite struct.\n\n2023-06-14\n‚≠êÔ∏è New\n\nTuple type syntax is now supported, e.g.¬†the following works:\n\nfn return_tuple() -> (Int, Int):\n    return (1, 2)\nü¶ã Changed\nThe TupleLiteral type was renamed to just Tuple, e.g. Tuple[Int, Float].\nüõ†Ô∏è Fixed\nIssue #354 - Returning a tuple doesn‚Äôt work even with parens.\nIssue #365 - Copy-paste error in FloatLiteral docs.\nIssue #357 - Crash when missing input parameter to variadic parameter struct member function.\n2023-06-07\n‚≠êÔ∏è New\nTuple syntax now works on the left-hand side of assignments (in ‚Äúlvalue‚Äù positions), enabling things like (a, b) = (b, a). There are several caveats: the element types must exactly match (no implicit conversions), this only works with values of TupleLiteral type (notably, it will not work with PythonObject yet) and parentheses are required for tuple syntax.\n‚ùå Removed\nMojo Playground no longer includes the following Python packages (due to size, compute costs, and environment complications): torch, tensorflow, keras, transformers.\nü¶ã Changed\nThe data types and scalar names now conform to the naming convention used by numpy. So we use Int32 instead of SI32, similarly using Float32 instead of F32. Closes Issue #152.\nüõ†Ô∏è Fixed\nIssue #287 - computed lvalues don‚Äôt handle raising functions correctly\nIssue #318 - Large integers are not being printed correctly\nIssue #326 - Float modulo operator is not working as expected\nIssue #282 - Default arguments are not working as expected\nIssue #271 - Confusing error message when converting between function types with different result semantics\nMay 2023\n2023-05-31\n‚≠êÔ∏è New\n\nMojo Playground now includes the following Python packages (in response to popular demand): torch, tensorflow, polars, opencv-python, keras, Pillow, plotly, seaborn, sympy, transformers.\n\nA new optimization is applied to non-trivial copyable values that are passed as an owned value without using the transfer (^) operator. Consider code like this:\n\n  var someValue : T = ...\n  ...\n  takeValueAsOwned(someValue)\n  ...\n\nWhen takeValueAsOwned() takes its argument as an owned value (this is common in initializers for example), it is allowed to do whatever it wants with the value and destroy it when it is finished. In order to support this, the Mojo compiler is forced to make a temporary copy of the someValue value, and pass that value instead of someValue, because there may be other uses of someValue after the call.\n\nThe Mojo compiler is now smart enough to detect when there are no uses of someValue later, and it will elide the copy just as if you had manually specified the transfer operator like takeValueAsOwned(someValue^). This provides a nice ‚Äúit just works‚Äù behavior for non-trivial types without requiring manual management of transfers.\n\nIf you‚Äôd like to take full control and expose full ownership for your type, just don‚Äôt make it copyable. Move-only types require the explicit transfer operator so you can see in your code where all ownership transfer happen.\n\nSimilarly, the Mojo compiler now transforms calls to __copyinit__ methods into calls to __moveinit__ when that is the last use of the source value along a control flow path. This allows types which are both copyable and movable to get transparent move optimization. For example, the following code is compiled into moves instead of copies even without the use of the transfer operator:\n\n  var someValue = somethingCopyableAndMovable()\n  use(someValue)\n  ...\n  let otherValue = someValue      # Last use of someValue\n  use(otherValue)\n  ...\n  var yetAnother = otherValue     # Last use of otherValue\n  mutate(yetAnother)\n\nThis is a significant performance optimization for things like PythonObject (and more complex value semantic types) that are commonly used in a fluid programming style. These don‚Äôt want extraneous reference counting operations performed by its copy constructor.\n\nIf you want explicit control over copying, it is recommended to use a non-dunder .copy() method instead of __copyinit__, and recall that non-copyable types must always use of the transfer operator for those that want fully explicit behavior.\n\nüõ†Ô∏è Fixed\nIssue #231 - Unexpected error when a Python expression raises an exception\nIssue #119 - The REPL fails when a python variable is redefined\n2023-05-24\n‚≠êÔ∏è New\nfinally clauses are now supported on try statements. In addition, try statements no longer require except clauses, allowing try-finally blocks. finally clauses contain code that is always executed from control-flow leaves any of the other clauses of a try statement by any means.\nü¶ã Changed\n\nwith statement emission changed to use the new finally logic so that\n\nwith ContextMgr():\n    return\n\nWill correctly execute ContextMgr.__exit__ before returning.\n\nüõ†Ô∏è Fixed\nIssue #204 - Mojo REPL crash when returning a String at compile-time\nIssue #143 - synthesized init in @register_passable type doesn‚Äôt get correct convention.\nIssue #201 - String literal concatenation is too eager.\nIssue #209 - [QoI] Terrible error message trying to convert a type to itself.\nIssue #32 - Include struct fields in docgen\nIssue #50 - Int to string conversion crashes due to buffer overflow\nIssue #132 - PythonObject to_int method has a misleading name\nIssue #189 - PythonObject bool conversion is incorrect\nIssue #65 - Add SIMD constructor from Bool\nIssue #153 - Meaning of Time.now function result is unclear\nIssue #165 - Type in Pointer.free documentation\nIssue #210 - Parameter results cannot be declared outside top-level in function\nIssue #214 - Pointer offset calculations at compile-time are incorrect\nIssue #115 - Float printing does not include the right number of digits\nIssue #202 - kgen.unreachable inside nested functions is illegal\nIssue #235 - Crash when register passable struct field is not register passable\nIssue #237 - Parameter closure sharp edges are not documented\n2023-05-16\n‚≠êÔ∏è New\n\nAdded missing dunder methods to PythonObject, enabling the use of common arithmetic and logical operators on imported Python values.\n\nPythonObject is now printable from Mojo, instead of requiring you to import Python‚Äôs print function.\n\nüõ†Ô∏è Fixed\n\nIssue #98: Incorrect error with lifetime tracking in loop.\n\nIssue #49: Type inference issue (?) in ‚Äòternary assignment‚Äô operation (FloatLiteral vs.¬†‚ÄòSIMD[f32, 1]‚Äô).\n\nIssue #48: and/or don‚Äôt work with memory-only types.\n\nIssue #11: setitem Support for PythonObject.\n\n2023-05-11\n‚≠êÔ∏è New\n\nNDBuffer and Buffer are now constructable via Pointer and DTypePointer.\n\nString now supports indexing with either integers or slices.\n\nAdded factorial function to the Math module.\n\nü¶ã Changed\n\nThe ‚Äúbyref‚Äù syntax with the & sigil has changed to use an inout keyword to be more similar to the borrowed and owned syntax in arguments. Please see Issue #7 for more information.\n\nOptimized the Matrix multiplication implementation in the notebook. Initially we were optimizing for expandability rather than performance. We have found a way to get the best of both worlds and now the performance of the optimized Matmul implementation is 3x faster.\n\nRenamed the ^ postfix operator from ‚Äúconsume‚Äù to ‚Äútransfer.‚Äù\n\nüõ†Ô∏è Fixed\n\nFixed missing overloads for Testing.assertEqual so that they work on Integer and String values.\n\nIssue #6: Playground stops evaluating cells when a simple generic is defined.\n\nIssue #18: Memory leak in Python interoperability was removed.\n\n2023-05-02\nüì¢ Released\nMojo publicly launched! This was epic, with lots of great coverage online including a wonderful post by Jeremy Howard. The team is busy this week.\n‚≠êÔ∏è New\nAdded a Base64 encoding function to perform base64 encoding on strings.\nü¶ã Changed\n\nDecreased memory usage of serialization of integers to strings.\n\nSpeedup the sort function.\n\nüõ†Ô∏è Fixed\nFixed time unit in the sleep function.\nApril 2023\nWeek of 2023-04-24\n\nüì¢ The default behavior of nested functions has been changed. Mojo nested functions that capture are by default are non-parametric, runtime closures, meaning that:\n\ndef foo(x):\n    # This:\n    def bar(y): return x*y\n    # Is the same as:\n    let bar = lambda y: x*y\n\nThese closures cannot have input or result parameters, because they are always materialized as runtime values. Values captured in the closure (x in the above example), are captured by copy: values with copy constructors cannot be copied and captures are immutable in the closure.\n\nNested functions that don‚Äôt capture anything are by default ‚Äúparametric‚Äù closures: they can have parameters and they can be used as parameter values. To restore the previous behavior for capturing closures, ‚Äúparametric, capture-by-unsafe-reference closures‚Äù, tag the nested function with the @parameter decorator.\n\nüì¢ Mojo now has full support for ‚Äúruntime‚Äù closures: nested functions that capture state materialized as runtime values. This includes taking the address of functions, indirect calls, and passing closures around through function arguments. Note that capture-by-reference is still unsafe!\n\nYou can also take references to member functions with instances of that class using foo.member_function, which creates a closure with foo bound to the self argument.\n\nüì¢ Mojo now supports Python style with statements and context managers.\n\nThese things are very helpful for implementing things like our trace region support and things like Runtime support.\n\nA context manager in Mojo implements three methods:\n\nfn __enter__(self) -> T:\nfn __exit__(self):\nfn __exit__(self, err: Error) -> Bool:\n\nThe first is invoked when the context is entered, and returns a value that may optionally be bound to a target for use in the with body. If the with block exits normally, the second method is invoked to clean it up. If an error is raised, the third method is invoked with the Error value. If that method returns true, the error is considered handled, if it returns false, the error is re-thrown so propagation continues out of the ‚Äòwith‚Äô block.\n\nüì¢ Mojo functions now support variable scopes! Explicit var and let declarations inside functions can shadow declarations from higher ‚Äúscopes‚Äù, where a scope is defined as any new indentation block. In addition, the for loop iteration variable is now scoped to the loop body, so it is finally possible to write\n\nfor i in range(1): pass\nfor i in range(2): pass\n\nüì¢ Mojo now supports an @value decorator on structs to reduce boilerplate and encourage best practices in value semantics. The @value decorator looks to see the struct has a memberwise initializer (which has arguments for each field of the struct), a __copyinit__ method, and a __moveinit__ method, and synthesizes the missing ones if possible. For example, if you write:\n\n@value\nstruct MyPet:\n  var name: String\n  var age: Int\n\nThe @value decorator will synthesize the following members for you:\n\n  fn __init__(inout self, owned name: String, age: Int):\n     self.name = name^\n     self.age = age\n  fn __copyinit__(inout self, existing: Self):\n     self.name = existing.name\n     self.age = existing.age\n  fn __moveinit__(inout self, owned existing: Self):\n     self.name = existing.name^\n     self.age = existing.age\n\nThis decorator can greatly reduce the boilerplate needed to define common aggregates, and gives you best practices in ownership management automatically. The @value decorator can be used with types that need custom copy constructors (your definition wins). We can explore having the decorator take arguments to further customize its behavior in the future.\n\nüìö Memcpy and memcmp now consistently use count as the byte count.\n\nüìö Add a variadic sting join on strings.\n\nüìö Introduce a reduce_bit_count method to count the number of 1 across all elements in a SIMD vector.\n\nüìö Optimize the pow function if the exponent is integral.\n\nüìö Add a len function which dispatches to __len__ across the different structs that support it.\n\nWeek of 2023-04-17\n\nüì¢ Error messages have been significantly improved, thanks to prettier printing for Mojo types in diagnostics.\n\nüì¢ Variadic values can now be indexed directly without wrapping them in a VariadicList!\n\nüì¢ let declarations in a function can now be lazily initialized, and var declarations that are never mutated get a warning suggesting they be converted to a let declaration. Lazy initialization allows more flexible patterns of initialization than requiring the initializer be inline, e.g.:\n\nlet x : Int\nif cond:\n    x = foo()\nelse:\n    x = bar()\nuse(x)\n\nüì¢ Functions defined with def now return object by default, instead of None. This means you can return values (convertible to object) inside def functions without specifying a return type.\n\nüì¢ The @raises decorator has been removed. Raising fn should be declared by specifying raises after the function argument list. The rationale is that raises is part of the type system, instead of a function modifier.\n\nüì¢ The BoolLiteral type has been removed. Mojo now emits True and False directly as Bool.\n\nüì¢ Syntax for function types has been added. You can now write function types with fn(Int) -> String or async def(&String, *Int) -> None. No more writing !kgen.signature types by hand!\n\nüì¢ Float literals are not emitted as FloatLiteral instead of an MLIR f64 type!\n\nüì¢ Automatic destructors are now supported by Mojo types, currently spelled fn __del___(owned self): (the extra underscore will be dropped shortly). These destructors work like Python object destructors and similar to C++ destructors, with the major difference being that they run ‚Äúas soon as possible‚Äù after the last use of a value. This means they are not suitable for use in C++-style RAII patterns (use the with statement for that, which is currently unsupported).\n\nThese should be generally reliable for both memory-only and register-passable types, with the caveat that closures are known to not capture values correctly. Be very careful with interesting types in the vicinity of a closure!\n\nA new (extremely dangerous!) builtin function is available for low-level ownership muckery. The __get_address_as_owned_value(x) builtin takes a low-level address value (of !kgen.pointer type) and returns an owned value for the memory that is pointed to. This value is assumed live at the invocation of the builtin, but is ‚Äúowned‚Äù so it needs to be consumed by the caller, otherwise it will be automatically destroyed. This is an effective way to do a ‚Äúplacement delete‚Äù on a pointer.\n\n# \"Placement delete\": destroy the initialized object begin pointed to.\n_ = __get_address_as_owned_value(somePointer.value)\n\n# Result value can be consumed by anything that takes it as an 'owned'\n# argument as well.\nconsume(__get_address_as_owned_value(somePointer.value))\n\nAnother magic operator, named __get_address_as_uninit_lvalue(x) joins the magic LValue operator family. This operator projects a pointer to an LValue like __get_address_as_lvalue(x). The difference is that __get_address_as_uninit_lvalue(x) tells the compiler that the pointee is uninitialized on entry and initialized on exit, which means that you can use it as a ‚Äúplacement new‚Äù in C++ sense. __get_address_as_lvalue(x) tells the compiler that the pointee is initialized already, so reassigning over it will run the destructor.\n\n# \"*Re*placement new\": destroy the existing SomeHeavy value in the memory,\n# then initialize a new value into the slot.\n__get_address_as_lvalue(somePointer.value) = SomeHeavy(4, 5)\n\n# Ok to use an lvalue, convert to borrow etc.\nuse(__get_address_as_lvalue(somePointer.value))\n\n# \"Placement new\": Initialize a new value into uninitialied memory.\n__get_address_as_uninit_lvalue(somePointer.value) = SomeHeavy(4, 5)\n\n# Error, cannot read from uninitialized memory.\nuse(__get_address_as_uninit_lvalue(somePointer.value))\n\nNote that __get_address_as_lvalue assumes that there is already a value at the specified address, so the assignment above will run the SomeHeavy destructor (if any) before reassigning over the value.\n\nüì¢ Implement full support for __moveinit__ (aka move constructors)\n\nThis implements the ability for memory-only types to define two different types of move ctors if they‚Äôd like:\n\nfn __moveinit__(inout self, owned existing: Self): Traditional Rust style moving constructors that shuffles data around while taking ownership of the source binding.\nfn __moveinit__(inout self, inout existing: Self):: C++ style ‚Äústealing‚Äù move constructors that can be used to take from an arbitrary LValue.\n\nThis gives us great expressive capability (better than Rust/C++/Swift) and composes naturally into our lifetime tracking and value categorization system.\n\nThe __call__ method of a callable type has been relaxed to take self by borrow, allow non-copyable callees to be called.\n\nImplicit conversions are now invoked in raise statements properly, allowing converting strings to Error type.\n\nAutomatic destructors are turned on for __del__ instead of __del___.\n\nüìö Add the builtin FloatLiteral type.\n\nüìö Add integral floordiv and mod for the SIMD type that handle negative values.\n\nüìö Add an F64 to String converter.\n\nüìö Make the print function take variadic inputs.\n\nWeek of 2023-04-10\n\nüì¢ Introduce consume operator x^\n\nThis introduces the postfix consume operator, which produces an RValue given a lifetime tracked object (and, someday, a movable LValue).\n\nMojo now automatically synthesizes empty destructor methods for certain types when needed.\n\nThe object type has been built out into a fully-dynamic type, with dynamic function dispatch, with full error handling support.\n\ndef foo(a) -> object:\n    return (a + 3.45) < [1, 2, 3] # raises a TypeError\n\nüì¢ The @always_inline decorator is no longer required for passing capturing closures as parameters, for both the functions themselves as functions with capturing closures in their parameters. These functions are still inlined but it is an implementation detail of capturing parameter closures. Mojo now distinguishes between capturing and non-capturing closures. Nested functions are capturing by default and can be made non-capturing with the @noncapturing decorator. A top-level function can be passed as a capturing closure by marking it with the @closure decorator.\n\nüì¢ Support for list literals has been added. List literals [1, 2, 3] generate a variadic heterogeneous list type.\n\nVariadics have been extended to work with memory-primary types.\n\nSlice syntax is now fully-supported with a new builtin slice object, added to the compiler builtins. Slice indexing with a[1:2:3] now emits calls to __setitem__ and __getitem__ with a slice object.\n\nCall syntax has been wired up to __call__. You can now f() on custom types!\n\nClosures are now explicitly typed as capturing or non-capturing. If a function intends to accept a capturing closure, it must specify the capturing function effect.\n\nüìö Add a Tile2D function to enable generic 2D tiling optimizations.\n\nüìö Add the slice struct to enable getting/setting spans of elements via getitem/setitem.\n\nüìö Add syntax sugar to autotuning for both specifying the autotuned values, searching, and declaring the evaluation function.\n\nWeek of 2023-04-03\n\nThe AnyType and NoneType aliases were added and auto-imported in all files.\n\nüì¢ The Mojo VS Code extension has been improved with docstring validation. It will now warn when a function‚Äôs docstring has a wrong argument name, for example.\n\nüì¢ A new built-in literal type TupleLiteral was added in _CompilerBuiltin. It represents literal tuple values such as (1, 2.0) or ().\n\nüì¢ The Int type has been moved to a new Builtin module and is auto-imported in all code. The type of integer literals has been changed from the MLIR index type to the Int type.\n\nMojo now has a powerful flow-sensitive uninitialized variable checker. This means that you need to initialize values before using them, even if you overwrite all subcomponents. This enables the compiler to reason about the true lifetime of values, which is an important stepping stone to getting automatic value destruction in place.\n\nüì¢ Call syntax support has been added. Now you can directly call an object that implements the __call__ method, like foo(5).\n\nüì¢ The name for copy constructors got renamed from __copy__ to __copyinit__. Furthermore, non-@register_passable types now implement it like they do an init method where you fill in a by-reference self, for example:\n\nfn __copyinit__(inout self, existing: Self):\n    self.first = existing.first\n    self.second = existing.second\n\nThis makes copy construction work more similarly to initialization, and still keeps copies x = y distinct from initialization x = T(y).\n\nüì¢ Initializers for memory-primary types are now required to be in the form __init__(inout self, ...): with a None result type, but for register primary types, it remains in the form __init__(...) -> Self:. The T{} initializer syntax has been removed for memory-primary types.\n\nMojo String literals now emit a builtin StringLiteral type! One less MLIR type to worry about.\n\nNew __getattr__ and __setattr__ dunder methods were added. Mojo calls these methods on a type when attempting member lookup of a non-static member. This allows writing dynamic objects like x.foo() where foo is not a member of x.\n\nEarly destructor support has been added. Types can now define a special destructor method __del___ (note three underscores). This is an early feature and it is still being built out. There are many caveats, bugs, and missing pieces. Stay tuned!\n\nüìö Integer division and mod have been corrected for rounding in the presence of negative numbers.\n\nüìö Add scalar types (UI8, SI32, F32, F64, etc.) which are aliases to SIMD[1, type].\n\nMarch 2023\nWeek of 2023-03-27\n\nüì¢ Parameter names are no longer load-bearing in function signatures. This gives more flexibility in defining higher-order functions, because the functions passed as parameters do not need their parameter names to match.\n\n# Define a higher-order function...\nfn generator[\n   func: __mlir_type[`!kgen.signature<`, Int, `>() -> !kgen.none`]\n]():\n   pass\n\n# Int parameter is named \"foo\".\nfn f0[foo: Int]():\n   pass\n\n# Int parameter is named \"bar\".\nfn f1[bar: Int]():\n   pass\n\nfn main():\n   # Both can be used as `func`!\n   generator[f0]()\n   generator[f1]()\n\nStay tuned for improved function type syntax‚Ä¶\n\nüì¢ Two magic operators, named __get_lvalue_as_address(x) and __get_address_as_lvalue convert stored LValues to and from !kgen.pointer types (respectively). This is most useful when using the Pointer[T] library type. The Pointer.address_of(lvalue) method uses the first one internally. The second one must currently be used explicitly, and can be used to project a pointer to a reference that you can pass around and use as a self value, for example:\n\n# \"Replacement new\" SomeHeavy value into the memory pointed to by a\n# Pointer[SomeHeavy].\n__get_address_as_lvalue(somePointer.value) = SomeHeavy(4, 5)\n\nNote that __get_address_as_lvalue assumes that there is already a value at the specified address, so the assignment above will run the SomeHeavy destructor (if any) before reassigning over the value.\n\nThe (((x))) syntax is __mlir_op has been removed in favor of __get_lvalue_as_address which solves the same problem and is more general.\n\nüì¢ When using a mutable self argument to a struct __init__ method, it now must be declared with &, like any other mutable method. This clarifies the mutation model by making __init__ consistent with other mutating methods.\n\nüìö Add variadic string join function.\n\nüìö Default initialize values with 0 or null if possible.\n\nüìö Add compressed, aligned, and mask store intrinsics.\n\nWeek of 2023-03-20\n\nInitial String type is added to the standard library with some very basic methods.\n\nAdd DimList to remove the need to use an MLIR list type throughout the standard library.\n\nüì¢ The __clone__ method for copying a value is now named __copy__ to better follow Python term of art.\n\nüì¢ The __copy__ method now takes its self argument as a ‚Äúborrowed‚Äù value, instead of taking it by reference. This makes it easier to write, works for @register_passable types, and exposes more optimization opportunities to the early optimizer and dataflow analysis passes.\n\n# Before:\nfn __clone__(inout self) -> Self: ...\n\n# After:\nfn __copy__(self) -> Self: ...\n\nüì¢ A new @register_passable(\"trivial\") may be applied to structs that have no need for a custom __copy__ or __del__ method, and whose state is only made up of @register_passable(\"trivial\") types. This eliminates the need to define __copy__ boilerplate and reduces the amount of IR generated by the compiler for trivial types like Int.\n\nYou can now write back to attributes of structs that are produced by a computed lvalue expression. For example a[i].x = .. works when a[i] is produced with a __getitem__/__setitem__ call. This is implemented by performing a read of a[i], updating the temporary, then doing a writeback.\n\nThe remaining hurdles to using non-parametric, @register_passable types as parameter values have been cleared. Types like Int should enjoy full use as parameter values.\n\nParameter pack inference has been added to function calls. Calls to functions with parameter packs can now elide the pack types:\n\nfn foo[*Ts: AnyType](*args: *Ts): pass\n\nfoo(1, 1.2, True, \"hello\")\n\nNote that the syntax for parameter packs has been changed as well.\n\nüìö Add the runtime string type.\n\nüìö Introduce the DimList struct to remove the need to use low-level MLIR operations.\n\nWeek of 2023-03-13\n\nüì¢ Initializers for structs now use __init__ instead of __new__, following standard practice in Python. You can write them in one of two styles, either traditional where you mutate self:\n\nfn __init__(self, x: Int):\n    self.x = x\n\nor as a function that returns an instance:\n\nfn __init__(x: Int) -> Self:\n    return Self {x: x}\n\nNote that @register_passable types must use the later style.\n\nüì¢ The default argument convention is now the borrowed convention. A ‚Äúborrowed‚Äù argument is passed like a C++ const& so it doesn‚Äôt need to invoke the copy constructor (aka the __clone__ method) when passing a value to the function. There are two differences from C++ const&:\n\nA future borrow checker will make sure there are no mutable aliases with an immutable borrow.\n@register_passable values are passed directly in an SSA register (and thus, usually in a machine register) instead of using an extra reference wrapper. This is more efficient and is the ‚Äòright default‚Äô for @register_passable values like integers and pointers.\n\nThis also paves the way to remove the reference requirement from __clone__ method arguments, which will allow us to fill in more support for them.\n\nSupport for variadic pack arguments has been added to Mojo. You can now write heterogeneous variadic packs like:\n\nfn foo[*Ts: AnyType](args*: Ts): pass\n\nfoo[Int, F32, String, Bool](1, 1.5, \"hello\", True)\n\nThe owned argument convention has been added. This argument convention indicates that the function takes ownership of the argument and is responsible for managing its lifetime.\n\nThe borrowed argument convention has been added. This convention signifies the callee gets an immutable shared reference to a value in the caller‚Äôs context.\n\nüìö Add the getenv function to the OS module to enable getting environment variables.\n\nüìö Enable the use of dynamic strides in NDBuffer.\n\nWeek of 2023-03-06\n\nüì¢ Support added for using capturing async functions as parameters.\n\nüì¢ Returning result parameters has been moved from return statements to a new param_return statement. This allows returning result parameters from throwing functions:\n\n@raises\nfn foo[() -> out: Int]():\n    param_return[42]\n    raise Error()\n\nAnd returning different parameters along @parameter if branches:\n\nfn bar[in: Bool -> out: Int]():\n    @parameter\n    if in:\n        param_return[1]\n    else:\n        param_return[2]\n\nüì¢ Mojo now supports omitting returns at the end of functions when they would not reachable. For instance,\n\nfn foo(cond: Bool) -> Int:\n    if cond:\n        return 0\n    else:\n        return 1\n\nfn bar() -> Int:\n    while True:\n        pass\n\nString literals now support concatenation, so \"hello \" \"world\" is treated the same as \"hello world\".\n\nEmpty bodies on functions, structs, and control flow statements are no longer allowed. Please use pass in them to explicitly mark that they are empty, just like in Python.\n\nüì¢ Structs in Mojo now default to living in memory instead of being passed around in registers. This is the right default for generality (large structures, structures whose pointer identity matters, etc) and is a key technology that enables the borrow model. For simple types like Int and SIMD, they can be marked as @register_passable.\n\nNote that memory-only types currently have some limitations: they cannot be used in generic algorithms that take and return a !mlirtype argument, and they cannot be used in parameter expressions. Because of this, a lot of types have to be marked @register_passable just to work around the limitations. We expect to enable these use-cases over time.\n\nüì¢ Mojo now supports computed lvalues, which means you can finally assign to subscript expressions instead of having to call __setitem__ explicitly.\n\nSome details on this: Mojo allows you to define multiple __setitem__ overloads, but will pick the one that matches your __getitem__ type if present. It allows you to pass computed lvalues into inout arguments by introducing a temporary copy of the value in question.\n\nMojo now has much better support for using register-primary struct types in parameter expressions and as the types of parameter values. This will allow migration of many standard library types away from using bare MLIR types like __mlir_type.index and towards using Int. This moves us towards getting rid of MLIR types everywhere and makes struct types first-class citizens in the parameter system.\n\nüìö Add a sort function.\n\nüìö Add non-temporal store to enable cache bypass.\n\nFebruary 2023\nWeek of 2023-02-27\n\nüì¢ The @interface, @implements, and @evaluator trio of decorators have been removed, replaced by the @parameter if and @adaptive features.\n\nüì¢ Parameter inference can now infer the type of variadic lists.\n\nüì¢ Memory primary types are now supported in function results. A result slot is allocated in the caller, and the callee writes the result of the function into that slow. This is more efficient for large types that don‚Äôt fit into registers neatly! And initializers for memory-primary types now initialize the value in-place, instead of emitting a copy!\n\nSupport for let decls of memory primary types has been implemented. These are constant, ready-only values of memory primary types but which are allocated on the function stack.\n\nOverload conversion resolution and parameter inference has been improved:\n\nInference now works with let decls in some scenarios that weren‚Äôt working before.\nParameter bindings can now infer types into parameter expressions. This helps resolve higher-order functions in parameter expressions.\n\nüìö Optimize floor, ceil, and ldexp on X86 hardware.\n\nüìö Implement the log math function.\n\nWeek of 2023-02-20\n\nüì¢ A new @__memory_primary struct decorator has been introduced. Memory primary types must always have an address. For instance, they are always stack-allocated when declared in a function and their values are passed into function calls by address instead of copy. This is in contract with register primary types that may not have an address, and which are passed by value in function calls. Memory-primary fields are not allowed inside register-primary structs, because struct elements are stored in-line.\n\nüì¢ A new _CompilerBuiltin module was added. This module defines core types and functions of the language that are referenced by the parser, and hence, is auto-imported by all other modules. For example new types for literal values like the boolean True/False will be included in _CompilerBuiltin.\n\nüì¢ A special __adaptive_set property can be accessed on a function reference marked as @adaptive. The property returns the adaptive overload set of that function. The return type is a !kgen.variadic. This feature is useful to implement a generic evaluate function in the standard library.\n\nüì¢ A new built-in literal type BoolLiteral was added in _CompilerBuiltin. It represents the literal boolean values True and False. This is the first Mojo literal to be emitted as a standard library type!\n\nüìö Add the prefetch intrinsic to enable HW prefetching a cache line.\n\nüìö Add the InlinedFixedVector, which is optimized for small vectors and stores values on both the stack and the heap.\n\nWeek of 2023-02-13\n\nUnqualified lookups of struct members apply contextual parameters. This means for instance that you can refer to static methods without binding the struct parameters.\n\nstruct Foo[x: Int]:\n    @staticmethod\n    bar(): pass\n\n    foo(self):\n        bar()         # implicitly binds to Foo[x].bar()\n        Foo[2].bar()  # explicitly bind to another parameter\n\nüì¢ A new Self type refers to the enclosing type with all parameters bound to their current values. This is useful when working with complex parametric types, e.g.:\n\nstruct MyArray[size: Int, element_type: type]:\n   fn __new__() -> Self:\n       return Self {...}\n\nwhich is a lot nicer than having to say MyArray[size, element_type] over and over again.\n\nüì¢ Mojo now supports an @adaptive decorator. This decorator will supersede interfaces, and it represents an overloaded function that is allowed to resolve to multiple valid candidates. In that case, the call is emitted as a fork, resulting in multiple function candidates to search over.\n\n@adaptive\nfn sort(arr: ArraySlice[Int]):\n    bubble_sort(arr)\n\n@adaptive\nfn sort(arr: ArraySlice[Int]):\n    merge_sort(arr)\n\nfn concat_and_sort(lhs: ArraySlice[Int], rhs: ArraySlice[Int]):\n    let arr = lhs + rhs\n    sort(arr) # this forks compilation, creating two instances\n              # of the surrounding function\n\nüì¢ Mojo now requires that types implement the __clone__ special member in order to copy them. This allows the safe definition of non-copyable types like Atomic. Note that Mojo still doesn‚Äôt implement destructors, and (due to the absence of non-mutable references) it doesn‚Äôt actually invoke the __clone__ member when copying a let value. As such, this forces to you as a Mojo user to write maximal boilerplate without getting much value out of it.\n\nIn the future, we will reduce the boilerplate with decorators, and we will actually start using it. This will take some time to build out though.\n\nüì¢ A special __mlir_region statement was added to provide stronger invariants around defining MLIR operation regions in Mojo. It similar syntax to function declarations, except it there are no results and no input conventions.\n\nüìö Implement the log math function.\n\nüìö Improve the DType struct to enable compile-time equality checks.\n\nüìö Add the Complex struct class.\n\nWeek of 2023-02-06\n\nüì¢ The if statement now supports a @parameter decorator, which requires its condition to be a parameter expression, but which only emits the ‚ÄòTrue‚Äô side of the condition to the binary, providing a ‚Äústatic if‚Äù functionality. This should eliminate many uses of @interface that are just used to provide different constraint on the implementations.\n\nüì¢ fn main(): is now automatically exported and directly runnable by the command-line mojo tool. This is a stop-gap solution to enable script-like use cases until we have more of the language built out.\n\nü™¶ The @nodebug_inline feature has been removed, please use @alwaysinline(\"nodebug\") for methods that must be inlined and that we don‚Äôt want to step into.\n\nüì¢ Python chained comparisons, ex. a < b < c, are now supported in Mojo.\n\nüì¢ Functions can now be defined with default argument values, such as def f(x: Int, y: Int = 5):. The default argument value is used when callers do not provide a value for that argument: f(3), for example, uses the default argument value of y = 5.\n\nUnused coroutine results are now nicely diagnosed as ‚Äúmissing await‚Äù warnings.\n\nüìö Introduce a vectorized reduction operations to the SIMD type.\n\nJanuary 2023\nWeek of 2023-01-30\n\nA basic Mojo language server has been added to the VS Code extension, which parses your code as you write it, and provides warnings, errors, and fix-it suggestions!\n\nüíØ The Mojo standard library is now implicitly imported by default.\n\nThe coroutine lowering support was reworked and a new Coroutine[T] type was implemented. Now, the result of a call to an async function MUST be wrapped in a Coroutine[T], or else memory will leak. In the future, when Mojo supports destructors and library types as literal types, the results of async function calls will automatically wrapped in a Coroutine[T]. But today, it must be done manually. This type implements all the expected hooks, such as __await__, and get() to retrieve the result. Typical usage:\n\nasync fn add_three(a: Int, b: Int, c: Int) -> Int:\n    return a + b + c\n\nasync fn call_it():\n    let task: Coroutine[Int] = add_three(1, 2, 3)\n    print(await task)\n\n‚≠êÔ∏è We now diagnose unused expression values at statement context in fn declarations (but not in defs). This catches bugs with unused values, e.g. when you forget the parens to call a function.\n\nüì¢ An @always_inline(\"nodebug\") function decorator can be used on functions that need to be force inlined, but when they should not have debug info in the result. This should be used on methods like Int.__add__ which should be treated as builtin.\n\nüì¢ The @export decorator now supports an explicit symbol name to export to, for example:\n\n@export(\"baz\") # exported as 'baz'\nfn some_mojo_fn_name():\n\nüì¢ üöß Subscript syntax is now wired up to the __getitem__ dunder method.\n\nThis allows type authors to implement the __getitem__ method to enable values to be subscripted. This is an extended version of the Python semantics (given we support overloading) that allows you to define N indices instead of a single version that takes a tuple (also convenient because we don‚Äôt have tuples yet).\n\nNote that this has a very, very important limitation: subscripts are NOT wired up to __setitem__ yet. This means that you can read values with .. = v[i] but you cannot store to them with v[i] = ... For this, please continue to call __setitem__ directly.\n\nüì¢ Function calls support parameter inference.\n\nFor calls to functions that have an insufficient number of parameters specified at the callsite, we can now infer them from the argument list. We do this by matching up the parallel type structure to infer what the parameters must be.\n\nNote that this works left to right in the parameter list, applying explicitly specified parameters before trying to infer new ones. This is similar to how C++ does things, which means that you may want to reorder the list of parameters with this in mind. For example, a dyn_cast-like function will be more elegant when implemented as:\n\nfn dyn_cast[DstType: type, SrcType: type](src: SrcType) -> DstType:\n\nThan with the SrcType/DstType parameters flipped around.\n\nüìö Add the growable Dynamic vector struct.\n\nWeek of 2023-01-23\n\nInplace operations like +=/__iadd__ may now take self by-val if they want to, instead of requiring it to be by-ref.\n\n‚≠êÔ∏è Inplace operations are no longer allowed to return a non-None value. The corresponding syntax is a statement, not an expression.\n\nA new TaskGroup type was added to the standard library. This type can be used to schedule multiple tasks on a multi-threaded workqueue to be executed in parallel. An async function can await all the tasks at once with the taskgroup.\n\nüì¢ We now support for loops! A type that defines an __iter__ method that returns a type that defines __next__ and __len__ methods is eligible to be used in the statement for el in X(). Control flow exits the loop when the length is zero.\n\nThis means things like this now work:\n\nfor item in range(start, end, step):\n    print(item)\n\nResult parameters now have names. This is useful for referring to result parameters in the return types of a function:\n\nfn return_simd[() -> nelts: Int]() -> SIMD[f32, nelts]:\n\nüì¢ We now support homogeneous variadics in value argument lists, using the standard Python fn thing(*args: Int): syntax! Variadics also have support in parameter lists:\n\nfn variadic_params_and_args[*a: Int](*b: Int):\n    print(a[0])\n    print(b[1])\n\nüìö Add the range struct to enable for ... range(...) loops.\n\nüìö Introduce the unroll generator to allow one to unroll loops via a library function.\n\nWeek of 2023-01-16\n\nüì¢ Struct field references are now supported in parameter context, so you can use someInt.value to get the underlying MLIR thing out of it. This should allow using first-class types in parameters more widely.\n\nüì¢ We now support ‚Äúpretty‚Äù initialization syntax for structs, e.g.:\n\nstruct Int:\n    var value: __mlir_type.index\n    fn __new__(value: __mlir_type.index) -> Int:\n        return Int {value: value}\n\nThis eliminates the need to directly use the MLIR lit.struct.create op in struct initializers. This syntax may change in the future when ownership comes in, because we will be able to support the standard __init__ model then.\n\nüì¢ It is now possible to attach regions to __mlir_op operations. This is done with a hack that allows an optional _region attribute that lists references to the region bodies (max 1 region right now due to lack of list [] literal).\n\nNested functions now parse, e.g.:\n\nfn foo():\n    fn bar():\n        pass\n    bar()\n\nPython-style async functions should now work and the await expression prefix is now supported. This provides the joy of async/await syntactic sugar when working with asynchronous functions. This is still somewhat dangerous to use because we don‚Äôt have proper memory ownership support yet.\n\nString literals are now supported.\n\nReturn processing is now handled by a dataflow pass inside the compiler, so it is possible to return early out of if statements.\n\nThe parser now supports generating ‚Äòfixit‚Äô hints on diagnostics, and uses them when a dictionary literal uses a colon instead of equal, e.g.:\n\nx.mojo:8:48: error: expected ':' in subscript slice, not '='\n    return __mlir_op.`lit.struct.create`[value = 42]()\n                                               ^\n                                               :\n\nüìö Add reduction methods which operate on buffers.\n\nüìö Add more math functions like sigmoid, sqrt, rsqrt, etc.\n\nüìö Add partial load / store which enable loads and stores that are predicated on a condition.\n\nWeek of 2023-01-09\n\nThe / and * markers in function signatures are now parsed and their invariants are checked. We do not yet support keyword arguments yet though, so they aren‚Äôt very useful.\n\nFunctions now support a new @nodebug_inline decorator. (Historical note: this was later replaced with @alwaysinline(\"nodebug\")).\n\nMany of the things at the bottom level of the Mojo stack are trivial zero-abstraction wrappers around MLIR things, for example, the + operator on Int or the __bool__ method on Bool itself. These operators need to be force inlined even at -O0, but they have some additional things that we need to wrestle with:\n\nIn no case would a user actually want to step into the __bool__ method on Bool or the + method on Int. This would be terrible debugger QoI for unless you‚Äôre debugging Int itself. We need something like __always_inline__, __nodebug__ attributes that clang uses in headers like xmmintrin.h.\n\nSimilarly, these ‚Äúoperators‚Äù should be treated by users as primitives: they don‚Äôt want to know about MLIR or internal implementation details of Int.\n\nThese trivial zero abstraction things should be eliminated early in the compiler pipeline so they don‚Äôt slow down the compiler, bloating out the call graph with trivial leaves. Such thing slows down the elaborator, interferes with basic MLIR things like fold(), bloats out the IR, or bloats out generated debug info.\n\nIn a parameter context, we want some of these things to get inlined so they can be simplified by the attribute logic and play more nicely with canonical types. This is just a nice to have thing those of us who have to stare at generated IR.\n\nThe solution to this is a new @nodebug_inline decorator. This decorator causes the parser to force-inline the callee instead of generating a call to it. While doing so, it gives the operations the location of the call itself (that‚Äôs the ‚Äúnodebug‚Äù part) and strips out let decls that were part of the internal implementation details.\n\nThis is a super-power-user-feature intended for those building the standard library itself, so it is intentionally limited in power and scope: It can only be used on small functions, it doesn‚Äôt support regions, by-ref, throws, async, etc.\n\nSeparately, we now support an @alwaysInline decorator on functions. This is a general decorator that works on any function, and indicates that the function must be inlined. Unlike @nodebug_inline, this kind of inlining is performed later in the compilation pipeline.\n\nThe __include hack has been removed now that we have proper import support.\n\n__mlir_op can now get address of l-value:\n\nYou can use magic (((x))) syntax in __mlir_op that forces the x expression to be an lvalue, and yields its address. This provides an escape hatch (isolated off in __mlir_op land) that allows unsafe access to lvalue addresses.\n\nWe now support __rlshift__ and __rtruediv__.\n\nüì¢ The parser now resolves scoped alias references. This allows us to support things like SomeType.someAlias, forward substituting the value. This unblocks use of aliases in types like DType. We‚Äôd like to eventually preserve the reference in the AST, but this unblocks library development.\n\nüìö Add a now function and Benchmark struct to enable timing and benchmarking.\n\nüìö Move more of the computation in NDBuffer from runtime to compile time if possible (e.g.¬†when the dimensions are known at compile time).\n\nWeek of 2023-01-02\n\nüìö Added the print function which works on Integers and SIMD values.\n\nThe frontend now has a new diagnostic subsystem used by the kgen tool (but not by kgen-translate for tests) that supports source ranges on diagnostics. Before we‚Äôd emit an error like:\n\nx.mojo:13:3: error: invalid call to 'callee': in argument #0, value of type '$F32::F32' cannot be converted to expected type '$int::Int'\n  callee(1.0+F32(2.0))\n  ^\nx.lit:4:1: note: function declared here\nfn callee(a: Int):\n^\n\nnow we produce:\n\nx.mojo:13:3: error: invalid call to 'callee': in argument #0, value of type '$F32::F32' cannot be converted to expected type '$int::Int'\n  callee(1.0+F32(2.0))\n  ^      ~~~~~~~~~~~~\nx.lit:4:1: note: function declared here\nfn callee(a: Int):\n^\n\nüì¢ Parameter results are now supported in a proper way. They are now forward declared with an alias declaration and then bound in a call with an arrow, e.g.:\n\nalias a : __mlir_type.index\nalias b : __mlir_type.index\nidx_result_params[xyz*2 -> a, b]()\n\nVarious minor issues with implicit conversions are fixed. For instances, implicit conversions are now supported in parameter binding contexts and alias declarations with explicit types.\n\nDoc strings are allowed on functions and structs, but they are currently discarded by the parser.\n\nüìö Add a print method!!!\n\nüìö Demonstrate a naive matmul in Mojo.\n\nüìö Initial work on functions that depend on types (e.g.¬†FPUtils, nan, inf, etc.)\n\nüìö Allow one to query hardware properties such as simd_width, os, etc. via TargetInfo at compile time.\n\nDecember 2022\nWeek of 2022-12-26\n\nüì¢ You can now call functions in a parameter context! Calling a function in a parameter context will evaluate the function at compile time. The result can then be used as parameter values. For example,\n\nfn fma(x: Int, y: Int, z: Int) -> Int:\n    return a + b * c\n\nfn parameter_call():\n    alias nelts = fma(32, 2, 16)\n    var x: SIMD[f32, nelts]\n\nYou can now disable printing of types in an __mlir_attr substitution by using unary + expression.\n\nüì¢ let declarations are now supported in functions. let declarations are local run-time constant values, which are always rvalues. They complement ‚Äòvar‚Äô decls (which are mutable lvalues) and are the normal thing to use in most cases. They also generate less IR and are always in SSA form when initialized.\n\nWe will want to extend this to support ‚Äòlet‚Äô decls in structs at some point and support lazy initialized ‚Äòlet‚Äô declarations (using dataflow analysis) but that isn‚Äôt supported yet.\n\nüìö Add the NDBuffer struct.\n\nHappy new year.\n\nWeek of 2022-12-19\n\nüìö Start of the Standard library:\n\nAdded Integer and SIMD structs to bootstrap the standard library.\nAdded very basic buffer data structure.\n\nWe have basic support for parsing parameter results in function calls! Result parameters are an important Mojo metaprogramming feature. They allow functions to return compile-time constants.\n\nfn get_preferred_simdwidthof[() -> nelts: Int]():\n    return[2]\n\nfn vectorized_function():\n    get_preferred_simdwidthof[() -> nelts]()\n    var x: SIMD[f32, nelts]\n\nTypes can now be used as parameters of !kgen.mlirtype in many more cases.\n\nMLIR operations with zero results don‚Äôt need to specify _type: [] anymore.\n\nWe support parsing triple quoted strings, for writing docstrings for your functions and structs!\n\nA new __mlir_type[a,b,c] syntax is available for substituting into MLIR types and attributes is available, and the old placeholder approach is removed. This approach has a few advantages beyond what placeholders do:\n\nIt‚Äôs simpler.\nIt doesn‚Äôt form the intermediate result with placeholders, which gets rejected by MLIR‚Äôs semantic analysis, e.g.¬†the complex case couldn‚Äôt be expressed before.\nIt provides a simple way to break long attrs/types across multiple lines.\n\nWe now support an @evaluator decorator on functions for KGEN evaluators. This enables specifying user-defined interface evaluators when performing search during compilation.\n\nüì¢ import syntax is now supported!\n\nThis handles packaging imported modules into file ops, enables effective isolation from the other decls. ‚Äúimport‚Äù into the desired context is just aliasing decls, with the proper symbols references handle automatically during IR generation. As a starting point, this doesn‚Äôt handle any notion of packages (as those haven‚Äôt been sketched out enough).\n\nüì¢ Reversed binary operators (like __radd__) are now looked up and used if the forward version (like __add__) doesn‚Äôt work for some reason.\n\nüì¢ Implicit conversions are now generally available, e.g.¬†in assign statements, variable initializers etc. There are probably a few more places they should work, but we can start eliminating all the extraneous explicit casts from literals now.\n\nHappy Holidays\n\nWeek of 2022-12-12\n\nüì¢ Function overloading now works. Call resolution filters candidate list according to the actual parameter and value argument specified at the site of the call, diagnosing an error if none of the candidates are viable or if multiple are viable and ambiguous. We also consider implicit conversions in overload look:\n\nfn foo(x: Int): pass\nfn foo(x: F64): pass\n\nfoo(Int(1)) # resolves to the first overload\nfoo(1.0)    # resolves to the second overload\nfoo(1)      # error: both candidates viable with 1 implicit conversion!\n\nThe short circuiting binary and and or expressions are now supported.\n\nUnary operator processing is a lot more robust, now handling the not expression and ~x on Bool.\n\nüì¢ The compiler now generates debug information for use with GDB/LLDB that describes variables and functions.\n\nThe first version of the Mojo Visual Studio Code extension has been released! It supports syntax highlighting for Mojo files.\n\nThe first version of the Bool type has landed in the new Mojo standard library!\n\nüì¢ Implicit conversions are now supported in return statements.\n\nWeek of 2022-12-05\n\n‚ÄúDiscard‚Äù patterns are now supported, e.g.¬†_ = foo()\n\nWe now support implicit conversions in function call arguments, e.g. converting an index value to Int automatically. This eliminates a bunch of casts, e.g.¬†the need to say F32(1.0) everywhere.\n\nThis is limited for a few reasons that will be improved later:\n\nWe don‚Äôt support overloading, so lots of types aren‚Äôt convertible from all the things they should be, e.g.¬†you can‚Äôt pass ‚Äú1‚Äù to something that expects F32, because F32 can‚Äôt be created from index.\nThis doesn‚Äôt ‚Äúcheck to see if we can invoke __new__‚Äù it force applies it on a mismatch, which leads to poor QoI.\nThis doesn‚Äôt fix things that need radd.\nNovember 2022\nWeek of 2022-11-28\n\nüì¢ We support the True and False keywords as expressions.\n\nüì¢ A new alias declaration is supported which allows defining local parameter values. This will eventually subsume type aliases and other things as it gets built out.\n\nüì¢ We now have end-to-end execution of Mojo files using the kgen tool! Functions exported with @export can be executed.\n\nüì¢ We have try-except-else and raise statements and implicit error propagation! The error semantics are that def can raise by default, but fn must explicitly declare raising with a @raises decorator. Stub out basic Error type.\n\nThe & sigil for by-ref arguments is now specified after the identifier. Postfix works better for ref and move operators on the expression side because it chains an mentally associates correctly: thing.method().result^. We don‚Äôt do that yet, but align param decl syntax to it so that things won‚Äôt be odd looking when we do. In practice this looks like:\n\ndef mutate_argument(a&: index):\n    a = 25\nWeek of 2022-11-21\n\nüì¢ The magic index type is gone. Long live __mlir_type.index.\n\nImplement parameter substitution into parametric __mlir_type decls. This allows us to define parametric opaque MLIR types with exposed parameters using a new ‚Äúplaceholder‚Äù attribute. This allows us to expose the power of the KGEN type parametric system directly into Mojo.\n\nüì¢ Fully-parametric custom types can now be defined and work in Mojo, bringing together a lot of the recent work. We can write the SIMD type directly as a wrapper around the KGEN type, for example:\n\nstruct SIMD[dt: __mlir_type.`!kgen.dtype`, nelts: __mlir_type.index]:\n    var value:\n      __mlir_type.`!pop.simd<#lit<placeholder index>,\n                             #lit<placeholder !kgen.dtype>>`[nelts, dt]\n\n    fn __add__(self, rhs: SIMD[dt, nelts]) -> SIMD[dt, nelts]:\n        return __mlir_op.`pop.add`(self.value, rhs.value)\nWeek of 2022-11-14\n\nüì¢ Implement a magic __mlir_type declaration that can be used to access any MLIR type. E.g. __mlir_type.f64.\n\nüì¢ Add an fn declaration. These are like def declarations, but are more strict in a few ways: they require type annotations on arguments, don‚Äôt allow implicit variable declarations in their body, and make their arguments rvalues instead of lvalues.\n\nImplemented Swift-style backtick identifiers, which are useful for code migration where names may collide with new keywords.\n\nüì¢ A new __include directive has been added that performs source-level textual includes. This is temporary until we have an import model.\n\nImplement IR generation for arithmetic operators like + and * in terms of the __add__ and __mul__ methods.\n\nüì¢ Added support for break and continue statements, as well as early returns inside loops and conditionals!\n\nüì¢ Implemented augmented assignment operators, like += and @=.\n\nüì¢ Mojo now has access to generating any MLIR operations (without regions) with a new __mlir_op magic declaration. We can start to build out the language‚Äôs builtin types with this:\n\nstruct Int:\n    var value: __mlir_type.index\n\n    fn __add__(self, rhs: Int) -> Int:\n        return __mlir_op.`index.add`(self.value, rhs.value)\n\nAttributes can be attached to the declaration with subscript [] syntax, and an explicit result type can be specified with a special _type attribute if it cannot be inferred. Attributes can be accessed via the __mlir_attr magic decl:\n\n__mlir_op.`index.cmp`[\n    _type: __mlir_type.i1,\n    pred: __mlir_attr.`#index<cmp_predicate slt>`\n](lhs, rhs)\n\nImproved diagnostics emissions with ranges! Now errors highlight the whole section of code and not just the first character.\n\nWeek of 2022-11-07\n\nImplemented the @interface and @implements decorators, which provide access to KGEN generator interfaces. A function marked as an @interface has no body, but it can be implemented by multiple other functions.\n\n@interface\ndef add(lhs: index, rhs: index):\n\n@implements(add)\ndef normal_add(lhs: index, rhs: index) -> index:\n    return lhs + rhs\n\n@implements(add)\ndef slow_add(lhs: index, rhs: index) -> index:\n    wait(1000)\n    return normal_add(lhs, rhs)\n\nüì¢ Support for static struct methods and initializer syntax has been added. Initializing a struct with Foo() calls an implicitly static __new__ method. This method should be used instead of __init__ inside structs.\n\nstruct Foo:\n    var value: index\n\n    def __new__() -> Foo:\n        var result: Foo\n        result.value = Foo.return_a_number() # static method!\n        return result\n\n    @staticmethod\n    def return_a_number() -> index:\n        return 42\n\nüì¢ Full by-ref argument support. It‚Äôs now possible to define in-place operators like __iadd__ and functions like swap(x, y) correctly.\n\nüì¢ Implemented support for field extract from rvalues, like x.value where x is not an lvalue (var declaration or by-ref function argument).\n\nOctober 2022\nWeek of 2022-10-31\n\nRevised return handling so that a return statement with no expression is syntax sugar for return None. This enables early exits in functions that implicitly return None to be cleaner:\n\ndef just_return():\n    return\n\nAdded support for parsing more expressions: if-else, bitwise operators, shift operators, comparisons, floor division, remainder, and matmul.\n\nüì¢ The type of the self argument can now be omitted on member methods.\n\nWeek of 2022-10-24\n\nAdded parser support for right-associativity and unary ops, like the power operator a ** b ** c and negation operator -a.\n\nAdd support for &expr in Mojo, which allows denoting a by-ref argument in functions. This is required because the self type of a struct method is implicitly a pointer.\n\nImplemented support for parametric function declarations, such as:\n\nstruct SIMD[dt: DType, width: index]:\n    fn struct_method(self: &SIMD[dt, width]):\n        pass\n\ndef fancy_add[dt: DType, width: index](\n    lhs: SIMD[dt, width], rhs: SIMD[dt, width]) -> index:\n  return width\nWeek of 2022-10-17\n\nAdded explicit variable declarations with var, for declaring variables both inside functions and structs, with support for type references. Added index as a temporary built-in type.\n\ndef foo(lhs: index, rhs: index) -> index:\n    var result: index = lhs + rhs\n    return result\n\nImplemented support for parsing struct declarations and references to type declarations in functions! In def, the type can be omitted to signal an object type.\n\nstruct Foo:\n    var member: index\n\ndef bar(x: Foo, obj) -> index:\n    return x.member\n\nImplemented parser support for if statements and while loops!\n\ndef if_stmt(c: index, a: index, b: index) -> index:\n    var result: index = 0\n    if c:\n        result = a\n    else:\n        result = b\n    return result\n\ndef while_stmt(init: index):\n    while init > 1:\n        init = init - 1\n\nSignificantly improved error emission and handling, allowing the parser to emit multiple errors while parsing a file.\n\nWeek of 2022-10-10\n\nAdded support for parsing integer, float, and string literals.\n\nImplemented parser support for function input parameters and results. You can now write parametric functions like,\n\ndef foo[param: Int](arg: Int) -> Int:\n    result = param + arg\n    return result\nWeek of 2022-10-03\n\nAdded some basic parser scaffolding and initial parser productions, including trivial expressions and assignment parser productions.\n\nImplemented basic scope handling and function IR generation, with support for forward declarations. Simple functions like,\n\ndef foo(x: Int):\n\nNow parse! But all argument types are hard-coded to the MLIR index type.\n\nAdded IR emission for simple arithmetic expressions on builtin types, like x + y.\n\nSeptember 2022\nWeek of 2022-09-26\n\nMojo‚Äôs first patch to add a lexer was Sep 27, 2022.\n\nSettled on [] for Mojo generics instead of <>. Square brackets are consistent with Python generics and don‚Äôt have the less than ambiguity other languages have.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - Mojoüî• roadmap & sharp edges",
    "url": "https://docs.modular.com/mojo/roadmap.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nOverall priorities\nWhy not add syntactic sugar or other minor new features?\nMojo SDK known issues\nSmall independent features\nOwnership and Lifetimes\nProtocols / Traits\nClasses\nC/C++ Interop\nFull MLIR decorator reflection\nSharp Edges\nMojoüî• roadmap & sharp edges\n\nThis document captures the broad plan about how we plan to implement things in Mojo, and some early thoughts about key design decisions. This is not a full design spec for any of these features, but it can provide a ‚Äúbig picture‚Äù view of what to expect over time. It is also an acknowledgement of major missing components that we plan to add.\n\nOverall priorities\n\nMojo is still in early development and many language features will arrive in the coming months. We are highly focused on building Mojo the right way (for the long-term), so we want to fully build-out the core Mojo language features before we work on other dependent features and enhancements.\n\nCurrently, that means we are focused on the core system programming features that are essential to Mojo‚Äôs mission, and as outlined in the following sections of this roadmap.\n\nIn the near-term, we will not prioritize ‚Äúgeneral goodness‚Äù work such as:\n\nAdding syntactic sugar and short-hands for Python.\nAdding features from other languages that are missing from Python (such as public/private declarations).\nTackling broad Python ecosystem challenges like packaging.\n\nIf you have encountered any bugs with current Mojo behavior, please submit an issue on GitHub.\n\nIf you have ideas about how to improve the core Mojo features, we prefer that you first look for similar topics or start a new conversation about it in our GitHub Discussions.\n\nWe also consider Mojo to be a new member of the Python family, so if you have suggestions to improve the experience with Python, we encourage you to propose these ‚Äúgeneral goodness‚Äù enhancements through the formal PEP process.\n\nWhy not add syntactic sugar or other minor new features?\n\nWe are frequently asked whether Mojo will add minor features that people love in other languages but that are missing in Python, such as ‚Äúimplicit return‚Äù at the end of a function, public/private access control, fixing Python packaging, and various syntactic shorthands. As mentioned above, we are intentionally not adding these kinds of features to Mojo right now. There are three major reasons for this:\n\nFirst, Mojo is still young: we are still ‚Äúbuilding a house‚Äù by laying down major bricks in the type system and adding system programming features that Python lacks. We know we need to implement support for many existing Python features (compatibility a massive and important goal of Mojo) and this work is not done yet. We have limited engineering bandwidth and want focus on building essential functionality, and we will not debate whether certain syntactic sugar is important or not.\n\nSecond, syntactic sugar is like mortar in a building‚Äîits best use is to hold the building together by filling in usability gaps. Sugar (and mortar) is problematic to add early into a system: you can run into problems with laying the next bricks because the sugar gets in the way. We have experience building other languages (such as Swift) that added sugar early, which could have been subsumed by more general features if time and care were given to broader evaluation.\n\nThird, the Python community should tackle some of these ideas first. It is important to us that Mojo be a good member of the Python family (a ‚ÄúPython++‚Äù), not just a language with Pythonic syntax. As such, we don‚Äôt want to needlessly diverge from Python evolution: adding a bunch of features could lead to problems down the road if Python makes incompatible decisions. Such a future would fracture the community which would cause massively more harm than any minor language feature could offset.\n\nFor all these reasons, ‚Äúnice to have‚Äù syntactic sugar is not a priority, and we will quickly close such proposals to avoid cluttering the issue tracker. If you‚Äôd like to propose a ‚Äúgeneral goodness‚Äù syntactic feature, please do so with the existing Python PEP process. If/when Python adopts a feature, Mojo will also add it, because Mojo‚Äôs goal is to be a superset. We are happy with this approach because the Python community is better equipped to evaluate these features, they have mature code bases to evaluate them with, and they have processes and infrastructure for making structured language evolution features.\n\nMojo SDK known issues\n\nThe Mojo SDK is still in early development and currently only available for Ubuntu Linux and macOS (Apple silicon) systems. Here are some of the notable issues that we plan to fix:\n\nMissing native support for Windows, Intel Macs, and Linux distributions other than Ubuntu. Currently, we support Ubuntu systems with x86-64 processors only. Support for more Linux distributions (including Debian and RHEL) and Windows is in progress.\n\nPython interoperability might fail when running a compiled Mojo program, with the message Unable to locate a suitable libpython, please set MOJO_PYTHON_LIBRARY. This is because we currently do not embed the Python version into the Mojo binary. For details and the workaround, see issue #551.\n\nMojo programs that import NumPy might fail with the following error:\n\nImporting the numpy C-extensions failed. This error can happen for\nmany reasons, often due to issues with your setup or how NumPy was\ninstalled.\n\nThis may occur because the version of NumPy doesn‚Äôt match the Python interpreter Mojo is using. As a workaround, follow the instructions in issue #1085 to install a Python virtual environment using Conda. This can solve many issues with Python interoperability.\n\nModular CLI install might fail and require modular clean before you re-install.\n\nIf it asks you to perform auth, run modular auth <MODULAR_AUTH> and use the MODULAR_AUTH value shown for the curl command on the download page.\n\nmodular install mojo is slow and might appear unresponsive (as the installer is downloading packages in the background). We will add a progress bar in a future release.\n\nIf you attempt to uninstall Mojo with modular uninstall, your subsequent attempt to install Mojo might fail with an HTTP 500 error code. If so, run modular clean and try again.\n\nMojo REPL might hang (become unresponsive for more than 10 seconds) when interpreting an expression if your system has 4 GiB or less RAM. If you encounter this issue, please report it with your system specs.\n\nAdditionally, we‚Äôre aware of some issues that we might not be able to solve, but we mention them here with some more information:\n\nWhen installing Mojo, if you receive the error, failed to reach URL https://cas.modular.com, it could be because your network connection is behind a firewall. Try updating your firewall settings to allow access to these end points: https://packages.modular.com and https://cas.modular.com. Then retry with modular clean and modular install mojo.\n\nWhen installing Mojo, if you receive the error, gpg: no valid OpenGPG data found, this is likely because you are located outside our supported geographies. Due to US export control restrictions, we are unable to provide access to Mojo to users situated in specific countries.\n\nIf using Windows Subsystem for Linux (WSL), you might face issues with WSL 1. We recommend you upgrade to WSL 2. To check the version, run wsl -l -v. If you‚Äôre running WSL 1, refer to the WSL upgrade instructions.\n\nWhen installing on macOS (Apple silicon), the Modular CLI install might fail with the message:\n\nmodular: The arm64 architecture is required for this software.\n\nThis occurs because Apple‚Äôs Rosetta x86 emulation is active. Check the following:\n\nRight click on the terminal application you use (for example, Terminal.app), click Get Info, and make sure the Open in Rosetta checkbox is not selected.\n\nRun the following command:\n\nbrew config | grep Rosetta\n\nIf the output shows Rosetta 2: True, the x86 version of Homebrew is installed. Uninstall and reinstall Homebrew before retrying the Modular installation.\n\nNote: Before uninstalling Homebrew, verify that you don‚Äôt have other projects specifically depending on the x86 version of Homebrew.\n\nYou can see other reported issues on GitHub.\n\nSmall independent features\n\nThere are a number of features that are missing that are important to round out the language fully, but which don‚Äôt depend strongly on other features. These include things like:\n\nImproved package management support.\nMany standard library features, including canonical arrays and dictionary types, copy-on-write data structures, etc.\nSupport for ‚Äútop level code‚Äù at file scope.\nAlgebraic data types like enum in Swift/Rust, and pattern matching.\nMany standard library types, including Optional[T] and Result[T, Error] types when we have algebraic datatypes and basic traits.\nSupport for keyword-only arguments and variadic keyword arguments (**kwargs).\nOwnership and Lifetimes\n\nThe ownership system is partially implemented, and is expected to get built out in the next couple of months. The basic support for ownership includes features like:\n\nCapture declarations in closures.\nBorrow checker: complain about invalid mutable references.\n\nThe next step in this is to bring proper lifetime support in. This will add the ability to return references and store references in structures safely. In the immediate future, one can use the unsafe Pointer struct to do this like in C++.\n\nProtocols / Traits\n\nUnlike C++, Mojo does not ‚Äúinstantiate templates‚Äù in its parser. Instead, it has a separate phase that works later in the compilation pipeline (the ‚ÄúElaborator‚Äù) that instantiates parametric code, which is aware of autotuning and caching. This means that the parser has to perform full type checking and IR generation without instantiating algorithms.\n\nThe planned solution is to implement language support for Protocols - variants of this feature exist in many languages (e.g.¬†Swift protocols, Rust traits, Haskell typeclasses, C++ concepts) all with different details. This feature allows defining requirements for types that conform to them, and dovetails into static and dynamic metaprogramming features.\n\nClasses\n\nMojo still doesn‚Äôt support classes, the primary thing Python programmers use pervasively! This isn‚Äôt because we hate dynamism - quite the opposite. It is because we need to get the core language semantics nailed down before adding them. We expect to provide full support for all the dynamic features in Python classes, and want the right framework to hang that off of.\n\nWhen we get here, we will discuss what the right default is: for example, is full Python hash-table dynamism the default? Or do we use a more efficient model by default (e.g.¬†vtable-based dispatch and explicitly declared stored properties) and allow opt‚Äôing into dynamism with a @dynamic decorator on the class. The latter approach worked well for Swift (its @objc attribute), but we‚Äôll have to prototype to better understand the tradeoffs.\n\nC/C++ Interop\n\nIntegration to transparently import Clang C/C++ modules. Mojo‚Äôs type system and C++‚Äôs are pretty compatible, so we should be able to have something pretty nice here. Mojo can leverage Clang to transparently generate a foreign function interface between C/C++ and Mojo, with the ability to directly import functions:\n\nfrom \"math.h\" import cos\n\nprint(cos(0))\nFull MLIR decorator reflection\n\nAll decorators in Mojo have hard-coded behavior in the parser. In time, we will move these decorators to being compile-time metaprograms that use MLIR integration. This may depend on C++ interop for talking to MLIR. This completely opens up the compiler to programmers. Static decorators are functions executed at compile-time with the capability to inspect and modify the IR of functions and types.\n\nfn value(t: TypeSpec):\n    t.__copyinit__ = # synthesize dunder copyinit automatically\n\n@value\nstruct TrivialType: pass\n\nfn full_unroll(loop: mlir.Operation):\n    # unrolling of structured loop\n\nfn main():\n    @full_unroll\n    for i in range(10):\n        print(i)\nSharp Edges\n\nThe entire Modular kernel library is written in Mojo, and its development has been prioritized based on the internal needs of those users. Given that Mojo is still a young language, there are a litany of missing small features that many Python and systems programmers may expect from their language, as well as features that don‚Äôt quite work the way we want to yet, and in ways that can be surprising or unexpected. This section of the document describes a variety of ‚Äúsharp edges‚Äù in Mojo, and potentially how to work around them if needed. We expect all of these to be resolved in time, but in the meantime, they are documented here.\n\nNo list or dict comprehensions\n\nMojo does not yet support Python list or dictionary comprehension expressions, like [x for x in range(10)], because Mojo‚Äôs standard library has not yet grown a standard list or dictionary type.\n\nNo lambda syntax\n\nMojo does not yet support defining anonymous functions with the lambda keyword.\n\nNo parametric aliases\n\nMojo aliases can refer to parametric values but cannot themselves be a parameter. We would like this example to work, however:\n\nalias Scalar[dt: DType] = SIMD[dt, 1]\nalias mul2[x: Int] = x * 2\nException is actually called Error\n\nIn Python, programmers expect that exceptions all subclass the Exception builtin class. The only available type for Mojo ‚Äúexceptions‚Äù is Error:\n\nfn raise_an_error() raises:\n    raise Error(\"I'm an error!\")\n\nThe reason we call this type Error instead of Exception is because it‚Äôs not really an exception. It‚Äôs not an exception, because raising an error does not cause stack unwinding, but most importantly it does not have a stack trace. And without polymorphism, the Error type is the only kind of error that can be raised in Mojo right now.\n\nNo Python-style generator functions\n\nMojo does not yet support Python-style generator functions (yield syntax). These are ‚Äúsynchronous co-routines‚Äù ‚Äì functions with multiple suspend points.\n\nNo async for or async with\n\nAlthough Mojo has support for async functions with async fn and async def, Mojo does not yet support the async for and async with statements.\n\nThe rebind builtin\n\nOne of the consequences of Mojo not performing function instantiation in the parser like C++ is that Mojo cannot always figure out whether some parametric types are equal and complain about an invalid conversion. This typically occurs in static dispatch patterns, like:\n\nfn take_simd8(x: SIMD[DType.float32, 8]): pass\n\nfn generic_simd[nelts: Int](x: SIMD[DType.float32, nelts]):\n    @parameter\n    if nelts == 8:\n        take_simd8(x)\n\nThe parser will complain,\n\nerror: invalid call to 'take_simd8': argument #0 cannot be converted from\n'SIMD[f32, nelts]' to 'SIMD[f32, 8]'\n        take_simd8(x)\n        ~~~~~~~~~~^~~\n\nThis is because the parser fully type-checks the function without instantiation, and the type of x is still SIMD[f32, nelts], and not SIMD[f32, 8], despite the static conditional. The remedy is to manually ‚Äúrebind‚Äù the type of x, using the rebind builtin, which inserts a compile-time assert that the input and result types resolve to the same type after function instantiation.\n\nfn generic_simd[nelts: Int](x: SIMD[DType.float32, nelts]):\n    @parameter\n    if nelts == 8:\n        take_simd8(rebind[SIMD[DType.float32, 8]](x))\nScoping and mutability of statement variables\n\nPython programmers understand that local variables are implicitly declared and scoped at the function level. As the programming manual explains, this feature is supported in Mojo only inside def functions. However, there are some nuances to Python‚Äôs implicit declaration rules that Mojo does not match 1-to-1.\n\nFor example, the scope of for loop iteration variables and caught exceptions in except statements is limited to the next indentation block, for both def and fn functions. Python programmers will expect the following program to print ‚Äú2‚Äù:\n\nfor i in range(3): pass\nprint(i)\n\nHowever, Mojo will complain that print(i) is a use of an unknown declaration. This is because whether i is defined at this line is dynamic in Python. For instance the following Python program will fail:\n\nfor i range(0): pass\nprint(i)\n\nWith NameError: name 'i' is not defined, because the definition of i is a dynamic characteristic of the function. Mojo‚Äôs lifetime tracker is intentionally simple (so lifetimes are easy to use!), and cannot reason that i would be defined even when the loop bounds are constant.\n\nAlso stated in the programming manual: in def functions, the function arguments are mutable and re-assignable, whereas in fn, function arguments are rvalues and cannot be re-assigned. The same logic extends to statement variables, like for loop iteration variables or caught exceptions:\n\ndef foo():\n    try:\n        bad_function():\n    except e:\n        e = Error() # ok: we can overwrite 'e'\n\nfn bar():\n    try:\n        bad_function():\n    except e:\n        e = Error() # error: 'e' is not mutable\nName scoping of nested function declarations\n\nIn Python, nested function declarations produce dynamic values. They are essentially syntax sugar for bar = lambda ....\n\ndef foo():\n    def bar(): # creates a function bound to the dynamic value 'bar'\n        pass\n    bar() # indirect call\n\nIn Mojo, nested function declarations are static, so calls to them are direct unless made otherwise.\n\nfn foo():\n    fn bar(): # static function definition bound to 'bar'\n        pass\n    bar() # direct call\n    let f = bar # materialize 'bar' as a dynamic value\n    f() # indirect call\n\nCurrently, this means you cannot declare two nested functions with the same name. For instance, the following example does not work in Mojo:\n\ndef pick_func(cond):\n    if cond:\n        def bar(): return 42\n    else:\n        def bar(): return 3 # error: redeclaration of 'bar'\n    return bar\n\nThe functions in each conditional must be explicitly materialized as dynamic values.\n\ndef pick_func(cond):\n    let result: def() capturing # Mojo function type\n    if cond:\n        def bar0(): return 42\n        result = bar0\n    else:\n        def bar1(): return 3 # error: redeclaration of 'bar'\n        result = bar1\n    return result\n\nWe hope to sort out these oddities with nested function naming as our model of closures in Mojo develops further.\n\nNo polymorphism\n\nMojo will implement static polymorphism through traits/protocols in the near future and dynamic polymorphism through classes and MLIR reflection. None of those things exist today, which presents several limitations to the language.\n\nPython programmers are used to implementing special dunder methods on their classes to interface with generic methods like print and len. For instance, one expects that implementing __repr__ or __str__ on a class will enable that class to be printed via print.\n\nclass One:\n    def __init__(self): pass\n    def __repr__(self): return '1'\n\nprint(One()) # prints '1'\n\nThis is not currently possible in Mojo. Overloads of print are provided for common types, like Int and SIMD and String, but otherwise the builtin is not extensible. Overloads also have the limitation that they must be defined within the same module, so you cannot add a new overload of print for your struct types.\n\nThe same extends to range, len, and other builtins.\n\nNo lifetime tracking inside collections\n\nDue to the aforementioned lack of polymorphism, collections like lists, maps, and sets are unable to invoke element destructors. For collections of trivial types, like DynamicVector[Int], this is no problem, but for collections of types with lifetimes, like DynamicVector[String], the elements have to be manually destructed. Doing so requires quite an ugly pattern, shown in the next section.\n\nNo safe value references\n\nMojo does not have proper lifetime marker support yet, and that means it cannot reason about returned references, so Mojo doesn‚Äôt support them. You can return or keep unsafe references by passing explicit pointers around.\n\nstruct StringRef:\n    var ref: Pointer[SI8]\n    var size: Int\n    # ...\n\nfn bar(x: StringRef): pass\n\nfn foo():\n    let s: String = \"1234\"\n    let ref: StringRef = s # unsafe reference\n    bar(ref)\n    _ = s # keep the backing memory alive!\n\nMojo will destruct objects as soon as it thinks it can. That means the lifetime of objects to which there are unsafe references must be manually extended. See the lifetime document for more details. This disables the RAII pattern in Mojo. Context managers and with statements are your friends in Mojo.\n\nNo lvalue returns also mean that implementing certain patterns require magic keywords until proper lifetime support is built. One such pattern is retrieving an unsafe reference from an object.\n\nstruct UnsafeIntRef:\n    var ptr: Pointer[Int]\n\nfn printIntRef(x: UnsafeIntRef):\n    # \"deference\" operator\n    print(__get_address_as_lvalue(x.ptr)) # Pointer[Int] -> &Int\n\nvar c: Int = 10\n# \"reference\" operator\nlet ref = UnsafeIntRef(__get_lvalue_as_address(c)) # &Int -> Pointer[Int]\nParameter closure captures are unsafe references\n\nYou may have seen nested functions, or ‚Äúclosures‚Äù, annotated with the @parameter decorator. This creates a ‚Äúparameter closure‚Äù, which behaves differently than a normal ‚Äústateful‚Äù closure. A parameter closure declares a compile-time value, similar to an alias declaration. That means parameter closures can be passed as parameters:\n\nfn take_func[f: fn() capturing -> Int]():\n    pass\n\nfn call_it(a: Int):\n    @parameter\n    fn inner() -> Int:\n        return a # capture 'a'\n\n    take_func[inner]() # pass 'inner' as a parameter\n\nParameter closures can even be parametric and capturing:\n\nfn take_func[f: fn[a: Int]() capturing -> Int]():\n    pass\n\nfn call_it(a: Int):\n    @parameter\n    fn inner[b: Int]() -> Int:\n        return a + b # capture 'a'\n\n    take_func[inner]() # pass 'inner' as a parameter\n\nHowever, note that parameter closures are always capture by unsafe reference. Mojo‚Äôs lifetime tracking is not yet sophisticated enough to form safe references to objects (see above section). This means that variable lifetimes need to be manually extended according to the lifetime of the parametric closure:\n\nfn print_it[f: fn() capturing -> String]():\n    print(f())\n\nfn call_it():\n    let s: String = \"hello world\"\n    @parameter\n    fn inner() -> String:\n        return s # 's' captured by reference, so a copy is made here\n    # lifetime tracker destroys 's' here\n\n    print_it[inner]() # crash! 's' has been destroyed\n\nThe lifetime of the variable can be manually extended by discarding it explicitly.\n\nfn call_it():\n    let s: String = \"hello world\"\n    @parameter\n    fn inner() -> String:\n        return s\n\n    print_it[inner]()\n    _ = s^ # discard 's' explicitly\n\nA quick note on the behaviour of ‚Äústateful‚Äù closures. One sharp edge here is that stateful closures are always capture-by-copy; Mojo lacks syntax for move-captures and the lifetime tracking necessary for capture-by-reference. Stateful closures are runtime values ‚Äì they cannot be passed as parameters, and they cannot be parametric. However, a nested function is promoted to a parametric closure if it does not capture anything. That is:\n\nfn foo0[f: fn() capturing -> String](): pass\nfn foo1[f: fn[a: Int]() capturing -> None](): pass\n\nfn main():\n    let s: String = \"hello world\"\n    fn stateful_captures() -> String:\n        return s # 's' is captured by copy\n\n    foo0[stateful_captures]() # not ok: 'stateful_captures' is not a parameter\n\n    fn stateful_nocapture[a: Int](): # ok: can be parametric, since no captures\n        print(a)\n\n    foo1[stateful_nocapture]() # ok: 'stateful_nocapture' is a parameter\nThe standard library has limited exceptions use\n\nFor historic and performance reasons, core standard library types typically do not use exceptions. For instance, DynamicVector will not raise an out-of-bounds access (it will crash), and Int does not throw on divide by zero. In other words, most standard library types are considered ‚Äúunsafe‚Äù.\n\nlet v = DynamicVector[Int](0)\nprint(v[1]) # could crash or print garbage values (undefined behaviour)\n\nprint(1//0) # does not raise and could print anything (undefined behaviour)\n\nThis is clearly unacceptable given the strong memory safety goals of Mojo. We will circle back to this when more language features and language-level optimizations are avaiable.\n\nNested functions cannot be recursive\n\nNested functions (any function that is not a top-level function) cannot be recursive in any way. Nested functions are considered ‚Äúparameters‚Äù, and although parameter values do not have to obey lexical order, their uses and definitions cannot form a cycle. Current limitations in Mojo mean that nested functions, which are considered parameter values, cannot be cyclic.\n\nfn try_recursion():\n    fn bar(x: Int): # error: circular reference :<\n        if x < 10:\n            bar(x + 1)\nOnly certain loaded MLIR dialects can be accessed\n\nAlthough Mojo provides features to access the full power of MLIR, in reality only a certain number of loaded MLIR dialects can be accessed in the Playground at the moment.\n\nThe upstream dialects available in the Playground are the index dialect and the LLVM dialect.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - mojo run",
    "url": "https://docs.modular.com/mojo/cli/run.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nSynopsis\nDescription\nOptions\nmojo run\n\nBuilds and executes a Mojo file.\n\nSynopsis\nmojo run [options] <path>\nDescription\n\nCompiles the Mojo file at the given path and immediately executes it. Another way to execute this command is to simply pass a file to mojo. For example:\n\nmojo hello.mojo\n\nOptions for this command itself, such as the ones listed below, must appear before the input file path argument. Any command line arguments that appear after the Mojo source file path are interpreted as arguments for that Mojo program.\n\nOptions\nCompilation options\n--no-optimization, -O0\n\nDisables compiler optimizations. This might reduce the amount of time it takes to compile the Mojo source file. It might also reduce the runtime performance of the compiled executable.\n\n--target-triple <TRIPLE>\n\nSets the compilation target triple. Defaults to the host target.\n\n--target-cpu <CPU>\n\nSets the compilation target CPU. Defaults to the host CPU.\n\n--target-features <FEATURES>\n\nSets the compilation target CPU features. Defaults to the host features.\n\n-march <ARCHITECTURE>\n\nSets the architecture to generate code for.\n\n-mcpu <CPU>\n\nSets the CPU to generate code for.\n\n-mtune <TUNE>\n\nSets the CPU to tune code for.\n\n-I <PATH>\n\nAppends the given path to the list of directories to search for imported Mojo files.\n\n-D <KEY=VALUE>\n\nDefines a named value that can be used from within the Mojo source file being executed. For example, -D foo=42 defines a name foo that, when queried with the sys.param_env module from within the Mojo program, would yield the compile-time value 42.\n\n--parsing-stdlib\n\nParses the input file(s) as the Mojo standard library.\n\nDiagnostic options\n--warn-missing-doc-strings\n\nEmits warnings for missing or partial docstrings.\n\n--max-notes-per-diagnostic <INTEGER>\n\nWhen the Mojo compiler emits diagnostics, it sometimes also prints notes with additional information. This option sets an upper threshold on the number of notes that can be printed with a diagnostic. If not specified, the default maximum is 10.\n\nExperimental compilation options\n--debug-level <LEVEL>\n\nSets the level of debug info to use at compilation. The value must be one of: none (the default value), line-tables, or full. Please note that there are issues when generating debug info for some Mojo programs that have yet to be addressed.\n\n--sanitize <CHECK>\n\nTurns on runtime checks. The following values are supported: address (detects memory issues), and thread (detects multi-threading issues). Please note that these checks are not currently supported when executing Mojo programs.\n\n--debug-info-language <LANGUAGE>\n\nSets the language to emit as part of the debug info. The supported languages are: Mojo, and C. C is the default, and is useful to enable rudimentary debugging and binary introspection in tools that don‚Äôt understand Mojo.\n\n--no-alnum-symbols\n\nDon‚Äôt emit mangled symbol names in alnum format.\n\nCommon options\n--help, -h\n\nDisplays help information.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - mojo repl",
    "url": "https://docs.modular.com/mojo/cli/repl.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nSynopsis\nDescription\nOptions\nmojo repl\n\nLaunches the Mojo REPL.\n\nSynopsis\nmojo repl [lldb-options]\nDescription\n\nLaunches a Mojo read-evaluate-print loop (REPL) environment, which provides interactive development in the terminal. You can also start the REPL by simply running mojo.\n\nAny number of options and arguments may be specified on the command line. These are then forwarded to the underlying lldb tool, which runs the REPL.\n\nOptions\nCommon options\n--help, -h\n\nDisplays help information.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - mojo package",
    "url": "https://docs.modular.com/mojo/cli/package.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nSynopsis\nDescription\nOptions\nmojo package\n\nCompiles a Mojo package.\n\nSynopsis\nmojo package [options] <path>\nDescription\n\nCompiles a directory of Mojo source files into a binary package suitable to share and import into other Mojo programs and modules.\n\nTo create a Mojo package, first add an __init__.mojo file to your package directory. Then pass that directory name to this command, and specify the output path and filename with -o.\n\nFor more information, see Mojo modules and packages.\n\nOptions\nOutput options\n-o <PATH>\n\nSets the path and filename for the output package. The filename must end with either .mojopkg or .üì¶. The filename given here defines the package name you can then use to import the code (minus the file extension). If you don‚Äôt specify this option, output is written to stdout.\n\nCompilation options\n--no-optimization, -O0\n\nDisables compiler optimizations. This might reduce the amount of time it takes to compile the Mojo source file. It might also reduce the runtime performance of the compiled executable.\n\n--target-triple <TRIPLE>\n\nSets the compilation target triple. Defaults to the host target.\n\n--target-cpu <CPU>\n\nSets the compilation target CPU. Defaults to the host CPU.\n\n--target-features <FEATURES>\n\nSets the compilation target CPU features. Defaults to the host features.\n\n-march <ARCHITECTURE>\n\nSets the architecture to generate code for.\n\n-mcpu <CPU>\n\nSets the CPU to generate code for.\n\n-mtune <TUNE>\n\nSets the CPU to tune code for.\n\n-I <PATH>\n\nAppends the given path to the list of directories to search for imported Mojo files.\n\n-D <KEY=VALUE>\n\nDefines a named value that can be used from within the Mojo source file being executed. For example, -D foo=42 defines a name foo that, when queried with the sys.param_env module from within the Mojo program, would yield the compile-time value 42.\n\n--parsing-stdlib\n\nParses the input file(s) as the Mojo standard library.\n\nDiagnostic options\n--warn-missing-doc-strings\n\nEmits warnings for missing or partial docstrings.\n\n--max-notes-per-diagnostic <INTEGER>\n\nWhen the Mojo compiler emits diagnostics, it sometimes also prints notes with additional information. This option sets an upper threshold on the number of notes that can be printed with a diagnostic. If not specified, the default maximum is 10.\n\nExperimental compilation options\n--debug-level <LEVEL>\n\nSets the level of debug info to use at compilation. The value must be one of: none (the default value), line-tables, or full. Please note that there are issues when generating debug info for some Mojo programs that have yet to be addressed.\n\n--sanitize <CHECK>\n\nTurns on runtime checks. The following values are supported: address (detects memory issues), and thread (detects multi-threading issues). Please note that these checks are not currently supported when executing Mojo programs.\n\n--debug-info-language <LANGUAGE>\n\nSets the language to emit as part of the debug info. The supported languages are: Mojo, and C. C is the default, and is useful to enable rudimentary debugging and binary introspection in tools that don‚Äôt understand Mojo.\n\n--no-alnum-symbols\n\nDon‚Äôt emit mangled symbol names in alnum format.\n\nCommon options\n--help, -h\n\nDisplays help information.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - mojo format",
    "url": "https://docs.modular.com/mojo/cli/format.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nSynopsis\nDescription\nOptions\nmojo format\n\nFormats Mojo source files.\n\nSynopsis\nmojo format [options] <sources...>\nDescription\n\nFormats the given set of Mojo sources using a Mojo-specific lint tool.\n\nOptions\nFormat options\n--line-length <INTEGER>, -l <INTEGER>\n\nSets the max character line length. Default is 80.\n\nDiagnostic options\n--quiet, -q\n\nDisables non-error messages.\n\nCommon options\n--help, -h\n\nDisplays help information.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - mojo doc",
    "url": "https://docs.modular.com/mojo/cli/doc.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nSynopsis\nDescription\nOptions\nmojo doc\n\nCompiles docstrings from a Mojo file.\n\nSynopsis\nmojo doc [options] <path>\nDescription\n\nThis is an early version of a documentation tool that generates an API reference from Mojo code comments. Currently, it generates a structured output of all docstrings into a JSON file, and it does not generate HTML. This output format is subject to change.\n\nThe input must be the path to a single Mojo source file.\n\nOptions\nOutput options\n-o <PATH>\n\nSets the path and filename for the JSON output. If not provided, output is written to stdout.\n\nCompilation options\n-I <PATH>\n\nAppends the given path to the list of directories that Mojo will search for any package/module dependencies. That is, if the file you pass to mojo doc imports any packages that do not reside in the local path and are not part of the Mojo standard library, use this to specify the path where Mojo can find those packages.\n\n--parsing-stdlib\n\nFor internal use only.\n\nValidation options\n\nThe following validation options help ensure that your docstrings use valid structure and meet other style criteria. By default, warnings are emitted only if the docstrings contain errors that prevent translation to the output format. (More options coming later.)\n\n--warn-missing-doc-strings\n\nEmits warnings for missing or partial docstrings.\n\nCommon options\n--help, -h\n\nDisplays help information.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - mojo demangle",
    "url": "https://docs.modular.com/mojo/cli/demangle.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nSynopsis\nDescription\nOptions\nmojo demangle\n\nDemangles the given name.\n\nSynopsis\nmojo demangle [options] <name>\nDescription\n\nIf the given name is a mangled Mojo symbol name, prints the demangled name. If no name is provided, one is read from standard input.\n\nOptions\nCommon options\n--help, -h\n\nDisplays help information.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - mojo debug",
    "url": "https://docs.modular.com/mojo/cli/debug.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nSynopsis\nDescription\nOptions\nmojo debug\n\nLaunches the LLDB debugger with support for debugging Mojo programs.\n\nSynopsis\nmojo debug [debug-options]\nDescription\n\nLaunches the LLDB debugger with support for debugging programs written in Mojo, as well as other standard languages like C and C++. This feature is still experimental.\n\nOptions\nCommon options\n--help, -h\n\nDisplays help information.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - mojo build",
    "url": "https://docs.modular.com/mojo/cli/build.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nSynopsis\nDescription\nOptions\nmojo build\n\nBuilds an executable from a Mojo file.\n\nSynopsis\nmojo build [options] <path>\nDescription\n\nCompiles the Mojo file at the given path into an executable.\n\nBy default, the executable is saved to the current directory and named the same as the input file, but without a file extension.\n\nOptions\nOutput options\n-o <PATH>\n\nSets the path and filename for the executable output. By default, it outputs the executable to the same location as the Mojo file, with the same name and no extension.\n\nCompilation options\n--no-optimization, -O0\n\nDisables compiler optimizations. This might reduce the amount of time it takes to compile the Mojo source file. It might also reduce the runtime performance of the compiled executable.\n\n--target-triple <TRIPLE>\n\nSets the compilation target triple. Defaults to the host target.\n\n--target-cpu <CPU>\n\nSets the compilation target CPU. Defaults to the host CPU.\n\n--target-features <FEATURES>\n\nSets the compilation target CPU features. Defaults to the host features.\n\n-march <ARCHITECTURE>\n\nSets the architecture to generate code for.\n\n-mcpu <CPU>\n\nSets the CPU to generate code for.\n\n-mtune <TUNE>\n\nSets the CPU to tune code for.\n\n-I <PATH>\n\nAppends the given path to the list of directories to search for imported Mojo files.\n\n-D <KEY=VALUE>\n\nDefines a named value that can be used from within the Mojo source file being executed. For example, -D foo=42 defines a name foo that, when queried with the sys.param_env module from within the Mojo program, would yield the compile-time value 42.\n\n--parsing-stdlib\n\nParses the input file(s) as the Mojo standard library.\n\nDiagnostic options\n--warn-missing-doc-strings\n\nEmits warnings for missing or partial docstrings.\n\n--max-notes-per-diagnostic <INTEGER>\n\nWhen the Mojo compiler emits diagnostics, it sometimes also prints notes with additional information. This option sets an upper threshold on the number of notes that can be printed with a diagnostic. If not specified, the default maximum is 10.\n\nExperimental compilation options\n--debug-level <LEVEL>\n\nSets the level of debug info to use at compilation. The value must be one of: none (the default value), line-tables, or full. Please note that there are issues when generating debug info for some Mojo programs that have yet to be addressed.\n\n--sanitize <CHECK>\n\nTurns on runtime checks. The following values are supported: address (detects memory issues), and thread (detects multi-threading issues). Please note that these checks are not currently supported when executing Mojo programs.\n\n--debug-info-language <LANGUAGE>\n\nSets the language to emit as part of the debug info. The supported languages are: Mojo, and C. C is the default, and is useful to enable rudimentary debugging and binary introspection in tools that don‚Äôt understand Mojo.\n\n--no-alnum-symbols\n\nDon‚Äôt emit mangled symbol names in alnum format.\n\nCommon options\n--help, -h\n\nDisplays help information.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - mojo",
    "url": "https://docs.modular.com/mojo/cli/",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nSynopsis\nDescription\nCommands\nOptions\nmojo\n\nThe Mojoüî• command line interface.\n\nSynopsis\nmojo <command>\nmojo [run-options] <path>\nmojo [options]\nmojo\nDescription\n\nThe mojo CLI provides all the tools you need for Mojo development, such as commands to run, compile, and package Mojo code. A list of all commands are listed below, and you can learn more about each one by adding the --help option to the command (for example, mojo package --help).\n\nHowever, you may omit the run and repl commands. That is, you can run a Mojo file by simply passing the filename to mojo:\n\nmojo hello.mojo\n\nAnd you can start a REPL session by running mojo with no commands.\n\nTo update Mojo to the latest version, use the modular tool:\n\nmodular update mojo\n\nYou can check your current version with mojo --version. For information about Mojo updates, see the Mojo changelog.\n\nCommands\n\nrun ‚Äî Builds and executes a Mojo file.\n\nbuild ‚Äî Builds an executable from a Mojo file.\n\nrepl ‚Äî Launches the Mojo REPL.\n\ndebug ‚Äî Launches the LLDB debugger with support for debugging Mojo programs.\n\npackage ‚Äî Compiles a Mojo package.\n\nformat ‚Äî Formats Mojo source files.\n\ndoc ‚Äî Compiles docstrings from a Mojo file.\n\ndemangle ‚Äî Demangles the given name.\n\nOptions\nDiagnostic options\n--version, -v\n\nPrints the Mojo version and exits.\n\nCommon options\n--help, -h\n\nDisplays help information.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - vector",
    "url": "https://docs.modular.com/mojo/stdlib/utils/vector.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nindex\nlist\nstatic_tuple\nvector\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nInlinedFixedVector\n__init__\n__copyinit__\n__getitem__\n__setitem__\ndeepcopy\nappend\n__len__\nclear\n__iter__\nUnsafeFixedVector\nDynamicVector\nvector\n\nModule\n\nDefines several vector-like classes.\n\nYou can import these APIs from the utils package. For example:\n\nfrom utils.vector import InlinedFixedVector\nInlinedFixedVector\n\nA dynamically-allocated vector with small-vector optimization and a fixed maximum capacity.\n\nThe InlinedFixedVector does not resize or implement bounds checks. It is initialized with both a small-vector size (specified at compile time) and a maximum capacity (specified at runtime).\n\nThe first size elements are stored in the statically-allocated small vector storage. Any remaining elements are stored in dynamically-allocated storage.\n\nWhen it is deallocated, it frees its memory.\n\nTODO: It should call its element destructors once we have traits.\n\nThis data structure is useful for applications where the number of required elements is not known at compile time, but once known at runtime, is guaranteed to be equal to or less than a certain capacity.\n\nParameters:\n\n‚Äãtype (AnyType): The type of the elements.\n‚Äãsize (Int): The statically-known small-vector size.\n\nAliases:\n\n‚Äãstatic_size = _68x20_size\n‚Äãstatic_data_type = StaticTuple[size, *\"type\"]\n\nFields:\n\n‚Äãstatic_data (StaticTuple[size, *\"type\"]): The underlying static storage, used for small vectors.\n‚Äãdynamic_data (Pointer[*\"type\"]): The underlying dynamic storage, used to grow large vectors.\n‚Äãcurrent_size (Int): The number of elements in the vector.\n‚Äãcapacity (Int): The maximum number of elements that can fit in the vector.\n\nFunctions:\n\n__init__\n\n__init__(inout self: Self, capacity: Int)\n\nConstructs InlinedFixedVector with the given capacity.\n\nThe dynamically allocated portion is capacity - size.\n\nArgs:\n\n‚Äãcapacity (Int): The requested maximum capacity of the vector.\n__copyinit__\n\n__copyinit__(inout self: Self, existing: Self)\n\nCreates a shallow copy (doesn‚Äôt copy the underlying elements).\n\nArgs:\n\n‚Äãexisting (Self): The InlinedFixedVector to copy.\n__getitem__\n\n__getitem__(self: Self, i: Int) -> *\"type\"\n\nGets a vector element at the given index.\n\nArgs:\n\n‚Äãi (Int): The index of the element.\n\nReturns:\n\nThe element at the given index.\n\n__setitem__\n\n__setitem__(inout self: Self, i: Int, *value: \"type\")\n\nSets a vector element at the given index.\n\nArgs:\n\n‚Äãi (Int): The index of the element.\n‚Äãvalue (*\"type\"): The value to assign.\ndeepcopy\n\ndeepcopy(self: Self) -> Self\n\nCreates a deep copy of this vector.\n\nReturns:\n\nThe created copy of this vector.\n\nappend\n\nappend(inout self: Self, *value: \"type\")\n\nAppends a value to this vector.\n\nArgs:\n\n‚Äãvalue (*\"type\"): The value to append.\n__len__\n\n__len__(self: Self) -> Int\n\nGets the number of elements in the vector.\n\nReturns:\n\nThe number of elements in the vector.\n\nclear\n\nclear(inout self: Self)\n\nClears the elements in the vector.\n\n__iter__\n\n__iter__(inout self: Self) -> _VecIter[*\"type\", InlinedFixedVector[*\"type\", size], _deref_iter_impl[*\"type\", size]]\n\nIterate over the vector.\n\nReturns:\n\nAn iterator to the start of the vector.\n\nUnsafeFixedVector\n\nThe UnsafeFixedVector type is a dynamically-allocated vector that does not resize or implement bounds checks.\n\nIt is initialized with a dynamic (not known at compile time) number of slots, and when it is deallocated, it frees its memory.\n\nTODO: It should call its element destructors once we have traits.\n\nThis data structure is useful for applications where the number of required elements is not known at compile time, but once known at runtime, is guaranteed to be equal to or less than a certain capacity.\n\nParameters:\n\n‚Äãtype (AnyType): The type of the elements.\n\nFields:\n\n‚Äãdata (Pointer[*\"type\"]): The underlying storage for the vector.\n‚Äãsize (Int): The number of elements in the vector.\n‚Äãcapacity (Int): The amount of elements that can fit in the vector.\n\nFunctions:\n\n__init__\n\n__init__(inout self: Self, capacity: Int)\n\nConstructs UnsafeFixedVector with the given capacity.\n\nArgs:\n\n‚Äãcapacity (Int): The requested capacity of the vector.\n__copyinit__\n\n__copyinit__(inout self: Self, existing: Self)\n\nCreates a shallow copy (it doesn‚Äôt copy the data).\n\nArgs:\n\n‚Äãexisting (Self): The UnsafeFixedVector to copy.\n__getitem__\n\n__getitem__(self: Self, i: Int) -> *\"type\"\n\nGets a vector element at the given index.\n\nArgs:\n\n‚Äãi (Int): The index of the element.\n\nReturns:\n\nThe element at the given index.\n\n__setitem__\n\n__setitem__(self: Self, i: Int, *value: \"type\")\n\nSets a vector element at the given index.\n\nArgs:\n\n‚Äãi (Int): The index of the element.\n‚Äãvalue (*\"type\"): The value to assign.\n__len__\n\n__len__(self: Self) -> Int\n\nGets the number of elements in the vector.\n\nReturns:\n\nThe number of elements in the vector.\n\nappend\n\nappend(inout self: Self, *value: \"type\")\n\nAppends a value to this vector.\n\nArgs:\n\n‚Äãvalue (*\"type\"): The value to append.\nclear\n\nclear(inout self: Self)\n\nClears the elements in the vector.\n\nDynamicVector\n\nThe DynamicVector type is a dynamically-allocated vector.\n\nIt supports pushing and popping from the back resizing the underlying storage as needed. When it is deallocated, it frees its memory.\n\nTODO: It should call its element destructors once we have traits. TODO: It should perform bound checks.\n\nParameters:\n\n‚Äãtype (AnyType): The type of the elements.\n\nFields:\n\n‚Äãdata (Pointer[*\"type\"]): The underlying storage for the vector.\n‚Äãsize (Int): The number of elements in the vector.\n‚Äãcapacity (Int): The amount of elements that can fit in the vector without resizing it.\n\nFunctions:\n\n__init__\n\n__init__(inout self: Self)\n\nConstructs an empty vector.\n\n__init__(inout self: Self, capacity: Int)\n\nConstructs a vector with the given capacity.\n\nArgs:\n\n‚Äãcapacity (Int): The requested capacity of the vector.\n\n__init__(inout self: Self, pointer: Pointer[*\"type\"], size: Int)\n\nConstructs a vector with the given pointer and size.\n\nArgs:\n\n‚Äãpointer (Pointer[*\"type\"]): The pointer to the buffer.\n‚Äãsize (Int): The size of the buffer.\n__copyinit__\n\n__copyinit__(inout self: Self, existing: Self)\n\nCreates a shallow copy (it doesn‚Äôt copy the data).\n\nArgs:\n\n‚Äãexisting (Self): The DynamicVector to copy.\n__getitem__\n\n__getitem__(self: Self, i: Int) -> *\"type\"\n\nGets a vector element at the given index.\n\nArgs:\n\n‚Äãi (Int): The index of the element.\n\nReturns:\n\nThe element at the given index.\n\n__setitem__\n\n__setitem__(inout self: Self, i: Int, *value: \"type\")\n\nSets a vector element at the given index.\n\nArgs:\n\n‚Äãi (Int): The index of the element.\n‚Äãvalue (*\"type\"): The value to assign.\n__len__\n\n__len__(self: Self) -> Int\n\nGets the number of elements in the vector.\n\nReturns:\n\nThe number of elements in the vector.\n\nresize\n\nresize(inout self: Self, size: Int)\n\nResizes the vector to the given new size.\n\nIf the new size is smaller than the current one, elements at the end are discarded. If the new size is larger than the current one, the vector is appended with non-initialized elements up to the requested size.\n\nArgs:\n\n‚Äãsize (Int): The new size.\ndeepcopy\n\ndeepcopy(self: Self) -> Self\n\nCreates a deepcopy of this vector.\n\nReturns:\n\nThe created copy of this vector.\n\nreserve\n\nreserve(inout self: Self, new_capacity: Int)\n\nReserves the requested capacity.\n\nIf the current capacity is greater or equal, this is a no-op. Otherwise, the storage is reallocated and the date is moved.\n\nArgs:\n\n‚Äãnew_capacity (Int): The new capacity.\npush_back\n\npush_back(inout self: Self, *value: \"type\")\n\nAppends a value to this vector.\n\nArgs:\n\n‚Äãvalue (*\"type\"): The value to append.\npop_back\n\npop_back(inout self: Self) -> *\"type\"\n\nPops a value from the back of this vector.\n\nReturns:\n\nThe popped value.\n\nclear\n\nclear(inout self: Self)\n\nClears the elements in the vector.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - static_tuple",
    "url": "https://docs.modular.com/mojo/stdlib/utils/static_tuple.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nindex\nlist\nstatic_tuple\nvector\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nStaticTuple\n__init__\n__getitem__\n__setitem__\n__len__\nstatic_tuple\n\nModule\n\nImplements StaticTuple, a statically-sized uniform container.\n\nYou can import these APIs from the utils package. For example:\n\nfrom utils.static_tuple import StaticTuple\nStaticTuple\n\nA statically sized tuple type which contains elements of homogeneous types.\n\nParameters:\n\n‚Äãsize (Int): The size of the tuple.\n‚Äã_element_type (AnyType): The type of the elements in the tuple.\n\nAliases:\n\n‚Äãelement_type = _88x31__element_type\n‚Äãtype = array<#lit.struct.extract<:!kgen.declref<@\"$builtin\"::@\"$int\"::@Int, !lit.metatype<@\"$builtin\"::@\"$int\"::@Int>> size, \"value\">, _element_type>\n\nFields:\n\n‚Äãarray (array<#lit.struct.extract<:!kgen.declref<@\"$builtin\"::@\"$int\"::@Int, !lit.metatype<@\"$builtin\"::@\"$int\"::@Int>> size, \"value\">, _element_type>): The underlying storage for the static tuple.\n\nFunctions:\n\n__init__\n\n__init__() -> Self\n\nConstructs an empty (undefined) tuple.\n\nReturns:\n\nThe tuple.\n\n__init__(*elems: _element_type) -> Self\n\nConstructs a static tuple given a set of arguments.\n\nArgs:\n\n‚Äãelems (*_element_type): The element types.\n\nReturns:\n\nThe tuple.\n\n__init__(values: VariadicList[_element_type]) -> Self\n\nCreates a tuple constant using the specified values.\n\nArgs:\n\n‚Äãvalues (VariadicList[_element_type]): The list of values.\n\nReturns:\n\nA tuple with the values filled in.\n\n__init__(array: array<#lit.struct.extract<:!kgen.declref<_\"$builtin\"::_\"$int\"::_Int, !lit.metatype<_\"$builtin\"::_\"$int\"::_Int>> size, \"value\">, _element_type>, /) -> Self\n\n__getitem__\n\n__getitem__[index: Int](self: Self) -> _element_type\n\nReturns the value of the tuple at the given index.\n\nParameters:\n\n‚Äãindex (Int): The index into the tuple.\n\nReturns:\n\nThe value at the specified position.\n\n__getitem__(self: Self, index: Int) -> _element_type\n\nReturns the value of the tuple at the given dynamic index.\n\nArgs:\n\n‚Äãindex (Int): The index into the tuple.\n\nReturns:\n\nThe value at the specified position.\n\n__setitem__\n\n__setitem__[index: Int](inout self: Self, val: _element_type)\n\nStores a single value into the tuple at the specified index.\n\nParameters:\n\n‚Äãindex (Int): The index into the tuple.\n\nArgs:\n\n‚Äãval (_element_type): The value to store.\n\n__setitem__(inout self: Self, index: Int, val: _element_type)\n\nStores a single value into the tuple at the specified dynamic index.\n\nArgs:\n\n‚Äãindex (Int): The index into the tuple.\n‚Äãval (_element_type): The value to store.\n__len__\n\n__len__(self: Self) -> Int\n\nReturns the length of the array. This is a known constant value.\n\nReturns:\n\nThe size of the list.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - list",
    "url": "https://docs.modular.com/mojo/stdlib/utils/list.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nindex\nlist\nstatic_tuple\nvector\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nDim\n__init__\n__bool__\n__eq__\n__mul__\nhas_value\nis_dynamic\nget\nis_multiple\nDimList\nlist\n\nModule\n\nProvides utilities for working with static and variadic lists.\n\nYou can import these APIs from the utils package. For example:\n\nfrom utils.list import Dim\nDim\n\nA static or dynamic dimension modeled with an optional integer.\n\nThis class is meant to represent an optional static dimension. When a value is present, the dimension has that static value. When a value is not present, the dimension is dynamic.\n\nAliases:\n\n‚Äãtype = Variant[i1, Int]\n\nFields:\n\n‚Äãvalue (Variant[i1, Int]): Either a boolean indicating that the dimension is dynamic, or the static value of the dimension.\n\nFunctions:\n\n__init__\n\n__init__(value: Int) -> Self\n\nCreates a statically-known dimension.\n\nArgs:\n\n‚Äãvalue (Int): The static dimension value.\n\nReturns:\n\nA dimension with a static value.\n\n__init__(value: index) -> Self\n\nCreates a statically-known dimension.\n\nArgs:\n\n‚Äãvalue (index): The static dimension value.\n\nReturns:\n\nA dimension with a static value.\n\n__init__() -> Self\n\nCreates a dynamic dimension.\n\nReturns:\n\nA dimension value with no static value.\n\n__init__(value: Variant[i1, Int], /) -> Self\n\n__bool__\n\n__bool__(self: Self) -> Bool\n\nReturns True if the dimension has a static value.\n\nReturns:\n\nWhether the dimension has a static value.\n\n__eq__\n\n__eq__(self: Self, rhs: Self) -> Bool\n\nCompares two dimensions for equality.\n\nArgs:\n\n‚Äãrhs (Self): The other dimension.\n\nReturns:\n\nTrue if the dimensions are the same.\n\n__mul__\n\n__mul__(self: Self, rhs: Self) -> Self\n\nMultiplies two dimensions.\n\nIf either are unknown, the result is unknown as well.\n\nArgs:\n\n‚Äãrhs (Self): The other dimension.\n\nReturns:\n\nThe product of the two dimensions.\n\nhas_value\n\nhas_value(self: Self) -> Bool\n\nReturns True if the dimension has a static value.\n\nReturns:\n\nWhether the dimension has a static value.\n\nis_dynamic\n\nis_dynamic(self: Self) -> Bool\n\nReturns True if the dimension has a dynamic value.\n\nReturns:\n\nWhether the dimension is dynamic.\n\nget\n\nget(self: Self) -> Int\n\nGets the static dimension value.\n\nReturns:\n\nThe static dimension value.\n\nis_multiple\n\nis_multiple[alignment: Int](self: Self) -> Bool\n\nChecks if the dimension is aligned.\n\nParameters:\n\n‚Äãalignment (Int): The alignment requirement.\n\nReturns:\n\nWhether the dimension is aligned.\n\nDimList\n\nThis type represents a list of dimensions. Each dimension may have a static value or not have a value, which represents a dynamic dimension.\n\nFields:\n\n‚Äãvalue (VariadicList[Dim]): The underlying storage for the list of dimensions.\n\nFunctions:\n\n__init__\n\n__init__(values: VariadicList[Dim]) -> Self\n\nCreates a dimension list from the given list of values.\n\nArgs:\n\n‚Äãvalues (VariadicList[Dim]): The initial dim values list.\n\nReturns:\n\nA dimension list.\n\n__init__(*values: Dim) -> Self\n\nCreates a dimension list from the given Dim values.\n\nArgs:\n\n‚Äãvalues (*Dim): The initial dim values.\n\nReturns:\n\nA dimension list.\n\n__len__\n\n__len__(self: Self) -> Int\n\nGets the size of the DimList.\n\nReturns:\n\nThe number of elements in the DimList.\n\nat\n\nat[i: Int](self: Self) -> Dim\n\nGets the dimension at a specified index.\n\nParameters:\n\n‚Äãi (Int): The dimension index.\n\nReturns:\n\nThe dimension at the specified index.\n\nproduct\n\nproduct[length: Int](self: Self) -> Dim\n\nComputes the product of all the dimensions in the list.\n\nIf any are dynamic, the result is a dynamic dimension value.\n\nParameters:\n\n‚Äãlength (Int): The number of elements in the list.\n\nReturns:\n\nThe product of all the dimensions.\n\nproduct_range\n\nproduct_range[start: Int, end: Int](self: Self) -> Dim\n\nComputes the product of a range of the dimensions in the list.\n\nIf any in the range are dynamic, the result is a dynamic dimension value.\n\nParameters:\n\n‚Äãstart (Int): The starting index.\n‚Äãend (Int): The end index.\n\nReturns:\n\nThe product of all the dimensions.\n\ncontains\n\ncontains[length: Int](self: Self, value: Dim) -> Bool\n\nDetermines whether the dimension list contains a specified dimension value.\n\nParameters:\n\n‚Äãlength (Int): The number of elements in the list.\n\nArgs:\n\n‚Äãvalue (Dim): The value to find.\n\nReturns:\n\nTrue if the list contains a dimension of the specified value.\n\nall_known\n\nall_known[length: Int](self: Self) -> Bool\n\nDetermines whether all dimensions are statically known.\n\nParameters:\n\n‚Äãlength (Int): The number of elements in the list.\n\nReturns:\n\nTrue if all dimensions have a static value.\n\ncreate_unknown\n\ncreate_unknown[length: Int]() -> Self\n\nCreates a dimension list of all dynamic dimension values.\n\nParameters:\n\n‚Äãlength (Int): The number of elements in the list.\n\nReturns:\n\nA list of all dynamic dimension values.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - index",
    "url": "https://docs.modular.com/mojo/stdlib/utils/index_.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nindex\nlist\nstatic_tuple\nvector\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nStaticIntTuple\n__init__\n__getitem__\n__setitem__\n__lt__\n__le__\n__eq__\n__ne__\n__gt__\n__ge__\n__add__\n__sub__\n__mul__\n__floordiv__\n__len__\nas_tuple\nflattened_length\nremu\nIndex\nproduct\nindex\n\nModule\n\nImplements StaticIntTuple which is commonly used to represent N-D indices.\n\nYou can import these APIs from the utils package. For example:\n\nfrom utils.index import StaticIntTuple\n\nAliases:\n\n‚Äãmlir_bool = scalar<bool>\nStaticIntTuple\n\nA base struct that implements size agnostic index functions.\n\nParameters:\n\n‚Äãsize (Int): The size of the tuple.\n\nFields:\n\n‚Äãdata (StaticTuple[size, Int]): The underlying storage of the tuple value.\n\nFunctions:\n\n__init__\n\n__init__() -> Self\n\nConstructs a static int tuple of the given size.\n\nReturns:\n\nThe constructed tuple.\n\n__init__(value: index) -> Self\n\nConstructs a sized 1 static int tuple of given the element value.\n\nArgs:\n\n‚Äãvalue (index): The initial value.\n\nReturns:\n\nThe constructed tuple.\n\n__init__(*elems: Int) -> Self\n\nConstructs a static int tuple given a set of arguments.\n\nArgs:\n\n‚Äãelems (*Int): The elements to construct the tuple.\n\nReturns:\n\nThe constructed tuple.\n\n__init__(elem: Int) -> Self\n\nConstructs a static int tuple given a set of arguments.\n\nArgs:\n\n‚Äãelem (Int): The elem to splat into the tuple.\n\nReturns:\n\nThe constructed tuple.\n\n__init__(values: VariadicList[Int]) -> Self\n\nCreates a tuple constant using the specified values.\n\nArgs:\n\n‚Äãvalues (VariadicList[Int]): The list of values.\n\nReturns:\n\nA tuple with the values filled in.\n\n__init__(values: DimList) -> Self\n\nCreates a tuple constant using the specified values.\n\nArgs:\n\n‚Äãvalues (DimList): The list of values.\n\nReturns:\n\nA tuple with the values filled in.\n\n__init__(data: StaticTuple[size, Int], /) -> Self\n\n__getitem__\n\n__getitem__(self: Self, index: Int) -> Int\n\nGets an element from the tuple by index.\n\nArgs:\n\n‚Äãindex (Int): The element index.\n\nReturns:\n\nThe tuple element value.\n\n__setitem__\n\n__setitem__[index: Int](inout self: Self, val: Int)\n\nSets an element in the tuple at the given static index.\n\nParameters:\n\n‚Äãindex (Int): The element index.\n\nArgs:\n\n‚Äãval (Int): The value to store.\n\n__setitem__(inout self: Self, index: Int, val: Int)\n\nSets an element in the tuple at the given index.\n\nArgs:\n\n‚Äãindex (Int): The element index.\n‚Äãval (Int): The value to store.\n__lt__\n\n__lt__(self: Self, rhs: Self) -> Bool\n\nCompares this tuple to another tuple using LT comparison.\n\nA tuple is less-than another tuple if all corresponding elements of lhs is less than rhs.\n\nNote: This is not a lexical comparison.\n\nArgs:\n\n‚Äãrhs (Self): Right hand side tuple.\n\nReturns:\n\nThe comparison result.\n\n__le__\n\n__le__(self: Self, rhs: Self) -> Bool\n\nCompares this tuple to another tuple using LE comparison.\n\nA tuple is less-or-equal than another tuple if all corresponding elements of lhs is less-or-equal than rhs.\n\nNote: This is not a lexical comparison.\n\nArgs:\n\n‚Äãrhs (Self): Right hand side tuple.\n\nReturns:\n\nThe comparison result.\n\n__eq__\n\n__eq__(self: Self, rhs: Self) -> Bool\n\nCompares this tuple to another tuple for equality.\n\nThe tuples are equal if all corresponding elements are equal.\n\nArgs:\n\n‚Äãrhs (Self): The other tuple.\n\nReturns:\n\nThe comparison result.\n\n__ne__\n\n__ne__(self: Self, rhs: Self) -> Bool\n\nCompares this tuple to another tuple for non-equality.\n\nThe tuples are non-equal if at least one element of LHS isn‚Äôt equal to the corresponding element from RHS.\n\nArgs:\n\n‚Äãrhs (Self): The other tuple.\n\nReturns:\n\nThe comparison result.\n\n__gt__\n\n__gt__(self: Self, rhs: Self) -> Bool\n\nCompares this tuple to another tuple using GT comparison.\n\nA tuple is greater-than than another tuple if all corresponding elements of lhs is greater-than than rhs.\n\nNote: This is not a lexical comparison.\n\nArgs:\n\n‚Äãrhs (Self): Right hand side tuple.\n\nReturns:\n\nThe comparison result.\n\n__ge__\n\n__ge__(self: Self, rhs: Self) -> Bool\n\nCompares this tuple to another tuple using GE comparison.\n\nA tuple is greater-or-equal than another tuple if all corresponding elements of lhs is greater-or-equal than rhs.\n\nNote: This is not a lexical comparison.\n\nArgs:\n\n‚Äãrhs (Self): Right hand side tuple.\n\nReturns:\n\nThe comparison result.\n\n__add__\n\n__add__(self: Self, rhs: Self) -> Self\n\nPerforms element-wise integer add.\n\nArgs:\n\n‚Äãrhs (Self): Right hand side operand.\n\nReturns:\n\nThe resulting index tuple.\n\n__sub__\n\n__sub__(self: Self, rhs: Self) -> Self\n\nPerforms element-wise integer subtract.\n\nArgs:\n\n‚Äãrhs (Self): Right hand side operand.\n\nReturns:\n\nThe resulting index tuple.\n\n__mul__\n\n__mul__(self: Self, rhs: Self) -> Self\n\nPerforms element-wise integer multiply.\n\nArgs:\n\n‚Äãrhs (Self): Right hand side operand.\n\nReturns:\n\nThe resulting index tuple.\n\n__floordiv__\n\n__floordiv__(self: Self, rhs: Self) -> Self\n\nPerforms element-wise integer floor division.\n\nArgs:\n\n‚Äãrhs (Self): Right hand side operand.\n\nReturns:\n\nThe resulting index tuple.\n\n__len__\n\n__len__(self: Self) -> Int\n\nReturns the size of the tuple.\n\nReturns:\n\nThe tuple size.\n\nas_tuple\n\nas_tuple(self: Self) -> StaticTuple[size, Int]\n\nConverts this StaticIntTuple to StaticTuple.\n\nReturns:\n\nThe corresponding StaticTuple object.\n\nflattened_length\n\nflattened_length(self: Self) -> Int\n\nReturns the flattened length of the tuple.\n\nReturns:\n\nThe flattened length of the tuple.\n\nremu\n\nremu(self: Self, rhs: Self) -> Self\n\nPerforms element-wise integer unsigned modulo.\n\nArgs:\n\n‚Äãrhs (Self): Right hand side operand.\n\nReturns:\n\nThe resulting index tuple.\n\nIndex\n\nIndex(x: Int) -> StaticIntTuple[1]\n\nConstructs a 1-D Index from the given value.\n\nArgs:\n\n‚Äãx (Int): The initial value.\n\nReturns:\n\nThe constructed StaticIntTuple.\n\nIndex(x: Int, y: Int) -> StaticIntTuple[2]\n\nConstructs a 2-D Index from the given values.\n\nArgs:\n\n‚Äãx (Int): The 1st initial value.\n‚Äãy (Int): The 2nd initial value.\n\nReturns:\n\nThe constructed StaticIntTuple.\n\nIndex(x: Int, y: Int, z: Int) -> StaticIntTuple[3]\n\nConstructs a 3-D Index from the given values.\n\nArgs:\n\n‚Äãx (Int): The 1st initial value.\n‚Äãy (Int): The 2nd initial value.\n‚Äãz (Int): The 3nd initial value.\n\nReturns:\n\nThe constructed StaticIntTuple.\n\nIndex(x: Int, y: Int, z: Int, w: Int) -> StaticIntTuple[4]\n\nConstructs a 4-D Index from the given values.\n\nArgs:\n\n‚Äãx (Int): The 1st initial value.\n‚Äãy (Int): The 2nd initial value.\n‚Äãz (Int): The 3nd initial value.\n‚Äãw (Int): The 4th initial value.\n\nReturns:\n\nThe constructed StaticIntTuple.\n\nIndex(x: Int, y: Int, z: Int, w: Int, v: Int) -> StaticIntTuple[5]\n\nConstructs a 5-D Index from the given values.\n\nArgs:\n\n‚Äãx (Int): The 1st initial value.\n‚Äãy (Int): The 2nd initial value.\n‚Äãz (Int): The 3nd initial value.\n‚Äãw (Int): The 4th initial value.\n‚Äãv (Int): The 5th initial value.\n\nReturns:\n\nThe constructed StaticIntTuple.\n\nproduct\n\nproduct[size: Int](tuple: StaticIntTuple[size], end_idx: Int) -> Int\n\nComputes a product of values in the tuple up to the given index.\n\nParameters:\n\n‚Äãsize (Int): The tuple size.\n\nArgs:\n\n‚Äãtuple (StaticIntTuple[size]): The tuple to get a product of.\n‚Äãend_idx (Int): The end index.\n\nReturns:\n\nThe product of all tuple elements in the given range.\n\nproduct[size: Int](tuple: StaticIntTuple[size], start_idx: Int, end_idx: Int) -> Int\n\nComputes a product of values in the tuple in the given index range.\n\nParameters:\n\n‚Äãsize (Int): The tuple size.\n\nArgs:\n\n‚Äãtuple (StaticIntTuple[size]): The tuple to get a product of.\n‚Äãstart_idx (Int): The start index of the range.\n‚Äãend_idx (Int): The end index of the range.\n\nReturns:\n\nThe product of all tuple elements in the given range.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - time",
    "url": "https://docs.modular.com/mojo/stdlib/time/time.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nnow\ntime_function\nsleep\ntime\n\nModule\n\nImplements basic utils for working with time.\n\nYou can import these APIs from the time package. For example:\n\nfrom time import now\nnow\n\nnow() -> Int\n\nReturns the current monotonic time time in nanoseconds. This function queries the current platform‚Äôs monotonic clock, making it useful for measuring time differences, but the significance of the returned value varies depending on the underlying implementation.\n\nReturns:\n\nThe current time in ns.\n\ntime_function\n\ntime_function[func: fn() capturing -> None]() -> Int\n\nMeasures the time spent in the function.\n\nParameters:\n\n‚Äãfunc (fn() capturing -> None): The function to time.\n\nReturns:\n\nThe time elapsed in the function in ns.\n\nsleep\n\nsleep(sec: SIMD[f64, 1])\n\nSuspends the current thread for the seconds specified.\n\nArgs:\n\n‚Äãsec (SIMD[f64, 1]): The number of seconds to sleep for.\n\nsleep(sec: Int)\n\nSuspends the current thread for the seconds specified.\n\nArgs:\n\n‚Äãsec (Int): The number of seconds to sleep for.\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - testing",
    "url": "https://docs.modular.com/mojo/stdlib/testing/testing.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nassert_true\nassert_false\nassert_equal\nassert_not_equal\nassert_almost_equal\ntesting\n\nModule\n\nImplements various testing utils.\n\nYou can import these APIs from the testing package. For example:\n\nfrom testing import assert_true\nassert_true\n\nassert_true(val: Bool, msg: String) -> Bool\n\nAsserts that the input value is True. If it is not then a message is printed which contains the input message.\n\nArgs:\n\n‚Äãval (Bool): The value to assert to be True.\n‚Äãmsg (String): The message to be printed if the assertion fails.\n\nReturns:\n\nTrue if the assert succeeds and False otherwise.\n\nassert_false\n\nassert_false(val: Bool, msg: String) -> Bool\n\nAsserts that the input value is False. If it is not then a message is printed which contains the input message.\n\nArgs:\n\n‚Äãval (Bool): The value to assert to be False.\n‚Äãmsg (String): The message to be printed if the assertion fails.\n\nReturns:\n\nTrue if the assert succeeds and False otherwise.\n\nassert_false(val: Bool) -> Bool\n\nAsserts that the input value is False. If it is not then a message is printed.\n\nArgs:\n\n‚Äãval (Bool): The value to assert to be False.\n\nReturns:\n\nTrue if the assert succeeds and False otherwise.\n\nassert_equal\n\nassert_equal(lhs: Int, rhs: Int) -> Bool\n\nAsserts that the input values are equal. If it is not then a message is printed.\n\nArgs:\n\n‚Äãlhs (Int): The lhs of the equality.\n‚Äãrhs (Int): The rhs of the equality.\n\nReturns:\n\nTrue if the assert succeeds and False otherwise.\n\nassert_equal(lhs: String, rhs: String) -> Bool\n\nAsserts that the input values are equal. If it is not then a message is printed.\n\nArgs:\n\n‚Äãlhs (String): The lhs of the equality.\n‚Äãrhs (String): The rhs of the equality.\n\nReturns:\n\nTrue if the assert succeeds and False otherwise.\n\nassert_equal[type: DType, size: Int](lhs: SIMD[type, size], rhs: SIMD[type, size]) -> Bool\n\nAsserts that the input values are equal. If it is not then a message is printed.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the left- and right-hand-side SIMD vectors.\n‚Äãsize (Int): The width of the left- and right-hand-side SIMD vectors.\n\nArgs:\n\n‚Äãlhs (SIMD[type, size]): The lhs of the equality.\n‚Äãrhs (SIMD[type, size]): The rhs of the equality.\n\nReturns:\n\nTrue if the assert succeeds and False otherwise.\n\nassert_not_equal\n\nassert_not_equal(lhs: Int, rhs: Int) -> Bool\n\nAsserts that the input values are not equal. If it is not then a message is printed.\n\nArgs:\n\n‚Äãlhs (Int): The lhs of the inequality.\n‚Äãrhs (Int): The rhs of the inequality.\n\nReturns:\n\nTrue if the assert succeeds and False otherwise.\n\nassert_not_equal(lhs: String, rhs: String) -> Bool\n\nAsserts that the input values are not equal. If it is not then a message is printed.\n\nArgs:\n\n‚Äãlhs (String): The lhs of the inequality.\n‚Äãrhs (String): The rhs of the inequality.\n\nReturns:\n\nTrue if the assert succeeds and False otherwise.\n\nassert_not_equal[type: DType, size: Int](lhs: SIMD[type, size], rhs: SIMD[type, size]) -> Bool\n\nAsserts that the input values are not equal. If it is not then a message is printed.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the left- and right-hand-side SIMD vectors.\n‚Äãsize (Int): The width of the left- and right-hand-side SIMD vectors.\n\nArgs:\n\n‚Äãlhs (SIMD[type, size]): The lhs of the inequality.\n‚Äãrhs (SIMD[type, size]): The rhs of the inequality.\n\nReturns:\n\nTrue if the assert succeeds and False otherwise.\n\nassert_almost_equal\n\nassert_almost_equal[type: DType, size: Int](lhs: SIMD[type, size], rhs: SIMD[type, size]) -> Bool\n\nAsserts that the input values are equal up to a tolerance. If it is not then a message is printed.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the left- and right-hand-side SIMD vectors.\n‚Äãsize (Int): The width of the left- and right-hand-side SIMD vectors.\n\nArgs:\n\n‚Äãlhs (SIMD[type, size]): The lhs of the equality.\n‚Äãrhs (SIMD[type, size]): The rhs of the equality.\n\nReturns:\n\nTrue if the assert succeeds and False otherwise.\n\nassert_almost_equal[type: DType, size: Int](lhs: SIMD[type, size], rhs: SIMD[type, size], absolute_tolerance: SIMD[type, 1], relative_tolerance: SIMD[type, 1]) -> Bool\n\nAsserts that the input values are equal up to a tolerance. If it is not then a message is printed.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the left- and right-hand-side SIMD vectors.\n‚Äãsize (Int): The width of the left- and right-hand-side SIMD vectors.\n\nArgs:\n\n‚Äãlhs (SIMD[type, size]): The lhs of the equality.\n‚Äãrhs (SIMD[type, size]): The rhs of the equality.\n‚Äãabsolute_tolerance (SIMD[type, 1]): The absolute tolerance.\n‚Äãrelative_tolerance (SIMD[type, 1]): The relative tolerance.\n\nReturns:\n\nTrue if the assert succeeds and False otherwise.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - tensor_spec",
    "url": "https://docs.modular.com/mojo/stdlib/tensor/tensor_spec.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntensor\ntensor_shape\ntensor_spec\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nTensorSpec\n__init__\n__copyinit__\n__moveinit__\n__del__\n__getitem__\n__eq__\n__ne__\nrank\ndtype\nnum_elements\nbytecount\n__repr__\n__str__\ntensor_spec\n\nModule\n\nImplements the TensorSpec type.\n\nYou can import these APIs from the tensor package. For example:\n\nfrom tensor import TensorSpec\nTensorSpec\n\nA space efficient representation of a tensor shape and dtype. This struct implements value semantics and owns its underlying data.\n\nFields:\n\n‚Äãshape (TensorShape): The underlying shape of the specification.\n\nFunctions:\n\n__init__\n\n__init__(inout self: Self)\n\nDefault initializer for TensorShape.\n\n__init__(inout self: Self, type: DType, *shapes: Int)\n\nInitializes a Tensorspec from the dtype and shapes provided.\n\nArgs:\n\n‚Äãtype (DType): The dtype of the specification.\n‚Äãshapes (*Int): The shapes to initialize the shape with.\n\n__init__(inout self: Self, type: DType, shapes: VariadicList[Int])\n\nInitializes a Tensorspec from the dtype and shapes provided.\n\nArgs:\n\n‚Äãtype (DType): The dtype of the specification.\n‚Äãshapes (VariadicList[Int]): The shapes to initialize the shape with.\n\n__init__(inout self: Self, type: DType, shapes: DynamicVector[Int])\n\nInitializes a Tensorspec from the dtype and shapes provided.\n\nArgs:\n\n‚Äãtype (DType): The dtype of the specification.\n‚Äãshapes (DynamicVector[Int]): The shapes to initialize the shape with.\n\n__init__(inout self: Self, type: DType, owned shape: TensorShape)\n\nInitializes a Tensorspec from the dtype and shape provided.\n\nArgs:\n\n‚Äãtype (DType): The dtype of the specification.\n‚Äãshape (TensorShape): The shapes to initialize the shape with.\n__copyinit__\n\n__copyinit__(inout self: Self, other: Self)\n\nCreates a deep copy of an existing spec.\n\nArgs:\n\n‚Äãother (Self): The spec to copy.\n__moveinit__\n\n__moveinit__(inout self: Self, owned existing: Self)\n\nMove initializer for the spec.\n\nArgs:\n\n‚Äãexisting (Self): The spec to move.\n__del__\n\n__del__(owned self: Self)\n\n__getitem__\n\n__getitem__(self: Self, index: Int) -> Int\n\nGets the dimension at the specified index.\n\nArgs:\n\n‚Äãindex (Int): The dimension index.\n\nReturns:\n\nThe dimension at the specified index.\n\n__eq__\n\n__eq__(self: Self, other: Self) -> Bool\n\nReturns True if the two values are the same and False otherwise.\n\nArgs:\n\n‚Äãother (Self): The other TensorSpec to compare against.\n\nReturns:\n\nTrue if the two specs are the same and False otherwise.\n\n__ne__\n\n__ne__(self: Self, other: Self) -> Bool\n\nReturns True if the two values are not the same and False otherwise.\n\nArgs:\n\n‚Äãother (Self): The other TensorSpec to compare against.\n\nReturns:\n\nTrue if the two specs are the not the same and False otherwise.\n\nrank\n\nrank(self: Self) -> Int\n\nGets the rank of the spec.\n\nReturns:\n\nThe rank of the spec.\n\ndtype\n\ndtype(self: Self) -> DType\n\nGets the rank of the DType of the spec.\n\nReturns:\n\nThe DType of the spec.\n\nnum_elements\n\nnum_elements(self: Self) -> Int\n\nGets the total number of elements in the spec.\n\nReturns:\n\nThe total number of elements in the spec.\n\nbytecount\n\nbytecount(self: Self) -> Int\n\nGets the total byte count.\n\nReturns:\n\nThe total byte count.\n\n__repr__\n\n__repr__(self: Self) -> String\n\nReturns the string representation of the spec.\n\nReturns:\n\nThe string representation of the spec.\n\n__str__\n\n__str__(self: Self) -> String\n\nReturns the string representation of the spec.\n\nReturns:\n\nThe string representation of the spec.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - tensor_shape",
    "url": "https://docs.modular.com/mojo/stdlib/tensor/tensor_shape.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntensor\ntensor_shape\ntensor_spec\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nTensorShape\n__init__\n__copyinit__\n__moveinit__\n__del__\n__getitem__\n__eq__\n__ne__\nrank\nnum_elements\n__repr__\n__str__\ntensor_shape\n\nModule\n\nImplements the TensorShape type.\n\nYou can import these APIs from the tensor package. For example:\n\nfrom tensor import TensorShape\nTensorShape\n\nA space efficient representation of a tensor shape. This struct implements value semantics and owns its underlying data.\n\nFunctions:\n\n__init__\n\n__init__(inout self: Self)\n\nDefault initializer for TensorShape.\n\n__init__(inout self: Self, *shapes: Int)\n\nInitializes a TensorShape from the values provided.\n\nArgs:\n\n‚Äãshapes (*Int): The shapes to initialize the shape with.\n\n__init__(inout self: Self, shapes: VariadicList[Int])\n\nInitializes a TensorShape from the values provided.\n\nArgs:\n\n‚Äãshapes (VariadicList[Int]): The shapes to initialize the shape with.\n\n__init__(inout self: Self, shapes: DynamicVector[Int])\n\nInitializes a TensorShape from the vector provided.\n\nArgs:\n\n‚Äãshapes (DynamicVector[Int]): The vector to initialize the shape with.\n\n__init__[rank: Int](inout self: Self, shapes: StaticIntTuple[rank])\n\nInitializes a TensorShape from the values provided.\n\nArgs:\n\n‚Äãshapes (StaticIntTuple[rank]): The shapes to initialize the shape with.\n__copyinit__\n\n__copyinit__(inout self: Self, other: Self)\n\nCreates a deep copy of an existing shape.\n\nArgs:\n\n‚Äãother (Self): The shape to copy.\n__moveinit__\n\n__moveinit__(inout self: Self, owned existing: Self)\n\nMove initializer for the shape.\n\nArgs:\n\n‚Äãexisting (Self): The shape to move.\n__del__\n\n__del__(owned self: Self)\n\nDelete the shape and release any owned memory.\n\n__getitem__\n\n__getitem__(self: Self, index: Int) -> Int\n\nGets the dimension at the specified index.\n\nArgs:\n\n‚Äãindex (Int): The dimension index.\n\nReturns:\n\nThe dimension at the specified index.\n\n__eq__\n\n__eq__(self: Self, other: Self) -> Bool\n\nReturns True if the two values are the same and False otherwise.\n\nArgs:\n\n‚Äãother (Self): The other TensorShape to compare against.\n\nReturns:\n\nTrue if the two shapes are the same and False otherwise.\n\n__ne__\n\n__ne__(self: Self, other: Self) -> Bool\n\nReturns True if the two values are not the same and False otherwise.\n\nArgs:\n\n‚Äãother (Self): The other TensorShape to compare against.\n\nReturns:\n\nTrue if the two shapes are the not the same and False otherwise.\n\nrank\n\nrank(self: Self) -> Int\n\nGets the rank of the shape.\n\nReturns:\n\nThe rank of the shape.\n\nnum_elements\n\nnum_elements(self: Self) -> Int\n\nGets the total number of elements in the shape.\n\nReturns:\n\nThe total number of elements in the shape.\n\n__repr__\n\n__repr__(self: Self) -> String\n\nReturns the string representation of the shape.\n\nReturns:\n\nThe string representation of the shape.\n\n__str__\n\n__str__(self: Self) -> String\n\nReturns the string representation of the shape.\n\nReturns:\n\nThe string representation of the shape.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - tensor",
    "url": "https://docs.modular.com/mojo/stdlib/tensor/tensor.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntensor\ntensor_shape\ntensor_spec\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nTensor\n__init__\n__copyinit__\n__moveinit__\n__del__\n__getitem__\n__setitem__\n__eq__\n__ne__\ndata\ntype\nrank\nnum_elements\nbytecount\nspec\nshape\ndim\n__str__\n__repr__\nsimd_load\nsimd_store\ntofile\nfromfile\ntensor\n\nModule\n\nImplements the Tensor type.\n\nExample:\n\nfrom tensor import Tensor, TensorSpec, TensorShape\nfrom utils.index import Index\nfrom random import rand\n\nlet height = 256\nlet width = 256\nlet channels = 3\n\n# Create the tensor of dimensions height, width, channels\n# and fill with random values.\nlet image = rand[DType.float32](height, width, channels)\n\n# Declare the grayscale image.\nlet spec = TensorSpec(DType.float32, height, width)\nvar gray_scale_image = Tensor[DType.float32](spec)\n\n# Perform the RGB to grayscale transform.\nfor y in range(height):\n  for x in range(width):\n    let r = image[y,x,0]\n    let g = image[y,x,1]\n    let b = image[y,x,2]\n    gray_scale_image[Index(y,x)] = 0.299 * r + 0.587 * g + 0.114 * b\n\nprint(gray_scale_image.shape().__str__())\nTensor\n\nA tensor type which owns its underlying data and is parameterized on DType.\n\nParameters:\n\n‚Äãdtype (DType): The underlying element type of the tensor.\n\nFunctions:\n\n__init__\n\n__init__(inout self: Self)\n\nDefault initializer for TensorShape.\n\n__init__(inout self: Self, *dims: Int)\n\nAllocates a tensor using the shape provided.\n\nArgs:\n\n‚Äãdims (*Int): The tensor dimensions.\n\n__init__(inout self: Self, owned shape: TensorShape)\n\nAllocates a tensor using the shape provided.\n\nArgs:\n\n‚Äãshape (TensorShape): The tensor shape.\n\n__init__(inout self: Self, owned spec: TensorSpec)\n\nAllocates a tensor using the spec provided.\n\nArgs:\n\n‚Äãspec (TensorSpec): The tensor spec.\n\n__init__(inout self: Self, owned ptr: DTypePointer[dtype], owned shape: TensorShape)\n\nInitializes a Tensor from the pointer and shape provided. The caller relinquishes the ownership of the pointer being passed in.\n\nArgs:\n\n‚Äãptr (DTypePointer[dtype]): The data pointer.\n‚Äãshape (TensorShape): The tensor shapes.\n\n__init__(inout self: Self, owned ptr: DTypePointer[dtype], owned spec: TensorSpec)\n\nInitializes a Tensor from the pointer and shape provided. The caller relinquishes the ownership of the pointer being passed in.\n\nArgs:\n\n‚Äãptr (DTypePointer[dtype]): The data pointer.\n‚Äãspec (TensorSpec): The tensor spec.\n__copyinit__\n\n__copyinit__(inout self: Self, other: Self)\n\nCreates a deep copy of an existing tensor.\n\nArgs:\n\n‚Äãother (Self): The tensor to copy from.\n__moveinit__\n\n__moveinit__(inout self: Self, owned existing: Self)\n\nMove initializer for the tensor.\n\nArgs:\n\n‚Äãexisting (Self): The tensor to move.\n__del__\n\n__del__(owned self: Self)\n\nDelete the spec and release any owned memory.\n\n__getitem__\n\n__getitem__(self: Self, index: Int) -> SIMD[dtype, 1]\n\nGets the value at the specified index.\n\nArgs:\n\n‚Äãindex (Int): The index of the value to retrieve.\n\nReturns:\n\nThe value at the specified indices.\n\n__getitem__(self: Self, *indices: Int) -> SIMD[dtype, 1]\n\nGets the value at the specified indices.\n\nArgs:\n\n‚Äãindices (*Int): The indices of the value to retrieve.\n\nReturns:\n\nThe value at the specified indices.\n\n__getitem__(self: Self, indices: VariadicList[Int]) -> SIMD[dtype, 1]\n\nGets the value at the specified indices.\n\nArgs:\n\n‚Äãindices (VariadicList[Int]): The indices of the value to retrieve.\n\nReturns:\n\nThe value at the specified indices.\n\n__getitem__[len: Int](self: Self, indices: StaticIntTuple[len]) -> SIMD[dtype, 1]\n\nGets the SIMD value at the specified indices.\n\nParameters:\n\n‚Äãlen (Int): The length of the indecies.\n\nArgs:\n\n‚Äãindices (StaticIntTuple[len]): The indices of the value to retrieve.\n\nReturns:\n\nThe value at the specified indices.\n\n__setitem__\n\n__setitem__(inout self: Self, index: Int, val: SIMD[dtype, 1])\n\nSets the value at the specified index.\n\nArgs:\n\n‚Äãindex (Int): The index of the value to set.\n‚Äãval (SIMD[dtype, 1]): The value to store.\n\n__setitem__(inout self: Self, indices: VariadicList[Int], val: SIMD[dtype, 1])\n\nSets the value at the specified indices.\n\nArgs:\n\n‚Äãindices (VariadicList[Int]): The indices of the value to set.\n‚Äãval (SIMD[dtype, 1]): The value to store.\n\n__setitem__[len: Int](inout self: Self, indices: StaticIntTuple[len], val: SIMD[dtype, 1])\n\nSets the value at the specified indices.\n\nParameters:\n\n‚Äãlen (Int): The length of the indecies.\n\nArgs:\n\n‚Äãindices (StaticIntTuple[len]): The indices of the value to set.\n‚Äãval (SIMD[dtype, 1]): The value to store.\n__eq__\n\n__eq__(self: Self, other: Self) -> Bool\n\nReturns True if the two tensors are the same and False otherwise.\n\nArgs:\n\n‚Äãother (Self): The other Tensor to compare against.\n\nReturns:\n\nTrue if the two tensors are the same and False otherwise.\n\n__ne__\n\n__ne__(self: Self, other: Self) -> Bool\n\nReturns True if the two tensors are not the same and False otherwise.\n\nArgs:\n\n‚Äãother (Self): The other Tensor to compare against.\n\nReturns:\n\nTrue if the two tensors are the not the same and False otherwise.\n\ndata\n\ndata(self: Self) -> DTypePointer[dtype]\n\nGets the underlying Data pointer to the Tensor.\n\nReturns:\n\nThe underlying data pointer of the tensor.\n\ntype\n\ntype(self: Self) -> DType\n\nGets the underlying DType of the tensor.\n\nReturns:\n\nThe underlying DType of the tensor.\n\nrank\n\nrank(self: Self) -> Int\n\nGets the rank of the tensor.\n\nReturns:\n\nThe rank of the tensor.\n\nnum_elements\n\nnum_elements(self: Self) -> Int\n\nGets the total number of elements in the tensor.\n\nReturns:\n\nThe total number of elements in the tensor.\n\nbytecount\n\nbytecount(self: Self) -> Int\n\nGets the total bytecount of the tensor.\n\nReturns:\n\nThe total bytecount of the tensor.\n\nspec\n\nspec(self: Self) -> TensorSpec\n\nGets the specification of the tensor.\n\nReturns:\n\nThe underlying tensor spec of the tensor.\n\nshape\n\nshape(self: Self) -> TensorShape\n\nGets the shape of the tensor.\n\nReturns:\n\nThe underlying tensor shape of the tensor.\n\ndim\n\ndim(self: Self, idx: Int) -> Int\n\nGets the dimension at the specified index.\n\nArgs:\n\n‚Äãidx (Int): The dimension index.\n\nReturns:\n\nThe dimension at the specified index.\n\n__str__\n\n__str__(self: Self) -> String\n\nGets the tensor as a string.\n\nReturns:\n\nA compact string of the tensor.\n\n__repr__\n\n__repr__(self: Self) -> String\n\nGets the tensor as a string.\n\nReturns:\n\nA compact string representation of the tensor.\n\nsimd_load\n\nsimd_load[simd_width: Int](self: Self, index: Int) -> SIMD[dtype, simd_width]\n\nGets the SIMD value at the specified index.\n\nParameters:\n\n‚Äãsimd_width (Int): The SIMD width of the vector.\n\nArgs:\n\n‚Äãindex (Int): The index of the value to retrieve.\n\nReturns:\n\nThe SIMD value at the specified indices.\n\nsimd_load[simd_width: Int](self: Self, *indices: Int) -> SIMD[dtype, simd_width]\n\nGets the SIMD value at the specified indices.\n\nParameters:\n\n‚Äãsimd_width (Int): The SIMD width of the vector.\n\nArgs:\n\n‚Äãindices (*Int): The indices of the value to retrieve.\n\nReturns:\n\nThe SIMD value at the specified indices.\n\nsimd_load[simd_width: Int](self: Self, indices: VariadicList[Int]) -> SIMD[dtype, simd_width]\n\nGets the SIMD value at the specified indices.\n\nParameters:\n\n‚Äãsimd_width (Int): The SIMD width of the vector.\n\nArgs:\n\n‚Äãindices (VariadicList[Int]): The indices of the value to retrieve.\n\nReturns:\n\nThe SIMD value at the specified indices.\n\nsimd_load[simd_width: Int, len: Int](self: Self, indices: StaticIntTuple[len]) -> SIMD[dtype, simd_width]\n\nGets the SIMD value at the specified indices.\n\nParameters:\n\n‚Äãsimd_width (Int): The SIMD width of the vector.\n‚Äãlen (Int): The length of the indecies.\n\nArgs:\n\n‚Äãindices (StaticIntTuple[len]): The indices of the value to retrieve.\n\nReturns:\n\nThe SIMD value at the specified indices.\n\nsimd_store\n\nsimd_store[simd_width: Int](inout self: Self, index: Int, val: SIMD[dtype, simd_width])\n\nSets the SIMD value at the specified index.\n\nParameters:\n\n‚Äãsimd_width (Int): The SIMD width of the vector.\n\nArgs:\n\n‚Äãindex (Int): The index of the value to set.\n‚Äãval (SIMD[dtype, simd_width]): The SIMD value to store.\n\nsimd_store[simd_width: Int](inout self: Self, indices: VariadicList[Int], val: SIMD[dtype, simd_width])\n\nSets the SIMD value at the specified indices.\n\nParameters:\n\n‚Äãsimd_width (Int): The SIMD width of the vector.\n\nArgs:\n\n‚Äãindices (VariadicList[Int]): The indices of the value to set.\n‚Äãval (SIMD[dtype, simd_width]): The SIMD value to store.\n\nsimd_store[simd_width: Int, len: Int](inout self: Self, indices: StaticIntTuple[len], val: SIMD[dtype, simd_width])\n\nSets the SIMD value at the specified indices.\n\nParameters:\n\n‚Äãsimd_width (Int): The SIMD width of the vector.\n‚Äãlen (Int): The length of the indecies.\n\nArgs:\n\n‚Äãindices (StaticIntTuple[len]): The indices of the value to set.\n‚Äãval (SIMD[dtype, simd_width]): The SIMD value to store.\ntofile\n\ntofile(self: Self, path: Path)\n\nWrite values to a file.\n\nArgs:\n\n‚Äãpath (Path): Path to the output file.\nfromfile\n\nfromfile(path: Path) -> Self\n\nRead tensor from a file.\n\nArgs:\n\n‚Äãpath (Path): Path to the output file.\n\nReturns:\n\nThe tensor read from file.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - param_env",
    "url": "https://docs.modular.com/mojo/stdlib/sys/param_env.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\narg\ninfo\nintrinsics\nparam_env\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nis_defined\nenv_get_int\nenv_get_string\nparam_env\n\nModule\n\nImplements functions for retrieving compile-time defines.\n\nYou can use these functions to set parameter values or runtime constants based on name-value pairs defined on the command line. For example:\n\nfrom sys.param_env import is_defined\nfrom tensor import Tensor, TensorSpec\n\nalias float_type: DType = DType.float32 if is_defined[\"FLOAT32\"]() else DType.float64\n\nlet spec = TensorSpec(float_type, 256, 256)\nvar image = Tensor[float_type](spec)\n\nAnd on the command line:\n\n  mojo -D FLOAT_32 main.mojo\n\nFor more information, see the Mojo build docs. The mojo run command also supports the -D option.\n\nYou can import these APIs from the sys package. For example:\n\nfrom sys.param_env import is_defined\nis_defined\n\nis_defined[name: StringLiteral]() -> Bool\n\nReturn true if the named value is defined.\n\nParameters:\n\n‚Äãname (StringLiteral): The name to test.\n\nReturns:\n\nTrue if the name is defined.\n\nenv_get_int\n\nenv_get_int[name: StringLiteral]() -> Int\n\nTry to get an integer-valued define. Compilation fails if the name is not defined.\n\nParameters:\n\n‚Äãname (StringLiteral): The name of the define.\n\nReturns:\n\nAn integer parameter value.\n\nenv_get_int[name: StringLiteral, default: Int]() -> Int\n\nTry to get an integer-valued define. If the name is not defined, return a default value instead.\n\nParameters:\n\n‚Äãname (StringLiteral): The name of the define.\n‚Äãdefault (Int): The default value to use.\n\nReturns:\n\nAn integer parameter value.\n\nenv_get_string\n\nenv_get_string[name: StringLiteral]() -> StringLiteral\n\nTry to get a string-valued define. Compilation fails if the name is not defined.\n\nParameters:\n\n‚Äãname (StringLiteral): The name of the define.\n\nReturns:\n\nA string parameter value.\n\nenv_get_string[name: StringLiteral, default: StringLiteral]() -> StringLiteral\n\nTry to get a string-valued define. If the name is not defined, return a default value instead.\n\nParameters:\n\n‚Äãname (StringLiteral): The name of the define.\n‚Äãdefault (StringLiteral): The default value to use.\n\nReturns:\n\nA string parameter value.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - intrinsics",
    "url": "https://docs.modular.com/mojo/stdlib/sys/intrinsics.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\narg\ninfo\nintrinsics\nparam_env\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nPrefetchLocality\n__init__\nPrefetchRW\nPrefetchCache\nPrefetchOptions\nllvm_intrinsic\nexternal_call\ngather\nscatter\nprefetch\nmasked_load\nmasked_store\ncompressed_store\nstrided_load\nstrided_store\nintrinsics\n\nModule\n\nDefines intrinsics.\n\nYou can import these APIs from the complex package. For example:\n\nfrom sys.intrinsics import PrefetchLocality\nPrefetchLocality\n\nThe prefetch locality.\n\nThe locality, rw, and cache type correspond to LLVM prefetch intrinsic‚Äôs inputs (see LLVM prefetch locality)\n\nAliases:\n\n‚ÄãNONE = __init__(0): No locality.\n‚ÄãLOW = __init__(1): Low locality.\n‚ÄãMEDIUM = __init__(2): Medium locality.\n‚ÄãHIGH = __init__(3): Extremely local locality (keep in cache).\n\nFields:\n\n‚Äãvalue (SIMD[si32, 1]): The prefetch locality to use. It should be a value in [0, 3].\n\nFunctions:\n\n__init__\n\n__init__(value: Int) -> Self\n\nConstructs a prefetch locality option.\n\nArgs:\n\n‚Äãvalue (Int): An integer value representing the locality. Should be a value in the range [0, 3].\n\nReturns:\n\nThe prefetch locality constructed.\n\nPrefetchRW\n\nPrefetch read or write.\n\nAliases:\n\n‚ÄãREAD = __init__(0): Read prefetch.\n‚ÄãWRITE = __init__(1): Write prefetch.\n\nFields:\n\n‚Äãvalue (SIMD[si32, 1]): The read-write prefetch. It should be in [0, 1].\n\nFunctions:\n\n__init__\n\n__init__(value: Int) -> Self\n\nConstructs a prefetch read-write option.\n\nArgs:\n\n‚Äãvalue (Int): An integer value representing the prefetch read-write option to be used. Should be a value in the range [0, 1].\n\nReturns:\n\nThe prefetch read-write option constructed.\n\nPrefetchCache\n\nPrefetch cache type.\n\nAliases:\n\n‚ÄãINSTRUCTION = __init__(0): The instruction prefetching option.\n‚ÄãDATA = __init__(1): The data prefetching option.\n\nFields:\n\n‚Äãvalue (SIMD[si32, 1]): The cache prefetch. It should be in [0, 1].\n\nFunctions:\n\n__init__\n\n__init__(value: Int) -> Self\n\nConstructs a prefetch option.\n\nArgs:\n\n‚Äãvalue (Int): An integer value representing the prefetch cache option to be used. Should be a value in the range [0, 1].\n\nReturns:\n\nThe prefetch cache type that was constructed.\n\nPrefetchOptions\n\nCollection of configuration parameters for a prefetch intrinsic call.\n\nThe op configuration follows similar interface as LLVM intrinsic prefetch op, with a ‚Äúlocality‚Äù attribute that specifies the level of temporal locality in the application, that is, how soon would the same data be visited again. Possible locality values are: NONE, LOW, MEDIUM, and HIGH.\n\nThe op also takes a ‚Äúcache tag‚Äù attribute giving hints on how the prefetched data will be used. Possible tags are: ReadICache, ReadDCache and WriteDCache.\n\nNote: the actual behavior of the prefetch op and concrete interpretation of these attributes are target-dependent.\n\nFields:\n\n‚Äãrw (PrefetchRW): Indicates prefetching for read or write.\n‚Äãlocality (PrefetchLocality): Indicates locality level.\n‚Äãcache (PrefetchCache): Indicates i-cache or d-cache prefetching.\n\nFunctions:\n\n__init__\n\n__init__() -> Self\n\nConstructs an instance of PrefetchOptions with default params.\n\nReturns:\n\nThe Prefetch configuration constructed.\n\nfor_read\n\nfor_read(self: Self) -> Self\n\nSets the prefetch purpose to read.\n\nReturns:\n\nThe updated prefetch parameter.\n\nfor_write\n\nfor_write(self: Self) -> Self\n\nSets the prefetch purpose to write.\n\nReturns:\n\nThe updated prefetch parameter.\n\nno_locality\n\nno_locality(self: Self) -> Self\n\nSets the prefetch locality to none.\n\nReturns:\n\nThe updated prefetch parameter.\n\nlow_locality\n\nlow_locality(self: Self) -> Self\n\nSets the prefetch locality to low.\n\nReturns:\n\nThe updated prefetch parameter.\n\nmedium_locality\n\nmedium_locality(self: Self) -> Self\n\nSets the prefetch locality to medium.\n\nReturns:\n\nThe updated prefetch parameter.\n\nhigh_locality\n\nhigh_locality(self: Self) -> Self\n\nSets the prefetch locality to high.\n\nReturns:\n\nThe updated prefetch parameter.\n\nto_data_cache\n\nto_data_cache(self: Self) -> Self\n\nSets the prefetch target to data cache.\n\nReturns:\n\nThe updated prefetch parameter.\n\nto_instruction_cache\n\nto_instruction_cache(self: Self) -> Self\n\nSets the prefetch target to instruction cache.\n\nReturns:\n\nThe updated prefetch parameter.\n\nllvm_intrinsic\n\nllvm_intrinsic[intrin: StringLiteral, type: AnyType]() -> *\"type\"\n\nCalls an LLVM intrinsic with no arguments.\n\nCalls an LLVM intrinsic with the name intrin and return type type.\n\nParameters:\n\n‚Äãintrin (StringLiteral): The name of the llvm intrinsic.\n‚Äãtype (AnyType): The return type of the intrinsic.\n\nReturns:\n\nThe result of calling the llvm intrinsic with no arguments.\n\nllvm_intrinsic[intrin: StringLiteral, type: AnyType, T0: AnyType](arg0: T0) -> *\"type\"\n\nCalls an LLVM intrinsic with one argument.\n\nCalls the intrinsic with the name intrin and return type type on argument arg0.\n\nParameters:\n\n‚Äãintrin (StringLiteral): The name of the llvm intrinsic.\n‚Äãtype (AnyType): The return type of the intrinsic.\n‚ÄãT0 (AnyType): The type of the first argument to the intrinsic (arg0).\n\nArgs:\n\n‚Äãarg0 (T0): The argument to call the LLVM intrinsic with. The type of arg0 must be T0.\n\nReturns:\n\nThe result of calling the llvm intrinsic with arg0 as an argument.\n\nllvm_intrinsic[intrin: StringLiteral, type: AnyType, T0: AnyType, T1: AnyType](arg0: T0, arg1: T1) -> *\"type\"\n\nCalls an LLVM intrinsic with two arguments.\n\nCalls the LLVM intrinsic with the name intrin and return type type on arguments arg0 and arg1.\n\nParameters:\n\n‚Äãintrin (StringLiteral): The name of the llvm intrinsic.\n‚Äãtype (AnyType): The return type of the intrinsic.\n‚ÄãT0 (AnyType): The type of the first argument to the intrinsic (arg0).\n‚ÄãT1 (AnyType): The type of the second argument to the intrinsic (arg1).\n\nArgs:\n\n‚Äãarg0 (T0): The first argument to call the LLVM intrinsic with. The type of arg0 must be T0.\n‚Äãarg1 (T1): The second argument to call the LLVM intrinsic with. The type of arg1 must be T1.\n\nReturns:\n\nThe result of calling the llvm intrinsic with arg0 and arg1 as arguments.\n\nllvm_intrinsic[intrin: StringLiteral, type: AnyType, T0: AnyType, T1: AnyType, T2: AnyType](arg0: T0, arg1: T1, arg2: T2) -> *\"type\"\n\nCalls an LLVM intrinsic with three arguments.\n\nCalls the LLVM intrinsic with the name intrin and return type type on arguments arg0, arg1 and arg2.\n\nParameters:\n\n‚Äãintrin (StringLiteral): The name of the llvm intrinsic.\n‚Äãtype (AnyType): The return type of the intrinsic.\n‚ÄãT0 (AnyType): The type of the first argument to the intrinsic (arg0).\n‚ÄãT1 (AnyType): The type of the second argument to the intrinsic (arg1).\n‚ÄãT2 (AnyType): The type of the third argument to the intrinsic (arg2).\n\nArgs:\n\n‚Äãarg0 (T0): The first argument to call the LLVM intrinsic with. The type of arg0 must be T0.\n‚Äãarg1 (T1): The second argument to call the LLVM intrinsic with. The type of arg1 must be T1.\n‚Äãarg2 (T2): The third argument to call the LLVM intrinsic with. The type of arg2 must be T2.\n\nReturns:\n\nThe result of calling the llvm intrinsic with arg0, arg1 and arg2 as arguments.\n\nllvm_intrinsic[intrin: StringLiteral, type: AnyType, T0: AnyType, T1: AnyType, T2: AnyType, T3: AnyType](arg0: T0, arg1: T1, arg2: T2, arg3: T3) -> *\"type\"\n\nCalls an LLVM intrinsic with four arguments.\n\nCalls the LLVM intrinsic with the name intrin and return type type on arguments arg0, arg1, arg2 and arg3.\n\nParameters:\n\n‚Äãintrin (StringLiteral): The name of the llvm intrinsic.\n‚Äãtype (AnyType): The return type of the intrinsic.\n‚ÄãT0 (AnyType): The type of the first argument to the intrinsic (arg0).\n‚ÄãT1 (AnyType): The type of the second argument to the intrinsic (arg1).\n‚ÄãT2 (AnyType): The type of the third argument to the intrinsic (arg2).\n‚ÄãT3 (AnyType): The type of the fourth argument to the intrinsic (arg3).\n\nArgs:\n\n‚Äãarg0 (T0): The first argument to call the LLVM intrinsic with. The type of arg0 must be T0.\n‚Äãarg1 (T1): The second argument to call the LLVM intrinsic with. The type of arg1 must be T1.\n‚Äãarg2 (T2): The third argument to call the LLVM intrinsic with. The type of arg2 must be T2.\n‚Äãarg3 (T3): The fourth argument to call the LLVM intrinsic with. The type of arg3 must be T3.\n\nReturns:\n\nThe result of calling the llvm intrinsic with arg0, arg1, arg2 and arg3 as arguments.\n\nllvm_intrinsic[intrin: StringLiteral, type: AnyType, T0: AnyType, T1: AnyType, T2: AnyType, T3: AnyType, T4: AnyType](arg0: T0, arg1: T1, arg2: T2, arg3: T3, arg4: T4) -> *\"type\"\n\nCalls an LLVM intrinsic with five arguments.\n\nCalls the LLVM intrinsic with the name intrin and return type type on arguments arg0, arg1, arg2, arg3 and arg4.\n\nParameters:\n\n‚Äãintrin (StringLiteral): The name of the llvm intrinsic.\n‚Äãtype (AnyType): The return type of the intrinsic.\n‚ÄãT0 (AnyType): The type of the first argument to the intrinsic (arg0).\n‚ÄãT1 (AnyType): The type of the second argument to the intrinsic (arg1).\n‚ÄãT2 (AnyType): The type of the third argument to the intrinsic (arg2).\n‚ÄãT3 (AnyType): The type of the fourth argument to the intrinsic (arg3).\n‚ÄãT4 (AnyType): The type of the fifth argument to the intrinsic (arg4).\n\nArgs:\n\n‚Äãarg0 (T0): The first argument to call the LLVM intrinsic with. The type of arg0 must be T0.\n‚Äãarg1 (T1): The second argument to call the LLVM intrinsic with. The type of arg1 must be T1.\n‚Äãarg2 (T2): The third argument to call the LLVM intrinsic with. The type of arg2 must be T2.\n‚Äãarg3 (T3): The fourth argument to call the LLVM intrinsic with. The type of arg3 must be T3.\n‚Äãarg4 (T4): The fourth argument to call the LLVM intrinsic with. The type of arg4 must be T4.\n\nReturns:\n\nThe result of calling the llvm intrinsic with arg0, arg1, arg2, arg3 and arg4 as arguments.\n\nexternal_call\n\nexternal_call[callee: StringLiteral, type: AnyType]() -> *\"type\"\n\nCalls an external function.\n\nParameters:\n\n‚Äãcallee (StringLiteral): The name of the external function.\n‚Äãtype (AnyType): The return type.\n\nReturns:\n\nThe external call result.\n\nexternal_call[callee: StringLiteral, type: AnyType, T0: AnyType](arg0: T0) -> *\"type\"\n\nCalls an external function.\n\nParameters:\n\n‚Äãcallee (StringLiteral): The name of the external function.\n‚Äãtype (AnyType): The return type.\n‚ÄãT0 (AnyType): The first argument type.\n\nArgs:\n\n‚Äãarg0 (T0): The first argument.\n\nReturns:\n\nThe external call result.\n\nexternal_call[callee: StringLiteral, type: AnyType, T0: AnyType, T1: AnyType](arg0: T0, arg1: T1) -> *\"type\"\n\nCalls an external function.\n\nParameters:\n\n‚Äãcallee (StringLiteral): The name of the external function.\n‚Äãtype (AnyType): The return type.\n‚ÄãT0 (AnyType): The first argument type.\n‚ÄãT1 (AnyType): The second argument type.\n\nArgs:\n\n‚Äãarg0 (T0): The first argument.\n‚Äãarg1 (T1): The second argument.\n\nReturns:\n\nThe external call result.\n\nexternal_call[callee: StringLiteral, type: AnyType, T0: AnyType, T1: AnyType, T2: AnyType](arg0: T0, arg1: T1, arg2: T2) -> *\"type\"\n\nCalls an external function.\n\nParameters:\n\n‚Äãcallee (StringLiteral): The name of the external function.\n‚Äãtype (AnyType): The return type.\n‚ÄãT0 (AnyType): The first argument type.\n‚ÄãT1 (AnyType): The second argument type.\n‚ÄãT2 (AnyType): The third argument type.\n\nArgs:\n\n‚Äãarg0 (T0): The first argument.\n‚Äãarg1 (T1): The second argument.\n‚Äãarg2 (T2): The third argument.\n\nReturns:\n\nThe external call result.\n\nexternal_call[callee: StringLiteral, type: AnyType, T0: AnyType, T1: AnyType, T2: AnyType, T3: AnyType](arg0: T0, arg1: T1, arg2: T2, arg3: T3) -> *\"type\"\n\nCalls an external function.\n\nParameters:\n\n‚Äãcallee (StringLiteral): The name of the external function.\n‚Äãtype (AnyType): The return type.\n‚ÄãT0 (AnyType): The first argument type.\n‚ÄãT1 (AnyType): The second argument type.\n‚ÄãT2 (AnyType): The third argument type.\n‚ÄãT3 (AnyType): The fourth argument type.\n\nArgs:\n\n‚Äãarg0 (T0): The first argument.\n‚Äãarg1 (T1): The second argument.\n‚Äãarg2 (T2): The third argument.\n‚Äãarg3 (T3): The fourth argument.\n\nReturns:\n\nThe external call result.\n\nexternal_call[callee: StringLiteral, type: AnyType, T0: AnyType, T1: AnyType, T2: AnyType, T3: AnyType, T4: AnyType](arg0: T0, arg1: T1, arg2: T2, arg3: T3, arg4: T4) -> *\"type\"\n\nCalls an external function.\n\nParameters:\n\n‚Äãcallee (StringLiteral): The name of the external function.\n‚Äãtype (AnyType): The return type.\n‚ÄãT0 (AnyType): The first argument type.\n‚ÄãT1 (AnyType): The second argument type.\n‚ÄãT2 (AnyType): The third argument type.\n‚ÄãT3 (AnyType): The fourth argument type.\n‚ÄãT4 (AnyType): The fifth argument type.\n\nArgs:\n\n‚Äãarg0 (T0): The first argument.\n‚Äãarg1 (T1): The second argument.\n‚Äãarg2 (T2): The third argument.\n‚Äãarg3 (T3): The fourth argument.\n‚Äãarg4 (T4): The fifth argument.\n\nReturns:\n\nThe external call result.\n\ngather\n\ngather[type: DType, size: Int](base: SIMD[address, size], mask: SIMD[bool, size], passthrough: SIMD[type, size], alignment: Int) -> SIMD[type, size]\n\nReads scalar values from a SIMD vector, and gathers them into one vector.\n\nThe gather function reads scalar values from a SIMD vector of memory locations and gathers them into one vector. The memory locations are provided in the vector of pointers base as addresses. The memory is accessed according to the provided mask. The mask holds a bit for each vector lane, and is used to prevent memory accesses to the masked-off lanes. The masked-off lanes in the result vector are taken from the corresponding lanes of the passthrough operand.\n\nIn general, for some vector of pointers base, mask mask, and passthrough pass a call of the form:\n\ngather(base, mask, pass)\n\nis equivalent to the following sequence of scalar loads in C++:\n\nfor (int i = 0; i < N; i++)\n  result[i] = mask[i] ? *base[i] : passthrough[i];\n\nParameters:\n\n‚Äãtype (DType): DType of the return SIMD buffer.\n‚Äãsize (Int): Size of the return SIMD buffer.\n\nArgs:\n\n‚Äãbase (SIMD[address, size]): The vector containing memory addresses that gather will access.\n‚Äãmask (SIMD[bool, size]): A binary vector which prevents memory access to certain lanes of the base vector.\n‚Äãpassthrough (SIMD[type, size]): In the result vector, the masked-off lanes are replaced with the passthrough vector.\n‚Äãalignment (Int): The alignment of the source addresses. Must be 0 or a power of two constant integer value.\n\nReturns:\n\nA SIMD[type, size] containing the result of the gather operation.\n\nscatter\n\nscatter[type: DType, size: Int](value: SIMD[type, size], base: SIMD[address, size], mask: SIMD[bool, size], alignment: Int)\n\nTakes scalar values from a SIMD vector and scatters them into a vector of pointers.\n\nThe scatter operation stores scalar values from a SIMD vector of memory locations and scatters them into a vector of pointers. The memory locations are provided in the vector of pointers base as addresses. The memory is stored according to the provided mask. The mask holds a bit for each vector lane, and is used to prevent memory accesses to the masked-off lanes.\n\nThe value operand is a vector value to be written to memory. The base operand is a vector of pointers, pointing to where the value elements should be stored. It has the same underlying type as the value operand. The mask operand, mask, is a vector of boolean values. The types of the mask and the value operand must have the same number of vector elements.\n\nThe behavior of the _scatter is undefined if the op stores into the same memory location more than once.\n\nIn general, for some vector %value, vector of pointers %base, and mask %mask instructions of the form:\n\n%0 = pop.simd.scatter %value, %base[%mask] : !pop.simd<N, type>\n\nis equivalent to the following sequence of scalar loads in C++:\n\nfor (int i = 0; i < N; i++)\n  if (mask[i])\n    base[i] = value[i];\n\nParameters:\n\n‚Äãtype (DType): DType of value, the result SIMD buffer.\n‚Äãsize (Int): Size of value, the result SIMD buffer.\n\nArgs:\n\n‚Äãvalue (SIMD[type, size]): The vector that will contain the result of the scatter operation.\n‚Äãbase (SIMD[address, size]): The vector containing memory addresses that scatter will access.\n‚Äãmask (SIMD[bool, size]): A binary vector which prevents memory access to certain lanes of the base vector.\n‚Äãalignment (Int): The alignment of the source addresses. Must be 0 or a power of two constant integer value.\nprefetch\n\nprefetch[type: DType, params: PrefetchOptions](addr: DTypePointer[type])\n\nPrefetches an instruction or data into cache before it is used.\n\nThe prefetch function provides prefetching hints for the target to prefetch instruction or data into cache before they are used.\n\nParameters:\n\n‚Äãtype (DType): The DType of value stored in addr.\n‚Äãparams (PrefetchOptions): Configuration options for the prefect intrinsic.\n\nArgs:\n\n‚Äãaddr (DTypePointer[type]): The data pointer to prefetch.\nmasked_load\n\nmasked_load[type: DType, size: Int](addr: DTypePointer[type], mask: SIMD[bool, size], passthrough: SIMD[type, size], alignment: Int) -> SIMD[type, size]\n\nLoads data from memory and return it, replacing masked lanes with values from the passthrough vector.\n\nParameters:\n\n‚Äãtype (DType): DType of the return SIMD buffer.\n‚Äãsize (Int): Size of the return SIMD buffer.\n\nArgs:\n\n‚Äãaddr (DTypePointer[type]): The base pointer for the load.\n‚Äãmask (SIMD[bool, size]): A binary vector which prevents memory access to certain lanes of the memory stored at addr.\n‚Äãpassthrough (SIMD[type, size]): In the result vector, the masked-off lanes are replaced with the passthrough vector.\n‚Äãalignment (Int): The alignment of the source addresses. Must be 0 or a power of two constant integer value. Default is 1.\n\nReturns:\n\nThe loaded memory stored in a vector of type SIMD[type, size].\n\nmasked_store\n\nmasked_store[type: DType, size: Int](value: SIMD[type, size], addr: DTypePointer[type], mask: SIMD[bool, size], alignment: Int)\n\nStores a value at a memory location, skipping masked lanes.\n\nParameters:\n\n‚Äãtype (DType): DType of value, the data to store.\n‚Äãsize (Int): Size of value, the data to store.\n\nArgs:\n\n‚Äãvalue (SIMD[type, size]): The vector containing data to store.\n‚Äãaddr (DTypePointer[type]): A vector of memory location to store data at.\n‚Äãmask (SIMD[bool, size]): A binary vector which prevents memory access to certain lanes of value.\n‚Äãalignment (Int): The alignment of the destination locations. Must be 0 or a power of two constant integer value.\ncompressed_store\n\ncompressed_store[type: DType, size: Int](value: SIMD[type, size], addr: DTypePointer[type], mask: SIMD[bool, size])\n\nCompresses the lanes of value, skipping mask lanes, and stores at addr.\n\nParameters:\n\n‚Äãtype (DType): DType of value, the value to store.\n‚Äãsize (Int): Size of value, the value to store.\n\nArgs:\n\n‚Äãvalue (SIMD[type, size]): The vector containing data to store.\n‚Äãaddr (DTypePointer[type]): The memory location to store the compressed data.\n‚Äãmask (SIMD[bool, size]): A binary vector which prevents memory access to certain lanes of value.\nstrided_load\n\nstrided_load[type: DType, simd_width: Int](addr: DTypePointer[type], stride: Int, mask: SIMD[bool, simd_width]) -> SIMD[type, simd_width]\n\nLoads values from addr according to a specific stride.\n\nParameters:\n\n‚Äãtype (DType): DType of value, the value to store.\n‚Äãsimd_width (Int): The width of the SIMD vectors.\n\nArgs:\n\n‚Äãaddr (DTypePointer[type]): The memory location to load data from.\n‚Äãstride (Int): How many lanes to skip before loading again.\n‚Äãmask (SIMD[bool, simd_width]): A binary vector which prevents memory access to certain lanes of value.\n\nReturns:\n\nA vector containing the loaded data.\n\nstrided_load[type: DType, simd_width: Int](addr: DTypePointer[type], stride: Int) -> SIMD[type, simd_width]\n\nLoads values from addr according to a specific stride.\n\nParameters:\n\n‚Äãtype (DType): DType of value, the value to store.\n‚Äãsimd_width (Int): The width of the SIMD vectors.\n\nArgs:\n\n‚Äãaddr (DTypePointer[type]): The memory location to load data from.\n‚Äãstride (Int): How many lanes to skip before loading again.\n\nReturns:\n\nA vector containing the loaded data.\n\nstrided_store\n\nstrided_store[type: DType, simd_width: Int](value: SIMD[type, simd_width], addr: DTypePointer[type], stride: Int, mask: SIMD[bool, simd_width])\n\nLoads values from addr according to a specific stride.\n\nParameters:\n\n‚Äãtype (DType): DType of value, the value to store.\n‚Äãsimd_width (Int): The width of the SIMD vectors.\n\nArgs:\n\n‚Äãvalue (SIMD[type, simd_width]): The values to store.\n‚Äãaddr (DTypePointer[type]): The location to store values at.\n‚Äãstride (Int): How many lanes to skip before storing again.\n‚Äãmask (SIMD[bool, simd_width]): A binary vector which prevents memory access to certain lanes of value.\n\nstrided_store[type: DType, simd_width: Int](value: SIMD[type, simd_width], addr: DTypePointer[type], stride: Int)\n\nLoads values from addr according to a specific stride.\n\nParameters:\n\n‚Äãtype (DType): DType of value, the value to store.\n‚Äãsimd_width (Int): The width of the SIMD vectors.\n\nArgs:\n\n‚Äãvalue (SIMD[type, simd_width]): The values to store.\n‚Äãaddr (DTypePointer[type]): The location to store values at.\n‚Äãstride (Int): How many lanes to skip before storing again.\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - info",
    "url": "https://docs.modular.com/mojo/stdlib/sys/info.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\narg\ninfo\nintrinsics\nparam_env\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nis_x86\nhas_sse4\nhas_avx\nhas_avx2\nhas_avx512f\nhas_vnni\nhas_neon\nis_apple_m1\nis_neoverse_n1\nhas_intel_amx\nos_is_macos\nos_is_linux\nos_is_windows\nis_triple\ntriple_is_nvidia_cuda\nsimdbitwidth\nis_little_endian\nis_big_endian\nsimd_byte_width\nsizeof\nalignof\nbitwidthof\nsimdwidthof\ninfo\n\nModule\n\nImplements methods for querying the host target info.\n\nYou can import these APIs from the sys package. For example:\n\nfrom sys.info import is_x86\nis_x86\n\nis_x86() -> Bool\n\nReturns True if the host system architecture is X86 and False otherwise.\n\nReturns:\n\nTrue if the host system architecture is X86 and False otherwise.\n\nhas_sse4\n\nhas_sse4() -> Bool\n\nReturns True if the host system has sse4, otherwise returns False.\n\nReturns:\n\nTrue if the host system has sse4, otherwise returns False.\n\nhas_avx\n\nhas_avx() -> Bool\n\nReturns True if the host system has AVX, otherwise returns False.\n\nReturns:\n\nTrue if the host system has AVX, otherwise returns False.\n\nhas_avx2\n\nhas_avx2() -> Bool\n\nReturns True if the host system has AVX2, otherwise returns False.\n\nReturns:\n\nTrue if the host system has AVX2, otherwise returns False.\n\nhas_avx512f\n\nhas_avx512f() -> Bool\n\nReturns True if the host system has AVX512, otherwise returns False.\n\nReturns:\n\nTrue if the host system has AVX512, otherwise returns False.\n\nhas_vnni\n\nhas_vnni() -> Bool\n\nReturns True if the host system has avx512_vnni, otherwise returns False.\n\nReturns:\n\nTrue if the host system has avx512_vnni, otherwise returns False.\n\nhas_neon\n\nhas_neon() -> Bool\n\nReturns True if the host system has Neon support, otherwise returns False.\n\nReturns:\n\nTrue if the host system support the Neon instruction set.\n\nis_apple_m1\n\nis_apple_m1() -> Bool\n\nReturns True if the host system is an Apple M1 with AMX support, otherwise returns False.\n\nReturns:\n\nTrue if the host system is an Apple M1 with AMX support and False otherwise.\n\nis_neoverse_n1\n\nis_neoverse_n1() -> Bool\n\nReturns True if the host system is a Neoverse N1 system, otherwise returns False.\n\nReturns:\n\nTrue if the host system is a Neoverse N1 system and False otherwise.\n\nhas_intel_amx\n\nhas_intel_amx() -> Bool\n\nReturns True if the host system has Intel AMX support, otherwise returns False.\n\nReturns:\n\nTrue if the host system has Intel AMX and False otherwise.\n\nos_is_macos\n\nos_is_macos() -> Bool\n\nReturns True if the host operating system is macOS.\n\nReturns:\n\nTrue if the host operating system is macOS and False otherwise.\n\nos_is_linux\n\nos_is_linux() -> Bool\n\nReturns True if the host operating system is Linux.\n\nReturns:\n\nTrue if the host operating system is Linux and False otherwise.\n\nos_is_windows\n\nos_is_windows() -> Bool\n\nReturns True if the host operating system is Windows.\n\nReturns:\n\nTrue if the host operating system is Windows and False otherwise.\n\nis_triple\n\nis_triple[triple: StringLiteral]() -> Bool\n\nReturns True if the target triple of the compiler matches the input and False otherwise.\n\nParameters:\n\n‚Äãtriple (StringLiteral): The triple value to be checked against.\n\nReturns:\n\nTrue if the triple matches and False otherwise.\n\ntriple_is_nvidia_cuda\n\ntriple_is_nvidia_cuda() -> Bool\n\nReturns True if the target triple of the compiler is nvptx64-nvidia-cuda False otherwise.\n\nReturns:\n\nTrue if the triple target is cuda and False otherwise.\n\nsimdbitwidth\n\nsimdbitwidth() -> Int\n\nReturns the vector size (in bits) of the host system.\n\nReturns:\n\nThe vector size (in bits) of the host system.\n\nis_little_endian\n\nis_little_endian() -> Bool\n\nReturns True if the host endianness is little and False otherwise.\n\nReturns:\n\nTrue if the host target is little endian and False otherwise.\n\nis_big_endian\n\nis_big_endian() -> Bool\n\nReturns True if the host endianness is big and False otherwise.\n\nReturns:\n\nTrue if the host target is big endian and False otherwise.\n\nsimd_byte_width\n\nsimd_byte_width() -> Int\n\nReturns the vector size (in bytes) of the host system.\n\nReturns:\n\nThe vector size (in bytes) of the host system.\n\nsizeof\n\nsizeof[type: AnyType]() -> Int\n\nReturns the size of (in bytes) of the type.\n\nParameters:\n\n‚Äãtype (AnyType): The type in question.\n\nReturns:\n\nThe size of the type in bytes.\n\nsizeof[type: DType]() -> Int\n\nReturns the size of (in bytes) of the dtype.\n\nParameters:\n\n‚Äãtype (DType): The DType in question.\n\nReturns:\n\nThe size of the dtype in bytes.\n\nalignof\n\nalignof[type: AnyType]() -> Int\n\nReturns the align of (in bytes) of the type.\n\nParameters:\n\n‚Äãtype (AnyType): The type in question.\n\nReturns:\n\nThe alignment of the type in bytes.\n\nalignof[type: DType]() -> Int\n\nReturns the align of (in bytes) of the dtype.\n\nParameters:\n\n‚Äãtype (DType): The DType in question.\n\nReturns:\n\nThe alignment of the dtype in bytes.\n\nbitwidthof\n\nbitwidthof[type: AnyType]() -> Int\n\nReturns the size of (in bits) of the type.\n\nParameters:\n\n‚Äãtype (AnyType): The type in question.\n\nReturns:\n\nThe size of the type in bits.\n\nbitwidthof[type: DType]() -> Int\n\nReturns the size of (in bits) of the dtype.\n\nParameters:\n\n‚Äãtype (DType): The type in question.\n\nReturns:\n\nThe size of the dtype in bits.\n\nsimdwidthof\n\nsimdwidthof[type: AnyType]() -> Int\n\nReturns the vector size of the type on the host system.\n\nParameters:\n\n‚Äãtype (AnyType): The type in question.\n\nReturns:\n\nThe vector size of the type on the host system.\n\nsimdwidthof[type: DType]() -> Int\n\nReturns the vector size of the type on the host system.\n\nParameters:\n\n‚Äãtype (DType): The DType in question.\n\nReturns:\n\nThe vector size of the dtype on the host system.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - arg",
    "url": "https://docs.modular.com/mojo/stdlib/sys/arg.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\narg\ninfo\nintrinsics\nparam_env\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nargv\narg\n\nModule\n\nImplements functions and variables for interacting with execution and system environment.\n\nYou can import these APIs from the sys package. For example:\n\nfrom sys import argv\nargv\n\nargv() -> VariadicList[StringRef]\n\nThe list of command line arguments.\n\nReturns:\n\nThe list of command line arguments provided when mojo was invoked.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - object",
    "url": "https://docs.modular.com/mojo/stdlib/python/object.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nobject\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nPythonObject\n__init__\n__copyinit__\n__moveinit__\n__del__\n__bool__\n__getitem__\n__neg__\n__pos__\n__invert__\n__lt__\n__le__\n__eq__\n__ne__\n__gt__\n__ge__\n__add__\n__sub__\n__mul__\n__truediv__\n__floordiv__\n__mod__\n__pow__\n__lshift__\n__rshift__\n__and__\n__or__\n__xor__\n__radd__\n__rsub__\n__rmul__\n__rtruediv__\n__rfloordiv__\n__rmod__\n__rpow__\n__rlshift__\n__rrshift__\n__rand__\n__ror__\n__rxor__\n__iadd__\n__isub__\n__imul__\n__itruediv__\n__ifloordiv__\n__imod__\n__ipow__\n__ilshift__\n__irshift__\n__iand__\n__ixor__\n__ior__\n__iter__\n__getattr__\n__setattr__\n__call__\nto_float64\n__index__\nto_string\nobject\n\nModule\n\nImplements PythonObject.\n\nYou can import these APIs from the python package. For example:\n\nfrom python.object import PythonObject\nPythonObject\n\nA Python object.\n\nFields:\n\n‚Äãpy_object (PyObjectPtr): A pointer to the underlying Python object.\n\nFunctions:\n\n__init__\n\n__init__(inout self: Self)\n\nInitialize the object with a None value.\n\n__init__(inout self: Self, none: None)\n\nInitialize a none value object from a None literal.\n\nArgs:\n\n‚Äãnone (None): None.\n\n__init__(inout self: Self, integer: Int)\n\nInitialize the object with an integer value.\n\nArgs:\n\n‚Äãinteger (Int): The integer value.\n\n__init__(inout self: Self, float: FloatLiteral)\n\nInitialize the object with an floating-point value.\n\nArgs:\n\n‚Äãfloat (FloatLiteral): The float value.\n\n__init__[dt: DType](inout self: Self, value: SIMD[dt, 1])\n\nInitialize the object with a generic scalar value. If the scalar value type is bool, it is converted to a boolean. Otherwise, it is converted to the appropriate integer or floating point type.\n\nParameters:\n\n‚Äãdt (DType): The scalar value type.\n\nArgs:\n\n‚Äãvalue (SIMD[dt, 1]): The scalar value.\n\n__init__(inout self: Self, value: Bool)\n\nInitialize the object from a bool.\n\nArgs:\n\n‚Äãvalue (Bool): The boolean value.\n\n__init__(inout self: Self, str: StringLiteral)\n\nInitialize the object from a string literal.\n\nArgs:\n\n‚Äãstr (StringLiteral): The string value.\n\n__init__(inout self: Self, str: StringRef)\n\nInitialize the object from a string reference.\n\nArgs:\n\n‚Äãstr (StringRef): The string value.\n\n__init__(inout self: Self, str: String)\n\nInitialize the object from a string.\n\nArgs:\n\n‚Äãstr (String): The string value.\n\n__init__[*Ts: AnyType](inout self: Self, value: ListLiteral[Ts])\n\nInitialize the object from a list literal.\n\nParameters:\n\n‚ÄãTs (*AnyType): The list element types.\n\nArgs:\n\n‚Äãvalue (ListLiteral[Ts]): The list value.\n\n__init__[*Ts: AnyType](inout self: Self, value: Tuple[Ts])\n\nInitialize the object from a tuple literal.\n\nParameters:\n\n‚ÄãTs (*AnyType): The tuple element types.\n\nArgs:\n\n‚Äãvalue (Tuple[Ts]): The tuple value.\n\n__init__(inout self: Self, py_object: PyObjectPtr, /)\n\n__copyinit__\n\n__copyinit__(inout self: Self, existing: Self)\n\nCopy the object.\n\nThis increments the underlying refcount of the existing object.\n\nArgs:\n\n‚Äãexisting (Self): The value to copy.\n__moveinit__\n\n__moveinit__(inout self: Self, owned other: Self, /)\n\n__del__\n\n__del__(owned self: Self)\n\nDestroy the object.\n\nThis decrements the underlying refcount of the pointed-to object.\n\n__bool__\n\n__bool__(self: Self) -> Bool\n\nEvaluate the boolean value of the object.\n\nReturns:\n\nWhether the object evaluates as true.\n\n__getitem__\n\n__getitem__(self: Self, *args: Self) -> Self\n\nReturn the value for the given key or keys.\n\nArgs:\n\n‚Äãargs (*Self): The key or keys to access on this object.\n\nReturns:\n\nThe value corresponding to the given key for this object.\n\n__neg__\n\n__neg__(self: Self) -> Self\n\nNegative.\n\nCalls the underlying object‚Äôs __neg__ method.\n\nReturns:\n\nThe result of prefixing this object with a - operator. For most numerical objects, this returns the negative.\n\n__pos__\n\n__pos__(self: Self) -> Self\n\nPositive.\n\nCalls the underlying object‚Äôs __pos__ method.\n\nReturns:\n\nThe result of prefixing this object with a + operator. For most numerical objects, this does nothing.\n\n__invert__\n\n__invert__(self: Self) -> Self\n\nInversion.\n\nCalls the underlying object‚Äôs __invert__ method.\n\nReturns:\n\nThe logical inverse of this object: a bitwise representation where all bits are flipped, from zero to one, and from one to zero.\n\n__lt__\n\n__lt__(self: Self, rhs: Self) -> Self\n\nLess than comparator. This lexicographically compares strings and lists.\n\nArgs:\n\n‚Äãrhs (Self): Right hand value.\n\nReturns:\n\nTrue if the object is less than the right hard argument.\n\n__le__\n\n__le__(self: Self, rhs: Self) -> Self\n\nLess than or equal to comparator. This lexicographically compares strings and lists.\n\nArgs:\n\n‚Äãrhs (Self): Right hand value.\n\nReturns:\n\nTrue if the object is less than or equal to the right hard argument.\n\n__eq__\n\n__eq__(self: Self, rhs: Self) -> Self\n\nEquality comparator. This compares the elements of strings and lists.\n\nArgs:\n\n‚Äãrhs (Self): Right hand value.\n\nReturns:\n\nTrue if the objects are equal.\n\n__ne__\n\n__ne__(self: Self, rhs: Self) -> Self\n\nInequality comparator. This compares the elements of strings and lists.\n\nArgs:\n\n‚Äãrhs (Self): Right hand value.\n\nReturns:\n\nTrue if the objects are not equal.\n\n__gt__\n\n__gt__(self: Self, rhs: Self) -> Self\n\nGreater than comparator. This lexicographically compares the elements of strings and lists.\n\nArgs:\n\n‚Äãrhs (Self): Right hand value.\n\nReturns:\n\nTrue if the left hand value is greater.\n\n__ge__\n\n__ge__(self: Self, rhs: Self) -> Self\n\nGreater than or equal to comparator. This lexicographically compares the elements of strings and lists.\n\nArgs:\n\n‚Äãrhs (Self): Right hand value.\n\nReturns:\n\nTrue if the left hand value is greater than or equal to the right hand value.\n\n__add__\n\n__add__(self: Self, rhs: Self) -> Self\n\nAddition and concatenation.\n\nCalls the underlying object‚Äôs __add__ method.\n\nArgs:\n\n‚Äãrhs (Self): Right hand value.\n\nReturns:\n\nThe sum or concatenated values.\n\n__sub__\n\n__sub__(self: Self, rhs: Self) -> Self\n\nSubtraction.\n\nCalls the underlying object‚Äôs __sub__ method.\n\nArgs:\n\n‚Äãrhs (Self): Right hand value.\n\nReturns:\n\nThe difference.\n\n__mul__\n\n__mul__(self: Self, rhs: Self) -> Self\n\nMultiplication.\n\nCalls the underlying object‚Äôs __mul__ method.\n\nArgs:\n\n‚Äãrhs (Self): Right hand value.\n\nReturns:\n\nThe product.\n\n__truediv__\n\n__truediv__(self: Self, rhs: Self) -> Self\n\nDivision.\n\nCalls the underlying object‚Äôs __truediv__ method.\n\nArgs:\n\n‚Äãrhs (Self): The right-hand-side value by which this object is divided.\n\nReturns:\n\nThe result of dividing the right-hand-side value by this.\n\n__floordiv__\n\n__floordiv__(self: Self, rhs: Self) -> Self\n\nReturn the division of self and rhs rounded down to the nearest integer.\n\nCalls the underlying object‚Äôs __floordiv__ method.\n\nArgs:\n\n‚Äãrhs (Self): The right-hand-side value by which this object is divided.\n\nReturns:\n\nThe result of dividing this by the right-hand-side value, modulo any remainder.\n\n__mod__\n\n__mod__(self: Self, rhs: Self) -> Self\n\nReturn the remainder of self divided by rhs.\n\nCalls the underlying object‚Äôs __mod__ method.\n\nArgs:\n\n‚Äãrhs (Self): The value to divide on.\n\nReturns:\n\nThe remainder of dividing self by rhs.\n\n__pow__\n\n__pow__(self: Self, rhs: Self) -> Self\n\nRaises this object to the power of the given value.\n\nArgs:\n\n‚Äãrhs (Self): The exponent.\n\nReturns:\n\nThe result of raising this by the given exponent.\n\n__lshift__\n\n__lshift__(self: Self, rhs: Self) -> Self\n\nBitwise left shift.\n\nArgs:\n\n‚Äãrhs (Self): The right-hand-side value by which this object is bitwise shifted to the left.\n\nReturns:\n\nThis value, shifted left by the given value.\n\n__rshift__\n\n__rshift__(self: Self, rhs: Self) -> Self\n\nBitwise right shift.\n\nArgs:\n\n‚Äãrhs (Self): The right-hand-side value by which this object is bitwise shifted to the right.\n\nReturns:\n\nThis value, shifted right by the given value.\n\n__and__\n\n__and__(self: Self, rhs: Self) -> Self\n\nBitwise AND.\n\nArgs:\n\n‚Äãrhs (Self): The right-hand-side value with which this object is bitwise AND‚Äôed.\n\nReturns:\n\nThe bitwise AND result of this and the given value.\n\n__or__\n\n__or__(self: Self, rhs: Self) -> Self\n\nBitwise OR.\n\nArgs:\n\n‚Äãrhs (Self): The right-hand-side value with which this object is bitwise OR‚Äôed.\n\nReturns:\n\nThe bitwise OR result of this and the given value.\n\n__xor__\n\n__xor__(self: Self, rhs: Self) -> Self\n\nExclusive OR.\n\nArgs:\n\n‚Äãrhs (Self): The right-hand-side value with which this object is exclusive OR‚Äôed.\n\nReturns:\n\nThe exclusive OR result of this and the given value.\n\n__radd__\n\n__radd__(self: Self, lhs: Self) -> Self\n\nReverse addition and concatenation.\n\nCalls the underlying object‚Äôs __radd__ method.\n\nArgs:\n\n‚Äãlhs (Self): The left-hand-side value to which this object is added or concatenated.\n\nReturns:\n\nThe sum.\n\n__rsub__\n\n__rsub__(self: Self, lhs: Self) -> Self\n\nReverse subtraction.\n\nCalls the underlying object‚Äôs __rsub__ method.\n\nArgs:\n\n‚Äãlhs (Self): The left-hand-side value from which this object is subtracted.\n\nReturns:\n\nThe result of subtracting this from the given value.\n\n__rmul__\n\n__rmul__(self: Self, lhs: Self) -> Self\n\nReverse multiplication.\n\nCalls the underlying object‚Äôs __rmul__ method.\n\nArgs:\n\n‚Äãlhs (Self): The left-hand-side value that is multiplied by this object.\n\nReturns:\n\nThe product of the multiplication.\n\n__rtruediv__\n\n__rtruediv__(self: Self, lhs: Self) -> Self\n\nReverse division.\n\nCalls the underlying object‚Äôs __rtruediv__ method.\n\nArgs:\n\n‚Äãlhs (Self): The left-hand-side value that is divided by this object.\n\nReturns:\n\nThe result of dividing the given value by this.\n\n__rfloordiv__\n\n__rfloordiv__(self: Self, lhs: Self) -> Self\n\nReverse floor division.\n\nCalls the underlying object‚Äôs __rfloordiv__ method.\n\nArgs:\n\n‚Äãlhs (Self): The left-hand-side value that is divided by this object.\n\nReturns:\n\nThe result of dividing the given value by this, modulo any remainder.\n\n__rmod__\n\n__rmod__(self: Self, lhs: Self) -> Self\n\nReverse modulo.\n\nCalls the underlying object‚Äôs __rmod__ method.\n\nArgs:\n\n‚Äãlhs (Self): The left-hand-side value that is divided by this object.\n\nReturns:\n\nThe remainder from dividing the given value by this.\n\n__rpow__\n\n__rpow__(self: Self, lhs: Self) -> Self\n\nReverse power of.\n\nArgs:\n\n‚Äãlhs (Self): The number that is raised to the power of this object.\n\nReturns:\n\nThe result of raising the given value by this exponent.\n\n__rlshift__\n\n__rlshift__(self: Self, lhs: Self) -> Self\n\nReverse bitwise left shift.\n\nArgs:\n\n‚Äãlhs (Self): The left-hand-side value that is bitwise shifted to the left by this object.\n\nReturns:\n\nThe given value, shifted left by this.\n\n__rrshift__\n\n__rrshift__(self: Self, lhs: Self) -> Self\n\nReverse bitwise right shift.\n\nArgs:\n\n‚Äãlhs (Self): The left-hand-side value that is bitwise shifted to the right by this object.\n\nReturns:\n\nThe given value, shifted right by this.\n\n__rand__\n\n__rand__(self: Self, lhs: Self) -> Self\n\nReverse bitwise and.\n\nArgs:\n\n‚Äãlhs (Self): The left-hand-side value that is bitwise AND‚Äôed with this object.\n\nReturns:\n\nThe bitwise AND result of the given value and this.\n\n__ror__\n\n__ror__(self: Self, lhs: Self) -> Self\n\nReverse bitwise OR.\n\nArgs:\n\n‚Äãlhs (Self): The left-hand-side value that is bitwise OR‚Äôed with this object.\n\nReturns:\n\nThe bitwise OR result of the given value and this.\n\n__rxor__\n\n__rxor__(self: Self, lhs: Self) -> Self\n\nReverse exclusive OR.\n\nArgs:\n\n‚Äãlhs (Self): The left-hand-side value that is exclusive OR‚Äôed with this object.\n\nReturns:\n\nThe exclusive OR result of the given value and this.\n\n__iadd__\n\n__iadd__(inout self: Self, rhs: Self)\n\nImmediate addition and concatenation.\n\nArgs:\n\n‚Äãrhs (Self): The right-hand-side value that is added to this object.\n__isub__\n\n__isub__(inout self: Self, rhs: Self)\n\nImmediate subtraction.\n\nArgs:\n\n‚Äãrhs (Self): The right-hand-side value that is subtracted from this object.\n__imul__\n\n__imul__(inout self: Self, rhs: Self)\n\nIn-place multiplication.\n\nCalls the underlying object‚Äôs __imul__ method.\n\nArgs:\n\n‚Äãrhs (Self): The right-hand-side value by which this object is multiplied.\n__itruediv__\n\n__itruediv__(inout self: Self, rhs: Self)\n\nImmediate division.\n\nArgs:\n\n‚Äãrhs (Self): The value by which this object is divided.\n__ifloordiv__\n\n__ifloordiv__(inout self: Self, rhs: Self)\n\nImmediate floor division.\n\nArgs:\n\n‚Äãrhs (Self): The value by which this object is divided.\n__imod__\n\n__imod__(inout self: Self, rhs: Self)\n\nImmediate modulo.\n\nArgs:\n\n‚Äãrhs (Self): The right-hand-side value that is used to divide this object.\n__ipow__\n\n__ipow__(inout self: Self, rhs: Self)\n\nImmediate power of.\n\nArgs:\n\n‚Äãrhs (Self): The exponent.\n__ilshift__\n\n__ilshift__(inout self: Self, rhs: Self)\n\nImmediate bitwise left shift.\n\nArgs:\n\n‚Äãrhs (Self): The right-hand-side value by which this object is bitwise shifted to the left.\n__irshift__\n\n__irshift__(inout self: Self, rhs: Self)\n\nImmediate bitwise right shift.\n\nArgs:\n\n‚Äãrhs (Self): The right-hand-side value by which this object is bitwise shifted to the right.\n__iand__\n\n__iand__(inout self: Self, rhs: Self)\n\nImmediate bitwise AND.\n\nArgs:\n\n‚Äãrhs (Self): The right-hand-side value with which this object is bitwise AND‚Äôed.\n__ixor__\n\n__ixor__(inout self: Self, rhs: Self)\n\nImmediate exclusive OR.\n\nArgs:\n\n‚Äãrhs (Self): The right-hand-side value with which this object is exclusive OR‚Äôed.\n__ior__\n\n__ior__(inout self: Self, rhs: Self)\n\nImmediate bitwise OR.\n\nArgs:\n\n‚Äãrhs (Self): The right-hand-side value with which this object is bitwise OR‚Äôed.\n__iter__\n\n__iter__(inout self: Self) -> _PyIter\n\nIterate over object if supported.\n\nReturns:\n\nAn iterator object.\n\n__getattr__\n\n__getattr__(self: Self, name: StringLiteral) -> Self\n\nReturn the value of the object attribute with the given name.\n\nArgs:\n\n‚Äãname (StringLiteral): The name of the object attribute to return.\n\nReturns:\n\nThe value of the object attribute with the given name.\n\n__setattr__\n\n__setattr__(self: Self, name: StringLiteral, newValue: Self)\n\nSet the given value for the object attribute with the given name.\n\nArgs:\n\n‚Äãname (StringLiteral): The name of the object attribute to set.\n‚ÄãnewValue (Self): The new value to be set for that attribute.\n\n__setattr__(self: Self, name: StringLiteral, newValue: Dictionary)\n\nSet the given dict for the object attribute with the given name.\n\nArgs:\n\n‚Äãname (StringLiteral): The name of the object attribute to set.\n‚ÄãnewValue (Dictionary): The new dict value to be set for that attribute.\n__call__\n\n__call__(self: Self, *args: Self) -> Self\n\nCall the underlying object as if it were a function.\n\nReturns:\n\nThe return value from the called object.\n\nto_float64\n\nto_float64(self: Self) -> SIMD[f64, 1]\n\nReturns a float representation of the object.\n\nReturns:\n\nA floating point value that represents this object.\n\n__index__\n\n__index__(self: Self) -> Int\n\nReturns an index representation of the object.\n\nReturns:\n\nAn index value that represents this object.\n\nto_string\n\nto_string(self: Self) -> String\n\nReturns a string representation of the object.\n\nCalls the underlying object‚Äôs __str__ method.\n\nReturns:\n\nA string that represents this object.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - python",
    "url": "https://docs.modular.com/mojo/stdlib/python/python.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nobject\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nPython\n__init__\n__copyinit__\neval\nevaluate\nadd_to_path\nimport_module\ndict\n__str__\nthrow_python_exception_if_error_state\nis_type\ntype\nnone\npython\n\nModule\n\nImplements Python interoperability.\n\nYou can import these APIs from the python package. For example:\n\nfrom python import Python\nPython\n\nProvides methods that help you use Python code in Mojo.\n\nFields:\n\n‚Äãimpl (_PythonInterfaceImpl): The underlying implementation of Mojo‚Äôs Python interface.\n\nFunctions:\n\n__init__\n\n__init__(inout self: Self)\n\nDefault constructor.\n\n__copyinit__\n\n__copyinit__(inout self: Self, existing: Self)\n\nCopy constructor.\n\nArgs:\n\n‚Äãexisting (Self): The existing instance to copy from.\neval\n\neval(inout self: Self, str: StringRef) -> Bool\n\nExecutes the given Python code.\n\nArgs:\n\n‚Äãstr (StringRef): The python code to execute.\n\nReturns:\n\nTrue if the code executed successfully or False if the code raised an exception.\n\nevaluate\n\nevaluate(str: StringRef) -> PythonObject\n\nExecutes the given Python code.\n\nArgs:\n\n‚Äãstr (StringRef): The Python expression to evaluate.\n\nReturns:\n\nPythonObject containing the result of the evaluation.\n\nadd_to_path\n\nadd_to_path(str: StringRef)\n\nAdds a directory to the Python path.\n\nThis might be necessary to import a Python module via import_module(). For example:\n\nfrom python import Python\n\n# Specify path to `mypython.py` module\nPython.add_to_path(\"path/to/module\")\nlet mypython = Python.import_module(\"mypython\")\n\nlet c = mypython.my_algorithm(2, 3)\n\nArgs:\n\n‚Äãstr (StringRef): The path to a Python module you want to import.\nimport_module\n\nimport_module(str: StringRef) -> PythonObject\n\nImports a Python module.\n\nThis provides you with a module object you can use just like you would in Python. For example:\n\nfrom python import Python\n\n# This is equivalent to Python's `import numpy as np`\nlet np = Python.import_module(\"numpy\")\na = np.array([1, 2, 3])\n\nArgs:\n\n‚Äãstr (StringRef): The Python module name. This module must be visible from the list of available Python paths (you might need to add the module‚Äôs path with add_to_path()).\n\nReturns:\n\nThe Python module.\n\ndict\n\ndict() -> Dictionary\n\nConstruct an empty Python dictionary.\n\nReturns:\n\nThe constructed empty Python dictionary.\n\n__str__\n\n__str__(inout self: Self, str: PythonObject) -> StringRef\n\nReturn a string representing the given Python object.\n\nThis function allows to convert Python objects to Mojo string type.\n\nReturns:\n\nMojo string representing the given Python object.\n\nthrow_python_exception_if_error_state\n\nthrow_python_exception_if_error_state(inout cpython: CPython)\n\nRaise an exception if CPython interpreter is in an error state.\n\nArgs:\n\n‚Äãcpython (CPython): The cpython instance we wish to error check.\nis_type\n\nis_type(x: PythonObject, y: PythonObject) -> Bool\n\nTest if the x object is the y object, the same as x is y in Python.\n\nArgs:\n\n‚Äãx (PythonObject): The left-hand-side value in the comparison.\n‚Äãy (PythonObject): The right-hand-side type value in the comparison.\n\nReturns:\n\nTrue if x and y are the same object and False otherwise.\n\ntype\n\ntype(obj: PythonObject) -> PythonObject\n\nReturn Type of this PythonObject.\n\nArgs:\n\n‚Äãobj (PythonObject): PythonObject we want the type of.\n\nReturns:\n\nA PythonObject that holds the type object.\n\nnone\n\nnone() -> PythonObject\n\nGet a PythonObject representing None.\n\nReturns:\n\nPythonObject representing None.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - random",
    "url": "https://docs.modular.com/mojo/stdlib/random/random.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nseed\nrandom_float64\nrandom_si64\nrandom_ui64\nrandint\nrand\nrandn_float64\nrandn\nrandom\n\nModule\n\nProvides functions for random numbers.\n\nYou can import these APIs from the random package. For example:\n\nfrom random import seed\nseed\n\nseed()\n\nSeeds the random number generator using the current time.\n\nseed(a: Int)\n\nSeeds the random number generator using the value provided.\n\nArgs:\n\n‚Äãa (Int): The seed value.\nrandom_float64\n\nrandom_float64(min: SIMD[f64, 1], max: SIMD[f64, 1]) -> SIMD[f64, 1]\n\nReturns a random Float64 number from the given range.\n\nArgs:\n\n‚Äãmin (SIMD[f64, 1]): The minimum number in the range (default is 0.0).\n‚Äãmax (SIMD[f64, 1]): The maximum number in the range (default is 1.0).\n\nReturns:\n\nA random number from the specified range.\n\nrandom_si64\n\nrandom_si64(min: SIMD[si64, 1], max: SIMD[si64, 1]) -> SIMD[si64, 1]\n\nReturns a random Int64 number from the given range.\n\nArgs:\n\n‚Äãmin (SIMD[si64, 1]): The minimum number in the range.\n‚Äãmax (SIMD[si64, 1]): The maximum number in the range.\n\nReturns:\n\nA random number from the specified range.\n\nrandom_ui64\n\nrandom_ui64(min: SIMD[ui64, 1], max: SIMD[ui64, 1]) -> SIMD[ui64, 1]\n\nReturns a random UInt64 number from the given range.\n\nArgs:\n\n‚Äãmin (SIMD[ui64, 1]): The minimum number in the range.\n‚Äãmax (SIMD[ui64, 1]): The maximum number in the range.\n\nReturns:\n\nA random number from the specified range.\n\nrandint\n\nrandint[type: DType](ptr: DTypePointer[type], size: Int, low: Int, high: Int)\n\nFills memory with uniform random in range [low, high].\n\nConstraints:\n\nThe type should be integral.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the pointer.\n\nArgs:\n\n‚Äãptr (DTypePointer[type]): The pointer to the memory area to fill.\n‚Äãsize (Int): The number of elements to fill.\n‚Äãlow (Int): The minimal value for random.\n‚Äãhigh (Int): The maximal value for random.\nrand\n\nrand[type: DType](ptr: DTypePointer[type], size: Int)\n\nFills memory with random values from a uniform distribution.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the pointer.\n\nArgs:\n\n‚Äãptr (DTypePointer[type]): The pointer to the memory area to fill.\n‚Äãsize (Int): The number of elements to fill.\n\nrand[type: DType](*shape: Int) -> Tensor[type]\n\nConstructs a new tensor with the specified shape and fills it with random elements.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the tensor.\n\nArgs:\n\n‚Äãshape (*Int): The tensor shape.\n\nReturns:\n\nA new tensor of specified shape and filled with random elements.\n\nrand[type: DType](owned shape: TensorShape) -> Tensor[type]\n\nConstructs a new tensor with the specified shape and fills it with random elements.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the tensor.\n\nArgs:\n\n‚Äãshape (TensorShape): The tensor shape.\n\nReturns:\n\nA new tensor of specified shape and filled with random elements.\n\nrand[type: DType](owned spec: TensorSpec) -> Tensor[type]\n\nConstructs a new tensor with the specified specification and fills it with random elements.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the tensor.\n\nArgs:\n\n‚Äãspec (TensorSpec): The tensor specification.\n\nReturns:\n\nA new tensor of specified specification and filled with random elements.\n\nrandn_float64\n\nrandn_float64(mean: SIMD[f64, 1], variance: SIMD[f64, 1]) -> SIMD[f64, 1]\n\nReturns a random double sampled from Normal(mean, variance) distribution.\n\nArgs:\n\n‚Äãmean (SIMD[f64, 1]): Normal distribution mean.\n‚Äãvariance (SIMD[f64, 1]): Normal distribution variance.\n\nReturns:\n\nA random float64 sampled from Normal(mean, variance).\n\nrandn\n\nrandn[type: DType](ptr: DTypePointer[type], size: Int, mean: SIMD[f64, 1], variance: SIMD[f64, 1])\n\nFills memory with random values from a Normal(mean, variance) distribution.\n\nConstraints:\n\nThe type should be floating point.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the pointer.\n\nArgs:\n\n‚Äãptr (DTypePointer[type]): The pointer to the memory area to fill.\n‚Äãsize (Int): The number of elements to fill.\n‚Äãmean (SIMD[f64, 1]): Normal distribution mean.\n‚Äãvariance (SIMD[f64, 1]): Normal distribution variance.\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - path",
    "url": "https://docs.modular.com/mojo/stdlib/pathlib/path.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npath\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nPath\n__init__\n__copyinit__\n__del__\n__eq__\n__ne__\n__truediv__\n__str__\n__repr__\ncwd\npath\n\nModule\n\nAliases:\n\n‚ÄãDIR_SEPARATOR = cond(apply(:!lit.signature<(\"self\": !kgen.declref<@\"$builtin\"::@\"$bool\"::@Bool, !lit.metatype<@\"$builtin\"::@\"$bool\"::@Bool>> borrow) -> i1> @\"$builtin\"::@\"$bool\"::@Bool::@\"__mlir_i1__($builtin::$bool::Bool)\", apply(:!lit.signature<() -> !kgen.declref<@\"$builtin\"::@\"$bool\"::@Bool, !lit.metatype<@\"$builtin\"::@\"$bool\"::@Bool>>> @\"$sys\"::@\"$info\"::@\"os_is_windows()\")), #lit.struct<{value: string = \"\\\\\"}>, #lit.struct<{value: string = \"/\"}>)\nPath\n\nThe Path object.\n\nFields:\n\n‚Äãpath (String): The underlying path string representation.\n\nFunctions:\n\n__init__\n\n__init__(inout self: Self)\n\nInitializes a path with the current directory.\n\n__init__(inout self: Self, path: StringLiteral)\n\nInitializes a path with the provided path.\n\nArgs:\n\n‚Äãpath (StringLiteral): The file system path.\n\n__init__(inout self: Self, path: StringRef)\n\nInitializes a path with the provided path.\n\nArgs:\n\n‚Äãpath (StringRef): The file system path.\n\n__init__(inout self: Self, path: String)\n\nInitializes a path with the provided path.\n\nArgs:\n\n‚Äãpath (String): The file system path.\n__copyinit__\n\n__copyinit__(inout self: Self, existing: Self)\n\nCopy constructor for the path struct.\n\nArgs:\n\n‚Äãexisting (Self): The existing struct to copy from.\n__del__\n\n__del__(owned self: Self)\n\n__eq__\n\n__eq__(self: Self, other: Self) -> Bool\n\nReturns True if the two paths are equal.\n\nArgs:\n\n‚Äãother (Self): The other path to compare against.\n\nReturns:\n\nTrue if the paths are equal and False otherwise.\n\n__ne__\n\n__ne__(self: Self, other: Self) -> Bool\n\nReturns True if the two paths are not equal.\n\nArgs:\n\n‚Äãother (Self): The other path to compare against.\n\nReturns:\n\nTrue if the paths are not equal and False otherwise.\n\n__truediv__\n\n__truediv__(self: Self, suffix: Self) -> Self\n\nJoins two paths using the system-defined path separator.\n\nArgs:\n\n‚Äãsuffix (Self): The suffix to append to the path.\n\nReturns:\n\nA new path with the suffix appended to the current path.\n\n__truediv__(self: Self, suffix: StringLiteral) -> Self\n\nJoins two paths using the system-defined path separator.\n\nArgs:\n\n‚Äãsuffix (StringLiteral): The suffix to append to the path.\n\nReturns:\n\nA new path with the suffix appended to the current path.\n\n__truediv__(self: Self, suffix: StringRef) -> Self\n\nJoins two paths using the system-defined path separator.\n\nArgs:\n\n‚Äãsuffix (StringRef): The suffix to append to the path.\n\nReturns:\n\nA new path with the suffix appended to the current path.\n\n__truediv__(self: Self, suffix: String) -> Self\n\nJoins two paths using the system-defined path separator.\n\nArgs:\n\n‚Äãsuffix (String): The suffix to append to the path.\n\nReturns:\n\nA new path with the suffix appended to the current path.\n\n__str__\n\n__str__(self: Self) -> String\n\nReturns a string representation of the path.\n\nReturns:\n\nA string represntation of the path.\n\n__repr__\n\n__repr__(self: Self) -> String\n\nReturns a printable representation of the path.\n\nReturns:\n\nA printable represntation of the path.\n\ncwd\n\ncwd() -> Path\n\nGets the current directory.\n\nReturns:\n\nThe current directory.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - math",
    "url": "https://docs.modular.com/mojo/stdlib/math/math.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nbit\nlimit\nmath\npolynomial\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nmod\nmul\nsub\nadd\ndiv\nclamp\nabs\nrotate_bits_left\nrotate_bits_right\nrotate_left\nrotate_right\nfloor\nceil\nceildiv\ntrunc\nround\nroundeven\nround_half_down\nround_half_up\nsqrt\nrsqrt\nexp2\nldexp\nexp\nfrexp\nlog\nlog2\ncopysign\nerf\ntanh\nisclose\nall_true\nany_true\nnone_true\nreduce_bit_count\niota\nis_power_of_2\nis_odd\nis_even\nfma\nreciprocal\nidentity\ngreater\ngreater_equal\nless\nless_equal\nequal\nlogical_and\nlogical_not\nlogical_xor\nnot_equal\nselect\nmax\nmin\npow\ndiv_ceil\nalign_down\nalign_down_residual\nalign_up\nacos\nasin\natan\natan2\ncos\nsin\ntan\nacosh\nasinh\natanh\ncosh\nsinh\nexpm1\nlog10\nlog1p\nlogb\ncbrt\nhypot\nerfc\nlgamma\ntgamma\nnearbyint\nrint\nremainder\nnextafter\nj0\nj1\ny0\ny1\nscalb\ngcd\nlcm\nfactorial\nnan\nisnan\nmath\n\nModule\n\nDefines math utilities.\n\nYou can import these APIs from the math package. For example:\n\nfrom math import mul\nmod\n\nmod[type: DType, simd_width: Int](x: SIMD[type, simd_width], y: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nPerforms elementwise modulo operation of two SIMD vectors.\n\nParameters:\n\n‚Äãtype (DType): DType of the input SIMD vectors.\n‚Äãsimd_width (Int): Width of the input SIMD vectors.\n\nArgs:\n\n‚Äãx (SIMD[type, simd_width]): The numerator of the operation.\n‚Äãy (SIMD[type, simd_width]): The denominator of the operation.\n\nReturns:\n\nThe remainder of x divided by y.\n\nmul\n\nmul[type: DType, simd_width: Int](x: SIMD[type, simd_width], y: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nPerforms elementwise multiplication of two SIMD vectors.\n\nParameters:\n\n‚Äãtype (DType): DType of the input SIMD vectors.\n‚Äãsimd_width (Int): Width of the input SIMD vectors.\n\nArgs:\n\n‚Äãx (SIMD[type, simd_width]): First SIMD vector to multiply.\n‚Äãy (SIMD[type, simd_width]): Second SIMD vector to multiply.\n\nReturns:\n\nElementwise multiplication of x and y.\n\nsub\n\nsub[type: DType, simd_width: Int](x: SIMD[type, simd_width], y: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nPerforms elementwise subtraction of two SIMD vectors.\n\nParameters:\n\n‚Äãtype (DType): DType of the input SIMD vectors.\n‚Äãsimd_width (Int): Width of the input SIMD vectors.\n\nArgs:\n\n‚Äãx (SIMD[type, simd_width]): SIMD vector which y will be subtracted from.\n‚Äãy (SIMD[type, simd_width]): SIMD vector to subtract from x.\n\nReturns:\n\nElementwise subtraction of SIMD vector y x - y).\n\nadd\n\nadd[type: DType, simd_width: Int](x: SIMD[type, simd_width], y: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nPerforms elementwise addition of two SIMD vectors.\n\nParameters:\n\n‚Äãtype (DType): DType of the input SIMD vectors.\n‚Äãsimd_width (Int): Width of the input SIMD vectors.\n\nArgs:\n\n‚Äãx (SIMD[type, simd_width]): First SIMD vector to add.\n‚Äãy (SIMD[type, simd_width]): Second SIMD vector to add.\n\nReturns:\n\nElementwise addition of x and y.\n\ndiv\n\ndiv[type: DType, simd_width: Int](x: SIMD[type, simd_width], y: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nPerforms elementwise division of two SIMD vectors.\n\nParameters:\n\n‚Äãtype (DType): DType of the input SIMD vectors.\n‚Äãsimd_width (Int): Width of the input SIMD vectors.\n\nArgs:\n\n‚Äãx (SIMD[type, simd_width]): SIMD vector containing the dividends.\n‚Äãy (SIMD[type, simd_width]): SIMD vector containing the quotients.\n\nReturns:\n\nElementwise division of SIMD vector x by SIMD vector y (this is x / y).\n\nclamp\n\nclamp[type: DType, simd_width: Int](x: SIMD[type, simd_width], lower_bound: SIMD[type, simd_width], upper_bound: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nClamps the values in a SIMD vector to be in a certain range.\n\nClamp cuts values in the input SIMD vector off at the upper bound and lower bound values. For example, SIMD vector [0, 1, 2, 3] clamped to a lower bound of 1 and an upper bound of 2 would return [1, 1, 2, 2].\n\nParameters:\n\n‚Äãtype (DType): DType of the input SIMD vectors.\n‚Äãsimd_width (Int): Width of the input SIMD vectors.\n\nArgs:\n\n‚Äãx (SIMD[type, simd_width]): SIMD vector to perform the clamp operation on.\n‚Äãlower_bound (SIMD[type, simd_width]): Minimum of the range to clamp to.\n‚Äãupper_bound (SIMD[type, simd_width]): Maximum of the range to clamp to.\n\nReturns:\n\nA new SIMD vector containing x clamped to be within lower_bound and upper_bound.\n\nabs\n\nabs(x: Int) -> Int\n\nGets the absolute value of an integer.\n\nArgs:\n\n‚Äãx (Int): Value to take the absolute value of.\n\nReturns:\n\nThe absolute value of x.\n\nabs[type: DType, simd_width: Int](x: ComplexSIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nPerforms elementwise abs (norm) on each element of the complex value.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãx (ComplexSIMD[type, simd_width]): The complex vector to perform absolute value on.\n\nReturns:\n\nThe elementwise abs of x.\n\nabs[type: DType, simd_width: Int](x: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nPerforms elementwise absolute value on the elements of a SIMD vector.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãx (SIMD[type, simd_width]): SIMD vector to perform absolute value on.\n\nReturns:\n\nThe elementwise absolute value of x.\n\nrotate_bits_left\n\nrotate_bits_left[shift: Int](x: Int) -> Int\n\nShifts the bits of a input to the left by shift bits (with wrap-around).\n\nConstraints:\n\n-size <= shift < size\n\nParameters:\n\n‚Äãshift (Int): The number of bit positions by which to rotate the bits of the integer to the left (with wrap-around).\n\nArgs:\n\n‚Äãx (Int): The input value.\n\nReturns:\n\nThe input rotated to the left by shift elements (with wrap-around).\n\nrotate_bits_left[shift: Int, type: DType, width: Int](x: SIMD[type, width]) -> SIMD[type, width]\n\nShifts bits to the left by shift positions (with wrap-around) for each element of a SIMD vector.\n\nConstraints:\n\n0 <= shift < size Only unsigned types can be rotated.\n\nParameters:\n\n‚Äãshift (Int): The number of positions by which to shift left the bits for each element of a SIMD vector to the left (with wrap-around).\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãwidth (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãx (SIMD[type, width]): SIMD vector to perform the operation on.\n\nReturns:\n\nThe SIMD vector with each element‚Äôs bits shifted to the left by shift bits (with wrap-around).\n\nrotate_bits_right\n\nrotate_bits_right[shift: Int](x: Int) -> Int\n\nShifts the bits of a input to the left by shift bits (with wrap-around).\n\nConstraints:\n\n-size <= shift < size\n\nParameters:\n\n‚Äãshift (Int): The number of bit positions by which to rotate the bits of the integer to the left (with wrap-around).\n\nArgs:\n\n‚Äãx (Int): The input value.\n\nReturns:\n\nThe input rotated to the left by shift elements (with wrap-around).\n\nrotate_bits_right[shift: Int, type: DType, width: Int](x: SIMD[type, width]) -> SIMD[type, width]\n\nShifts bits to the right by shift positions (with wrap-around) for each element of a SIMD vector.\n\nConstraints:\n\n0 <= shift < size Only unsigned types can be rotated.\n\nParameters:\n\n‚Äãshift (Int): The number of positions by which to shift right the bits for each element of a SIMD vector to the left (with wrap-around).\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãwidth (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãx (SIMD[type, width]): SIMD vector to perform the operation on.\n\nReturns:\n\nThe SIMD vector with each element‚Äôs bits shifted to the right by shift bits (with wrap-around).\n\nrotate_left\n\nrotate_left[shift: Int](x: Int) -> Int\n\nShifts the bits of a input to the left by shift bits (with wrap-around).\n\nConstraints:\n\n-size <= shift < size\n\nParameters:\n\n‚Äãshift (Int): The number of bit positions by which to rotate the bits of the integer to the left (with wrap-around).\n\nArgs:\n\n‚Äãx (Int): The input value.\n\nReturns:\n\nThe input rotated to the left by shift elements (with wrap-around).\n\nrotate_left[shift: Int, type: DType, size: Int](x: SIMD[type, size]) -> SIMD[type, size]\n\nShifts the elements of a SIMD vector to the left by shift elements (with wrap-around).\n\nConstraints:\n\n-size <= shift < size\n\nParameters:\n\n‚Äãshift (Int): The number of positions by which to rotate the elements of SIMD vector to the left (with wrap-around).\n‚Äãtype (DType): The DType of the input and output SIMD vector.\n‚Äãsize (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãx (SIMD[type, size]): The input value.\n\nReturns:\n\nThe SIMD vector rotated to the left by shift elements (with wrap-around).\n\nrotate_right\n\nrotate_right[shift: Int](x: Int) -> Int\n\nShifts the bits of a input to the right by shift bits (with wrap-around).\n\nConstraints:\n\n-size <= shift < size\n\nParameters:\n\n‚Äãshift (Int): The number of bit positions by which to rotate the bits of the integer to the right (with wrap-around).\n\nArgs:\n\n‚Äãx (Int): The input value.\n\nReturns:\n\nThe input rotated to the right by shift elements (with wrap-around).\n\nrotate_right[shift: Int, type: DType, size: Int](x: SIMD[type, size]) -> SIMD[type, size]\n\nShifts the elements of a SIMD vector to the right by shift elements (with wrap-around).\n\nConstraints:\n\n-size < shift <= size\n\nParameters:\n\n‚Äãshift (Int): The number of positions by which to rotate the elements of SIMD vector to the right (with wrap-around).\n‚Äãtype (DType): The DType of the input and output SIMD vector.\n‚Äãsize (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãx (SIMD[type, size]): The input value.\n\nReturns:\n\nThe SIMD vector rotated to the right by shift elements (with wrap-around).\n\nfloor\n\nfloor[type: DType, simd_width: Int](x: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nPerforms elementwise floor on the elements of a SIMD vector.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãx (SIMD[type, simd_width]): SIMD vector to perform floor on.\n\nReturns:\n\nThe elementwise floor of x.\n\nceil\n\nceil[type: DType, simd_width: Int](x: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nPerforms elementwise ceiling on the elements of a SIMD vector.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãx (SIMD[type, simd_width]): SIMD vector to perform ceiling on.\n\nReturns:\n\nThe elementwise ceiling of x.\n\nceildiv\n\nceildiv(x: Int, y: Int) -> Int\n\nReturn the rounded-up result of dividing x by y.\n\nArgs:\n\n‚Äãx (Int): The numerator.\n‚Äãy (Int): The denominator.\n\nReturns:\n\nThe ceiling of dividing x by y.\n\ntrunc\n\ntrunc[type: DType, simd_width: Int](x: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nPerforms elementwise truncation on the elements of a SIMD vector.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãx (SIMD[type, simd_width]): SIMD vector to perform trunc on.\n\nReturns:\n\nThe elementwise truncation of x.\n\nround\n\nround[type: DType, simd_width: Int](x: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nPerforms elementwise rounding on the elements of a SIMD vector.\n\nThis rounding goes to the nearest integer with ties away from zero.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãx (SIMD[type, simd_width]): SIMD vector to perform rounding on.\n\nReturns:\n\nThe elementwise rounding of x.\n\nroundeven\n\nroundeven[type: DType, simd_width: Int](x: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nPerforms elementwise banker‚Äôs rounding on the elements of a SIMD vector.\n\nThis rounding goes to the nearest integer with ties toward the nearest even integer.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãx (SIMD[type, simd_width]): SIMD vector to perform rounding on.\n\nReturns:\n\nThe elementwise banker‚Äôs rounding of x.\n\nround_half_down\n\nround_half_down[type: DType, simd_width: Int](x: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nRounds ties towards the smaller integer‚Äù.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãx (SIMD[type, simd_width]): SIMD vector to perform rounding on.\n\nReturns:\n\nThe elementwise rounding of x evaluating ties towards the smaller integer.\n\nround_half_up\n\nround_half_up[type: DType, simd_width: Int](x: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nRounds ties towards the larger integer‚Äù.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãx (SIMD[type, simd_width]): SIMD vector to perform rounding on.\n\nReturns:\n\nThe elementwise rounding of x evaluating ties towards the larger integer.\n\nsqrt\n\nsqrt(x: Int) -> Int\n\nPerforms square root on an integer.\n\nArgs:\n\n‚Äãx (Int): The integer value to perform square root on.\n\nReturns:\n\nThe square root of x.\n\nsqrt[type: DType, simd_width: Int](x: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nPerforms elementwise square root on the elements of a SIMD vector.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãx (SIMD[type, simd_width]): SIMD vector to perform square root on.\n\nReturns:\n\nThe elementwise square root of x.\n\nrsqrt\n\nrsqrt[type: DType, simd_width: Int](x: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nPerforms elementwise reciprocal square root on the elements of a SIMD vector.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãx (SIMD[type, simd_width]): SIMD vector to perform reciprocal square root on.\n\nReturns:\n\nThe elementwise reciprocal square root of x.\n\nexp2\n\nexp2[type: DType, simd_width: Int](x: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nComputes elementwise 2 raised to the power of n, where n is an element of the input SIMD vector.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãx (SIMD[type, simd_width]): SIMD vector to perform exp2 on.\n\nReturns:\n\nVector containing \n2\nùëõ\n computed elementwise, where n is an element in the input SIMD vector.\n\nldexp\n\nldexp[type: DType, simd_width: Int](x: SIMD[type, simd_width], exp: SIMD[si32, simd_width]) -> SIMD[type, simd_width]\n\nComputes elementwise ldexp function.\n\nThe ldexp function multiplies a floating point value x by the number 2 raised to the exp power. I.e. \nùëô\nùëë\nùëí\nùë•\nùëù\n(\nùë•\n,\nùëí\nùë•\nùëù\n)\n calculate the value of \nùë•\n‚àó\n2\nùëí\nùë•\nùëù\n and is used within the \nùëí\nùëü\nùëì\n function.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãx (SIMD[type, simd_width]): SIMD vector of floating point values.\n‚Äãexp (SIMD[si32, simd_width]): SIMD vector containing the exponents.\n\nReturns:\n\nVector containing elementwise result of ldexp on x and exp.\n\nexp\n\nexp[type: DType, simd_width: Int](x: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nCalculates elementwise e^{X_i}, where X_i is an element in the input SIMD vector at position i.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãx (SIMD[type, simd_width]): The input SIMD vector.\n\nReturns:\n\nA SIMD vector containing e raised to the power Xi where Xi is an element in the input SIMD vector.\n\nfrexp\n\nfrexp[type: DType, simd_width: Int](x: SIMD[type, simd_width]) -> StaticTuple[2, SIMD[type, simd_width]]\n\nBreaks floating point values into a fractional part and an exponent part.\n\nConstraints:\n\ntype must be a floating point value.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãx (SIMD[type, simd_width]): The input values.\n\nReturns:\n\nA tuple of two SIMD vectors containing the fractional and exponent parts of the input floating point values.\n\nlog\n\nlog[type: DType, simd_width: Int](x: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nPerforms elementwise natural log (base E) of a SIMD vector.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãx (SIMD[type, simd_width]): Vector to perform logarithm operation on.\n\nReturns:\n\nVector containing result of performing natural log base E on x.\n\nlog2\n\nlog2[type: DType, simd_width: Int](x: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nPerforms elementwise log (base 2) of a SIMD vector.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãx (SIMD[type, simd_width]): Vector to perform logarithm operation on.\n\nReturns:\n\nVector containing result of performing log base 2 on x.\n\ncopysign\n\ncopysign[type: DType, simd_width: Int](magnitude: SIMD[type, simd_width], sign: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nReturns a value with the magnitude of the first operand and the sign of the second operand.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãmagnitude (SIMD[type, simd_width]): The magnitude to use.\n‚Äãsign (SIMD[type, simd_width]): The sign to copy.\n\nReturns:\n\nCopies the sign from sign to magnitude.\n\nerf\n\nerf[type: DType, simd_width: Int](x: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nPerforms the elementwise Erf on a SIMD vector.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãx (SIMD[type, simd_width]): SIMD vector to perform elementwise Erf on.\n\nReturns:\n\nThe result of the elementwise Erf operation.\n\ntanh\n\ntanh[type: DType, simd_width: Int](x: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nPerforms elementwise evaluation of the tanh function.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãx (SIMD[type, simd_width]): The vector to perform the elementwise tanh on.\n\nReturns:\n\nThe result of the elementwise tanh operation.\n\nisclose\n\nisclose[type: DType, simd_width: Int](a: SIMD[type, simd_width], b: SIMD[type, simd_width], absolute_tolerance: SIMD[type, 1], relative_tolerance: SIMD[type, 1]) -> SIMD[bool, simd_width]\n\nChecks if the two input values are numerically within a tolerance.\n\nWhen the type is integral, then equality is checked. When the type is floating point, then this checks if the two input values are numerically the close using the \nùëé\nùëè\nùë†\n(\nùëé\n‚àí\nùëè\n)\n<=\nùëö\nùëé\nùë•\n(\nùëü\nùë°\nùëú\nùëô\n‚àó\nùëö\nùëé\nùë•\n(\nùëé\nùëè\nùë†\n(\nùëé\n)\n,\nùëé\nùëè\nùë†\n(\nùëè\n)\n)\n,\nùëé\nùë°\nùëú\nùëô\n)\n formula.\n\nUnlike Pythons‚Äôs math.isclose, this implementation is symmetric. I.e. isclose(a,b) == isclose(b,a).\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãa (SIMD[type, simd_width]): The first value to compare.\n‚Äãb (SIMD[type, simd_width]): The second value to compare.\n‚Äãabsolute_tolerance (SIMD[type, 1]): The absolute tolerance.\n‚Äãrelative_tolerance (SIMD[type, 1]): The relative tolerance.\n\nReturns:\n\nA boolean vector where a and b are equal within the specified tolerance.\n\nisclose[type: DType, simd_width: Int](a: SIMD[type, simd_width], b: SIMD[type, simd_width]) -> SIMD[bool, simd_width]\n\nChecks if the two input values are numerically within tolerance, with atol=1e-08 and rtol=1e-05.\n\nWhen the type is integral, then equality is checked. When the type is floating point, then this checks if the two input values are numerically the close using the abs(a - b) <= max(rtol * max(abs(a), abs(b)), atol) formula. The default absolute and relative tolerances are picked from the numpy default values.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãa (SIMD[type, simd_width]): The first value to compare.\n‚Äãb (SIMD[type, simd_width]): The second value to compare.\n\nReturns:\n\nA boolean vector where a and b are equal within tolerance, with atol=1e-08 and rtol=1e-05.\n\nall_true\n\nall_true[simd_width: Int](val: SIMD[bool, simd_width]) -> Bool\n\nReturns True if all elements in the SIMD vector are True and False otherwise.\n\nParameters:\n\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãval (SIMD[bool, simd_width]): The SIMD vector to reduce.\n\nReturns:\n\nTrue if all values in the SIMD vector are True and False otherwise.\n\nany_true\n\nany_true[simd_width: Int](val: SIMD[bool, simd_width]) -> Bool\n\nReturns True if any elements in the SIMD vector is True and False otherwise.\n\nParameters:\n\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãval (SIMD[bool, simd_width]): The SIMD vector to reduce.\n\nReturns:\n\nTrue if any values in the SIMD vector is True and False otherwise.\n\nnone_true\n\nnone_true[simd_width: Int](val: SIMD[bool, simd_width]) -> Bool\n\nReturns True if all element in the SIMD vector are False and False otherwise.\n\nParameters:\n\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãval (SIMD[bool, simd_width]): The SIMD vector to reduce.\n\nReturns:\n\nTrue if all values in the SIMD vector are False and False otherwise.\n\nreduce_bit_count\n\nreduce_bit_count[type: DType, simd_width: Int](val: SIMD[type, simd_width]) -> Int\n\nReturns a scalar containing total number of bits set in given vector.\n\nConstraints:\n\nThe input must be either integral or boolean type.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãval (SIMD[type, simd_width]): The SIMD vector to reduce.\n\nReturns:\n\nCount of set bits across all elements of the vector.\n\niota\n\niota[type: DType, simd_width: Int]() -> SIMD[type, simd_width]\n\nCreates a SIMD vector containing an increasing sequence, starting from 0.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nReturns:\n\nAn increasing sequence of values, starting from 0.\n\niota[type: DType, simd_width: Int](offset: SIMD[type, 1]) -> SIMD[type, simd_width]\n\nCreates a SIMD vector containing an increasing sequence, starting from offset.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãoffset (SIMD[type, 1]): The value to start the sequence at. Default is zero.\n\nReturns:\n\nAn increasing sequence of values, starting from offset.\n\niota[type: DType](buff: DTypePointer[type], len: Int, offset: Int)\n\nFill the buffer with numbers ranging from offset to offset + len - 1, spaced by 1.\n\nThe function doesn‚Äôt return anything, the buffer is updated inplace.\n\nParameters:\n\n‚Äãtype (DType): DType of the underlying data.\n\nArgs:\n\n‚Äãbuff (DTypePointer[type]): The buffer to fill.\n‚Äãlen (Int): The length of the buffer to fill.\n‚Äãoffset (Int): The value to fill at index 0.\n\niota[type: DType](v: DynamicVector[SIMD[type, 1]], offset: Int)\n\nFill the vector with numbers ranging from offset to offset + len - 1, spaced by 1.\n\nThe function doesn‚Äôt return anything, the vector is updated inplace.\n\nParameters:\n\n‚Äãtype (DType): DType of the underlying data.\n\nArgs:\n\n‚Äãv (DynamicVector[SIMD[type, 1]]): The vector to fill.\n‚Äãoffset (Int): The value to fill at index 0.\n\niota(v: DynamicVector[Int], offset: Int)\n\nFill the vector with numbers ranging from offset to offset + len - 1, spaced by 1.\n\nThe function doesn‚Äôt return anything, the vector is updated inplace.\n\nArgs:\n\n‚Äãv (DynamicVector[Int]): The vector to fill.\n‚Äãoffset (Int): The value to fill at index 0.\nis_power_of_2\n\nis_power_of_2[type: DType, simd_width: Int](val: SIMD[type, simd_width]) -> SIMD[bool, simd_width]\n\nPerforms elementwise check of whether SIMD vector contains integer powers of two.\n\nAn element of the result SIMD vector will be True if the value is an integer power of two, and False otherwise.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãval (SIMD[type, simd_width]): The SIMD vector to perform is_power_of_2 on.\n\nReturns:\n\nA SIMD vector containing True if the corresponding element in val is a power of two, otherwise False.\n\nis_power_of_2(val: Int) -> Bool\n\nChecks whether an integer is a power of two.\n\nArgs:\n\n‚Äãval (Int): The integer to check.\n\nReturns:\n\nTrue if val is a power of two, otherwise False.\n\nis_odd\n\nis_odd(val: Int) -> Bool\n\nPerforms elementwise check of whether an integer value is odd.\n\nArgs:\n\n‚Äãval (Int): The int value to check.\n\nReturns:\n\nTrue if the input is odd and False otherwise.\n\nis_odd[type: DType, simd_width: Int](val: SIMD[type, simd_width]) -> SIMD[bool, simd_width]\n\nPerforms elementwise check of whether SIMD vector contains odd values.\n\nAn element of the result SIMD vector will be True if the value is odd, and False otherwise.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãval (SIMD[type, simd_width]): The SIMD vector to check.\n\nReturns:\n\nA SIMD vector containing True if the corresponding element in val is odd, otherwise False.\n\nis_even\n\nis_even(val: Int) -> Bool\n\nPerforms elementwise check of whether an integer value is even.\n\nArgs:\n\n‚Äãval (Int): The int value to check.\n\nReturns:\n\nTrue if the input is even and False otherwise.\n\nis_even[type: DType, simd_width: Int](val: SIMD[type, simd_width]) -> SIMD[bool, simd_width]\n\nPerforms elementwise check of whether SIMD vector contains even values.\n\nAn element of the result SIMD vector will be True if the value is even, and False otherwise.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãval (SIMD[type, simd_width]): The SIMD vector to check.\n\nReturns:\n\nA SIMD vector containing True if the corresponding element in val is even, otherwise False.\n\nfma\n\nfma(a: Int, b: Int, c: Int) -> Int\n\nPerforms fma (fused multiply-add) on the inputs.\n\nThe result is (a * b) + c.\n\nArgs:\n\n‚Äãa (Int): The first input.\n‚Äãb (Int): The second input.\n‚Äãc (Int): The third input.\n\nReturns:\n\n(a * b) + c.\n\nfma[type: DType, simd_width: Int](a: SIMD[type, simd_width], b: SIMD[type, simd_width], c: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nPerforms elementwise fma (fused multiply-add) on the inputs.\n\nEach element in the result SIMD vector is \n(\nùê¥\nùëñ\n‚àó\nùêµ\nùëñ\n)\n+\nùê∂\nùëñ\n, where \nùê¥\nùëñ\n, \nùêµ\nùëñ\n and \nùê∂\nùëñ\n are elements at index \nùëñ\n in a, b, and c respectively.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãa (SIMD[type, simd_width]): The first vector of inputs.\n‚Äãb (SIMD[type, simd_width]): The second vector of inputs.\n‚Äãc (SIMD[type, simd_width]): The third vector of inputs.\n\nReturns:\n\nElementwise fma of a, b and c.\n\nreciprocal\n\nreciprocal[type: DType, simd_width: Int](x: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nTakes the elementwise reciprocal of a SIMD vector.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãx (SIMD[type, simd_width]): The SIMD vector to perform elementwise reciprocal on.\n\nReturns:\n\nA SIMD vector the elementwise reciprocal of x.\n\nidentity\n\nidentity[type: DType, simd_width: Int](x: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nGets the identity of a SIMD vector.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãx (SIMD[type, simd_width]): The SIMD vector to take identity of.\n\nReturns:\n\nIdentity of x, which is x.\n\ngreater\n\ngreater[type: DType, simd_width: Int](x: SIMD[type, simd_width], y: SIMD[type, simd_width]) -> SIMD[bool, simd_width]\n\nPerforms elementwise check of whether values in x are greater than values in y.\n\nAn element of the result SIMD vector will be True if the corresponding element in x is greater than the corresponding element in y, and False otherwise.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãx (SIMD[type, simd_width]): First SIMD vector to compare.\n‚Äãy (SIMD[type, simd_width]): Second SIMD vector to compare.\n\nReturns:\n\nA SIMD vector containing True if the corresponding element in x is greater than the corresponding element in y, otherwise False.\n\ngreater_equal\n\ngreater_equal[type: DType, simd_width: Int](x: SIMD[type, simd_width], y: SIMD[type, simd_width]) -> SIMD[bool, simd_width]\n\nPerforms elementwise check of whether values in x are greater than or equal to values in y.\n\nAn element of the result SIMD vector will be True if the corresponding element in x is greater than or equal to the corresponding element in y, and False otherwise.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãx (SIMD[type, simd_width]): First SIMD vector to compare.\n‚Äãy (SIMD[type, simd_width]): Second SIMD vector to compare.\n\nReturns:\n\nA SIMD vector containing True if the corresponding element in x is greater than or equal to the corresponding element in y, otherwise False.\n\nless\n\nless[type: DType, simd_width: Int](x: SIMD[type, simd_width], y: SIMD[type, simd_width]) -> SIMD[bool, simd_width]\n\nPerforms elementwise check of whether values in x are less than values in y.\n\nAn element of the result SIMD vector will be True if the corresponding element in x is less than the corresponding element in y, and False otherwise.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãx (SIMD[type, simd_width]): First SIMD vector to compare.\n‚Äãy (SIMD[type, simd_width]): Second SIMD vector to compare.\n\nReturns:\n\nA SIMD vector containing True if the corresponding element in x is less than the corresponding element in y, otherwise False.\n\nless_equal\n\nless_equal[type: DType, simd_width: Int](x: SIMD[type, simd_width], y: SIMD[type, simd_width]) -> SIMD[bool, simd_width]\n\nPerforms elementwise check of whether values in x are less than or equal to values in y.\n\nAn element of the result SIMD vector will be True if the corresponding element in x is less than or equal to the corresponding element in y, and False otherwise.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãx (SIMD[type, simd_width]): First SIMD vector to compare.\n‚Äãy (SIMD[type, simd_width]): Second SIMD vector to compare.\n\nReturns:\n\nA SIMD vector containing True if the corresponding element in x is less than or equal to the corresponding element in y, otherwise False.\n\nequal\n\nequal[type: DType, simd_width: Int](x: SIMD[type, simd_width], y: SIMD[type, simd_width]) -> SIMD[bool, simd_width]\n\nPerforms elementwise check of whether values in x are equal to values in y.\n\nAn element of the result SIMD vector will be True if the corresponding element in x is equal to the corresponding element in y, and False otherwise.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãx (SIMD[type, simd_width]): First SIMD vector to compare.\n‚Äãy (SIMD[type, simd_width]): Second SIMD vector to compare.\n\nReturns:\n\nA SIMD vector containing True if the corresponding element in x is equal to the corresponding element in y, otherwise False.\n\nlogical_and\n\nlogical_and[simd_width: Int](x: SIMD[bool, simd_width], y: SIMD[bool, simd_width]) -> SIMD[bool, simd_width]\n\nPerforms elementwise logical And operation.\n\nAn element of the result SIMD vector will be True if the corresponding elements in x and y are both True, and False otherwise.\n\nParameters:\n\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãx (SIMD[bool, simd_width]): First SIMD vector to perform the And operation.\n‚Äãy (SIMD[bool, simd_width]): Second SIMD vector to perform the And operation.\n\nReturns:\n\nA SIMD vector containing True if the corresponding elements in x and y are both True, otherwise False.\n\nlogical_not\n\nlogical_not[simd_width: Int](x: SIMD[bool, simd_width]) -> SIMD[bool, simd_width]\n\nPerforms elementwise logical Not operation.\n\nAn element of the result SIMD vector will be True if the corresponding element in x is True, and False otherwise.\n\nParameters:\n\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãx (SIMD[bool, simd_width]): SIMD vector to perform the Not operation.\n\nReturns:\n\nA SIMD vector containing True if the corresponding element in x is True, otherwise False.\n\nlogical_xor\n\nlogical_xor[simd_width: Int](x: SIMD[bool, simd_width], y: SIMD[bool, simd_width]) -> SIMD[bool, simd_width]\n\nPerforms elementwise logical Xor operation.\n\nAn element of the result SIMD vector will be True if only one of the corresponding elements in x and y is True, and False otherwise.\n\nParameters:\n\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãx (SIMD[bool, simd_width]): First SIMD vector to perform the Xor operation.\n‚Äãy (SIMD[bool, simd_width]): Second SIMD vector to perform the Xor operation.\n\nReturns:\n\nA SIMD vector containing True if only one of the corresponding elements in x and y is True, otherwise False.\n\nnot_equal\n\nnot_equal[type: DType, simd_width: Int](x: SIMD[type, simd_width], y: SIMD[type, simd_width]) -> SIMD[bool, simd_width]\n\nPerforms elementwise check of whether values in x are not equal to values in y.\n\nAn element of the result SIMD vector will be True if the corresponding element in x is not equal to the corresponding element in y, and False otherwise.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãx (SIMD[type, simd_width]): First SIMD vector to compare.\n‚Äãy (SIMD[type, simd_width]): Second SIMD vector to compare.\n\nReturns:\n\nA SIMD vector containing True if the corresponding element in x is not equal to the corresponding element in y, otherwise False.\n\nselect\n\nselect[type: DType, simd_width: Int](cond: SIMD[bool, simd_width], true_case: SIMD[type, simd_width], false_case: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nSelects the values of the true_case or the false_case based on the input boolean values of the given SIMD vector.\n\nParameters:\n\n‚Äãtype (DType): The element type of the input and output SIMD vectors.\n‚Äãsimd_width (Int): Width of the SIMD vectors we are comparing.\n\nArgs:\n\n‚Äãcond (SIMD[bool, simd_width]): The vector of bools to check.\n‚Äãtrue_case (SIMD[type, simd_width]): The values selected if the positional value is True.\n‚Äãfalse_case (SIMD[type, simd_width]): The values selected if the positional value is False.\n\nReturns:\n\nA new vector of the form [true_case[i] if cond[i] else false_case[i] in enumerate(self)].\n\nmax\n\nmax(x: Int, y: Int) -> Int\n\nGets the maximum of two integers.\n\nArgs:\n\n‚Äãx (Int): Integer input to max.\n‚Äãy (Int): Integer input to max.\n\nReturns:\n\nMaximum of x and y.\n\nmax[type: DType, simd_width: Int](x: SIMD[type, simd_width], y: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nPerforms elementwise maximum of x and y.\n\nAn element of the result SIMD vector will be the maximum of the corresponding elements in x and y.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãx (SIMD[type, simd_width]): First SIMD vector.\n‚Äãy (SIMD[type, simd_width]): Second SIMD vector.\n\nReturns:\n\nA SIMD vector containing the elementwise maximum of x and y.\n\nmin\n\nmin(x: Int, y: Int) -> Int\n\nGets the minimum of two integers.\n\nArgs:\n\n‚Äãx (Int): Integer input to max.\n‚Äãy (Int): Integer input to max.\n\nReturns:\n\nMinimum of x and y.\n\nmin[type: DType, simd_width: Int](x: SIMD[type, simd_width], y: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nGets the elementwise minimum of x and y.\n\nAn element of the result SIMD vector will be the minimum of the corresponding elements in x and y.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãx (SIMD[type, simd_width]): First SIMD vector.\n‚Äãy (SIMD[type, simd_width]): Second SIMD vector.\n\nReturns:\n\nA SIMD vector containing the elementwise minimum of x and y.\n\npow\n\npow[type: DType, simd_width: Int](lhs: SIMD[type, simd_width], rhs: Int) -> SIMD[type, simd_width]\n\nComputes the pow of the inputs.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãlhs (SIMD[type, simd_width]): The first input argument.\n‚Äãrhs (Int): The second input argument.\n\nReturns:\n\nThe pow of the inputs.\n\npow[lhs_type: DType, rhs_type: DType, simd_width: Int](lhs: SIMD[lhs_type, simd_width], rhs: SIMD[rhs_type, simd_width]) -> SIMD[lhs_type, simd_width]\n\nComputes elementwise power of a floating point type raised to another floating point type.\n\nAn element of the result SIMD vector will be the result of raising the corresponding element of lhs to the corresponding element of rhs.\n\nConstraints:\n\nrhs_type and lhs_type must be the same, and must be floating point types.\n\nParameters:\n\n‚Äãlhs_type (DType): The dtype of the lhs SIMD vector.\n‚Äãrhs_type (DType): The dtype of the rhs SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vectors.\n\nArgs:\n\n‚Äãlhs (SIMD[lhs_type, simd_width]): Base of the power operation.\n‚Äãrhs (SIMD[rhs_type, simd_width]): Exponent of the power operation.\n\nReturns:\n\nA SIMD vector containing elementwise lhs raised to the power of rhs.\n\npow[n: Int, type: DType, simd_width: Int](x: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nComputes the elementwise power where the exponent is an integer known at compile time.\n\nConstraints:\n\nn must be a signed si32 type.\n\nParameters:\n\n‚Äãn (Int): Exponent of the power operation.\n‚Äãtype (DType): The dtype of the x SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vectors.\n\nArgs:\n\n‚Äãx (SIMD[type, simd_width]): Base of the power operation.\n\nReturns:\n\nA SIMD vector containing elementwise x raised to the power of n.\n\ndiv_ceil\n\ndiv_ceil(numerator: Int, denominator: Int) -> Int\n\nDivides an integer by another integer, and round up to the nearest integer.\n\nConstraints:\n\nWill raise an exception if denominator is zero.\n\nArgs:\n\n‚Äãnumerator (Int): The numerator.\n‚Äãdenominator (Int): The denominator.\n\nReturns:\n\nThe ceiling of numerator divided by denominator.\n\nalign_down\n\nalign_down(value: Int, alignment: Int) -> Int\n\nReturns the closest multiple of alignment that is less than or equal to value.\n\nConstraints:\n\nWill raise an exception if the alignment is zero.\n\nArgs:\n\n‚Äãvalue (Int): The value to align.\n‚Äãalignment (Int): Value to align to.\n\nReturns:\n\nClosest multiple of the alignment that is less than or equal to the input value. In other words, floor(value / alignment) * alignment.\n\nalign_down_residual\n\nalign_down_residual(value: Int, alignment: Int) -> Int\n\nReturns the remainder after aligning down value to alignment.\n\nConstraints:\n\nWill raise an exception if the alignment is zero.\n\nArgs:\n\n‚Äãvalue (Int): The value to align.\n‚Äãalignment (Int): Value to align to.\n\nReturns:\n\nThe remainder after aligning down value to the closest multiple of alignment. In other words, value - align_down(value, alignment).\n\nalign_up\n\nalign_up(value: Int, alignment: Int) -> Int\n\nReturns the closest multiple of alignment that is greater than or equal to value.\n\nConstraints:\n\nWill raise an exception if the alignment is zero.\n\nArgs:\n\n‚Äãvalue (Int): The value to align.\n‚Äãalignment (Int): Value to align to.\n\nReturns:\n\nClosest multiple of the alignment that is greater than or equal to the input value. In other words, ceiling(value / alignment) * alignment.\n\nacos\n\nacos[type: DType, simd_width: Int](arg: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nComputes the acos of the inputs.\n\nConstraints:\n\nThe input must be a floating point type.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãarg (SIMD[type, simd_width]): The input argument.\n\nReturns:\n\nThe acos of the input.\n\nasin\n\nasin[type: DType, simd_width: Int](arg: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nComputes the asin of the inputs.\n\nConstraints:\n\nThe input must be of floating point type.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãarg (SIMD[type, simd_width]): The input argument.\n\nReturns:\n\nThe asin of the input.\n\natan\n\natan[type: DType, simd_width: Int](arg: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nComputes the atan of the inputs.\n\nConstraints:\n\nThe input must be of floating point type.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãarg (SIMD[type, simd_width]): The input argument.\n\nReturns:\n\nThe atan of the input.\n\natan2\n\natan2[type: DType, simd_width: Int](arg0: SIMD[type, simd_width], arg1: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nComputes the atan2 of the inputs.\n\nConstraints:\n\nThe inputs must be of floating point type.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãarg0 (SIMD[type, simd_width]): The first input argument.\n‚Äãarg1 (SIMD[type, simd_width]): The second input argument.\n\nReturns:\n\nThe atan2 of the inputs.\n\ncos\n\ncos[type: DType, simd_width: Int](arg: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nComputes the cos of the inputs.\n\nConstraints:\n\nThe input must be of floating point type.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãarg (SIMD[type, simd_width]): The input argument.\n\nReturns:\n\nThe cos of the input.\n\nsin\n\nsin[type: DType, simd_width: Int](arg: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nComputes the sin of the inputs.\n\nConstraints:\n\nThe input must be of floating point type.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãarg (SIMD[type, simd_width]): The input argument.\n\nReturns:\n\nThe sin of the input.\n\ntan\n\ntan[type: DType, simd_width: Int](arg: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nComputes the tan of the inputs.\n\nConstraints:\n\nThe input must be of floating point type.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãarg (SIMD[type, simd_width]): The input argument.\n\nReturns:\n\nThe tan of the input.\n\nacosh\n\nacosh[type: DType, simd_width: Int](arg: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nComputes the acosh of the inputs.\n\nConstraints:\n\nThe input must be of floating point type.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãarg (SIMD[type, simd_width]): The input argument.\n\nReturns:\n\nThe acosh of the input.\n\nasinh\n\nasinh[type: DType, simd_width: Int](arg: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nComputes the asinh of the inputs.\n\nConstraints:\n\nThe input must be of floating point type.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãarg (SIMD[type, simd_width]): The input argument.\n\nReturns:\n\nThe asinh of the input.\n\natanh\n\natanh[type: DType, simd_width: Int](arg: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nComputes the atanh of the inputs.\n\nConstraints:\n\nThe input must be of floating point type.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãarg (SIMD[type, simd_width]): The input argument.\n\nReturns:\n\nThe atanh of the input.\n\ncosh\n\ncosh[type: DType, simd_width: Int](arg: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nComputes the cosh of the inputs.\n\nConstraints:\n\nThe input must be of floating point type.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãarg (SIMD[type, simd_width]): The input argument.\n\nReturns:\n\nThe cosh of the input.\n\nsinh\n\nsinh[type: DType, simd_width: Int](arg: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nComputes the sinh of the inputs.\n\nConstraints:\n\nThe input must be of floating point type.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãarg (SIMD[type, simd_width]): The input argument.\n\nReturns:\n\nThe sinh of the input.\n\nexpm1\n\nexpm1[type: DType, simd_width: Int](arg: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nComputes the expm1 of the inputs.\n\nConstraints:\n\nThe input must be of floating point type.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãarg (SIMD[type, simd_width]): The input argument.\n\nReturns:\n\nThe expm1 of the input.\n\nlog10\n\nlog10[type: DType, simd_width: Int](arg: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nComputes the log10 of the inputs.\n\nConstraints:\n\nThe input must be of floating point type.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãarg (SIMD[type, simd_width]): The input argument.\n\nReturns:\n\nThe log10 of the input.\n\nlog1p\n\nlog1p[type: DType, simd_width: Int](arg: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nComputes the log1p of the inputs.\n\nConstraints:\n\nThe input must be of floating point type.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãarg (SIMD[type, simd_width]): The input argument.\n\nReturns:\n\nThe log1p of the input.\n\nlogb\n\nlogb[type: DType, simd_width: Int](arg: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nComputes the logb of the inputs.\n\nConstraints:\n\nThe input must be of floating point type.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãarg (SIMD[type, simd_width]): The input argument.\n\nReturns:\n\nThe logb of the input.\n\ncbrt\n\ncbrt[type: DType, simd_width: Int](arg: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nComputes the cbrt of the inputs.\n\nConstraints:\n\nThe input must be of floating point type.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãarg (SIMD[type, simd_width]): The input argument.\n\nReturns:\n\nThe cbrt of the input.\n\nhypot\n\nhypot[type: DType, simd_width: Int](arg0: SIMD[type, simd_width], arg1: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nComputes the hypot of the inputs.\n\nConstraints:\n\nThe inputs must be of floating point type.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãarg0 (SIMD[type, simd_width]): The first input argument.\n‚Äãarg1 (SIMD[type, simd_width]): The second input argument.\n\nReturns:\n\nThe hypot of the inputs.\n\nerfc\n\nerfc[type: DType, simd_width: Int](arg: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nComputes the erfc of the inputs.\n\nConstraints:\n\nThe input must be of floating point type.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãarg (SIMD[type, simd_width]): The input argument.\n\nReturns:\n\nThe erfc of the input.\n\nlgamma\n\nlgamma[type: DType, simd_width: Int](arg: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nComputes the lgamma of the inputs.\n\nConstraints:\n\nThe input must be of floating point type.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãarg (SIMD[type, simd_width]): The input argument.\n\nReturns:\n\nThe lgamma of the input.\n\ntgamma\n\ntgamma[type: DType, simd_width: Int](arg: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nComputes the tgamma of the inputs.\n\nConstraints:\n\nThe input must be of floating point type.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãarg (SIMD[type, simd_width]): The input argument.\n\nReturns:\n\nThe tgamma of the input.\n\nnearbyint\n\nnearbyint[type: DType, simd_width: Int](arg: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nComputes the nearbyint of the inputs.\n\nConstraints:\n\nThe input must be of floating point type.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãarg (SIMD[type, simd_width]): The input argument.\n\nReturns:\n\nThe nearbyint of the input.\n\nrint\n\nrint[type: DType, simd_width: Int](arg: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nComputes the rint of the inputs.\n\nConstraints:\n\nThe input must be of floating point type.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãarg (SIMD[type, simd_width]): The input argument.\n\nReturns:\n\nThe rint of the input.\n\nremainder\n\nremainder[type: DType, simd_width: Int](arg0: SIMD[type, simd_width], arg1: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nComputes the remainder of the inputs.\n\nConstraints:\n\nThe inputs must be of floating point type.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãarg0 (SIMD[type, simd_width]): The first input argument.\n‚Äãarg1 (SIMD[type, simd_width]): The second input argument.\n\nReturns:\n\nThe remainder of the inputs.\n\nnextafter\n\nnextafter[type: DType, simd_width: Int](arg0: SIMD[type, simd_width], arg1: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nComputes the nextafter of the inputs.\n\nConstraints:\n\nThe inputs must be of floating point type.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãarg0 (SIMD[type, simd_width]): The first input argument.\n‚Äãarg1 (SIMD[type, simd_width]): The second input argument.\n\nReturns:\n\nThe nextafter of the inputs.\n\nj0\n\nj0[type: DType, simd_width: Int](arg: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nComputes the j0 of the inputs.\n\nConstraints:\n\nThe input must be of floating point type.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãarg (SIMD[type, simd_width]): The input argument.\n\nReturns:\n\nThe j0 of the input.\n\nj1\n\nj1[type: DType, simd_width: Int](arg: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nComputes the j1 of the inputs.\n\nConstraints:\n\nThe input must be of floating point type.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãarg (SIMD[type, simd_width]): The input argument.\n\nReturns:\n\nThe j1 of the input.\n\ny0\n\ny0[type: DType, simd_width: Int](arg: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nComputes the y0 of the inputs.\n\nConstraints:\n\nThe input must be of floating point type.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãarg (SIMD[type, simd_width]): The input argument.\n\nReturns:\n\nThe y0 of the input.\n\ny1\n\ny1[type: DType, simd_width: Int](arg: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nComputes the y1 of the inputs.\n\nConstraints:\n\nThe input must be of floating point type.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãarg (SIMD[type, simd_width]): The input argument.\n\nReturns:\n\nThe y1 of the input.\n\nscalb\n\nscalb[type: DType, simd_width: Int](arg0: SIMD[type, simd_width], arg1: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nComputes the scalb of the inputs.\n\nConstraints:\n\nThe inputs must be of floating point type.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãarg0 (SIMD[type, simd_width]): The first input argument.\n‚Äãarg1 (SIMD[type, simd_width]): The second input argument.\n\nReturns:\n\nThe scalb of the inputs.\n\ngcd\n\ngcd(a: Int, b: Int) -> Int\n\nComputes the greatest common divisor of two integers.\n\nConstraints:\n\nThe inputs must be non-negative integers.\n\nArgs:\n\n‚Äãa (Int): The first input argument.\n‚Äãb (Int): The second input argument.\n\nReturns:\n\nThe gcd of the inputs.\n\nlcm\n\nlcm(a: Int, b: Int) -> Int\n\nComputes the least common divisor of two integers.\n\nConstraints:\n\nThe inputs must be non-negative integers.\n\nArgs:\n\n‚Äãa (Int): The first input argument.\n‚Äãb (Int): The second input argument.\n\nReturns:\n\nThe lcm of the inputs.\n\nfactorial\n\nfactorial(n: Int) -> Int\n\nComputes the factorial of the integer.\n\nArgs:\n\n‚Äãn (Int): The input value.\n\nReturns:\n\nThe factorial of the input.\n\nnan\n\nnan[type: DType]() -> SIMD[type, 1]\n\nGets a NaN value for the given dtype.\n\nConstraints:\n\nCan only be used for FP dtypes.\n\nParameters:\n\n‚Äãtype (DType): The value dtype.\n\nReturns:\n\nThe NaN value of the given dtype.\n\nisnan\n\nisnan[type: DType, simd_width: Int](val: SIMD[type, simd_width]) -> SIMD[bool, simd_width]\n\nChecks if the value is Not a Number (NaN).\n\nParameters:\n\n‚Äãtype (DType): The value dtype.\n‚Äãsimd_width (Int): The width of the SIMD vector.\n\nArgs:\n\n‚Äãval (SIMD[type, simd_width]): The value to check.\n\nReturns:\n\nTrue if val is NaN and False otherwise.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - env",
    "url": "https://docs.modular.com/mojo/stdlib/os/env.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\natomic\nenv\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nsetenv\ngetenv\nenv\n\nModule\n\nImplements basic routines for working with the OS.\n\nYou can import these APIs from the os package. For example:\n\nfrom os import setenv\nsetenv\n\nsetenv(name: StringRef, value: StringRef, overwrite: Bool) -> Bool\n\nChanges or adds an environment variable.\n\nConstraints:\n\nThe function only works on macOS or Linux and returns False otherwise.\n\nArgs:\n\n‚Äãname (StringRef): The name of the environment variable.\n‚Äãvalue (StringRef): The value of the environment variable.\n‚Äãoverwrite (Bool): If an environment variable with the given name already exists, its value is not changed unless overwrite is True.\n\nReturns:\n\nFalse if the name is empty or contains an = character. In any other case, True is returned.\n\ngetenv\n\ngetenv(name: StringRef, default: StringRef) -> StringRef\n\nReturns the value of the given environment variable.\n\nConstraints:\n\nThe function only works on macOS or Linux and returns an empty string otherwise.\n\nArgs:\n\n‚Äãname (StringRef): The name of the environment variable.\n‚Äãdefault (StringRef): The default value to return if the environment variable doesn‚Äôt exist.\n\nReturns:\n\nThe value of the environment variable.\n\ngetenv(name: StringRef) -> StringRef\n\nReturns the value of the given environment variable. If the environment variable is not found, then an empty string is returned.\n\nConstraints:\n\nThe function only works on macOS or Linux and returns an empty string otherwise.\n\nArgs:\n\n‚Äãname (StringRef): The name of the environment variable.\n\nReturns:\n\nThe value of the environment variable.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - atomic",
    "url": "https://docs.modular.com/mojo/stdlib/os/atomic.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\natomic\nenv\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nAtomic\n__init__\n__iadd__\n__isub__\nfetch_add\nfetch_sub\nmax\nmin\natomic\n\nModule\n\nImplements the Atomic class.\n\nYou can import these APIs from the os package. For example:\n\nfrom os.atomic import Atomic\nAtomic\n\nRepresents a value with atomic operations.\n\nThe class provides atomic add and sub methods for mutating the value.\n\nParameters:\n\n‚Äãtype (DType): DType of the value.\n\nFields:\n\n‚Äãvalue (SIMD[type, 1]): The atomic value.\n\nFunctions:\n\n__init__\n\n__init__(inout self: Self, value: SIMD[type, 1])\n\nConstructs a new atomic value.\n\nArgs:\n\n‚Äãvalue (SIMD[type, 1]): Initial value represented as SIMD[type, 1] type.\n\n__init__(inout self: Self, value: Int)\n\nConstructs a new atomic value.\n\nArgs:\n\n‚Äãvalue (Int): Initial value represented as mlir.index type.\n__iadd__\n\n__iadd__(inout self: Self, rhs: SIMD[type, 1])\n\nPerforms atomic in-place add.\n\nAtomically replaces the current value with the result of arithmetic addition of the value and arg. That is, it performs atomic post-increment. The operation is a read-modify-write operation. Memory is affected according to the value of order which is sequentially consistent.\n\nArgs:\n\n‚Äãrhs (SIMD[type, 1]): Value to add.\n__isub__\n\n__isub__(inout self: Self, rhs: SIMD[type, 1])\n\nPerforms atomic in-place sub.\n\nAtomically replaces the current value with the result of arithmetic subtraction of the value and arg. That is, it performs atomic post-decrement. The operation is a read-modify-write operation. Memory is affected according to the value of order which is sequentially consistent.\n\nArgs:\n\n‚Äãrhs (SIMD[type, 1]): Value to subtract.\nfetch_add\n\nfetch_add(inout self: Self, rhs: SIMD[type, 1]) -> SIMD[type, 1]\n\nPerforms atomic in-place add.\n\nAtomically replaces the current value with the result of arithmetic addition of the value and arg. That is, it performs atomic post-increment. The operation is a read-modify-write operation. Memory is affected according to the value of order which is sequentially consistent.\n\nArgs:\n\n‚Äãrhs (SIMD[type, 1]): Value to add.\n\nReturns:\n\nThe original value before addition.\n\nfetch_sub\n\nfetch_sub(inout self: Self, rhs: SIMD[type, 1]) -> SIMD[type, 1]\n\nPerforms atomic in-place sub.\n\nAtomically replaces the current value with the result of arithmetic subtraction of the value and arg. That is, it performs atomic post-decrement. The operation is a read-modify-write operation. Memory is affected according to the value of order which is sequentially consistent.\n\nArgs:\n\n‚Äãrhs (SIMD[type, 1]): Value to subtract.\n\nReturns:\n\nThe original value before subtraction.\n\nmax\n\nmax(inout self: Self, rhs: SIMD[type, 1])\n\nPerforms atomic in-place max.\n\nAtomically replaces the current value with the result of max of the value and arg. The operation is a read-modify-write operation perform according to sequential consistency semantics.\n\nConstraints:\n\nThe input type must be either integral or floating-point type.\n\nArgs:\n\n‚Äãrhs (SIMD[type, 1]): Value to max.\nmin\n\nmin(inout self: Self, rhs: SIMD[type, 1])\n\nPerforms atomic in-place min.\n\nAtomically replaces the current value with the result of min of the value and arg. The operation is a read-modify-write operation. The operation is a read-modify-write operation perform according to sequential consistency semantics.\n\nConstraints:\n\nThe input type must be either integral or floating-point type.\n\nArgs:\n\n‚Äãrhs (SIMD[type, 1]): Value to min.\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - unsafe",
    "url": "https://docs.modular.com/mojo/stdlib/memory/unsafe.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nbuffer\nmemory\nunsafe\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nPointer\n__init__\n__bool__\n__getitem__\n__eq__\n__ne__\n__add__\n__sub__\n__iadd__\n__isub__\nget_null\naddress_of\nload\nstore\nalloc\naligned_alloc\nfree\nbitcast\noffset\nDTypePointer\nbitcast\nunsafe\n\nModule\n\nImplements classes for working with unsafe pointers.\n\nYou can import these APIs from the memory package. For example:\n\nfrom memory.unsafe import Pointer\nPointer\n\nDefines a Pointer struct that contains an address of any mlirtype.\n\nParameters:\n\n‚Äãtype (AnyType): Type of the underlying data.\n\nAliases:\n\n‚Äãpointer_type = pointer<*\"type\">\n\nFields:\n\n‚Äãaddress (pointer<*\"type\">): The pointed-to address.\n\nFunctions:\n\n__init__\n\n__init__() -> Self\n\nConstructs a null Pointer from the value of pop.pointer type.\n\nReturns:\n\nConstructed Pointer object.\n\n__init__(address: Self) -> Self\n\nConstructs a Pointer from the address.\n\nArgs:\n\n‚Äãaddress (Self): The input pointer.\n\nReturns:\n\nConstructed Pointer object.\n\n__init__(address: pointer<*\"type\">) -> Self\n\nConstructs a Pointer from the address.\n\nArgs:\n\n‚Äãaddress (pointer<*\"type\">): The input pointer address.\n\nReturns:\n\nConstructed Pointer object.\n\n__init__(value: SIMD[address, 1]) -> Self\n\nConstructs a Pointer from the value of scalar address.\n\nArgs:\n\n‚Äãvalue (SIMD[address, 1]): The input pointer index.\n\nReturns:\n\nConstructed Pointer object.\n\n__bool__\n\n__bool__(self: Self) -> Bool\n\nChecks if the pointer is null.\n\nReturns:\n\nReturns False if the pointer is null and True otherwise.\n\n__getitem__\n\n__getitem__(self: Self, offset: Int) -> *\"type\"\n\nLoads the value the Pointer object points to with the given offset.\n\nArgs:\n\n‚Äãoffset (Int): The offset to load from.\n\nReturns:\n\nThe loaded value.\n\n__eq__\n\n__eq__(self: Self, rhs: Self) -> Bool\n\nReturns True if the two pointers are equal.\n\nArgs:\n\n‚Äãrhs (Self): The value of the other pointer.\n\nReturns:\n\nTrue if the two pointers are equal and False otherwise.\n\n__ne__\n\n__ne__(self: Self, rhs: Self) -> Bool\n\nReturns True if the two pointers are not equal.\n\nArgs:\n\n‚Äãrhs (Self): The value of the other pointer.\n\nReturns:\n\nTrue if the two pointers are not equal and False otherwise.\n\n__add__\n\n__add__(self: Self, rhs: Int) -> Self\n\nReturns a new pointer shifted by the specified offset.\n\nArgs:\n\n‚Äãrhs (Int): The offset.\n\nReturns:\n\nThe new Pointer shifted by the offset.\n\n__sub__\n\n__sub__(self: Self, rhs: Int) -> Self\n\nReturns a new pointer shifted back by the specified offset.\n\nArgs:\n\n‚Äãrhs (Int): The offset.\n\nReturns:\n\nThe new Pointer shifted back by the offset.\n\n__iadd__\n\n__iadd__(inout self: Self, rhs: Int)\n\nShifts the current pointer by the specified offset.\n\nArgs:\n\n‚Äãrhs (Int): The offset.\n__isub__\n\n__isub__(inout self: Self, rhs: Int)\n\nShifts back the current pointer by the specified offset.\n\nArgs:\n\n‚Äãrhs (Int): The offset.\nget_null\n\nget_null() -> Self\n\nConstructs a Pointer representing nullptr.\n\nReturns:\n\nConstructed nullptr Pointer object.\n\naddress_of\n\naddress_of(inout *arg: \"type\") -> Self\n\nGets the address of the argument.\n\nArgs:\n\n‚Äãarg (*\"type\"): The value to get the address of.\n\nReturns:\n\nA pointer struct which contains the address of the argument.\n\nload\n\nload(self: Self, offset: Int) -> *\"type\"\n\nLoads the value the Pointer object points to with the given offset.\n\nArgs:\n\n‚Äãoffset (Int): The offset to load from.\n\nReturns:\n\nThe loaded value.\n\nload(self: Self) -> *\"type\"\n\nLoads the value the Pointer object points to.\n\nReturns:\n\nThe loaded value.\n\nstore\n\nstore(self: Self, offset: Int, *value: \"type\")\n\nStores the specified value to the location the Pointer object points to with the given offset.\n\nArgs:\n\n‚Äãoffset (Int): The offset to load from.\n‚Äãvalue (*\"type\"): The value to store.\n\nstore(self: Self, *value: \"type\")\n\nStores the specified value to the location the Pointer object points to.\n\nArgs:\n\n‚Äãvalue (*\"type\"): The value to store.\nalloc\n\nalloc(count: Int) -> Self\n\nHeap-allocates a number of element of the specified type.\n\nArgs:\n\n‚Äãcount (Int): The number of elements to allocate (note that this is not the bytecount).\n\nReturns:\n\nA new Pointer object which has been allocated on the heap.\n\naligned_alloc\n\naligned_alloc(alignment: Int, count: Int) -> Self\n\nHeap-allocates a number of element of the specified type using the specified alignment.\n\nArgs:\n\n‚Äãalignment (Int): The alignment used for the allocation.\n‚Äãcount (Int): The number of elements to allocate (note that this is not the bytecount).\n\nReturns:\n\nA new Pointer object which has been allocated on the heap.\n\nfree\n\nfree(self: Self)\n\nFrees the heap allocated memory.\n\nbitcast\n\nbitcast[new_type: AnyType](self: Self) -> Pointer[new_type]\n\nBitcasts a Pointer to a different type.\n\nParameters:\n\n‚Äãnew_type (AnyType): The target type.\n\nReturns:\n\nA new Pointer object with the specified type and the same address, as the original Pointer.\n\noffset\n\noffset(self: Self, idx: Int) -> Self\n\nReturns a new pointer shifted by the specified offset.\n\nArgs:\n\n‚Äãidx (Int): The offset.\n\nReturns:\n\nThe new Pointer shifted by the offset.\n\nDTypePointer\n\nDefines a DTypePointer struct that contains an address of the given dtype.\n\nParameters:\n\n‚Äãtype (DType): DType of the underlying data.\n\nAliases:\n\n‚Äãelement_type = scalar<#lit.struct.extract<:!kgen.declref<@\"$builtin\"::@\"$dtype\"::@DType, !lit.metatype<@\"$builtin\"::@\"$dtype\"::@DType>> type, \"value\">>\n‚Äãpointer_type = pointer<scalar<#lit.struct.extract<:!kgen.declref<@\"$builtin\"::@\"$dtype\"::@DType, !lit.metatype<@\"$builtin\"::@\"$dtype\"::@DType>> type, \"value\">>>\n\nFields:\n\n‚Äãaddress (pointer<scalar<#lit.struct.extract<:!kgen.declref<@\"$builtin\"::@\"$dtype\"::@DType, !lit.metatype<@\"$builtin\"::@\"$dtype\"::@DType>> type, \"value\">>>): The pointed-to address.\n\nFunctions:\n\n__init__\n\n__init__() -> Self\n\nConstructs a null DTypePointer from the given type.\n\nReturns:\n\nConstructed DTypePointer object.\n\n__init__(address: Self) -> Self\n\nConstructs a DTypePointer from the address.\n\nArgs:\n\n‚Äãaddress (Self): The input pointer.\n\nReturns:\n\nConstructed Pointer object.\n\n__init__(address: pointer<scalar<#lit.struct.extract<:!kgen.declref<_\"$builtin\"::_\"$dtype\"::_DType, !lit.metatype<_\"$builtin\"::_\"$dtype\"::_DType>> type, \"value\">>>) -> Self\n\nConstructs a DTypePointer from the given address.\n\nArgs:\n\n‚Äãaddress (pointer<scalar<#lit.struct.extract<:!kgen.declref<_\"$builtin\"::_\"$dtype\"::_DType, !lit.metatype<_\"$builtin\"::_\"$dtype\"::_DType>> type, \"value\">>>): The input pointer.\n\nReturns:\n\nConstructed DTypePointer object.\n\n__init__(value: Pointer[SIMD[type, 1]]) -> Self\n\nConstructs a DTypePointer from a scalar pointer of the same type.\n\nArgs:\n\n‚Äãvalue (Pointer[SIMD[type, 1]]): The scalar pointer.\n\nReturns:\n\nConstructed DTypePointer.\n\n__init__(value: SIMD[address, 1]) -> Self\n\nConstructs a DTypePointer from the value of scalar address.\n\nArgs:\n\n‚Äãvalue (SIMD[address, 1]): The input pointer index.\n\nReturns:\n\nConstructed DTypePointer object.\n\n__bool__\n\n__bool__(self: Self) -> Bool\n\nChecks if the pointer is null.\n\nReturns:\n\nReturns False if the pointer is null and True otherwise.\n\n__lt__\n\n__lt__(self: Self, rhs: Self) -> Bool\n\nReturns True if this pointer represents a lower address than rhs.\n\nArgs:\n\n‚Äãrhs (Self): The value of the other pointer.\n\nReturns:\n\nTrue if this pointer represents a lower address and False otherwise.\n\n__eq__\n\n__eq__(self: Self, rhs: Self) -> Bool\n\nReturns True if the two pointers are equal.\n\nArgs:\n\n‚Äãrhs (Self): The value of the other pointer.\n\nReturns:\n\nTrue if the two pointers are equal and False otherwise.\n\n__ne__\n\n__ne__(self: Self, rhs: Self) -> Bool\n\nReturns True if the two pointers are not equal.\n\nArgs:\n\n‚Äãrhs (Self): The value of the other pointer.\n\nReturns:\n\nTrue if the two pointers are not equal and False otherwise.\n\n__add__\n\n__add__(self: Self, rhs: Int) -> Self\n\nReturns a new pointer shifted by the specified offset.\n\nArgs:\n\n‚Äãrhs (Int): The offset.\n\nReturns:\n\nThe new DTypePointer shifted by the offset.\n\n__sub__\n\n__sub__(self: Self, rhs: Int) -> Self\n\nReturns a new pointer shifted back by the specified offset.\n\nArgs:\n\n‚Äãrhs (Int): The offset.\n\nReturns:\n\nThe new DTypePointer shifted by the offset.\n\n__iadd__\n\n__iadd__(inout self: Self, rhs: Int)\n\nShifts the current pointer by the specified offset.\n\nArgs:\n\n‚Äãrhs (Int): The offset.\n__isub__\n\n__isub__(inout self: Self, rhs: Int)\n\nShifts back the current pointer by the specified offset.\n\nArgs:\n\n‚Äãrhs (Int): The offset.\nget_null\n\nget_null() -> Self\n\nConstructs a DTypePointer representing nullptr.\n\nReturns:\n\nConstructed nullptr DTypePointer object.\n\naddress_of\n\naddress_of(inout arg: scalar<#lit.struct.extract<:!kgen.declref<_\"$builtin\"::_\"$dtype\"::_DType, !lit.metatype<_\"$builtin\"::_\"$dtype\"::_DType>> type, \"value\">>) -> Self\n\nGets the address of the argument.\n\nArgs:\n\n‚Äãarg (scalar<#lit.struct.extract<:!kgen.declref<_\"$builtin\"::_\"$dtype\"::_DType, !lit.metatype<_\"$builtin\"::_\"$dtype\"::_DType>> type, \"value\">>): The value to get the address of.\n\nReturns:\n\nA pointer struct which contains the address of the argument.\n\nalloc\n\nalloc(count: Int) -> Self\n\nHeap-allocates a number of element of the specified type.\n\nArgs:\n\n‚Äãcount (Int): The number of elements to allocate (note that this is not the bytecount).\n\nReturns:\n\nA new DTypePointer object which has been allocated on the heap.\n\naligned_alloc\n\naligned_alloc(alignment: Int, count: Int) -> Self\n\nHeap-allocates a number of element of the specified type using the specified alignment.\n\nArgs:\n\n‚Äãalignment (Int): The alignment used for the allocation.\n‚Äãcount (Int): The number of elements to allocate (note that this is not the bytecount).\n\nReturns:\n\nA new DTypePointer object which has been allocated on the heap.\n\nfree\n\nfree(self: Self)\n\nFrees the heap allocates memory.\n\nbitcast\n\nbitcast[new_type: DType](self: Self) -> DTypePointer[new_type]\n\nBitcasts DTypePointer to a different dtype.\n\nParameters:\n\n‚Äãnew_type (DType): The target dtype.\n\nReturns:\n\nA new DTypePointer object with the specified dtype and the same address, as the original DTypePointer.\n\nload\n\nload(self: Self, offset: Int) -> SIMD[type, 1]\n\nLoads a single element (SIMD of size 1) from the pointer at the specified index.\n\nArgs:\n\n‚Äãoffset (Int): The offset to load from.\n\nReturns:\n\nThe loaded value.\n\nload(self: Self) -> SIMD[type, 1]\n\nLoads a single element (SIMD of size 1) from the pointer.\n\nReturns:\n\nThe loaded value.\n\nprefetch\n\nprefetch[params: PrefetchOptions](self: Self)\n\nPrefetches memory at the underlying address.\n\nParameters:\n\n‚Äãparams (PrefetchOptions): Prefetch options (see PrefetchOptions for details).\nsimd_load\n\nsimd_load[width: Int](self: Self, offset: Int) -> SIMD[type, width]\n\nLoads a SIMD vector of elements from the pointer at the specified offset.\n\nParameters:\n\n‚Äãwidth (Int): The SIMD width.\n\nArgs:\n\n‚Äãoffset (Int): The offset to load from.\n\nReturns:\n\nThe loaded value.\n\nsimd_load[width: Int](self: Self) -> SIMD[type, width]\n\nLoads a SIMD vector of elements from the pointer.\n\nParameters:\n\n‚Äãwidth (Int): The SIMD width.\n\nReturns:\n\nThe loaded SIMD value.\n\naligned_simd_load\n\naligned_simd_load[width: Int, alignment: Int](self: Self, offset: Int) -> SIMD[type, width]\n\nLoads a SIMD vector of elements from the pointer at the specified offset with the guaranteed specified alignment.\n\nParameters:\n\n‚Äãwidth (Int): The SIMD width.\n‚Äãalignment (Int): The minimal alignment of the address.\n\nArgs:\n\n‚Äãoffset (Int): The offset to load from.\n\nReturns:\n\nThe loaded SIMD value.\n\naligned_simd_load[width: Int, alignment: Int](self: Self) -> SIMD[type, width]\n\nLoads a SIMD vector of elements from the pointer with the guaranteed specified alignment.\n\nParameters:\n\n‚Äãwidth (Int): The SIMD width.\n‚Äãalignment (Int): The minimal alignment of the address.\n\nReturns:\n\nThe loaded SIMD value.\n\nstore\n\nstore(self: Self, offset: Int, val: SIMD[type, 1])\n\nStores a single element value at the given offset.\n\nArgs:\n\n‚Äãoffset (Int): The offset to store to.\n‚Äãval (SIMD[type, 1]): The value to store.\n\nstore(self: Self, val: SIMD[type, 1])\n\nStores a single element value.\n\nArgs:\n\n‚Äãval (SIMD[type, 1]): The value to store.\nsimd_store\n\nsimd_store[width: Int](self: Self, offset: Int, val: SIMD[type, width])\n\nStores a SIMD vector at the given offset.\n\nParameters:\n\n‚Äãwidth (Int): The SIMD width.\n\nArgs:\n\n‚Äãoffset (Int): The offset to store to.\n‚Äãval (SIMD[type, width]): The SIMD value to store.\n\nsimd_store[width: Int](self: Self, val: SIMD[type, width])\n\nStores a SIMD vector.\n\nParameters:\n\n‚Äãwidth (Int): The SIMD width.\n\nArgs:\n\n‚Äãval (SIMD[type, width]): The SIMD value to store.\nsimd_nt_store\n\nsimd_nt_store[width: Int](self: Self, offset: Int, val: SIMD[type, width])\n\nStores a SIMD vector using non-temporal store.\n\nParameters:\n\n‚Äãwidth (Int): The SIMD width.\n\nArgs:\n\n‚Äãoffset (Int): The offset to store to.\n‚Äãval (SIMD[type, width]): The SIMD value to store.\n\nsimd_nt_store[width: Int](self: Self, val: SIMD[type, width])\n\nStores a SIMD vector using non-temporal store.\n\nThe address must be properly aligned, 64B for avx512, 32B for avx2, and 16B for avx.\n\nParameters:\n\n‚Äãwidth (Int): The SIMD width.\n\nArgs:\n\n‚Äãval (SIMD[type, width]): The SIMD value to store.\nsimd_strided_load\n\nsimd_strided_load[width: Int](self: Self, stride: Int) -> SIMD[type, width]\n\nPerforms a strided load of the SIMD vector.\n\nParameters:\n\n‚Äãwidth (Int): The SIMD width.\n\nArgs:\n\n‚Äãstride (Int): The stride between loads.\n\nReturns:\n\nA vector which is stride loaded.\n\nsimd_strided_store\n\nsimd_strided_store[width: Int](self: Self, val: SIMD[type, width], stride: Int)\n\nPerforms a strided store of the SIMD vector.\n\nParameters:\n\n‚Äãwidth (Int): The SIMD width.\n\nArgs:\n\n‚Äãval (SIMD[type, width]): The SIMD value to store.\n‚Äãstride (Int): The stride between stores.\naligned_simd_store\n\naligned_simd_store[width: Int, alignment: Int](self: Self, offset: Int, val: SIMD[type, width])\n\nStores a SIMD vector at the given offset with a guaranteed alignment.\n\nParameters:\n\n‚Äãwidth (Int): The SIMD width.\n‚Äãalignment (Int): The minimal alignment of the address.\n\nArgs:\n\n‚Äãoffset (Int): The offset to store to.\n‚Äãval (SIMD[type, width]): The SIMD value to store.\n\naligned_simd_store[width: Int, alignment: Int](self: Self, val: SIMD[type, width])\n\nStores a SIMD vector with a guaranteed alignment.\n\nParameters:\n\n‚Äãwidth (Int): The SIMD width.\n‚Äãalignment (Int): The minimal alignment of the address.\n\nArgs:\n\n‚Äãval (SIMD[type, width]): The SIMD value to store.\nis_aligned\n\nis_aligned[alignment: Int](self: Self) -> Bool\n\nChecks if the pointer is aligned.\n\nParameters:\n\n‚Äãalignment (Int): The minimal desired alignment.\n\nReturns:\n\nTrue if the pointer is at least alignment-aligned or False otherwise.\n\noffset\n\noffset(self: Self, idx: Int) -> Self\n\nReturns a new pointer shifted by the specified offset.\n\nArgs:\n\n‚Äãidx (Int): The offset of the new pointer.\n\nReturns:\n\nThe new constructed DTypePointer.\n\nbitcast\n\nbitcast[type: AnyType](val: Int) -> Pointer[*\"type\"]\n\nBitcasts an integer to a pointer.\n\nParameters:\n\n‚Äãtype (AnyType): The target type.\n\nArgs:\n\n‚Äãval (Int): The pointer address.\n\nReturns:\n\nA new Pointer with the specified address.\n\nbitcast[type: DType](val: Int) -> DTypePointer[type]\n\nBitcasts an integer to a pointer.\n\nParameters:\n\n‚Äãtype (DType): The target type.\n\nArgs:\n\n‚Äãval (Int): The pointer address.\n\nReturns:\n\nA new Pointer with the specified address.\n\nbitcast[new_type: AnyType, src_type: AnyType](ptr: Pointer[src_type]) -> Pointer[new_type]\n\nBitcasts a Pointer to a different type.\n\nParameters:\n\n‚Äãnew_type (AnyType): The target type.\n‚Äãsrc_type (AnyType): The source type.\n\nArgs:\n\n‚Äãptr (Pointer[src_type]): The source pointer.\n\nReturns:\n\nA new Pointer with the specified type and the same address, as the original Pointer.\n\nbitcast[new_type: DType, src_type: DType](ptr: DTypePointer[src_type]) -> DTypePointer[new_type]\n\nBitcasts a DTypePointer to a different type.\n\nParameters:\n\n‚Äãnew_type (DType): The target type.\n‚Äãsrc_type (DType): The source type.\n\nArgs:\n\n‚Äãptr (DTypePointer[src_type]): The source pointer.\n\nReturns:\n\nA new DTypePointer with the specified type and the same address, as the original DTypePointer.\n\nbitcast[new_type: DType, new_width: Int, src_type: DType, src_width: Int](val: SIMD[src_type, src_width]) -> SIMD[new_type, new_width]\n\nBitcasts a SIMD value to another SIMD value.\n\nConstraints:\n\nThe bitwidth of the two types must be the same.\n\nParameters:\n\n‚Äãnew_type (DType): The target type.\n‚Äãnew_width (Int): The target width.\n‚Äãsrc_type (DType): The source type.\n‚Äãsrc_width (Int): The source width.\n\nArgs:\n\n‚Äãval (SIMD[src_type, src_width]): The source value.\n\nReturns:\n\nA new SIMD value with the specified type and width with a bitcopy of the source SIMD value.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - memory",
    "url": "https://docs.modular.com/mojo/stdlib/memory/memory.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nbuffer\nmemory\nunsafe\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nmemcmp\nmemcpy\nmemset\nmemset_zero\nstack_allocation\nmemory\n\nModule\n\nDefines functions for memory manipulations.\n\nYou can import these APIs from the memory package. For example:\n\nfrom memory import memcmp\nmemcmp\n\nmemcmp[type: DType](s1: DTypePointer[type], s2: DTypePointer[type], count: Int) -> Int\n\nCompares two buffers. Both strings are assumed to be of the same length.\n\nParameters:\n\n‚Äãtype (DType): The element dtype.\n\nArgs:\n\n‚Äãs1 (DTypePointer[type]): The first buffer address.\n‚Äãs2 (DTypePointer[type]): The second buffer address.\n‚Äãcount (Int): The number of elements in the buffers.\n\nReturns:\n\nReturns 0 if the bytes buffers are identical, 1 if s1 > s2, and -1 if s1 < s2. The comparison is performed by the first different byte in the buffer.\n\nmemcmp[type: AnyType](s1: Pointer[*\"type\"], s2: Pointer[*\"type\"], count: Int) -> Int\n\nCompares two buffers. Both strings are assumed to be of the same length.\n\nParameters:\n\n‚Äãtype (AnyType): The element type.\n\nArgs:\n\n‚Äãs1 (Pointer[*\"type\"]): The first buffer address.\n‚Äãs2 (Pointer[*\"type\"]): The second buffer address.\n‚Äãcount (Int): The number of elements in the buffers.\n\nReturns:\n\nReturns 0 if the bytes strings are identical, 1 if s1 > s2, and -1 if s1 < s2. The comparison is performed by the first different byte in the byte strings.\n\nmemcpy\n\nmemcpy[type: AnyType](dest: Pointer[*\"type\"], src: Pointer[*\"type\"], count: Int)\n\nCopies a memory area.\n\nParameters:\n\n‚Äãtype (AnyType): The element type.\n\nArgs:\n\n‚Äãdest (Pointer[*\"type\"]): The destination pointer.\n‚Äãsrc (Pointer[*\"type\"]): The source pointer.\n‚Äãcount (Int): The number of elements to copy.\n\nmemcpy[type: DType](dest: DTypePointer[type], src: DTypePointer[type], count: Int)\n\nCopies a memory area.\n\nParameters:\n\n‚Äãtype (DType): The element dtype.\n\nArgs:\n\n‚Äãdest (DTypePointer[type]): The destination pointer.\n‚Äãsrc (DTypePointer[type]): The source pointer.\n‚Äãcount (Int): The number of elements to copy (not bytes!).\n\nmemcpy[type: DType, size: Dim](dest: Buffer[size, type], src: Buffer[size, type])\n\nCopies a memory buffer from src to dest.\n\nParameters:\n\n‚Äãtype (DType): The element dtype.\n‚Äãsize (Dim): Number of elements in the buffer.\n\nArgs:\n\n‚Äãdest (Buffer[size, type]): The destination buffer.\n‚Äãsrc (Buffer[size, type]): The source buffer.\nmemset\n\nmemset[type: DType](ptr: DTypePointer[type], value: SIMD[ui8, 1], count: Int)\n\nFills memory with the given value.\n\nParameters:\n\n‚Äãtype (DType): The element dtype.\n\nArgs:\n\n‚Äãptr (DTypePointer[type]): Pointer to the beginning of the memory block to fill.\n‚Äãvalue (SIMD[ui8, 1]): The value to fill with.\n‚Äãcount (Int): Number of elements to fill (in elements, not bytes).\nmemset_zero\n\nmemset_zero[type: DType](ptr: DTypePointer[type], count: Int)\n\nFills memory with zeros.\n\nParameters:\n\n‚Äãtype (DType): The element dtype.\n\nArgs:\n\n‚Äãptr (DTypePointer[type]): Pointer to the beginning of the memory block to fill.\n‚Äãcount (Int): Number of elements to set (in elements, not bytes).\n\nmemset_zero[type: AnyType](ptr: Pointer[*\"type\"], count: Int)\n\nFills memory with zeros.\n\nParameters:\n\n‚Äãtype (AnyType): The element type.\n\nArgs:\n\n‚Äãptr (Pointer[*\"type\"]): Pointer to the beginning of the memory block to fill.\n‚Äãcount (Int): Number of elements to fill (in elements, not bytes).\nstack_allocation\n\nstack_allocation[count: Int, type: DType]() -> DTypePointer[type]\n\nAllocates data buffer space on the stack given a data type and number of elements.\n\nParameters:\n\n‚Äãcount (Int): Number of elements to allocate memory for.\n‚Äãtype (DType): The data type of each element.\n\nReturns:\n\nA data pointer of the given type pointing to the allocated space.\n\nstack_allocation[count: Int, type: DType, alignment: Int]() -> DTypePointer[type]\n\nAllocates data buffer space on the stack given a data type and number of elements.\n\nParameters:\n\n‚Äãcount (Int): Number of elements to allocate memory for.\n‚Äãtype (DType): The data type of each element.\n‚Äãalignment (Int): Address alignment of the allocated data.\n\nReturns:\n\nA data pointer of the given type pointing to the allocated space.\n\nstack_allocation[count: Int, type: AnyType]() -> Pointer[*\"type\"]\n\nAllocates data buffer space on the stack given a data type and number of elements.\n\nParameters:\n\n‚Äãcount (Int): Number of elements to allocate memory for.\n‚Äãtype (AnyType): The data type of each element.\n\nReturns:\n\nA data pointer of the given type pointing to the allocated space.\n\nstack_allocation[count: Int, type: AnyType, alignment: Int]() -> Pointer[*\"type\"]\n\nAllocates data buffer space on the stack given a data type and number of elements.\n\nParameters:\n\n‚Äãcount (Int): Number of elements to allocate memory for.\n‚Äãtype (AnyType): The data type of each element.\n‚Äãalignment (Int): Address alignment of the allocated data.\n\nReturns:\n\nA data pointer of the given type pointing to the allocated space.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - buffer",
    "url": "https://docs.modular.com/mojo/stdlib/memory/buffer.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nbuffer\nmemory\nunsafe\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nBuffer\n__init__\n__copyinit__\n__getitem__\n__setitem__\n__len__\nsimd_load\naligned_simd_load\nsimd_store\naligned_simd_store\nsimd_nt_store\nprefetch\nbytecount\nzero\nsimd_fill\nfill\ntofile\naligned_stack_allocation\nstack_allocation\nNDBuffer\nDynamicRankBuffer\npartial_simd_load\npartial_simd_store\nprod_dims\nbuffer\n\nModule\n\nImplements the Buffer class.\n\nYou can import these APIs from the memory package. For example:\n\nfrom memory.buffer import Buffer\nBuffer\n\nDefines a Buffer which can be parametrized on a static size and Dtype.\n\nThe Buffer does not own its underlying pointer.\n\nParameters:\n\n‚Äãsize (Dim): The static size (if known) of the Buffer.\n‚Äãtype (DType): The element type of the Buffer.\n\nFields:\n\n‚Äãdata (DTypePointer[type]): The underlying data pointer of the data.\n‚Äãdynamic_size (Int): The dynamic size of the buffer.\n‚Äãdtype (DType): The dynamic data type of the buffer.\n\nFunctions:\n\n__init__\n\n__init__() -> Self\n\nDefault initializer for Buffer. By default the fields are all initialized to 0.\n\nReturns:\n\nThe NDBuffer object.\n\n__init__(ptr: Pointer[scalar<#lit.struct.extract<:!kgen.declref<_\"$builtin\"::_\"$dtype\"::_DType, !lit.metatype<_\"$builtin\"::_\"$dtype\"::_DType>> type, \"value\">>]) -> Self\n\nConstructs a Buffer with statically known size and type.\n\nConstraints:\n\nThe size is known.\n\nArgs:\n\n‚Äãptr (Pointer[scalar<#lit.struct.extract<:!kgen.declref<_\"$builtin\"::_\"$dtype\"::_DType, !lit.metatype<_\"$builtin\"::_\"$dtype\"::_DType>> type, \"value\">>]): Pointer to the data.\n\nReturns:\n\nThe buffer object.\n\n__init__(ptr: DTypePointer[type]) -> Self\n\nConstructs a Buffer with statically known size and type.\n\nConstraints:\n\nThe size is known.\n\nArgs:\n\n‚Äãptr (DTypePointer[type]): Pointer to the data.\n\nReturns:\n\nThe buffer object.\n\n__init__(ptr: Pointer[scalar<#lit.struct.extract<:!kgen.declref<_\"$builtin\"::_\"$dtype\"::_DType, !lit.metatype<_\"$builtin\"::_\"$dtype\"::_DType>> type, \"value\">>], in_size: Int) -> Self\n\nConstructs a Buffer with statically known type.\n\nConstraints:\n\nThe size is unknown.\n\nArgs:\n\n‚Äãptr (Pointer[scalar<#lit.struct.extract<:!kgen.declref<_\"$builtin\"::_\"$dtype\"::_DType, !lit.metatype<_\"$builtin\"::_\"$dtype\"::_DType>> type, \"value\">>]): Pointer to the data.\n‚Äãin_size (Int): Dynamic size of the buffer.\n\nReturns:\n\nThe buffer object.\n\n__init__(ptr: DTypePointer[type], in_size: Int) -> Self\n\nConstructs a Buffer with statically known type.\n\nConstraints:\n\nThe size is unknown.\n\nArgs:\n\n‚Äãptr (DTypePointer[type]): Pointer to the data.\n‚Äãin_size (Int): Dynamic size of the buffer.\n\nReturns:\n\nThe buffer object.\n\n__init__(data: DTypePointer[type], dynamic_size: Int, dtype: DType, /) -> Self\n\n__copyinit__\n\n__copyinit__(other: Self) -> Self\n\n__getitem__\n\n__getitem__(self: Self, idx: Int) -> SIMD[type, 1]\n\nLoads a single element (SIMD of size 1) from the buffer at the specified index.\n\nArgs:\n\n‚Äãidx (Int): The index into the Buffer.\n\nReturns:\n\nThe value at the idx position.\n\n__setitem__\n\n__setitem__(self: Self, idx: Int, val: scalar<#lit.struct.extract<:!kgen.declref<_\"$builtin\"::_\"$dtype\"::_DType, !lit.metatype<_\"$builtin\"::_\"$dtype\"::_DType>> type, \"value\">>)\n\nStores a single value into the buffer at the specified index.\n\nArgs:\n\n‚Äãidx (Int): The index into the Buffer.\n‚Äãval (scalar<#lit.struct.extract<:!kgen.declref<_\"$builtin\"::_\"$dtype\"::_DType, !lit.metatype<_\"$builtin\"::_\"$dtype\"::_DType>> type, \"value\">>): The value to store.\n\n__setitem__(self: Self, idx: Int, val: SIMD[type, 1])\n\nStores a single value into the buffer at the specified index.\n\nArgs:\n\n‚Äãidx (Int): The index into the Buffer.\n‚Äãval (SIMD[type, 1]): The value to store.\n__len__\n\n__len__(self: Self) -> Int\n\nGets the size if it is a known constant, otherwise it gets the dynamic_size.\n\nThis method is used by Buffer.__len__ to get the size of the buffer. If the Buffer size is a known constant, then the size is returned. Otherwise, the dynamic_size is returned.\n\nReturns:\n\nThe size if static otherwise dynamic_size.\n\nsimd_load\n\nsimd_load[width: Int](self: Self, idx: Int) -> SIMD[type, width]\n\nLoads a simd value from the buffer at the specified index.\n\nParameters:\n\n‚Äãwidth (Int): The simd_width of the load.\n\nArgs:\n\n‚Äãidx (Int): The index into the Buffer.\n\nReturns:\n\nThe simd value starting at the idx position and ending at idx+width.\n\naligned_simd_load\n\naligned_simd_load[width: Int, alignment: Int](self: Self, idx: Int) -> SIMD[type, width]\n\nLoads a simd value from the buffer at the specified index.\n\nParameters:\n\n‚Äãwidth (Int): The simd_width of the load.\n‚Äãalignment (Int): The alignment value.\n\nArgs:\n\n‚Äãidx (Int): The index into the Buffer.\n\nReturns:\n\nThe simd value starting at the idx position and ending at idx+width.\n\nsimd_store\n\nsimd_store[width: Int](self: Self, idx: Int, val: SIMD[type, width])\n\nStores a simd value into the buffer at the specified index.\n\nParameters:\n\n‚Äãwidth (Int): The width of the simd vector.\n\nArgs:\n\n‚Äãidx (Int): The index into the Buffer.\n‚Äãval (SIMD[type, width]): The value to store.\naligned_simd_store\n\naligned_simd_store[width: Int, alignment: Int](self: Self, idx: Int, val: SIMD[type, width])\n\nStores a simd value into the buffer at the specified index.\n\nParameters:\n\n‚Äãwidth (Int): The width of the simd vector.\n‚Äãalignment (Int): The alignment value.\n\nArgs:\n\n‚Äãidx (Int): The index into the Buffer.\n‚Äãval (SIMD[type, width]): The value to store.\nsimd_nt_store\n\nsimd_nt_store[width: Int](self: Self, idx: Int, val: SIMD[type, width])\n\nStores a simd value using non-temporal store.\n\nConstraints:\n\nThe address must be properly aligned, 64B for avx512, 32B for avx2, and 16B for avx.\n\nParameters:\n\n‚Äãwidth (Int): The width of the simd vector.\n\nArgs:\n\n‚Äãidx (Int): The index into the Buffer.\n‚Äãval (SIMD[type, width]): The value to store.\nprefetch\n\nprefetch[params: PrefetchOptions](self: Self, idx: Int)\n\nPrefetches the data at the given index.\n\nParameters:\n\n‚Äãparams (PrefetchOptions): The prefetch configuration.\n\nArgs:\n\n‚Äãidx (Int): The index of the prefetched location.\nbytecount\n\nbytecount(self: Self) -> Int\n\nReturns the size of the Buffer in bytes.\n\nReturns:\n\nThe size of the Buffer in bytes.\n\nzero\n\nzero(self: Self)\n\nSets all bytes of the Buffer to 0.\n\nsimd_fill\n\nsimd_fill[simd_width: Int](self: Self, val: SIMD[type, 1])\n\nAssigns val to all elements in chunks of size simd_width.\n\nParameters:\n\n‚Äãsimd_width (Int): The simd_width of the fill.\n\nArgs:\n\n‚Äãval (SIMD[type, 1]): The value to store.\nfill\n\nfill(self: Self, val: SIMD[type, 1])\n\nAssigns val to all elements in the Buffer.\n\nThe fill is performed in chunks of size N, where N is the native SIMD width of type on the system.\n\nArgs:\n\n‚Äãval (SIMD[type, 1]): The value to store.\ntofile\n\ntofile(self: Self, path: Path)\n\nWrite values to a file.\n\nArgs:\n\n‚Äãpath (Path): Path to the output file.\naligned_stack_allocation\n\naligned_stack_allocation[alignment: Int]() -> Self\n\nConstructs a buffer instance backed by stack allocated memory space.\n\nParameters:\n\n‚Äãalignment (Int): Address alignment requirement for the allocation.\n\nReturns:\n\nConstructed buffer with the allocated space.\n\nstack_allocation\n\nstack_allocation() -> Self\n\nConstructs a buffer instance backed by stack allocated memory space.\n\nReturns:\n\nConstructed buffer with the allocated space.\n\nNDBuffer\n\nAn N-dimensional Buffer.\n\nNDBuffer can be parametrized on rank, static dimensions and Dtype. It does not own its underlying pointer.\n\nParameters:\n\n‚Äãrank (Int): The rank of the buffer.\n‚Äãshape (DimList): The static size (if known) of the buffer.\n‚Äãtype (DType): The element type of the buffer.\n\nFields:\n\n‚Äãdata (DTypePointer[type]): The underlying data for the buffer. The pointer is not owned by the NDBuffer.\n‚Äãdynamic_shape (StaticIntTuple[rank]): The dynamic value of the shape.\n‚Äãdynamic_stride (StaticIntTuple[rank]): The dynamic stride of the buffer.\n‚Äãis_contiguous (Bool): True if the contents of the buffer are contiguous in memory.\n\nFunctions:\n\n__init__\n\n__init__() -> Self\n\nDefault initializer for NDBuffer. By default the fields are all initialized to 0.\n\nReturns:\n\nThe NDBuffer object.\n\n__init__(ptr: Pointer[scalar<#lit.struct.extract<:!kgen.declref<_\"$builtin\"::_\"$dtype\"::_DType, !lit.metatype<_\"$builtin\"::_\"$dtype\"::_DType>> type, \"value\">>]) -> Self\n\nConstructs an NDBuffer with statically known rank, shapes and type.\n\nConstraints:\n\nThe rank, shapes, and type are known.\n\nArgs:\n\n‚Äãptr (Pointer[scalar<#lit.struct.extract<:!kgen.declref<_\"$builtin\"::_\"$dtype\"::_DType, !lit.metatype<_\"$builtin\"::_\"$dtype\"::_DType>> type, \"value\">>]): Pointer to the data.\n\nReturns:\n\nThe NDBuffer object.\n\n__init__(ptr: DTypePointer[type]) -> Self\n\nConstructs an NDBuffer with statically known rank, shapes and type.\n\nConstraints:\n\nThe rank, shapes, and type are known.\n\nArgs:\n\n‚Äãptr (DTypePointer[type]): Pointer to the data.\n\nReturns:\n\nThe NDBuffer object.\n\n__init__(ptr: pointer<scalar<#lit.struct.extract<:!kgen.declref<_\"$builtin\"::_\"$dtype\"::_DType, !lit.metatype<_\"$builtin\"::_\"$dtype\"::_DType>> type, \"value\">>>, dynamic_shape: StaticIntTuple[rank]) -> Self\n\nConstructs an NDBuffer with statically known rank, but dynamic shapes and type.\n\nConstraints:\n\nThe rank is known.\n\nArgs:\n\n‚Äãptr (pointer<scalar<#lit.struct.extract<:!kgen.declref<_\"$builtin\"::_\"$dtype\"::_DType, !lit.metatype<_\"$builtin\"::_\"$dtype\"::_DType>> type, \"value\">>>): Pointer to the data.\n‚Äãdynamic_shape (StaticIntTuple[rank]): A static tuple of size ‚Äòrank‚Äô representing shapes.\n\nReturns:\n\nThe NDBuffer object.\n\n__init__(ptr: Pointer[scalar<#lit.struct.extract<:!kgen.declref<_\"$builtin\"::_\"$dtype\"::_DType, !lit.metatype<_\"$builtin\"::_\"$dtype\"::_DType>> type, \"value\">>], dynamic_shape: StaticIntTuple[rank]) -> Self\n\nConstructs an NDBuffer with statically known rank, but dynamic shapes and type.\n\nConstraints:\n\nThe rank is known.\n\nArgs:\n\n‚Äãptr (Pointer[scalar<#lit.struct.extract<:!kgen.declref<_\"$builtin\"::_\"$dtype\"::_DType, !lit.metatype<_\"$builtin\"::_\"$dtype\"::_DType>> type, \"value\">>]): Pointer to the data.\n‚Äãdynamic_shape (StaticIntTuple[rank]): A static tuple of size ‚Äòrank‚Äô representing shapes.\n\nReturns:\n\nThe NDBuffer object.\n\n__init__(ptr: DTypePointer[type], dynamic_shape: StaticIntTuple[rank]) -> Self\n\nConstructs an NDBuffer with statically known rank, but dynamic shapes and type.\n\nConstraints:\n\nThe rank is known.\n\nArgs:\n\n‚Äãptr (DTypePointer[type]): Pointer to the data.\n‚Äãdynamic_shape (StaticIntTuple[rank]): A static tuple of size ‚Äòrank‚Äô representing shapes.\n\nReturns:\n\nThe NDBuffer object.\n\n__init__(ptr: Pointer[scalar<#lit.struct.extract<:!kgen.declref<_\"$builtin\"::_\"$dtype\"::_DType, !lit.metatype<_\"$builtin\"::_\"$dtype\"::_DType>> type, \"value\">>], dynamic_shape: StaticIntTuple[rank], dynamic_stride: StaticIntTuple[rank]) -> Self\n\nConstructs a strided NDBuffer with statically known rank, but dynamic shapes and type.\n\nConstraints:\n\nThe rank is known.\n\nArgs:\n\n‚Äãptr (Pointer[scalar<#lit.struct.extract<:!kgen.declref<_\"$builtin\"::_\"$dtype\"::_DType, !lit.metatype<_\"$builtin\"::_\"$dtype\"::_DType>> type, \"value\">>]): Pointer to the data.\n‚Äãdynamic_shape (StaticIntTuple[rank]): A static tuple of size ‚Äòrank‚Äô representing shapes.\n‚Äãdynamic_stride (StaticIntTuple[rank]): A static tuple of size ‚Äòrank‚Äô representing strides.\n\nReturns:\n\nThe NDBuffer object.\n\n__init__(ptr: DTypePointer[type], dynamic_shape: StaticIntTuple[rank], dynamic_stride: StaticIntTuple[rank]) -> Self\n\nConstructs a strided NDBuffer with statically known rank, but dynamic shapes and type.\n\nConstraints:\n\nThe rank is known.\n\nArgs:\n\n‚Äãptr (DTypePointer[type]): Pointer to the data.\n‚Äãdynamic_shape (StaticIntTuple[rank]): A static tuple of size ‚Äòrank‚Äô representing shapes.\n‚Äãdynamic_stride (StaticIntTuple[rank]): A static tuple of size ‚Äòrank‚Äô representing strides.\n\nReturns:\n\nThe NDBuffer object.\n\n__init__(data: DTypePointer[type], dynamic_shape: StaticIntTuple[rank], dynamic_stride: StaticIntTuple[rank], is_contiguous: Bool, /) -> Self\n\n__getitem__\n\n__getitem__(self: Self, *idx: Int) -> SIMD[type, 1]\n\nGets an element from the buffer from the specified index.\n\nArgs:\n\n‚Äãidx (*Int): Index of the element to retrieve.\n\nReturns:\n\nThe value of the element.\n\n__getitem__(self: Self, idx: StaticIntTuple[rank]) -> SIMD[type, 1]\n\nGets an element from the buffer from the specified index.\n\nArgs:\n\n‚Äãidx (StaticIntTuple[rank]): Index of the element to retrieve.\n\nReturns:\n\nThe value of the element.\n\n__setitem__\n\n__setitem__(self: Self, idx: StaticIntTuple[rank], val: SIMD[type, 1])\n\nStores a single value into the buffer at the specified index.\n\nArgs:\n\n‚Äãidx (StaticIntTuple[rank]): The index into the Buffer.\n‚Äãval (SIMD[type, 1]): The value to store.\nget_rank\n\nget_rank(self: Self) -> Int\n\nReturns the rank of the buffer.\n\nReturns:\n\nThe rank of NDBuffer.\n\nget_shape\n\nget_shape(self: Self) -> StaticIntTuple[rank]\n\nReturns the shapes of the buffer.\n\nReturns:\n\nA static tuple of size ‚Äòrank‚Äô representing shapes of the NDBuffer.\n\nget_nd_index\n\nget_nd_index(self: Self, idx: Int) -> StaticIntTuple[rank]\n\nComputes the NDBuffer‚Äôs ND-index based on the flat index.\n\nArgs:\n\n‚Äãidx (Int): The flat index.\n\nReturns:\n\nThe index positions.\n\n__len__\n\n__len__(self: Self) -> Int\n\nComputes the NDBuffer‚Äôs number of elements.\n\nReturns:\n\nThe total number of elements in the NDBuffer.\n\nnum_elements\n\nnum_elements(self: Self) -> Int\n\nComputes the NDBuffer‚Äôs number of elements.\n\nReturns:\n\nThe total number of elements in the NDBuffer.\n\nsize\n\nsize(self: Self) -> Int\n\nComputes the NDBuffer‚Äôs number of elements.\n\nReturns:\n\nThe total number of elements in the NDBuffer.\n\n__str__\n\n__str__(self: Self) -> String\n\nGets the buffer as a string.\n\nReturns:\n\nA compact string of the buffer.\n\n__repr__\n\n__repr__(self: Self) -> String\n\nGets the buffer as a string.\n\nReturns:\n\nA compact string representation of the buffer.\n\nsimd_load\n\nsimd_load[width: Int](self: Self, *idx: Int) -> SIMD[type, width]\n\nLoads a simd value from the buffer at the specified index.\n\nConstraints:\n\nThe buffer must be contiguous or width must be 1.\n\nParameters:\n\n‚Äãwidth (Int): The simd_width of the load.\n\nArgs:\n\n‚Äãidx (*Int): The index into the NDBuffer.\n\nReturns:\n\nThe simd value starting at the idx position and ending at idx+width.\n\nsimd_load[width: Int](self: Self, idx: VariadicList[Int]) -> SIMD[type, width]\n\nLoads a simd value from the buffer at the specified index.\n\nConstraints:\n\nThe buffer must be contiguous or width must be 1.\n\nParameters:\n\n‚Äãwidth (Int): The simd_width of the load.\n\nArgs:\n\n‚Äãidx (VariadicList[Int]): The index into the NDBuffer.\n\nReturns:\n\nThe simd value starting at the idx position and ending at idx+width.\n\nsimd_load[width: Int](self: Self, idx: StaticIntTuple[rank]) -> SIMD[type, width]\n\nLoads a simd value from the buffer at the specified index.\n\nConstraints:\n\nThe buffer must be contiguous or width must be 1.\n\nParameters:\n\n‚Äãwidth (Int): The simd_width of the load.\n\nArgs:\n\n‚Äãidx (StaticIntTuple[rank]): The index into the NDBuffer.\n\nReturns:\n\nThe simd value starting at the idx position and ending at idx+width.\n\nsimd_load[width: Int](self: Self, idx: StaticTuple[rank, Int]) -> SIMD[type, width]\n\nLoads a simd value from the buffer at the specified index.\n\nConstraints:\n\nThe buffer must be contiguous or width must be 1.\n\nParameters:\n\n‚Äãwidth (Int): The simd_width of the load.\n\nArgs:\n\n‚Äãidx (StaticTuple[rank, Int]): The index into the NDBuffer.\n\nReturns:\n\nThe simd value starting at the idx position and ending at idx+width.\n\naligned_simd_load\n\naligned_simd_load[width: Int, alignment: Int](self: Self, *idx: Int) -> SIMD[type, width]\n\nLoads a simd value from the buffer at the specified index.\n\nConstraints:\n\nThe buffer must be contiguous or width must be 1.\n\nParameters:\n\n‚Äãwidth (Int): The simd_width of the load.\n‚Äãalignment (Int): The alignment value.\n\nArgs:\n\n‚Äãidx (*Int): The index into the NDBuffer.\n\nReturns:\n\nThe simd value starting at the idx position and ending at idx+width.\n\naligned_simd_load[width: Int, alignment: Int](self: Self, idx: VariadicList[Int]) -> SIMD[type, width]\n\nLoads a simd value from the buffer at the specified index.\n\nConstraints:\n\nThe buffer must be contiguous or width must be 1.\n\nParameters:\n\n‚Äãwidth (Int): The simd_width of the load.\n‚Äãalignment (Int): The alignment value.\n\nArgs:\n\n‚Äãidx (VariadicList[Int]): The index into the NDBuffer.\n\nReturns:\n\nThe simd value starting at the idx position and ending at idx+width.\n\naligned_simd_load[width: Int, alignment: Int](self: Self, idx: StaticIntTuple[rank]) -> SIMD[type, width]\n\nLoads a simd value from the buffer at the specified index.\n\nConstraints:\n\nThe buffer must be contiguous or width must be 1.\n\nParameters:\n\n‚Äãwidth (Int): The simd_width of the load.\n‚Äãalignment (Int): The alignment value.\n\nArgs:\n\n‚Äãidx (StaticIntTuple[rank]): The index into the NDBuffer.\n\nReturns:\n\nThe simd value starting at the idx position and ending at idx+width.\n\naligned_simd_load[width: Int, alignment: Int](self: Self, idx: StaticTuple[rank, Int]) -> SIMD[type, width]\n\nLoads a simd value from the buffer at the specified index.\n\nConstraints:\n\nThe buffer must be contiguous or width must be 1.\n\nParameters:\n\n‚Äãwidth (Int): The simd_width of the load.\n‚Äãalignment (Int): The alignment value.\n\nArgs:\n\n‚Äãidx (StaticTuple[rank, Int]): The index into the NDBuffer.\n\nReturns:\n\nThe simd value starting at the idx position and ending at idx+width.\n\nsimd_store\n\nsimd_store[width: Int](self: Self, idx: StaticIntTuple[rank], val: SIMD[type, width])\n\nStores a simd value into the buffer at the specified index.\n\nConstraints:\n\nThe buffer must be contiguous or width must be 1.\n\nParameters:\n\n‚Äãwidth (Int): The width of the simd vector.\n\nArgs:\n\n‚Äãidx (StaticIntTuple[rank]): The index into the Buffer.\n‚Äãval (SIMD[type, width]): The value to store.\n\nsimd_store[width: Int](self: Self, idx: StaticTuple[rank, Int], val: SIMD[type, width])\n\nStores a simd value into the buffer at the specified index.\n\nConstraints:\n\nThe buffer must be contiguous or width must be 1.\n\nParameters:\n\n‚Äãwidth (Int): The width of the simd vector.\n\nArgs:\n\n‚Äãidx (StaticTuple[rank, Int]): The index into the Buffer.\n‚Äãval (SIMD[type, width]): The value to store.\naligned_simd_store\n\naligned_simd_store[width: Int, alignment: Int](self: Self, idx: StaticIntTuple[rank], val: SIMD[type, width])\n\nStores a simd value into the buffer at the specified index.\n\nConstraints:\n\nThe buffer must be contiguous or width must be 1.\n\nParameters:\n\n‚Äãwidth (Int): The width of the simd vector.\n‚Äãalignment (Int): The alignment value.\n\nArgs:\n\n‚Äãidx (StaticIntTuple[rank]): The index into the Buffer.\n‚Äãval (SIMD[type, width]): The value to store.\n\naligned_simd_store[width: Int, alignment: Int](self: Self, idx: StaticTuple[rank, Int], val: SIMD[type, width])\n\nStores a simd value into the buffer at the specified index.\n\nConstraints:\n\nThe buffer must be contiguous or width must be 1.\n\nParameters:\n\n‚Äãwidth (Int): The width of the simd vector.\n‚Äãalignment (Int): The alignment value.\n\nArgs:\n\n‚Äãidx (StaticTuple[rank, Int]): The index into the Buffer.\n‚Äãval (SIMD[type, width]): The value to store.\nsimd_nt_store\n\nsimd_nt_store[width: Int](self: Self, idx: StaticIntTuple[rank], val: SIMD[type, width])\n\nStores a simd value using non-temporal store.\n\nConstraints:\n\nThe buffer must be contiguous. The address must be properly aligned, 64B for avx512, 32B for avx2, and 16B for avx.\n\nParameters:\n\n‚Äãwidth (Int): The width of the simd vector.\n\nArgs:\n\n‚Äãidx (StaticIntTuple[rank]): The index into the Buffer.\n‚Äãval (SIMD[type, width]): The value to store.\n\nsimd_nt_store[width: Int](self: Self, idx: StaticTuple[rank, Int], val: SIMD[type, width])\n\nStores a simd value using non-temporal store.\n\nConstraints:\n\nThe buffer must be contiguous. The address must be properly aligned, 64B for avx512, 32B for avx2, and 16B for avx.\n\nParameters:\n\n‚Äãwidth (Int): The width of the simd vector.\n\nArgs:\n\n‚Äãidx (StaticTuple[rank, Int]): The index into the Buffer.\n‚Äãval (SIMD[type, width]): The value to store.\ndim\n\ndim[index: Int](self: Self) -> Int\n\nGets the buffer dimension at the given index.\n\nParameters:\n\n‚Äãindex (Int): The number of dimension to get.\n\nReturns:\n\nThe buffer size at the given dimension.\n\ndim(self: Self, index: Int) -> Int\n\nGets the buffer dimension at the given index.\n\nArgs:\n\n‚Äãindex (Int): The number of dimension to get.\n\nReturns:\n\nThe buffer size at the given dimension.\n\nstride\n\nstride(self: Self, index: Int) -> Int\n\nGets the buffer stride at the given index.\n\nArgs:\n\n‚Äãindex (Int): The number of dimension to get the stride for.\n\nReturns:\n\nThe stride at the given dimension.\n\nflatten\n\nflatten(self: Self) -> Buffer[#pop.variant<:i1 0, 0>, type]\n\nConstructs a flattened Buffer counterpart for this NDBuffer.\n\nConstraints:\n\nThe buffer must be contiguous.\n\nReturns:\n\nConstructed Buffer object.\n\nmake_dims_unknown\n\nmake_dims_unknown(self: Self) -> NDBuffer[rank, create_unknown[$builtin::$int::Int][rank](), type]\n\nRebinds the NDBuffer to one with unknown shape.\n\nReturns:\n\nThe rebound NDBuffer with unknown shape.\n\nbytecount\n\nbytecount(self: Self) -> Int\n\nReturns the size of the NDBuffer in bytes.\n\nReturns:\n\nThe size of the NDBuffer in bytes.\n\nzero\n\nzero(self: Self)\n\nSets all bytes of the NDBuffer to 0.\n\nConstraints:\n\nThe buffer must be contiguous.\n\nsimd_fill\n\nsimd_fill[simd_width: Int](self: Self, val: SIMD[type, 1])\n\nAssigns val to all elements in chunks of size simd_width.\n\nParameters:\n\n‚Äãsimd_width (Int): The simd_width of the fill.\n\nArgs:\n\n‚Äãval (SIMD[type, 1]): The value to store.\ntofile\n\ntofile(self: Self, path: Path)\n\nWrite values to a file.\n\nArgs:\n\n‚Äãpath (Path): Path to the output file.\nfill\n\nfill(self: Self, val: SIMD[type, 1])\n\nAssigns val to all elements in the Buffer.\n\nThe fill is performed in chunks of size N, where N is the native SIMD width of type on the system.\n\nArgs:\n\n‚Äãval (SIMD[type, 1]): The value to store.\naligned_stack_allocation\n\naligned_stack_allocation[alignment: Int]() -> Self\n\nConstructs an NDBuffer instance backed by stack allocated memory space.\n\nParameters:\n\n‚Äãalignment (Int): Address alignment requirement for the allocation.\n\nReturns:\n\nConstructed NDBuffer with the allocated space.\n\nstack_allocation\n\nstack_allocation() -> Self\n\nConstructs an NDBuffer instance backed by stack allocated memory space.\n\nReturns:\n\nConstructed NDBuffer with the allocated space.\n\nprefetch\n\nprefetch[params: PrefetchOptions](self: Self, *idx: Int)\n\nPrefetches the data at the given index.\n\nParameters:\n\n‚Äãparams (PrefetchOptions): The prefetch configuration.\n\nArgs:\n\n‚Äãidx (*Int): The N-D index of the prefetched location.\n\nprefetch[params: PrefetchOptions](self: Self, indices: StaticIntTuple[rank])\n\nPrefetches the data at the given index.\n\nParameters:\n\n‚Äãparams (PrefetchOptions): The prefetch configuration.\n\nArgs:\n\n‚Äãindices (StaticIntTuple[rank]): The N-D index of the prefetched location.\nDynamicRankBuffer\n\nDynamicRankBuffer represents a buffer with unknown rank, shapes and dtype.\n\nIt is not as efficient as the statically ranked buffer, but is useful when interacting with external functions. In particular the shape is represented as a fixed (ie _MAX_RANK) array of dimensions to simplify the ABI.\n\nFields:\n\n‚Äãdata (DTypePointer[invalid]): The pointer to the buffer.\n‚Äãrank (Int): The buffer rank. Has a max value of _MAX_RANK.\n‚Äãshape (StaticIntTuple[8]): The dynamic shape of the buffer.\n‚Äãtype (DType): The dynamic dtype of the buffer.\n\nFunctions:\n\n__init__\n\n__init__(data: DTypePointer[invalid], rank: Int, shape: StaticIntTuple[8], type: DType) -> Self\n\nConstruct DynamicRankBuffer.\n\nArgs:\n\n‚Äãdata (DTypePointer[invalid]): Pointer to the underlying data.\n‚Äãrank (Int): Rank of the buffer.\n‚Äãshape (StaticIntTuple[8]): Shapes of the buffer.\n‚Äãtype (DType): dtype of the buffer.\n\nReturns:\n\nConstructed DynamicRankBuffer.\n\nto_buffer\n\nto_buffer[type: DType](self: Self) -> Buffer[#pop.variant<:i1 0, 0>, type]\n\nCasts DynamicRankBuffer to Buffer.\n\nParameters:\n\n‚Äãtype (DType): dtype of the buffer.\n\nReturns:\n\nConstructed Buffer.\n\nto_ndbuffer\n\nto_ndbuffer[rank: Int, type: DType](self: Self) -> NDBuffer[rank, create_unknown[$builtin::$int::Int][rank](), type]\n\nCasts the buffer to NDBuffer.\n\nConstraints:\n\nRank of DynamicRankBuffer must equal rank of NDBuffer.\n\nParameters:\n\n‚Äãrank (Int): Rank of the buffer.\n‚Äãtype (DType): dtype of the buffer.\n\nReturns:\n\nConstructed NDBuffer.\n\nto_ndbuffer[rank: Int, type: DType](self: Self, stride: StaticIntTuple[rank]) -> NDBuffer[rank, create_unknown[$builtin::$int::Int][rank](), type]\n\nCasts the buffer to NDBuffer.\n\nConstraints:\n\nRank of DynamicRankBuffer must equal rank of NDBuffer.\n\nParameters:\n\n‚Äãrank (Int): Rank of the buffer.\n‚Äãtype (DType): dtype of the buffer.\n\nArgs:\n\n‚Äãstride (StaticIntTuple[rank]): Strides of the buffer.\n\nReturns:\n\nConstructed NDBuffer.\n\nrank_dispatch\n\nrank_dispatch[func: fn[Int]() capturing -> None](self: Self)\n\nDispatches the function call based on buffer rank.\n\nConstraints:\n\nRank must be positive and less or equal to 8.\n\nParameters:\n\n‚Äãfunc (fn[Int]() capturing -> None): Function to dispatch. The function should be parametrized on an index parameter, which will be used for rank when the function will be called.\n\nrank_dispatch[func: fn[Int]() capturing -> None](self: Self, out_chain: OutputChainPtr)\n\nDispatches the function call based on buffer rank.\n\nConstraints:\n\nRank must be positive and less or equal to 8.\n\nParameters:\n\n‚Äãfunc (fn[Int]() capturing -> None): Function to dispatch. The function should be parametrized on an index parameter, which will be used for rank when the function will be called.\n\nArgs:\n\n‚Äãout_chain (OutputChainPtr): The output chain.\nnum_elements\n\nnum_elements(self: Self) -> Int\n\nGets number of elements in the buffer.\n\nReturns:\n\nThe number of elements in the buffer.\n\nget_shape\n\nget_shape[rank: Int](self: Self) -> StaticIntTuple[rank]\n\nGets a static tuple representing the buffer shape.\n\nParameters:\n\n‚Äãrank (Int): Rank of the buffer.\n\nReturns:\n\nA static tuple of size ‚ÄòRank‚Äô filled with buffer shapes.\n\ndim\n\ndim(self: Self, idx: Int) -> Int\n\nGets given dimension.\n\nArgs:\n\n‚Äãidx (Int): The dimension index.\n\nReturns:\n\nThe buffer size on the given dimension.\n\npartial_simd_load\n\npartial_simd_load[type: DType, width: Int](storage: DTypePointer[type], lbound: Int, rbound: Int, pad_value: SIMD[type, 1]) -> SIMD[type, width]\n\nLoads a vector with dynamic bound.\n\nOut of bound data will be filled with pad value. Data is valid if lbound <= idx < rbound for idx from 0 to (simd_width-1). For example:\n\naddr 0  1  2  3\ndata x 42 43  x\n\npartial_simd_load[4](addr0,1,3) #gives [0 42 43 0]\n\nParameters:\n\n‚Äãtype (DType): The underlying dtype of computation.\n‚Äãwidth (Int): The system simd vector size.\n\nArgs:\n\n‚Äãstorage (DTypePointer[type]): Pointer to the address to perform load.\n‚Äãlbound (Int): Lower bound of valid index within simd (inclusive).\n‚Äãrbound (Int): Upper bound of valid index within simd (non-inclusive).\n‚Äãpad_value (SIMD[type, 1]): Value to fill for out of bound indices.\n\nReturns:\n\nThe SIMD vector loaded and zero-filled.\n\npartial_simd_store\n\npartial_simd_store[type: DType, width: Int](storage: DTypePointer[type], lbound: Int, rbound: Int, data: SIMD[type, width])\n\nStores a vector with dynamic bound.\n\nOut of bound data will ignored. Data is valid if lbound <= idx < rbound for idx from 0 to (simd_width-1).\n\ne.g. addr 0 1 2 3 data 0 0 0 0\n\npartial_simd_load[4](addr0,1,3, [-1, 42,43, -1]) #gives [0 42 43 0]\n\nParameters:\n\n‚Äãtype (DType): The underlying dtype of computation.\n‚Äãwidth (Int): The system simd vector size.\n\nArgs:\n\n‚Äãstorage (DTypePointer[type]): Pointer to the address to perform load.\n‚Äãlbound (Int): Lower bound of valid index within simd (inclusive).\n‚Äãrbound (Int): Upper bound of valid index within simd (non-inclusive).\n‚Äãdata (SIMD[type, width]): The vector value to store.\nprod_dims\n\nprod_dims[start_dim: Int, end_dim: Int, rank: Int, shape: DimList, type: DType](x: NDBuffer[rank, shape, type]) -> Int\n\nComputes the product of a slice of the given buffer‚Äôs dimensions.\n\nParameters:\n\n‚Äãstart_dim (Int): The index at which to begin computing the product.\n‚Äãend_dim (Int): The index at which to stop computing the product.\n‚Äãrank (Int): The rank of the NDBuffer.\n‚Äãshape (DimList): The shape of the NDBuffer.\n‚Äãtype (DType): The element-type of the NDBuffer.\n\nArgs:\n\n‚Äãx (NDBuffer[rank, shape, type]): The NDBuffer whose dimensions will be multiplied.\n\nReturns:\n\nThe product of the specified slice of the buffer‚Äôs dimensions.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - polynomial",
    "url": "https://docs.modular.com/mojo/stdlib/math/polynomial.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nbit\nlimit\nmath\npolynomial\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\npolynomial_evaluate\npolynomial\n\nModule\n\nProvides two implementations for evaluating polynomials.\n\nYou can import these APIs from the math package. For example:\n\nfrom math.polynomial import polynomial_evaluate\npolynomial_evaluate\n\npolynomial_evaluate[simd_width: Int, dtype: DType, coefficients: VariadicList[SIMD[dtype, simd_width]]](x: SIMD[dtype, simd_width]) -> SIMD[dtype, simd_width]\n\nEvaluates the 1st degree polynomial using the passed in value and the specified coefficients.\n\nThese methods evaluate the polynomial using either the Estrin scheme or the Horner scheme. The Estrin scheme is only implemented for polynomials of degrees between 4 and 10. The Horner scheme is implemented for polynomials for any polynomial degree.\n\nParameters:\n\n‚Äãsimd_width (Int): The simd_width of the computed value.\n‚Äãdtype (DType): The dtype of the value.\n‚Äãcoefficients (VariadicList[SIMD[dtype, simd_width]]): The coefficients.\n\nArgs:\n\n‚Äãx (SIMD[dtype, simd_width]): The value to compute the polynomial with.\n\nReturns:\n\nThe polynomial evaluation results using the specified value and the constant coefficients.\n\npolynomial_evaluate[simd_width: Int, dtype: DType, coefficients: VariadicList[SIMD[dtype, simd_width]]](x: SIMD[dtype, simd_width]) -> SIMD[dtype, simd_width]\n\nEvaluates the polynomial using the Horner scheme.\n\nThe Horner scheme evaluates the polynomial as horner(val, coeffs), where val is a scalar and coeffs is a list of coefficients [c0, c1, c2, ..., cn], by performing the following computation:\n\nhorner(val, coeffs) = c0 + val * (c1 + val * (c2 + val * (... + val * cn)))\n            = fma(val, horner(val, coeffs[1:]), c0)\n\nParameters:\n\n‚Äãsimd_width (Int): The simd_width of the computed value.\n‚Äãdtype (DType): The dtype of the value.\n‚Äãcoefficients (VariadicList[SIMD[dtype, simd_width]]): The coefficients.\n\nArgs:\n\n‚Äãx (SIMD[dtype, simd_width]): The value to compute the polynomial with.\n\nReturns:\n\nThe polynomial evaluation results using the specified value and the constant coefficients.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - limit",
    "url": "https://docs.modular.com/mojo/stdlib/math/limit.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nbit\nlimit\nmath\npolynomial\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\ninf\nneginf\nisinf\nisfinite\nmax_finite\nmax_or_inf\nmin_finite\nmin_or_neginf\nlimit\n\nModule\n\nProvides interfaces to query numeric various numeric properties of types.\n\nYou can import these APIs from the math package. For example:\n\nfrom math.limit import inf\ninf\n\ninf[type: DType]() -> SIMD[type, 1]\n\nGets a +inf value for the given dtype.\n\nConstraints:\n\nCan only be used for FP dtypes.\n\nParameters:\n\n‚Äãtype (DType): The value dtype.\n\nReturns:\n\nThe +inf value of the given dtype.\n\nneginf\n\nneginf[type: DType]() -> SIMD[type, 1]\n\nGets a -inf value for the given dtype.\n\nConstraints:\n\nCan only be used for FP dtypes.\n\nParameters:\n\n‚Äãtype (DType): The value dtype.\n\nReturns:\n\nThe -inf value of the given dtype.\n\nisinf\n\nisinf[type: DType, simd_width: Int](val: SIMD[type, simd_width]) -> SIMD[bool, simd_width]\n\nChecks if the value is infinite.\n\nThis is always False for non-FP data types.\n\nParameters:\n\n‚Äãtype (DType): The value dtype.\n‚Äãsimd_width (Int): The width of the SIMD vector.\n\nArgs:\n\n‚Äãval (SIMD[type, simd_width]): The value to check.\n\nReturns:\n\nTrue if val is infinite and False otherwise.\n\nisfinite\n\nisfinite[type: DType, simd_width: Int](val: SIMD[type, simd_width]) -> SIMD[bool, simd_width]\n\nChecks if the value is not infinite.\n\nThis is always True for non-FP data types.\n\nParameters:\n\n‚Äãtype (DType): The value dtype.\n‚Äãsimd_width (Int): The width of the SIMD vector.\n\nArgs:\n\n‚Äãval (SIMD[type, simd_width]): The value to check.\n\nReturns:\n\nTrue if val is finite and False otherwise.\n\nmax_finite\n\nmax_finite[type: DType]() -> SIMD[type, 1]\n\nReturns the maximum finite value of type.\n\nParameters:\n\n‚Äãtype (DType): The value dtype.\n\nReturns:\n\nThe maximum representable value of the type. Does not include infinity for floating-point types.\n\nmax_or_inf\n\nmax_or_inf[type: DType]() -> SIMD[type, 1]\n\nReturns the maximum value of type.\n\nParameters:\n\n‚Äãtype (DType): The value dtype.\n\nReturns:\n\nThe maximum value of the type or infinity for floating-point types.\n\nmin_finite\n\nmin_finite[type: DType]() -> SIMD[type, 1]\n\nReturns the minimum (lowest) finite value of type.\n\nParameters:\n\n‚Äãtype (DType): The value dtype.\n\nReturns:\n\nThe minimum representable value of the type. Does not include negative infinity for floating-point types.\n\nmin_or_neginf\n\nmin_or_neginf[type: DType]() -> SIMD[type, 1]\n\nReturns the minimum value of type.\n\nParameters:\n\n‚Äãtype (DType): The value dtype.\n\nReturns:\n\nThe minimum value of the type or infinity for floating-point types.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - bit",
    "url": "https://docs.modular.com/mojo/stdlib/math/bit.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nbit\nlimit\nmath\npolynomial\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nctlz\ncttz\nselect\nbitreverse\nbswap\nctpop\nbit_not\nbit_and\nbit_length\nbit\n\nModule\n\nProvides functions for bit manipulation.\n\nYou can import these APIs from the math package. For example:\n\nfrom math.bit import ctlz\nctlz\n\nctlz(val: Int) -> Int\n\nCounts the number of leading zeros of an integer.\n\nArgs:\n\n‚Äãval (Int): The input value.\n\nReturns:\n\nThe number of leading zeros of the input.\n\nctlz[type: DType, simd_width: Int](val: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nCounts the per-element number of leading zeros in a SIMD vector.\n\nConstraints:\n\nDType must be integral.\n\nParameters:\n\n‚Äãtype (DType): dtype used for the computation.\n‚Äãsimd_width (Int): SIMD width used for the computation.\n\nArgs:\n\n‚Äãval (SIMD[type, simd_width]): The input value.\n\nReturns:\n\nA SIMD value where the element at position i contains the number of leading zeros at position i of the input value.\n\ncttz\n\ncttz(val: Int) -> Int\n\nCounts the number of trailing zeros for an integer.\n\nArgs:\n\n‚Äãval (Int): The input value.\n\nReturns:\n\nThe number of trailing zeros of the input.\n\ncttz[type: DType, simd_width: Int](val: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nCounts the number of trailing zero for a SIMD vector.\n\nConstraints:\n\nDType must be integral.\n\nParameters:\n\n‚Äãtype (DType): dtype used for the computation.\n‚Äãsimd_width (Int): SIMD width used for the computation.\n\nArgs:\n\n‚Äãval (SIMD[type, simd_width]): The input value.\n\nReturns:\n\nA SIMD value where the element at position i contains the number of trailing zeros at position i of the input value.\n\nselect\n\nselect[type: DType, simd_width: Int](cond: SIMD[bool, simd_width], true_case: SIMD[type, simd_width], false_case: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nPerforms an elementwise select based on the input condition value.\n\nParameters:\n\n‚Äãtype (DType): dtype used for the computation.\n‚Äãsimd_width (Int): SIMD width used for the computation.\n\nArgs:\n\n‚Äãcond (SIMD[bool, simd_width]): The condition.\n‚Äãtrue_case (SIMD[type, simd_width]): The value to pick if the condition is True.\n‚Äãfalse_case (SIMD[type, simd_width]): The value to pick if the condition is False.\n\nReturns:\n\nA SIMD value where the element at position i contains true_case[i] if cond[i] is True and false_case[i] otherwise.\n\nbitreverse\n\nbitreverse[type: DType, simd_width: Int](val: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nReverses the bitpattern of an integral value.\n\nConstraints:\n\nDType must be integral.\n\nParameters:\n\n‚Äãtype (DType): dtype used for the computation.\n‚Äãsimd_width (Int): SIMD width used for the computation.\n\nArgs:\n\n‚Äãval (SIMD[type, simd_width]): The input value.\n\nReturns:\n\nA SIMD value where the element at position i has a reversed bitpattern of an integer value of the element at position i of the input value.\n\nbswap\n\nbswap[type: DType, simd_width: Int](val: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nByte-swaps a value.\n\nByte swap an integer value or vector of integer values with an even number of bytes (positive multiple of 16 bits). This is equivalent to llvm.bswap intrinsic that has the following semantics:\n\nThe llvm.bswap.i16 intrinsic returns an i16 value that has the high and low byte of the input i16 swapped. Similarly, the llvm.bswap.i32 intrinsic returns an i32 value that has the four bytes of the input i32 swapped, so that if the input bytes are numbered 0, 1, 2, 3 then the returned i32 will have its bytes in 3, 2, 1, 0 order. The llvm.bswap.i48, llvm.bswap.i64 and other intrinsics extend this concept to additional even-byte lengths (6 bytes, 8 bytes and more, respectively).\n\nConstraints:\n\nNumber of bytes must be even (Bitwidth % 16 == 0). DType must be integral.\n\nParameters:\n\n‚Äãtype (DType): dtype used for the computation.\n‚Äãsimd_width (Int): SIMD width used for the computation.\n\nArgs:\n\n‚Äãval (SIMD[type, simd_width]): The input value.\n\nReturns:\n\nA SIMD value where the element at position i is the value of the element at position i of the input value with its bytes swapped.\n\nctpop\n\nctpop[type: DType, simd_width: Int](val: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nCounts the number of bits set in a value.\n\nConstraints:\n\nDType must be integral.\n\nParameters:\n\n‚Äãtype (DType): dtype used for the computation.\n‚Äãsimd_width (Int): SIMD width used for the computation.\n\nArgs:\n\n‚Äãval (SIMD[type, simd_width]): The input value.\n\nReturns:\n\nA SIMD value where the element at position i contains the number of bits set in the element at position i of the input value.\n\nbit_not\n\nbit_not[type: DType, simd_width: Int](val: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nPerforms a bitwise NOT operation on an integral.\n\nConstraints:\n\nDType must be integral.\n\nParameters:\n\n‚Äãtype (DType): dtype used for the computation.\n‚Äãsimd_width (Int): SIMD width used for the computation.\n\nArgs:\n\n‚Äãval (SIMD[type, simd_width]): The input value.\n\nReturns:\n\nA SIMD value where the element at position i is computed as a bitwise NOT of the integer value at position i of the input value.\n\nbit_and\n\nbit_and[type: DType, simd_width: Int](a: SIMD[type, simd_width], b: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nPerforms a bitwise AND operation.\n\nConstraints:\n\nDType must be integral.\n\nParameters:\n\n‚Äãtype (DType): dtype used for the computation.\n‚Äãsimd_width (Int): SIMD width used for the computation.\n\nArgs:\n\n‚Äãa (SIMD[type, simd_width]): The first input value.\n‚Äãb (SIMD[type, simd_width]): The second input value.\n\nReturns:\n\nA SIMD value where the element at position i is computed as a bitwise AND of the elements at position i of the input values.\n\nbit_length\n\nbit_length[type: DType, simd_width: Int](val: SIMD[type, simd_width]) -> SIMD[type, simd_width]\n\nComputes the number of digits required to represent the integer.\n\nConstraints:\n\nDType must be integral. The function asserts on non-integral dtypes in debug builds and returns 0 in release builds.\n\nParameters:\n\n‚Äãtype (DType): dtype used for the computation.\n‚Äãsimd_width (Int): SIMD width used for the computation.\n\nArgs:\n\n‚Äãval (SIMD[type, simd_width]): The input value.\n\nReturns:\n\nA SIMD value where the element at position i equals to the number of digits required to represent the integer at position i of the input value.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - complex",
    "url": "https://docs.modular.com/mojo/stdlib/complex/complex.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nComplexSIMD\n__init__\n__neg__\n__add__\n__mul__\nnorm\nsquared_norm\nfma\nsquared_add\ncomplex\n\nModule\n\nImplements the Complex type.\n\nYou can import these APIs from the complex package. For example:\n\nfrom complex import ComplexSIMD\n\nAliases:\n\n‚ÄãComplexFloat32 = ComplexSIMD[f32, 1]\n‚ÄãComplexFloat64 = ComplexSIMD[f64, 1]\nComplexSIMD\n\nRepresents a complex SIMD value.\n\nThe class provides basic methods for manipulating complex values.\n\nParameters:\n\n‚Äãtype (DType): DType of the value.\n‚Äãsize (Int): SIMD width of the value.\n\nFields:\n\n‚Äãre (SIMD[type, size]): The real part of the complex SIMD value.\n‚Äãim (SIMD[type, size]): The imaginary part of the complex SIMD value.\n\nFunctions:\n\n__init__\n\n__init__(re: SIMD[type, size], im: SIMD[type, size], /) -> Self\n\n__neg__\n\n__neg__(self: Self) -> Self\n\nNegates the complex value.\n\nReturns:\n\nThe negative of the complex value.\n\n__add__\n\n__add__(self: Self, rhs: Self) -> Self\n\nAdds two complex values.\n\nArgs:\n\n‚Äãrhs (Self): Complex value to add.\n\nReturns:\n\nA sum of this and RHS complex values.\n\n__mul__\n\n__mul__(self: Self, rhs: Self) -> Self\n\nMultiplies two complex values.\n\nArgs:\n\n‚Äãrhs (Self): Complex value to multiply with.\n\nReturns:\n\nA product of this and RHS complex values.\n\nnorm\n\nnorm(self: Self) -> SIMD[type, size]\n\nReturns the magnitude of the complex value.\n\nReturns:\n\nValue of sqrt(re*re + im*im).\n\nsquared_norm\n\nsquared_norm(self: Self) -> SIMD[type, size]\n\nReturns the squared magnitude of the complex value.\n\nReturns:\n\nValue of re*re + im*im.\n\nfma\n\nfma(self: Self, b: Self, c: Self) -> Self\n\nComputes FMA operation.\n\nCompute fused multiple-add with two other complex values: result = self * b + c\n\nArgs:\n\n‚Äãb (Self): Multiplier complex value.\n‚Äãc (Self): Complex value to add.\n\nReturns:\n\nComputed Self * B + C complex value.\n\nsquared_add\n\nsquared_add(self: Self, c: Self) -> Self\n\nComputes Square-Add operation.\n\nCompute Self * Self + C.\n\nArgs:\n\n‚Äãc (Self): Complex value to add.\n\nReturns:\n\nComputed Self * Self + C complex value.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - type_aliases",
    "url": "https://docs.modular.com/mojo/stdlib/builtin/type_aliases.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\nbool\nbuiltin_list\nbuiltin_slice\nconstrained\ncoroutine\ndebug_assert\ndtype\nerror\nfile\nfloat_literal\nint\nio\nlen\nobject\nrange\nrebind\nsimd\nstring\nstring_literal\nstringref\ntuple\ntype_aliases\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\ntype_aliases\n\nModule\n\nDefines some type aliases.\n\nThese are Mojo built-ins, so you don‚Äôt need to import them.\n\nAliases:\n\n‚ÄãAnyType = AnyType: Represents any Mojo data type.\n‚ÄãNoneType = None: Represents the absence of a value.\n‚ÄãLifetime = lifetime: Value lifetime specifier.\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - tuple",
    "url": "https://docs.modular.com/mojo/stdlib/builtin/tuple.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\nbool\nbuiltin_list\nbuiltin_slice\nconstrained\ncoroutine\ndebug_assert\ndtype\nerror\nfile\nfloat_literal\nint\nio\nlen\nobject\nrange\nrebind\nsimd\nstring\nstring_literal\nstringref\ntuple\ntype_aliases\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nTuple\n__init__\n__copyinit__\n__len__\nget\ntuple\n\nModule\n\nImplements the Tuple type.\n\nThese are Mojo built-ins, so you don‚Äôt need to import them.\n\nTuple\n\nThe type of a literal tuple expression.\n\nA tuple consists of zero or more values, separated by commas.\n\nParameters:\n\n‚ÄãTs (*AnyType): The elements type.\n\nFields:\n\n‚Äãstorage (!kgen.pack<Ts>): The underlying storage for the tuple.\n\nFunctions:\n\n__init__\n\n__init__(args: !kgen.pack<Ts>) -> Self\n\nConstruct the tuple.\n\nArgs:\n\n‚Äãargs (!kgen.pack<Ts>): Initial values.\n\nReturns:\n\nConstructed tuple.\n\n__copyinit__\n\n__copyinit__(existing: Self) -> Self\n\nCopy construct the tuple.\n\nReturns:\n\nConstructed tuple.\n\n__len__\n\n__len__(self: Self) -> Int\n\nGet the number of elements in the tuple.\n\nReturns:\n\nThe tuple length.\n\nget\n\nget[i: Int, T: AnyType](self: Self) -> T\n\nGet a tuple element.\n\nParameters:\n\n‚Äãi (Int): The element index.\n‚ÄãT (AnyType): The element type.\n\nReturns:\n\nThe tuple element at the requested index.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - stringref",
    "url": "https://docs.modular.com/mojo/stdlib/builtin/stringref.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\nbool\nbuiltin_list\nbuiltin_slice\nconstrained\ncoroutine\ndebug_assert\ndtype\nerror\nfile\nfloat_literal\nint\nio\nlen\nobject\nrange\nrebind\nsimd\nstring\nstring_literal\nstringref\ntuple\ntype_aliases\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nStringRef\n__init__\n__bool__\n__getitem__\n__eq__\n__ne__\n__len__\nstringref\n\nModule\n\nImplements the StringRef class.\n\nThese are Mojo built-ins, so you don‚Äôt need to import them.\n\nStringRef\n\nRepresent a constant reference to a string, i.e.¬†a sequence of characters and a length, which need not be null terminated.\n\nFields:\n\n‚Äãdata (DTypePointer[si8]): A pointer to the beginning of the string data being referenced.\n‚Äãlength (Int): The length of the string being referenced.\n\nFunctions:\n\n__init__\n\n__init__(str: StringLiteral) -> Self\n\nConstruct a StringRef value given a constant string.\n\nArgs:\n\n‚Äãstr (StringLiteral): The input constant string.\n\nReturns:\n\nConstructed StringRef object.\n\n__init__(ptr: Pointer[SIMD[si8, 1]], len: Int) -> Self\n\nConstruct a StringRef value given a (potentially non-0 terminated string).\n\nThe constructor takes a raw pointer and a length.\n\nArgs:\n\n‚Äãptr (Pointer[SIMD[si8, 1]]): Pointer to the string.\n‚Äãlen (Int): The length of the string.\n\nReturns:\n\nConstructed StringRef object.\n\n__init__(ptr: DTypePointer[si8], len: Int) -> Self\n\nConstruct a StringRef value given a (potentially non-0 terminated string).\n\nThe constructor takes a raw pointer and a length.\n\nArgs:\n\n‚Äãptr (DTypePointer[si8]): Pointer to the string.\n‚Äãlen (Int): The length of the string.\n\nReturns:\n\nConstructed StringRef object.\n\n__init__(ptr: Pointer[SIMD[si8, 1]]) -> Self\n\nConstruct a StringRef value given a (potentially non-0 terminated string).\n\nThe constructor takes a raw pointer and a length.\n\nArgs:\n\n‚Äãptr (Pointer[SIMD[si8, 1]]): Pointer to the string.\n\nReturns:\n\nConstructed StringRef object.\n\n__init__(ptr: DTypePointer[si8]) -> Self\n\nConstruct a StringRef value given a (potentially non-0 terminated string).\n\nThe constructor takes a raw pointer and a length.\n\nArgs:\n\n‚Äãptr (DTypePointer[si8]): Pointer to the string.\n\nReturns:\n\nConstructed StringRef object.\n\n__bool__\n\n__bool__(self: Self) -> Bool\n\nChecks if the string is empty or not.\n\nReturns:\n\nReturns True if the string is not empty and False otherwise.\n\n__getitem__\n\n__getitem__(self: Self, idx: Int) -> Self\n\nGet the string value at the specified position.\n\nArgs:\n\n‚Äãidx (Int): The index position.\n\nReturns:\n\nThe character at the specified position.\n\n__eq__\n\n__eq__(self: Self, rhs: Self) -> Bool\n\nCompares two strings are equal.\n\nArgs:\n\n‚Äãrhs (Self): The other string.\n\nReturns:\n\nTrue if the strings match and False otherwise.\n\n__ne__\n\n__ne__(self: Self, rhs: Self) -> Bool\n\nCompares two strings are not equal.\n\nArgs:\n\n‚Äãrhs (Self): The other string.\n\nReturns:\n\nTrue if the strings do not match and False otherwise.\n\n__len__\n\n__len__(self: Self) -> Int\n\nReturns the length of the string.\n\nReturns:\n\nThe length of the string.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - string_literal",
    "url": "https://docs.modular.com/mojo/stdlib/builtin/string_literal.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\nbool\nbuiltin_list\nbuiltin_slice\nconstrained\ncoroutine\ndebug_assert\ndtype\nerror\nfile\nfloat_literal\nint\nio\nlen\nobject\nrange\nrebind\nsimd\nstring\nstring_literal\nstringref\ntuple\ntype_aliases\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nStringLiteral\n__init__\n__bool__\n__eq__\n__ne__\n__add__\n__len__\ndata\nstring_literal\n\nModule\n\nImplements the StringLiteral class.\n\nThese are Mojo built-ins, so you don‚Äôt need to import them.\n\nStringLiteral\n\nThis type represents a string literal.\n\nString literals are all null-terminated for compatibility with C APIs, but this is subject to change. String literals store their length as an integer, and this does not include the null terminator.\n\nAliases:\n\n‚Äãtype = string\n\nFields:\n\n‚Äãvalue (string): The underlying storage for the string literal.\n\nFunctions:\n\n__init__\n\n__init__(value: string) -> Self\n\nCreate a string literal from a builtin string type.\n\nArgs:\n\n‚Äãvalue (string): The string value.\n\nReturns:\n\nA string literal object.\n\n__bool__\n\n__bool__(self: Self) -> Bool\n\nConvert the string to a bool value.\n\nReturns:\n\nTrue if the string is not empty.\n\n__eq__\n\n__eq__(self: Self, rhs: Self) -> Bool\n\nCompare two string literals for equality.\n\nArgs:\n\n‚Äãrhs (Self): The string to compare.\n\nReturns:\n\nTrue if they are equal.\n\n__ne__\n\n__ne__(self: Self, rhs: Self) -> Bool\n\nCompare two string literals for inequality.\n\nArgs:\n\n‚Äãrhs (Self): The string to compare.\n\nReturns:\n\nTrue if they are not equal.\n\n__add__\n\n__add__(self: Self, rhs: Self) -> Self\n\nConcatenate two string literals.\n\nArgs:\n\n‚Äãrhs (Self): The string to concat.\n\nReturns:\n\nThe concatenated string.\n\n__len__\n\n__len__(self: Self) -> Int\n\nGet the string length.\n\nReturns:\n\nThe length of this StringLiteral.\n\ndata\n\ndata(self: Self) -> DTypePointer[si8]\n\nGet raw pointer to the underlying data.\n\nReturns:\n\nThe raw pointer to the data.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - string",
    "url": "https://docs.modular.com/mojo/stdlib/builtin/string.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\nbool\nbuiltin_list\nbuiltin_slice\nconstrained\ncoroutine\ndebug_assert\ndtype\nerror\nfile\nfloat_literal\nint\nio\nlen\nobject\nrange\nrebind\nsimd\nstring\nstring_literal\nstringref\ntuple\ntype_aliases\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nString\n__init__\n__copyinit__\n__del__\n__bool__\n__getitem__\n__eq__\n__ne__\n__add__\n__radd__\n__iadd__\n__len__\njoin\ncount\nfind\nreplace\nord\nchr\natol\nisdigit\nstring\n\nModule\n\nImplements basic object methods for working with strings.\n\nThese are Mojo built-ins, so you don‚Äôt need to import them.\n\nString\n\nRepresents a mutable string.\n\nFunctions:\n\n__init__\n\n__init__(inout self: Self)\n\nConstruct an empty string.\n\n__init__(inout self: Self, str: StringRef)\n\nConstruct a string from a StringRef object.\n\nArgs:\n\n‚Äãstr (StringRef): The StringRef from which to construct this string object.\n\n__init__(inout self: Self, str: StringLiteral)\n\nConstructs a String value given a constant string.\n\nArgs:\n\n‚Äãstr (StringLiteral): The input constant string.\n\n__init__(inout self: Self, str: Self)\n\nConstructs a String value given a constant string.\n\nArgs:\n\n‚Äãstr (Self): The input string.\n\n__init__(inout self: Self, val: Bool)\n\nConstructs a string representing an bool value.\n\nArgs:\n\n‚Äãval (Bool): The boolean value.\n\n__init__(inout self: Self, num: Int)\n\nConstructs a string representing an integer value.\n\nArgs:\n\n‚Äãnum (Int): The integer value.\n\n__init__(inout self: Self, num: FloatLiteral)\n\nConstructs a string representing a float value.\n\nArgs:\n\n‚Äãnum (FloatLiteral): The float value.\n\n__init__[type: DType, simd_width: Int](inout self: Self, vec: SIMD[type, simd_width])\n\nConstructs a string for a given SIMD value.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the SIMD value.\n‚Äãsimd_width (Int): The width of the SIMD value.\n\nArgs:\n\n‚Äãvec (SIMD[type, simd_width]): The SIMD value.\n\n__init__[type: DType, simd_width: Int](inout self: Self, vec: ComplexSIMD[type, simd_width])\n\nConstructs a string for a given complex value.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the SIMD value.\n‚Äãsimd_width (Int): The width of the SIMD value.\n\nArgs:\n\n‚Äãvec (ComplexSIMD[type, simd_width]): The complex value.\n\n__init__[size: Int](inout self: Self, tuple: StaticIntTuple[size])\n\nConstructs a string from a given StaticIntTuple.\n\nParameters:\n\n‚Äãsize (Int): The size of the tuple.\n\nArgs:\n\n‚Äãtuple (StaticIntTuple[size]): The input tuple.\n\n__init__(inout self: Self, ptr: Pointer[SIMD[si8, 1]], len: Int)\n\nCreates a string from the buffer. Note that the string now owns the buffer.\n\nArgs:\n\n‚Äãptr (Pointer[SIMD[si8, 1]]): The pointer to the buffer.\n‚Äãlen (Int): The length of the buffer.\n\n__init__(inout self: Self, ptr: DTypePointer[si8], len: Int)\n\nCreates a string from the buffer. Note that the string now owns the buffer.\n\nArgs:\n\n‚Äãptr (DTypePointer[si8]): The pointer to the buffer.\n‚Äãlen (Int): The length of the buffer.\n__copyinit__\n\n__copyinit__(inout self: Self, existing: Self)\n\nCreates a deep copy of an existing string.\n\nArgs:\n\n‚Äãexisting (Self): The string to copy.\n__del__\n\n__del__(owned self: Self)\n\nDeallocates the string.\n\n__bool__\n\n__bool__(self: Self) -> Bool\n\nChecks if the string is empty.\n\nReturns:\n\nTrue if the string is empty and False otherwise.\n\n__getitem__\n\n__getitem__(self: Self, idx: Int) -> Self\n\nGets the character at the specified position.\n\nArgs:\n\n‚Äãidx (Int): The index value.\n\nReturns:\n\nA new string containing the character at the specified position.\n\n__getitem__(self: Self, span: slice) -> Self\n\nGets the sequence of characters at the specified positions.\n\nArgs:\n\n‚Äãspan (slice): A slice that specifies positions of the new substring.\n\nReturns:\n\nA new string containing the string at the specified positions.\n\n__eq__\n\n__eq__(self: Self, other: Self) -> Bool\n\nCompares two Strings if they have the same values.\n\nArgs:\n\n‚Äãother (Self): The rhs of the operation.\n\nReturns:\n\nTrue if the Strings are equal and False otherwise.\n\n__ne__\n\n__ne__(self: Self, other: Self) -> Bool\n\nCompares two Strings if they do not have the same values.\n\nArgs:\n\n‚Äãother (Self): The rhs of the operation.\n\nReturns:\n\nTrue if the Strings are not equal and False otherwise.\n\n__add__\n\n__add__(self: Self, other: Self) -> Self\n\nCreates a string by appending another string at the end.\n\nArgs:\n\n‚Äãother (Self): The string to append.\n\nReturns:\n\nThe new constructed string.\n\n__radd__\n\n__radd__(self: Self, other: Self) -> Self\n\nCreates a string by prepending another string to the start.\n\nArgs:\n\n‚Äãother (Self): The string to prepend.\n\nReturns:\n\nThe new constructed string.\n\n__radd__(self: Self, other: StringLiteral) -> Self\n\nCreates a string by prepending another string to the start.\n\nArgs:\n\n‚Äãother (StringLiteral): The string to prepend.\n\nReturns:\n\nThe new constructed string.\n\n__iadd__\n\n__iadd__(inout self: Self, other: Self)\n\nAppends another string to this string.\n\nArgs:\n\n‚Äãother (Self): The string to append.\n__len__\n\n__len__(self: Self) -> Int\n\nReturns the string length.\n\nReturns:\n\nThe string length.\n\njoin\n\njoin[rank: Int](self: Self, elems: StaticIntTuple[rank]) -> Self\n\nJoins the elements from the tuple using the current string as a delimiter.\n\nParameters:\n\n‚Äãrank (Int): The size of the tuple.\n\nArgs:\n\n‚Äãelems (StaticIntTuple[rank]): The input tuple.\n\nReturns:\n\nThe joined string.\n\njoin(self: Self, *elems: Int) -> Self\n\nJoins integer elements using the current string as a delimiter.\n\nArgs:\n\n‚Äãelems (*Int): The input values.\n\nReturns:\n\nThe joined string.\n\njoin(self: Self, *strs: Self) -> Self\n\nJoins string elements using the current string as a delimiter.\n\nArgs:\n\n‚Äãstrs (*Self): The input values.\n\nReturns:\n\nThe joined string.\n\ncount\n\ncount(self: Self, substr: Self) -> Int\n\nReturn the number of non-overlapping occurrences of substring substr in the string.\n\nIf sub is empty, returns the number of empty strings between characters which is the length of the string plus one.\n\nArgs:\n\n‚Äãsubstr (Self): The substring to count.\n\nReturns:\n\nThe number of occurrences of substr.\n\nfind\n\nfind(self: Self, substr: Self, start: Int) -> Int\n\nFinds the offset of the first occurrence of substr starting at start.\n\nArgs:\n\n‚Äãsubstr (Self): The substring to find.\n‚Äãstart (Int): The offset from which to find.\n\nReturns:\n\nThe offset of substr.\n\nreplace\n\nreplace(self: Self, old: Self, new: Self) -> Self\n\nReturn a copy of the string with all occurrences of substring old if replaced by new.\n\nArgs:\n\n‚Äãold (Self): The substring to replace.\n‚Äãnew (Self): The substring to replace with.\n\nReturns:\n\nThe string where all occurences of old are replaced with new.\n\nord\n\nord(s: String) -> Int\n\nReturns an integer that represents the given one-character string.\n\nGiven a string representing one ASCII character, return an integer representing the code point of that character. For example, ord(\"a\") returns the integer 97. This is the inverse of the chr() function.\n\nArgs:\n\n‚Äãs (String): The input string, which must contain only a single character.\n\nReturns:\n\nAn integer representing the code point of the given character.\n\nchr\n\nchr(c: Int) -> String\n\nReturns a string based on the given Unicode code point.\n\nReturns the string representing a character whose code point (which must be a positive integer between 0 and 255) is the integer i. For example, chr(97) returns the string \"a\". This is the inverse of the ord() function.\n\nArgs:\n\n‚Äãc (Int): An integer between 0 and 255 that represents a code point.\n\nReturns:\n\nA string containing a single character based on the given code point.\n\natol\n\natol(str: String) -> Int\n\nParses the given string as a base-10 integer and returns that value.\n\nFor example, atol(\"19\") returns 19. If the given string cannot be parsed as an integer value, an error is raised. For example, atol(\"hi\") raises an error.\n\nArgs:\n\n‚Äãstr (String): A string to be parsed as a base-10 integer.\n\nReturns:\n\nAn integer value that represents the string, or otherwise raises.\n\nisdigit\n\nisdigit(c: SIMD[si8, 1]) -> Bool\n\nDetermines whether the given character is a digit [0-9].\n\nArgs:\n\n‚Äãc (SIMD[si8, 1]): The character to check.\n\nReturns:\n\nTrue if the character is a digit.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - simd",
    "url": "https://docs.modular.com/mojo/stdlib/builtin/simd.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\nbool\nbuiltin_list\nbuiltin_slice\nconstrained\ncoroutine\ndebug_assert\ndtype\nerror\nfile\nfloat_literal\nint\nio\nlen\nobject\nrange\nrebind\nsimd\nstring\nstring_literal\nstringref\ntuple\ntype_aliases\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nSIMD\n__init__\n__bool__\n__getitem__\n__setitem__\n__neg__\n__pos__\n__invert__\n__lt__\n__le__\n__eq__\n__ne__\n__gt__\n__ge__\n__add__\n__sub__\n__mul__\n__truediv__\n__floordiv__\n__mod__\n__pow__\n__lshift__\n__rshift__\n__and__\n__or__\n__xor__\n__radd__\n__rsub__\n__rmul__\n__rtruediv__\n__rfloordiv__\n__rmod__\n__rlshift__\n__rrshift__\n__rand__\n__ror__\n__rxor__\n__iadd__\n__isub__\n__imul__\n__itruediv__\n__ifloordiv__\n__imod__\n__ipow__\n__ilshift__\n__irshift__\n__iand__\n__ixor__\n__ior__\n__len__\nsplat\ncast\n__int__\nto_int\nfma\nshuffle\nslice\njoin\nmin\nmax\nreduce\nreduce_max\nreduce_min\nreduce_add\nreduce_mul\nreduce_and\nreduce_or\nselect\nrotate_left\nrotate_right\nshift_left\nshift_right\nsimd\n\nModule\n\nImplements SIMD struct.\n\nThese are Mojo built-ins, so you don‚Äôt need to import them.\n\nAliases:\n\n‚ÄãInt8 = SIMD[si8, 1]: Represents an 8-bit signed scalar integer.\n‚ÄãUInt8 = SIMD[ui8, 1]: Represents an 8-bit unsigned scalar integer.\n‚ÄãInt16 = SIMD[si16, 1]: Represents a 16-bit signed scalar integer.\n‚ÄãUInt16 = SIMD[ui16, 1]: Represents a 16-bit unsigned scalar integer.\n‚ÄãInt32 = SIMD[si32, 1]: Represents a 32-bit signed scalar integer.\n‚ÄãUInt32 = SIMD[ui32, 1]: Represents a 32-bit unsigned scalar integer.\n‚ÄãInt64 = SIMD[si64, 1]: Represents a 64-bit signed scalar integer.\n‚ÄãUInt64 = SIMD[ui64, 1]: Represents a 64-bit unsigned scalar integer.\n‚ÄãFloat16 = SIMD[f16, 1]: Represents a 16-bit floating point value.\n‚ÄãFloat32 = SIMD[f32, 1]: Represents a 32-bit floating point value.\n‚ÄãFloat64 = SIMD[f64, 1]: Represents a 64-bit floating point value.\nSIMD\n\nRepresents a small vector that is backed by a hardware vector element.\n\nSIMD allows a single instruction to be executed across the multiple data elements of the vector.\n\nConstraints:\n\nThe size of the SIMD vector to be positive and a power of 2.\n\nParameters:\n\n‚Äãtype (DType): The data type of SIMD vector elements.\n‚Äãsize (Int): The size of the SIMD vector.\n\nAliases:\n\n‚Äãelement_type = _65x13_type\n\nFields:\n\n‚Äãvalue (simd<#lit.struct.extract<:!kgen.declref<@\"$builtin\"::@\"$int\"::@Int, !lit.metatype<@\"$builtin\"::@\"$int\"::@Int>> size, \"value\">, #lit.struct.extract<:!kgen.declref<@\"$builtin\"::@\"$dtype\"::@DType, !lit.metatype<@\"$builtin\"::@\"$dtype\"::@DType>> type, \"value\">>): The underlying storage for the vector.\n\nFunctions:\n\n__init__\n\n__init__() -> Self\n\nDefault initializer of the SIMD vector.\n\nBy default the SIMD vectors are initialized to all zeros.\n\nReturns:\n\nSIMD vector whose elements are 0.\n\n__init__(value: Int) -> Self\n\nInitializes the SIMD vector with an integer.\n\nThe integer value is splatted across all the elements of the SIMD vector.\n\nArgs:\n\n‚Äãvalue (Int): The input value.\n\nReturns:\n\nSIMD vector whose elements have the specified value.\n\n__init__(value: IntLiteral) -> Self\n\nInitializes the SIMD vector with an integer.\n\nThe integer value is splatted across all the elements of the SIMD vector.\n\nArgs:\n\n‚Äãvalue (IntLiteral): The input value.\n\nReturns:\n\nSIMD vector whose elements have the specified value.\n\n__init__(value: Bool) -> Self\n\nInitializes the SIMD vector with a bool value.\n\nThe bool value is splatted across all elements of the SIMD vector.\n\nArgs:\n\n‚Äãvalue (Bool): The bool value.\n\nReturns:\n\nSIMD vector whose elements have the specified value.\n\n__init__(value: simd<#lit.struct.extract<:!kgen.declref<_\"$builtin\"::_\"$int\"::_Int, !lit.metatype<_\"$builtin\"::_\"$int\"::_Int>> size, \"value\">, #lit.struct.extract<:!kgen.declref<_\"$builtin\"::_\"$dtype\"::_DType, !lit.metatype<_\"$builtin\"::_\"$dtype\"::_DType>> type, \"value\">>) -> Self\n\nInitializes the SIMD vector with the underlying mlir value.\n\nArgs:\n\n‚Äãvalue (simd<#lit.struct.extract<:!kgen.declref<_\"$builtin\"::_\"$int\"::_Int, !lit.metatype<_\"$builtin\"::_\"$int\"::_Int>> size, \"value\">, #lit.struct.extract<:!kgen.declref<_\"$builtin\"::_\"$dtype\"::_DType, !lit.metatype<_\"$builtin\"::_\"$dtype\"::_DType>> type, \"value\">>): The input value.\n\nReturns:\n\nSIMD vector using the specified value.\n\n__init__(*elems: SIMD[type, 1]) -> Self\n\nConstructs a SIMD vector via a variadic list of elements.\n\nIf there is just one input value, then it is splatted to all elements of the SIMD vector. Otherwise, the input values are assigned to the corresponding elements of the SIMD vector.\n\nConstraints:\n\nThe number of input values is 1 or equal to size of the SIMD vector.\n\nArgs:\n\n‚Äãelems (*SIMD[type, 1]): The variadic list of elements from which the SIMD vector is constructed.\n\nReturns:\n\nThe constructed SIMD vector.\n\n__init__(value: FloatLiteral) -> Self\n\nInitializes the SIMD vector with a FP64 value.\n\nThe input value is splatted (broadcast) across all the elements of the SIMD vector.\n\nArgs:\n\n‚Äãvalue (FloatLiteral): The input value.\n\nReturns:\n\nA SIMD vector whose elements have the specified value.\n\n__bool__\n\n__bool__(self: Self) -> Bool\n\nConverts the SIMD vector into a boolean scalar value.\n\nReturns:\n\nTrue if all the elements in the SIMD vector are non-zero and False otherwise.\n\n__getitem__\n\n__getitem__(self: Self, idx: Int) -> SIMD[type, 1]\n\nGets an element from the vector.\n\nArgs:\n\n‚Äãidx (Int): The element index.\n\nReturns:\n\nThe value at position idx.\n\n__setitem__\n\n__setitem__(inout self: Self, idx: Int, val: SIMD[type, 1])\n\nSets an element in the vector.\n\nArgs:\n\n‚Äãidx (Int): The index to set.\n‚Äãval (SIMD[type, 1]): The value to set.\n\n__setitem__(inout self: Self, idx: Int, val: scalar<#lit.struct.extract<:!kgen.declref<_\"$builtin\"::_\"$dtype\"::_DType, !lit.metatype<_\"$builtin\"::_\"$dtype\"::_DType>> type, \"value\">>)\n\nSets an element in the vector.\n\nArgs:\n\n‚Äãidx (Int): The index to set.\n‚Äãval (scalar<#lit.struct.extract<:!kgen.declref<_\"$builtin\"::_\"$dtype\"::_DType, !lit.metatype<_\"$builtin\"::_\"$dtype\"::_DType>> type, \"value\">>): The value to set.\n__neg__\n\n__neg__(self: Self) -> Self\n\nDefines the unary - operation.\n\nReturns:\n\nThe negation of this SIMD vector.\n\n__pos__\n\n__pos__(self: Self) -> Self\n\nDefines the unary + operation.\n\nReturns:\n\nThis SIMD vector.\n\n__invert__\n\n__invert__(self: Self) -> Self\n\nReturns ~self.\n\nConstraints:\n\nThe element type of the SIMD vector must be boolean or integral.\n\nReturns:\n\nThe ~self value.\n\n__lt__\n\n__lt__(self: Self, rhs: Self) -> SIMD[bool, size]\n\nCompares two SIMD vectors using less-than comparison.\n\nArgs:\n\n‚Äãrhs (Self): The rhs of the operation.\n\nReturns:\n\nA new bool SIMD vector of the same size whose element at position i is True or False depending on the expression self[i] < rhs[i].\n\n__le__\n\n__le__(self: Self, rhs: Self) -> SIMD[bool, size]\n\nCompares two SIMD vectors using less-than-or-equal comparison.\n\nArgs:\n\n‚Äãrhs (Self): The rhs of the operation.\n\nReturns:\n\nA new bool SIMD vector of the same size whose element at position i is True or False depending on the expression self[i] <= rhs[i].\n\n__eq__\n\n__eq__(self: Self, rhs: Self) -> SIMD[bool, size]\n\nCompares two SIMD vectors using equal-to comparison.\n\nArgs:\n\n‚Äãrhs (Self): The rhs of the operation.\n\nReturns:\n\nA new bool SIMD vector of the same size whose element at position i is True or False depending on the expression self[i] == rhs[i].\n\n__ne__\n\n__ne__(self: Self, rhs: Self) -> SIMD[bool, size]\n\nCompares two SIMD vectors using not-equal comparison.\n\nArgs:\n\n‚Äãrhs (Self): The rhs of the operation.\n\nReturns:\n\nA new bool SIMD vector of the same size whose element at position i is True or False depending on the expression self[i] != rhs[i].\n\n__gt__\n\n__gt__(self: Self, rhs: Self) -> SIMD[bool, size]\n\nCompares two SIMD vectors using greater-than comparison.\n\nArgs:\n\n‚Äãrhs (Self): The rhs of the operation.\n\nReturns:\n\nA new bool SIMD vector of the same size whose element at position i is True or False depending on the expression self[i] > rhs[i].\n\n__ge__\n\n__ge__(self: Self, rhs: Self) -> SIMD[bool, size]\n\nCompares two SIMD vectors using greater-than-or-equal comparison.\n\nArgs:\n\n‚Äãrhs (Self): The rhs of the operation.\n\nReturns:\n\nA new bool SIMD vector of the same size whose element at position i is True or False depending on the expression self[i] >= rhs[i].\n\n__add__\n\n__add__(self: Self, rhs: Self) -> Self\n\nComputes self + rhs.\n\nArgs:\n\n‚Äãrhs (Self): The rhs value.\n\nReturns:\n\nA new vector whose element at position i is computed as self[i] + rhs[i].\n\n__sub__\n\n__sub__(self: Self, rhs: Self) -> Self\n\nComputes self - rhs.\n\nArgs:\n\n‚Äãrhs (Self): The rhs value.\n\nReturns:\n\nA new vector whose element at position i is computed as self[i] - rhs[i].\n\n__mul__\n\n__mul__(self: Self, rhs: Self) -> Self\n\nComputes self * rhs.\n\nArgs:\n\n‚Äãrhs (Self): The rhs value.\n\nReturns:\n\nA new vector whose element at position i is computed as self[i] * rhs[i].\n\n__truediv__\n\n__truediv__(self: Self, rhs: Self) -> Self\n\nComputes self / rhs.\n\nArgs:\n\n‚Äãrhs (Self): The rhs value.\n\nReturns:\n\nA new vector whose element at position i is computed as self[i] / rhs[i].\n\n__floordiv__\n\n__floordiv__(self: Self, rhs: Self) -> Self\n\nReturns the division of self and rhs rounded down to the nearest integer.\n\nConstraints:\n\nThe element type of the SIMD vector must be integral.\n\nArgs:\n\n‚Äãrhs (Self): The value to divide on.\n\nReturns:\n\nfloor(self / rhs) value.\n\n__mod__\n\n__mod__(self: Self, rhs: Self) -> Self\n\nReturns the remainder of self divided by rhs.\n\nArgs:\n\n‚Äãrhs (Self): The value to divide on.\n\nReturns:\n\nThe remainder of dividing self by rhs.\n\n__pow__\n\n__pow__(self: Self, rhs: Int) -> Self\n\nComputes the vector raised to the power of the input integer value.\n\nArgs:\n\n‚Äãrhs (Int): The exponential value.\n\nReturns:\n\nA SIMD vector where each element is raised to the power of the specified exponential value.\n\n__pow__(self: Self, rhs: Self) -> Self\n\nComputes the vector raised elementwise to the right hand side power.\n\nArgs:\n\n‚Äãrhs (Self): The exponential value.\n\nReturns:\n\nA SIMD vector where each element is raised to the power of the specified exponential value.\n\n__pow__[rhs_type: DType](self: Self, rhs: SIMD[rhs_type, size]) -> Self\n\nComputes the vector raised elementwise to the right hand side power.\n\nParameters:\n\n‚Äãrhs_type (DType): The dtype of the rhs SIMD vector.\n\nArgs:\n\n‚Äãrhs (SIMD[rhs_type, size]): The exponential value.\n\nReturns:\n\nA SIMD vector where each element is raised to the power of the specified exponential value.\n\n__lshift__\n\n__lshift__(self: Self, rhs: Self) -> Self\n\nReturns self << rhs.\n\nConstraints:\n\nThe element type of the SIMD vector must be integral.\n\nArgs:\n\n‚Äãrhs (Self): The RHS value.\n\nReturns:\n\nself << rhs.\n\n__rshift__\n\n__rshift__(self: Self, rhs: Self) -> Self\n\nReturns self >> rhs.\n\nConstraints:\n\nThe element type of the SIMD vector must be integral.\n\nArgs:\n\n‚Äãrhs (Self): The RHS value.\n\nReturns:\n\nself >> rhs.\n\n__and__\n\n__and__(self: Self, rhs: Self) -> Self\n\nReturns self & rhs.\n\nConstraints:\n\nThe element type of the SIMD vector must be bool or integral.\n\nArgs:\n\n‚Äãrhs (Self): The RHS value.\n\nReturns:\n\nself & rhs.\n\n__or__\n\n__or__(self: Self, rhs: Self) -> Self\n\nReturns self | rhs.\n\nConstraints:\n\nThe element type of the SIMD vector must be bool or integral.\n\nArgs:\n\n‚Äãrhs (Self): The RHS value.\n\nReturns:\n\nself | rhs.\n\n__xor__\n\n__xor__(self: Self, rhs: Self) -> Self\n\nReturns self ^ rhs.\n\nConstraints:\n\nThe element type of the SIMD vector must be bool or integral.\n\nArgs:\n\n‚Äãrhs (Self): The RHS value.\n\nReturns:\n\nself ^ rhs.\n\n__radd__\n\n__radd__(self: Self, value: Self) -> Self\n\nReturns value + self.\n\nArgs:\n\n‚Äãvalue (Self): The other value.\n\nReturns:\n\nvalue + self.\n\n__rsub__\n\n__rsub__(self: Self, value: Self) -> Self\n\nReturns value - self.\n\nArgs:\n\n‚Äãvalue (Self): The other value.\n\nReturns:\n\nvalue - self.\n\n__rmul__\n\n__rmul__(self: Self, value: Self) -> Self\n\nReturns value * self.\n\nArgs:\n\n‚Äãvalue (Self): The other value.\n\nReturns:\n\nvalue * self.\n\n__rtruediv__\n\n__rtruediv__(self: Self, value: Self) -> Self\n\nReturns value / self.\n\nArgs:\n\n‚Äãvalue (Self): The other value.\n\nReturns:\n\nvalue / self.\n\n__rfloordiv__\n\n__rfloordiv__(self: Self, value: Int) -> Int\n\nReturns value // self.\n\nArgs:\n\n‚Äãvalue (Int): The other value.\n\nReturns:\n\nvalue // self.\n\n__rmod__\n\n__rmod__(self: Self, value: Int) -> Int\n\nReturns value % self.\n\nArgs:\n\n‚Äãvalue (Int): The other value.\n\nReturns:\n\nvalue % self.\n\n__rlshift__\n\n__rlshift__(self: Self, value: Self) -> Self\n\nReturns value << self.\n\nConstraints:\n\nThe element type of the SIMD vector must be integral.\n\nArgs:\n\n‚Äãvalue (Self): The other value.\n\nReturns:\n\nvalue << self.\n\n__rrshift__\n\n__rrshift__(self: Self, value: Self) -> Self\n\nReturns value >> self.\n\nConstraints:\n\nThe element type of the SIMD vector must be integral.\n\nArgs:\n\n‚Äãvalue (Self): The other value.\n\nReturns:\n\nvalue >> self.\n\n__rand__\n\n__rand__(self: Self, value: Self) -> Self\n\nReturns value & self.\n\nConstraints:\n\nThe element type of the SIMD vector must be bool or integral.\n\nArgs:\n\n‚Äãvalue (Self): The other value.\n\nReturns:\n\nvalue & self.\n\n__ror__\n\n__ror__(self: Self, value: Self) -> Self\n\nReturns value | self.\n\nConstraints:\n\nThe element type of the SIMD vector must be bool or integral.\n\nArgs:\n\n‚Äãvalue (Self): The other value.\n\nReturns:\n\nvalue | self.\n\n__rxor__\n\n__rxor__(self: Self, value: Self) -> Self\n\nReturns value ^ self.\n\nConstraints:\n\nThe element type of the SIMD vector must be bool or integral.\n\nArgs:\n\n‚Äãvalue (Self): The other value.\n\nReturns:\n\nvalue ^ self.\n\n__iadd__\n\n__iadd__(inout self: Self, rhs: Self)\n\nPerforms in-place addition.\n\nThe vector is mutated where each element at position i is computed as self[i] + rhs[i].\n\nArgs:\n\n‚Äãrhs (Self): The rhs of the addition operation.\n__isub__\n\n__isub__(inout self: Self, rhs: Self)\n\nPerforms in-place subtraction.\n\nThe vector is mutated where each element at position i is computed as self[i] - rhs[i].\n\nArgs:\n\n‚Äãrhs (Self): The rhs of the operation.\n__imul__\n\n__imul__(inout self: Self, rhs: Self)\n\nPerforms in-place multiplication.\n\nThe vector is mutated where each element at position i is computed as self[i] * rhs[i].\n\nArgs:\n\n‚Äãrhs (Self): The rhs of the operation.\n__itruediv__\n\n__itruediv__(inout self: Self, rhs: Self)\n\nIn-place true divide operator.\n\nThe vector is mutated where each element at position i is computed as self[i] / rhs[i].\n\nArgs:\n\n‚Äãrhs (Self): The rhs of the operation.\n__ifloordiv__\n\n__ifloordiv__(inout self: Self, rhs: Self)\n\nIn-place flood div operator.\n\nThe vector is mutated where each element at position i is computed as self[i] // rhs[i].\n\nArgs:\n\n‚Äãrhs (Self): The rhs of the operation.\n__imod__\n\n__imod__(inout self: Self, rhs: Self)\n\nIn-place mod operator.\n\nThe vector is mutated where each element at position i is computed as self[i] % rhs[i].\n\nArgs:\n\n‚Äãrhs (Self): The rhs of the operation.\n__ipow__\n\n__ipow__(inout self: Self, rhs: Int)\n\nIn-place pow operator.\n\nThe vector is mutated where each element at position i is computed as pow(self[i], rhs).\n\nArgs:\n\n‚Äãrhs (Int): The rhs of the operation.\n__ilshift__\n\n__ilshift__(inout self: Self, rhs: Self)\n\nComputes self << rhs and save the result in self.\n\nConstraints:\n\nThe element type of the SIMD vector must be integral.\n\nArgs:\n\n‚Äãrhs (Self): The RHS value.\n__irshift__\n\n__irshift__(inout self: Self, rhs: Self)\n\nComputes self >> rhs and save the result in self.\n\nConstraints:\n\nThe element type of the SIMD vector must be integral.\n\nArgs:\n\n‚Äãrhs (Self): The RHS value.\n__iand__\n\n__iand__(inout self: Self, rhs: Self)\n\nComputes self & rhs and save the result in self.\n\nConstraints:\n\nThe element type of the SIMD vector must be bool or integral.\n\nArgs:\n\n‚Äãrhs (Self): The RHS value.\n__ixor__\n\n__ixor__(inout self: Self, rhs: Self)\n\nComputes self ^ rhs and save the result in self.\n\nConstraints:\n\nThe element type of the SIMD vector must be bool or integral.\n\nArgs:\n\n‚Äãrhs (Self): The RHS value.\n__ior__\n\n__ior__(inout self: Self, rhs: Self)\n\nComputes self | rhs and save the result in self.\n\nConstraints:\n\nThe element type of the SIMD vector must be bool or integral.\n\nArgs:\n\n‚Äãrhs (Self): The RHS value.\n__len__\n\n__len__(self: Self) -> Int\n\nGets the length of the SIMD vector.\n\nReturns:\n\nThe length of the SIMD vector.\n\nsplat\n\nsplat(x: Bool) -> Self\n\nSplats (broadcasts) the element onto the vector.\n\nArgs:\n\n‚Äãx (Bool): The input value.\n\nReturns:\n\nA new SIMD vector whose elements are the same as the input value.\n\nsplat(x: SIMD[type, 1]) -> Self\n\nSplats (broadcasts) the element onto the vector.\n\nArgs:\n\n‚Äãx (SIMD[type, 1]): The input scalar value.\n\nReturns:\n\nA new SIMD vector whose elements are the same as the input value.\n\ncast\n\ncast[target: DType](self: Self) -> SIMD[target, size]\n\nCasts the elements of the SIMD vector to the target element type.\n\nParameters:\n\n‚Äãtarget (DType): The target DType.\n\nReturns:\n\nA new SIMD vector whose elements have been casted to the target element type.\n\n__int__\n\n__int__(self: Self) -> Int\n\nCasts to the value to an Int. If there is a fractional component, then the value is truncated towards zero.\n\nConstraints:\n\nThe size of the SIMD vector must be 1.\n\nReturns:\n\nThe value as an integer.\n\nto_int\n\nto_int(self: Self) -> Int\n\nCasts to the value to an Int. If there is a fractional component, then the value is truncated towards zero.\n\nConstraints:\n\nThe size of the SIMD vector must be 1.\n\nReturns:\n\nThe value of the single integer element in the SIMD vector.\n\nfma\n\nfma(self: Self, multiplier: Self, accumulator: Self) -> Self\n\nPerforms a fused multiply-add operation, i.e.¬†self*multiplier + accumulator.\n\nArgs:\n\n‚Äãmultiplier (Self): The value to multiply.\n‚Äãaccumulator (Self): The value to accumulate.\n\nReturns:\n\nA new vector whose element at position i is computed as self[i]*multiplier[i] + accumulator[i].\n\nshuffle\n\nshuffle[*mask: Int](self: Self) -> Self\n\nShuffles (also called blend) the values of the current vector with the other value using the specified mask (permutation).\n\nParameters:\n\n‚Äãmask (*Int): The permutation to use in the shuffle.\n\nReturns:\n\nA new vector of length len where the value at position i is (self)[permutation[i]].\n\nshuffle[*mask: Int](self: Self, other: Self) -> Self\n\nShuffles (also called blend) the values of the current vector with the other value using the specified mask (permutation).\n\nParameters:\n\n‚Äãmask (*Int): The permutation to use in the shuffle.\n\nArgs:\n\n‚Äãother (Self): The other vector to shuffle with.\n\nReturns:\n\nA new vector of length len where the value at position i is (self+other)[permutation[i]].\n\nslice\n\nslice[output_width: Int](self: Self, offset: Int) -> SIMD[type, output_width]\n\nReturns a slice of the vector of the specified width with the given offset.\n\nConstraints:\n\noutput_width + offset must not exceed the size of this SIMD vector.\n\nParameters:\n\n‚Äãoutput_width (Int): The output SIMD vector size.\n\nArgs:\n\n‚Äãoffset (Int): The given offset for the slice.\n\nReturns:\n\nA new vector whose elements map to self[offset:offset+output_width].\n\njoin\n\njoin(self: Self, other: Self) -> SIMD[type, __mul__(2, size)]\n\nConcatenates the two vectors together.\n\nArgs:\n\n‚Äãother (Self): The other SIMD vector.\n\nReturns:\n\nA new vector self_0, self_1, ..., self_n, other_0, ..., other_n.\n\nmin\n\nmin(self: Self, other: Self) -> Self\n\nComputes the elementwise minimum between the two vectors.\n\nArgs:\n\n‚Äãother (Self): The other SIMD vector.\n\nReturns:\n\nA new SIMD vector where each element at position i is min(self[i], other[i]).\n\nmax\n\nmax(self: Self, other: Self) -> Self\n\nComputes the elementwise maximum between the two vectors.\n\nArgs:\n\n‚Äãother (Self): The other SIMD vector.\n\nReturns:\n\nA new SIMD vector where each element at position i is max(self[i], other[i]).\n\nreduce\n\nreduce[func: fn[DType, Int](SIMD[*(0,0), *(0,1)], SIMD[*(0,0), *(0,1)], /) capturing -> SIMD[*(0,0), *(0,1)], size_out: Int](self: Self) -> SIMD[type, size_out]\n\nReduces the vector using a provided reduce operator.\n\nParameters:\n\n‚Äãfunc (fn[DType, Int](SIMD[*(0,0), *(0,1)], SIMD[*(0,0), *(0,1)], /) capturing -> SIMD[*(0,0), *(0,1)]): The reduce function to apply to elements in this SIMD.\n‚Äãsize_out (Int): The width of the reduction.\n\nReturns:\n\nA new scalar which is the reduction of all vector elements.\n\nreduce_max\n\nreduce_max[size_out: Int](self: Self) -> SIMD[type, size_out]\n\nReduces the vector using the max operator.\n\nConstraints:\n\nThe element type of the vector must be integer or FP.\n\nParameters:\n\n‚Äãsize_out (Int): The width of the reduction.\n\nReturns:\n\nThe maximum element of the vector.\n\nreduce_min\n\nreduce_min[size_out: Int](self: Self) -> SIMD[type, size_out]\n\nReduces the vector using the min operator.\n\nConstraints:\n\nThe element type of the vector must be integer or FP.\n\nParameters:\n\n‚Äãsize_out (Int): The width of the reduction.\n\nReturns:\n\nThe minimum element of the vector.\n\nreduce_add\n\nreduce_add[size_out: Int](self: Self) -> SIMD[type, size_out]\n\nReduces the vector using the add operator.\n\nParameters:\n\n‚Äãsize_out (Int): The width of the reduction.\n\nReturns:\n\nThe sum of all vector elements.\n\nreduce_mul\n\nreduce_mul[size_out: Int](self: Self) -> SIMD[type, size_out]\n\nReduces the vector using the mul operator.\n\nConstraints:\n\nThe element type of the vector must be integer or FP.\n\nParameters:\n\n‚Äãsize_out (Int): The width of the reduction.\n\nReturns:\n\nThe product of all vector elements.\n\nreduce_and\n\nreduce_and(self: Self) -> Bool\n\nReduces the boolean vector using the and operator.\n\nConstraints:\n\nThe element type of the vector must be boolean.\n\nReturns:\n\nTrue if all element in the vector is True and False otherwise.\n\nreduce_or\n\nreduce_or(self: Self) -> Bool\n\nReduces the boolean vector using the or operator.\n\nConstraints:\n\nThe element type of the vector must be boolean.\n\nReturns:\n\nTrue if any element in the vector is True and False otherwise.\n\nselect\n\nselect[result_type: DType](self: Self, true_case: SIMD[result_type, size], false_case: SIMD[result_type, size]) -> SIMD[result_type, size]\n\nSelects the values of the true_case or the false_case based on the current boolean values of the SIMD vector.\n\nParameters:\n\n‚Äãresult_type (DType): The element type of the input and output SIMD vectors.\n\nArgs:\n\n‚Äãtrue_case (SIMD[result_type, size]): The values selected if the positional value is True.\n‚Äãfalse_case (SIMD[result_type, size]): The values selected if the positional value is False.\n\nReturns:\n\nA new vector of the form [true_case[i] if elem else false_case[i] in enumerate(self)].\n\nrotate_left\n\nrotate_left[shift: Int](self: Self) -> Self\n\nShifts the elements of a SIMD vector to the left by shift elements (with wrap-around).\n\nConstraints:\n\n-size <= shift < size\n\nParameters:\n\n‚Äãshift (Int): The number of positions by which to rotate the elements of SIMD vector to the left (with wrap-around).\n\nReturns:\n\nThe SIMD vector rotated to the left by shift elements (with wrap-around).\n\nrotate_right\n\nrotate_right[shift: Int](self: Self) -> Self\n\nShifts the elements of a SIMD vector to the right by shift elements (with wrap-around).\n\nConstraints:\n\n-size < shift <= size\n\nParameters:\n\n‚Äãshift (Int): The number of positions by which to rotate the elements of SIMD vector to the right (with wrap-around).\n\nReturns:\n\nThe SIMD vector rotated to the right by shift elements (with wrap-around).\n\nshift_left\n\nshift_left[shift: Int](self: Self) -> Self\n\nShifts the elements of a SIMD vector to the left by shift elements (no wrap-around, fill with zero).\n\nConstraints:\n\n0 <= shift <= size\n\nParameters:\n\n‚Äãshift (Int): The number of positions by which to rotate the elements of SIMD vector to the left (no wrap-around, fill with zero).\n\nReturns:\n\nThe SIMD vector rotated to the left by shift elements (no wrap-around, fill with zero).\n\nshift_right\n\nshift_right[shift: Int](self: Self) -> Self\n\nShifts the elements of a SIMD vector to the right by shift elements (no wrap-around, fill with zero).\n\nConstraints:\n\n0 <= shift <= size\n\nParameters:\n\n‚Äãshift (Int): The number of positions by which to rotate the elements of SIMD vector to the right (no wrap-around, fill with zero).\n\nReturns:\n\nThe SIMD vector rotated to the right by shift elements (no wrap-around, fill with zero).\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - rebind",
    "url": "https://docs.modular.com/mojo/stdlib/builtin/rebind.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\nbool\nbuiltin_list\nbuiltin_slice\nconstrained\ncoroutine\ndebug_assert\ndtype\nerror\nfile\nfloat_literal\nint\nio\nlen\nobject\nrange\nrebind\nsimd\nstring\nstring_literal\nstringref\ntuple\ntype_aliases\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nrebind\nrebind\n\nModule\n\nImplements type rebind.\n\nThese are Mojo built-ins, so you don‚Äôt need to import them.\n\nrebind\n\nrebind[dest_type: AnyType, src_type: AnyType](val: src_type) -> dest_type\n\nStatically assert that a parameter input type src_type resolves to the same type as a parameter result type dest_type after function instantiation and ‚Äúrebind‚Äù the input to the result type.\n\nThis function is meant to be used in uncommon cases where a parametric type depends on the value of a constrained parameter in order to manually refine the type with the constrained parameter value.\n\nParameters:\n\n‚Äãdest_type (AnyType): The type to rebind to.\n‚Äãsrc_type (AnyType): The original type.\n\nArgs:\n\n‚Äãval (src_type): The value to rebind.\n\nReturns:\n\nThe rebound value of dest_type.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - object",
    "url": "https://docs.modular.com/mojo/stdlib/builtin/object.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\nbool\nbuiltin_list\nbuiltin_slice\nconstrained\ncoroutine\ndebug_assert\ndtype\nerror\nfile\nfloat_literal\nint\nio\nlen\nobject\nrange\nrebind\nsimd\nstring\nstring_literal\nstringref\ntuple\ntype_aliases\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nAttr\n__init__\n__del__\nobject\nobject\n\nModule\n\nDefines the object type, which is used to represent untyped values.\n\nThese are Mojo built-ins, so you don‚Äôt need to import them.\n\nAttr\n\nA generic object‚Äôs attributes are set on construction, after which the attributes can be read and modified, but no attributes may be removed or added.\n\nFields:\n\n‚Äãkey (StringLiteral): The name of the attribute.\n‚Äãvalue (object): The value of the attribute.\n\nFunctions:\n\n__init__\n\n__init__(inout self: Self, key: StringLiteral, owned value: object)\n\nInitializes the attribute with a key and value.\n\nArgs:\n\n‚Äãkey (StringLiteral): The string literal key.\n‚Äãvalue (object): The object value of the attribute.\n__del__\n\n__del__(owned self: Self)\n\nobject\n\nRepresents an object without a concrete type.\n\nThis is the type of arguments in def functions that do not have a type annotation, such as the type of x in def f(x): pass. A value of any type can be passed in as the x argument in this case, and so that value is used to construct this object type.\n\nAliases:\n\n‚Äãnullary_function = fn() raises -> object: Nullary function type.\n‚Äãunary_function = fn(object, /) raises -> object: Unary function type.\n‚Äãbinary_function = fn(object, object, /) raises -> object: Binary function type.\n‚Äãternary_function = fn(object, object, object, /) raises -> object: Ternary function type.\n\nFunctions:\n\n__init__\n\n__init__(inout self: Self)\n\nInitializes the object with a None value.\n\n__init__(inout self: Self, impl: _ObjectImpl)\n\nInitializes the object with an implementation value. This is meant for internal use only.\n\nArgs:\n\n‚Äãimpl (_ObjectImpl): The object implementation.\n\n__init__(inout self: Self, none: None)\n\nInitializes a none value object from a None literal.\n\nArgs:\n\n‚Äãnone (None): None.\n\n__init__(inout self: Self, value: Int)\n\nInitializes the object with an integer value.\n\nArgs:\n\n‚Äãvalue (Int): The integer value.\n\n__init__(inout self: Self, value: FloatLiteral)\n\nInitializes the object with an floating-point value.\n\nArgs:\n\n‚Äãvalue (FloatLiteral): The float value.\n\n__init__[dt: DType](inout self: Self, value: SIMD[dt, 1])\n\nInitializes the object with a generic scalar value. If the scalar value type is bool, it is converted to a boolean. Otherwise, it is converted to the appropriate integer or floating point type.\n\nParameters:\n\n‚Äãdt (DType): The scalar value type.\n\nArgs:\n\n‚Äãvalue (SIMD[dt, 1]): The scalar value.\n\n__init__(inout self: Self, value: Bool)\n\nInitializes the object from a bool.\n\nArgs:\n\n‚Äãvalue (Bool): The boolean value.\n\n__init__(inout self: Self, value: StringLiteral)\n\nInitializes the object from a string literal.\n\nArgs:\n\n‚Äãvalue (StringLiteral): The string value.\n\n__init__(inout self: Self, value: StringRef)\n\nInitializes the object from a string reference.\n\nArgs:\n\n‚Äãvalue (StringRef): The string value.\n\n__init__[*Ts: AnyType](inout self: Self, value: ListLiteral[Ts])\n\nInitializes the object from a list literal.\n\nParameters:\n\n‚ÄãTs (*AnyType): The list element types.\n\nArgs:\n\n‚Äãvalue (ListLiteral[Ts]): The list value.\n\n__init__(inout self: Self, func: fn() raises -> object)\n\nInitializes an object from a function that takes no arguments.\n\nArgs:\n\n‚Äãfunc (fn() raises -> object): The function.\n\n__init__(inout self: Self, func: fn(object, /) raises -> object)\n\nInitializes an object from a function that takes one argument.\n\nArgs:\n\n‚Äãfunc (fn(object, /) raises -> object): The function.\n\n__init__(inout self: Self, func: fn(object, object, /) raises -> object)\n\nInitializes an object from a function that takes two arguments.\n\nArgs:\n\n‚Äãfunc (fn(object, object, /) raises -> object): The function.\n\n__init__(inout self: Self, func: fn(object, object, object, /) raises -> object)\n\nInitializes an object from a function that takes three arguments.\n\nArgs:\n\n‚Äãfunc (fn(object, object, object, /) raises -> object): The function.\n\n__init__(inout self: Self, *attrs: Attr)\n\nInitializes the object with a sequence of zero or more attributes.\n\nArgs:\n\n‚Äãattrs (*Attr): Zero or more attributes.\n__copyinit__\n\n__copyinit__(inout self: Self, existing: Self)\n\nCopies the object. This clones the underlying string value and increases the refcount of lists or dictionaries.\n\nArgs:\n\n‚Äãexisting (Self): The object to copy.\n__moveinit__\n\n__moveinit__(inout self: Self, owned existing: Self)\n\nMove the value of an object.\n\nArgs:\n\n‚Äãexisting (Self): The object to move.\n__del__\n\n__del__(owned self: Self)\n\nDelete the object and release any owned memory.\n\n__bool__\n\n__bool__(self: Self) -> Bool\n\nPerforms conversion to bool according to Python semantics. Integers and floats are true if they are non-zero, and strings and lists are true if they are non-empty.\n\nReturns:\n\nWhether the object is considered true.\n\n__getitem__\n\n__getitem__(self: Self, i: Self) -> Self\n\nGets the i-th item from the object. This is only valid for strings, lists, and dictionaries.\n\nArgs:\n\n‚Äãi (Self): The string or list index, or dictionary key.\n\nReturns:\n\nThe value at the index or key.\n\n__getitem__(self: Self, *index: Self) -> Self\n\nGets the i-th item from the object, where i is a tuple of indices.\n\nArgs:\n\n‚Äãindex (*Self): A compound index.\n\nReturns:\n\nThe value at the index.\n\n__setitem__\n\n__setitem__(self: Self, i: Self, value: Self)\n\nSets the i-th item in the object. This is only valid for strings, lists, and dictionaries.\n\nArgs:\n\n‚Äãi (Self): The string or list index, or dictionary key.\n‚Äãvalue (Self): The value to set.\n\n__setitem__(self: Self, i: Self, j: Self, value: Self)\n\nSets the (i, j)-th element in the object.\n\nFIXME: We need this because obj[i, j] = value will attempt to invoke this method with 3 arguments, and we can only have variadics as the last argument.\n\nArgs:\n\n‚Äãi (Self): The first index.\n‚Äãj (Self): The second index.\n‚Äãvalue (Self): The value to set.\n__neg__\n\n__neg__(self: Self) -> Self\n\nNegation operator. Only valid for bool, int, and float types. Negation on any bool value converts it to an integer.\n\nReturns:\n\nThe negative of the current value.\n\n__invert__\n\n__invert__(self: Self) -> Self\n\nInvert value operator. This is only valid for bool and int values.\n\nReturns:\n\nThe inverted value.\n\n__lt__\n\n__lt__(self: Self, rhs: Self) -> Self\n\nLess-than comparator. This lexicographically compares strings and lists.\n\nArgs:\n\n‚Äãrhs (Self): Right hand value.\n\nReturns:\n\nTrue if the object is less than the right hard argument.\n\n__le__\n\n__le__(self: Self, rhs: Self) -> Self\n\nLess-than-or-equal to comparator. This lexicographically compares strings and lists.\n\nArgs:\n\n‚Äãrhs (Self): Right hand value.\n\nReturns:\n\nTrue if the object is less than or equal to the right hard argument.\n\n__eq__\n\n__eq__(self: Self, rhs: Self) -> Self\n\nEquality comparator. This compares the elements of strings and lists.\n\nArgs:\n\n‚Äãrhs (Self): Right hand value.\n\nReturns:\n\nTrue if the objects are equal.\n\n__ne__\n\n__ne__(self: Self, rhs: Self) -> Self\n\nInequality comparator. This compares the elements of strings and lists.\n\nArgs:\n\n‚Äãrhs (Self): Right hand value.\n\nReturns:\n\nTrue if the objects are not equal.\n\n__gt__\n\n__gt__(self: Self, rhs: Self) -> Self\n\nGreater-than comparator. This lexicographically compares the elements of strings and lists.\n\nArgs:\n\n‚Äãrhs (Self): Right hand value.\n\nReturns:\n\nTrue if the left hand value is greater.\n\n__ge__\n\n__ge__(self: Self, rhs: Self) -> Self\n\nGreater-than-or-equal-to comparator. This lexicographically compares the elements of strings and lists.\n\nArgs:\n\n‚Äãrhs (Self): Right hand value.\n\nReturns:\n\nTrue if the left hand value is greater than or equal to the right hand value.\n\n__add__\n\n__add__(self: Self, rhs: Self) -> Self\n\nAddition and concatenation operator. For arithmetic types, this function will compute the sum of the left and right hand values. For strings and lists, this function will concat the objects.\n\nArgs:\n\n‚Äãrhs (Self): Right hand value.\n\nReturns:\n\nThe sum or concatenated values.\n\n__sub__\n\n__sub__(self: Self, rhs: Self) -> Self\n\nSubtraction operator. Valid only for arithmetic types.\n\nArgs:\n\n‚Äãrhs (Self): Right hand value.\n\nReturns:\n\nThe difference.\n\n__mul__\n\n__mul__(self: Self, rhs: Self) -> Self\n\nMultiplication operator. Valid only for arithmetic types.\n\nArgs:\n\n‚Äãrhs (Self): Right hand value.\n\nReturns:\n\nThe product.\n\n__pow__\n\n__pow__(self: Self, rhs: Self) -> Self\n\nExponentiation operator. Valid only for arithmetic types.\n\nArgs:\n\n‚Äãrhs (Self): Right hand value.\n\nReturns:\n\nThe left hand value raised to the power of the right hand value.\n\n__and__\n\n__and__(self: Self, rhs: Self) -> Self\n\nBool AND operator. If the left hand value is False, return the left-hand value.\n\nArgs:\n\n‚Äãrhs (Self): Right hand value.\n\nReturns:\n\nThe current value if it is False.\n\n__or__\n\n__or__(self: Self, rhs: Self) -> Self\n\nBool OR operator. If the left hand value is True, return the left-hand value.\n\nArgs:\n\n‚Äãrhs (Self): Right hand value.\n\nReturns:\n\nThe current value if it is True.\n\n__radd__\n\n__radd__(self: Self, lhs: Self) -> Self\n\nReverse addition or concatenation operator.\n\nArgs:\n\n‚Äãlhs (Self): Left hand value.\n\nReturns:\n\nThe sum or concatenated value.\n\n__rsub__\n\n__rsub__(self: Self, lhs: Self) -> Self\n\nReverse subtraction operator.\n\nArgs:\n\n‚Äãlhs (Self): Left hand value.\n\nReturns:\n\nThe result of subtracting this from the left-hand-side value.\n\n__rmul__\n\n__rmul__(self: Self, lhs: Self) -> Self\n\nReverse multiplication operator.\n\nArgs:\n\n‚Äãlhs (Self): Left hand value.\n\nReturns:\n\nThe product.\n\n__rpow__\n\n__rpow__(self: Self, lhs: Self) -> Self\n\nReverse exponentiation operator.\n\nArgs:\n\n‚Äãlhs (Self): Left hand value.\n\nReturns:\n\nThe left hand value raised to the power of the right hand value.\n\n__rand__\n\n__rand__(self: Self, lhs: Self) -> Self\n\nReverse AND operator.\n\nArgs:\n\n‚Äãlhs (Self): Left hand value.\n\nReturns:\n\nThe bitwise AND of the left-hand-side value and this.\n\n__ror__\n\n__ror__(self: Self, lhs: Self) -> Self\n\nReverse OR operator.\n\nArgs:\n\n‚Äãlhs (Self): Left hand value.\n\nReturns:\n\nThe bitwise OR of the left-hand-side value and this.\n\n__iadd__\n\n__iadd__(inout self: Self, rhs: Self)\n\nIn-place addition or concatenation operator.\n\nArgs:\n\n‚Äãrhs (Self): Right hand value.\n__isub__\n\n__isub__(inout self: Self, rhs: Self)\n\nIn-place subtraction operator.\n\nArgs:\n\n‚Äãrhs (Self): Right hand value.\n__imul__\n\n__imul__(inout self: Self, rhs: Self)\n\nIn-place multiplication operator.\n\nArgs:\n\n‚Äãrhs (Self): Right hand value.\n__ipow__\n\n__ipow__(inout self: Self, rhs: Self)\n\nIn-place exponentiation operator.\n\nArgs:\n\n‚Äãrhs (Self): Right hand value.\n__iand__\n\n__iand__(inout self: Self, rhs: Self)\n\nIn-place AND operator.\n\nArgs:\n\n‚Äãrhs (Self): Right hand value.\n__ior__\n\n__ior__(inout self: Self, rhs: Self)\n\nIn-place OR operator.\n\nArgs:\n\n‚Äãrhs (Self): Right hand value.\nappend\n\nappend(self: Self, value: Self)\n\nAppends a value to the list.\n\nArgs:\n\n‚Äãvalue (Self): The value to append.\n__len__\n\n__len__(self: Self) -> Int\n\nReturns the ‚Äúlength‚Äù of the object. Only strings, lists, and dictionaries have lengths.\n\nReturns:\n\nThe length of the string value or the number of elements in the list or dictionary value.\n\n__getattr__\n\n__getattr__(self: Self, key: StringLiteral) -> Self\n\n__setattr__\n\n__setattr__(inout self: Self, key: StringLiteral, value: Self)\n\n__call__\n\n__call__(self: Self) -> Self\n\n__call__(self: Self, arg0: Self) -> Self\n\n__call__(self: Self, arg0: Self, arg1: Self) -> Self\n\n__call__(self: Self, arg0: Self, arg1: Self, arg2: Self) -> Self\n\nprint\n\nprint(self: Self)\n\nPrints the value of the object.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - range",
    "url": "https://docs.modular.com/mojo/stdlib/builtin/range.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\nbool\nbuiltin_list\nbuiltin_slice\nconstrained\ncoroutine\ndebug_assert\ndtype\nerror\nfile\nfloat_literal\nint\nio\nlen\nobject\nrange\nrebind\nsimd\nstring\nstring_literal\nstringref\ntuple\ntype_aliases\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nrange\nrange\n\nModule\n\nImplements a ‚Äòrange‚Äô call.\n\nThese are Mojo built-ins, so you don‚Äôt need to import them.\n\nrange\n\nrange(end: Int) -> _ZeroStartingRange\n\nConstructs a [0; end) Range.\n\nArgs:\n\n‚Äãend (Int): The end of the range.\n\nReturns:\n\nThe constructed range.\n\nrange(end: PythonObject) -> _ZeroStartingRange\n\nConstructs a [0; end) Range.\n\nArgs:\n\n‚Äãend (PythonObject): The end of the range.\n\nReturns:\n\nThe constructed range.\n\nrange(length: object) -> _ZeroStartingRange\n\nConstructs a [0; length) Range.\n\nArgs:\n\n‚Äãlength (object): The end of the range.\n\nReturns:\n\nThe constructed range.\n\nrange(start: Int, end: Int) -> _SequentialRange\n\nConstructs a [start; end) Range.\n\nArgs:\n\n‚Äãstart (Int): The start of the range.\n‚Äãend (Int): The end of the range.\n\nReturns:\n\nThe constructed range.\n\nrange(start: object, end: object) -> _SequentialRange\n\nConstructs a [start; end) Range.\n\nArgs:\n\n‚Äãstart (object): The start of the range.\n‚Äãend (object): The end of the range.\n\nReturns:\n\nThe constructed range.\n\nrange(start: PythonObject, end: PythonObject) -> _SequentialRange\n\nConstructs a [start; end) Range.\n\nArgs:\n\n‚Äãstart (PythonObject): The start of the range.\n‚Äãend (PythonObject): The end of the range.\n\nReturns:\n\nThe constructed range.\n\nrange(start: Int, end: Int, step: Int) -> _StridedRange\n\nConstructs a [start; end) Range with a given step.\n\nArgs:\n\n‚Äãstart (Int): The start of the range.\n‚Äãend (Int): The end of the range.\n‚Äãstep (Int): The step for the range.\n\nReturns:\n\nThe constructed range.\n\nrange(start: object, end: object, step: object) -> _StridedRange\n\nConstructs a [start; end) Range with a given step.\n\nArgs:\n\n‚Äãstart (object): The start of the range.\n‚Äãend (object): The end of the range.\n‚Äãstep (object): The step for the range.\n\nReturns:\n\nThe constructed range.\n\nrange(start: PythonObject, end: PythonObject, step: PythonObject) -> _StridedRange\n\nConstructs a [start; end) Range with a given step.\n\nArgs:\n\n‚Äãstart (PythonObject): The start of the range.\n‚Äãend (PythonObject): The end of the range.\n‚Äãstep (PythonObject): The step for the range.\n\nReturns:\n\nThe constructed range.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - len",
    "url": "https://docs.modular.com/mojo/stdlib/builtin/len.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\nbool\nbuiltin_list\nbuiltin_slice\nconstrained\ncoroutine\ndebug_assert\ndtype\nerror\nfile\nfloat_literal\nint\nio\nlen\nobject\nrange\nrebind\nsimd\nstring\nstring_literal\nstringref\ntuple\ntype_aliases\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nlen\nlen\n\nModule\n\nProvides the len function.\n\nThese are Mojo built-ins, so you don‚Äôt need to import them.\n\nlen\n\nlen[type: DType, size: Int](value: SIMD[type, size]) -> Int\n\nReturns the length of the given SIMD value.\n\nParameters:\n\n‚Äãtype (DType): The element type of the SIMD value.\n‚Äãsize (Int): The number of elements in the value.\n\nArgs:\n\n‚Äãvalue (SIMD[type, size]): The SIMD value.\n\nReturns:\n\nThe length of the SIMD value.\n\nlen[size: Int, type: AnyType](value: InlinedFixedVector[*\"type\", size]) -> Int\n\nReturns the length of the given fixed vector.\n\nParameters:\n\n‚Äãsize (Int): The number of elements in the value.\n‚Äãtype (AnyType): The element type of the value.\n\nArgs:\n\n‚Äãvalue (InlinedFixedVector[*\"type\", size]): The vector value.\n\nReturns:\n\nThe length of the vector.\n\nlen[type: AnyType](value: UnsafeFixedVector[*\"type\"]) -> Int\n\nReturn the length of the given vector.\n\nParameters:\n\n‚Äãtype (AnyType): The element type of the value.\n\nArgs:\n\n‚Äãvalue (UnsafeFixedVector[*\"type\"]): The vector value.\n\nReturns:\n\nThe length of the vector.\n\nlen[type: AnyType](value: DynamicVector[*\"type\"]) -> Int\n\nReturn the length of the given vector.\n\nParameters:\n\n‚Äãtype (AnyType): The element type of the value.\n\nArgs:\n\n‚Äãvalue (DynamicVector[*\"type\"]): The vector value.\n\nReturns:\n\nThe length of the vector.\n\nlen(value: String) -> Int\n\nReturn the length of the given string.\n\nArgs:\n\n‚Äãvalue (String): The string value.\n\nReturns:\n\nThe length of the string.\n\nlen(value: StringRef) -> Int\n\nReturn the length of the given string reference.\n\nArgs:\n\n‚Äãvalue (StringRef): The string value.\n\nReturns:\n\nThe length of the string.\n\nlen(value: StringLiteral) -> Int\n\nReturn the length of the given string literal.\n\nArgs:\n\n‚Äãvalue (StringLiteral): The string literal value.\n\nReturns:\n\nThe length of the string literal.\n\nlen[size: Dim, type: DType](value: Buffer[size, type]) -> Int\n\nReturn the length of the given buffer.\n\nParameters:\n\n‚Äãsize (Dim): The number of elements in the value.\n‚Äãtype (DType): The element type of the value.\n\nArgs:\n\n‚Äãvalue (Buffer[size, type]): The buffer value.\n\nReturns:\n\nThe length of the buffer.\n\nlen[type: AnyType](value: VariadicList[*\"type\"]) -> Int\n\nReturn the length of the given variadic list.\n\nParameters:\n\n‚Äãtype (AnyType): The element type of the value.\n\nArgs:\n\n‚Äãvalue (VariadicList[*\"type\"]): The variadic list value.\n\nReturns:\n\nThe length of the variadic list.\n\nlen[type: AnyType](value: VariadicListMem[*\"type\"]) -> Int\n\nReturn the length of the given variadic list.\n\nParameters:\n\n‚Äãtype (AnyType): The element type of the value.\n\nArgs:\n\n‚Äãvalue (VariadicListMem[*\"type\"]): The variadic list value.\n\nReturns:\n\nThe length of the variadic list.\n\nlen[*types: AnyType](value: ListLiteral[types]) -> Int\n\nReturn the length of the given list literal.\n\nParameters:\n\n‚Äãtypes (*AnyType): The element types of the value.\n\nArgs:\n\n‚Äãvalue (ListLiteral[types]): The list literal value.\n\nReturns:\n\nThe length of the list literal.\n\nlen[*types: AnyType](value: Tuple[types]) -> Int\n\nReturn the length of the given tuple literal.\n\nParameters:\n\n‚Äãtypes (*AnyType): The element types of the value.\n\nArgs:\n\n‚Äãvalue (Tuple[types]): The tuple literal value.\n\nReturns:\n\nThe length of the tuple literal.\n\nlen[size: Int](value: StaticIntTuple[size]) -> Int\n\nReturn the length of the given static tuple.\n\nParameters:\n\n‚Äãsize (Int): The number of elements in the value.\n\nArgs:\n\n‚Äãvalue (StaticIntTuple[size]): The static tuple value.\n\nReturns:\n\nThe length of the static tuple.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - io",
    "url": "https://docs.modular.com/mojo/stdlib/builtin/io.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\nbool\nbuiltin_list\nbuiltin_slice\nconstrained\ncoroutine\ndebug_assert\ndtype\nerror\nfile\nfloat_literal\nint\nio\nlen\nobject\nrange\nrebind\nsimd\nstring\nstring_literal\nstringref\ntuple\ntype_aliases\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nput_new_line\nprint\nprint_no_newline\nio\n\nModule\n\nProvides utilities for working with input/output.\n\nThese are Mojo built-ins, so you don‚Äôt need to import them.\n\nput_new_line\n\nput_new_line()\n\nPrints a new line character.\n\nprint\n\nprint()\n\nPrints a newline.\n\nprint(t: DType)\n\nPrints a DType.\n\nArgs:\n\n‚Äãt (DType): The DType to print.\n\nprint(x: String)\n\nPrints a string.\n\nArgs:\n\n‚Äãx (String): The string to print.\n\nprint(x: StringRef)\n\nPrints a string.\n\nArgs:\n\n‚Äãx (StringRef): The string to print.\n\nprint(x: StringLiteral)\n\nPrints a string.\n\nArgs:\n\n‚Äãx (StringLiteral): The string to print.\n\nprint(x: Bool)\n\nPrints a boolean value.\n\nArgs:\n\n‚Äãx (Bool): The value to print.\n\nprint(x: FloatLiteral)\n\nPrints a float literal.\n\nArgs:\n\n‚Äãx (FloatLiteral): The value to print.\n\nprint(x: Int)\n\nPrints an integer value.\n\nArgs:\n\n‚Äãx (Int): The value to print.\n\nprint[simd_width: Int, type: DType](vec: SIMD[type, simd_width])\n\nPrints a SIMD value.\n\nParameters:\n\n‚Äãsimd_width (Int): The SIMD vector width.\n‚Äãtype (DType): The DType of the value.\n\nArgs:\n\n‚Äãvec (SIMD[type, simd_width]): The SIMD value to print.\n\nprint[simd_width: Int, type: DType](vec: ComplexSIMD[type, simd_width])\n\nPrints a SIMD value.\n\nParameters:\n\n‚Äãsimd_width (Int): The SIMD vector width.\n‚Äãtype (DType): The DType of the value.\n\nArgs:\n\n‚Äãvec (ComplexSIMD[type, simd_width]): The complex value to print.\n\nprint[type: DType](x: Atomic[type])\n\nPrints an atomic value.\n\nParameters:\n\n‚Äãtype (DType): The DType of the atomic value.\n\nArgs:\n\n‚Äãx (Atomic[type]): The value to print.\n\nprint[length: Int](shape: DimList)\n\nPrints a DimList object.\n\nParameters:\n\n‚Äãlength (Int): The length of the DimList.\n\nArgs:\n\n‚Äãshape (DimList): The DimList object to print.\n\nprint(obj: object)\n\nPrints an object type.\n\nArgs:\n\n‚Äãobj (object): The object to print.\n\nprint(err: Error)\n\nPrints an Error type.\n\nArgs:\n\n‚Äãerr (Error): The Error to print.\n\nprint(*elements: _Printable)\n\nPrints a sequence of elements, joined by spaces, followed by a newline.\n\nArgs:\n\n‚Äãelements (*_Printable): The elements to print.\nprint_no_newline\n\nprint_no_newline(*elements: _Printable)\n\nPrints a sequence of elements, joined by spaces.\n\nArgs:\n\n‚Äãelements (*_Printable): The elements to print.\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - int",
    "url": "https://docs.modular.com/mojo/stdlib/builtin/int.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\nbool\nbuiltin_list\nbuiltin_slice\nconstrained\ncoroutine\ndebug_assert\ndtype\nerror\nfile\nfloat_literal\nint\nio\nlen\nobject\nrange\nrebind\nsimd\nstring\nstring_literal\nstringref\ntuple\ntype_aliases\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nInt\n__init__\n__bool__\n__neg__\n__pos__\n__invert__\n__lt__\n__le__\n__eq__\n__ne__\n__gt__\n__ge__\n__add__\n__sub__\n__mul__\n__truediv__\n__floordiv__\n__mod__\n__pow__\n__lshift__\n__rshift__\n__and__\n__or__\n__xor__\n__radd__\n__rsub__\n__rmul__\n__rfloordiv__\n__rmod__\n__rpow__\n__rlshift__\n__rrshift__\n__rand__\n__ror__\n__rxor__\n__iadd__\n__isub__\n__imul__\n__itruediv__\n__ifloordiv__\n__imod__\n__ipow__\n__ilshift__\n__irshift__\n__iand__\n__ixor__\n__ior__\n__int__\n__mlir_index__\n__index__\nint\n\nModule\n\nImplements the Int class.\n\nThese are Mojo built-ins, so you don‚Äôt need to import them.\n\nInt\n\nThis type represents an integer value.\n\nFields:\n\n‚Äãvalue (index): The underlying storage for the integer value.\n\nFunctions:\n\n__init__\n\n__init__() -> Self\n\nDefault constructor.\n\nReturns:\n\nThe constructed Int object.\n\n__init__(value: Self) -> Self\n\nConstruct Int from another Int value.\n\nArgs:\n\n‚Äãvalue (Self): The init value.\n\nReturns:\n\nThe constructed Int object.\n\n__init__(value: index) -> Self\n\nConstruct Int from the given index value.\n\nArgs:\n\n‚Äãvalue (index): The init value.\n\nReturns:\n\nThe constructed Int object.\n\n__init__(value: scalar<si16>) -> Self\n\nConstruct Int from the given Int16 value.\n\nArgs:\n\n‚Äãvalue (scalar<si16>): The init value.\n\nReturns:\n\nThe constructed Int object.\n\n__init__(value: scalar<si32>) -> Self\n\nConstruct Int from the given Int32 value.\n\nArgs:\n\n‚Äãvalue (scalar<si32>): The init value.\n\nReturns:\n\nThe constructed Int object.\n\n__init__(value: scalar<si64>) -> Self\n\nConstruct Int from the given Int64 value.\n\nArgs:\n\n‚Äãvalue (scalar<si64>): The init value.\n\nReturns:\n\nThe constructed Int object.\n\n__init__(value: scalar<index>) -> Self\n\nConstruct Int from the given Index value.\n\nArgs:\n\n‚Äãvalue (scalar<index>): The init value.\n\nReturns:\n\nThe constructed Int object.\n\n__init__(value: IntLiteral) -> Self\n\nConstruct Int from the given IntLiteral value.\n\nArgs:\n\n‚Äãvalue (IntLiteral): The init value.\n\nReturns:\n\nThe constructed Int object.\n\n__bool__\n\n__bool__(self: Self) -> Bool\n\nConvert this Int to Bool.\n\nReturns:\n\nFalse Bool value if the value is equal to 0 and True otherwise.\n\n__neg__\n\n__neg__(self: Self) -> Self\n\nReturn -self.\n\nReturns:\n\nThe -self value.\n\n__pos__\n\n__pos__(self: Self) -> Self\n\nReturn +self.\n\nReturns:\n\nThe +self value.\n\n__invert__\n\n__invert__(self: Self) -> Self\n\nReturn ~self.\n\nReturns:\n\nThe ~self value.\n\n__lt__\n\n__lt__(self: Self, rhs: Self) -> Bool\n\nCompare this Int to the RHS using LT comparison.\n\nArgs:\n\n‚Äãrhs (Self): The other Int to compare against.\n\nReturns:\n\nTrue if this Int is less-than the RHS Int and False otherwise.\n\n__le__\n\n__le__(self: Self, rhs: Self) -> Bool\n\nCompare this Int to the RHS using LE comparison.\n\nArgs:\n\n‚Äãrhs (Self): The other Int to compare against.\n\nReturns:\n\nTrue if this Int is less-or-equal than the RHS Int and False otherwise.\n\n__eq__\n\n__eq__(self: Self, rhs: Self) -> Bool\n\nCompare this Int to the RHS using EQ comparison.\n\nArgs:\n\n‚Äãrhs (Self): The other Int to compare against.\n\nReturns:\n\nTrue if this Int is equal to the RHS Int and False otherwise.\n\n__ne__\n\n__ne__(self: Self, rhs: Self) -> Bool\n\nCompare this Int to the RHS using NE comparison.\n\nArgs:\n\n‚Äãrhs (Self): The other Int to compare against.\n\nReturns:\n\nTrue if this Int is non-equal to the RHS Int and False otherwise.\n\n__gt__\n\n__gt__(self: Self, rhs: Self) -> Bool\n\nCompare this Int to the RHS using GT comparison.\n\nArgs:\n\n‚Äãrhs (Self): The other Int to compare against.\n\nReturns:\n\nTrue if this Int is greater-than the RHS Int and False otherwise.\n\n__ge__\n\n__ge__(self: Self, rhs: Self) -> Bool\n\nCompare this Int to the RHS using GE comparison.\n\nArgs:\n\n‚Äãrhs (Self): The other Int to compare against.\n\nReturns:\n\nTrue if this Int is greater-or-equal than the RHS Int and False otherwise.\n\n__add__\n\n__add__(self: Self, rhs: Self) -> Self\n\nReturn self + rhs.\n\nArgs:\n\n‚Äãrhs (Self): The value to add.\n\nReturns:\n\nself + rhs value.\n\n__sub__\n\n__sub__(self: Self, rhs: Self) -> Self\n\nReturn self - rhs.\n\nArgs:\n\n‚Äãrhs (Self): The value to subtract.\n\nReturns:\n\nself - rhs value.\n\n__mul__\n\n__mul__(self: Self, rhs: Self) -> Self\n\nReturn self * rhs.\n\nArgs:\n\n‚Äãrhs (Self): The value to multiply with.\n\nReturns:\n\nself * rhs value.\n\n__truediv__\n\n__truediv__(self: Self, rhs: Self) -> SIMD[f64, 1]\n\nReturn the floating point division of self and rhs.\n\nArgs:\n\n‚Äãrhs (Self): The value to divide on.\n\nReturns:\n\nfloat(self)/float(rhs) value.\n\n__floordiv__\n\n__floordiv__(self: Self, rhs: Self) -> Self\n\nReturn the division of self and rhs rounded down to the nearest integer.\n\nArgs:\n\n‚Äãrhs (Self): The value to divide on.\n\nReturns:\n\nfloor(self/rhs) value.\n\n__mod__\n\n__mod__(self: Self, rhs: Self) -> Self\n\nReturn the remainder of self divided by rhs.\n\nArgs:\n\n‚Äãrhs (Self): The value to divide on.\n\nReturns:\n\nThe remainder of dividing self by rhs.\n\n__pow__\n\n__pow__(self: Self, rhs: Self) -> Self\n\nReturn pow(self, rhs).\n\nComputes the power of an integer using the Russian Peasant Method.\n\nArgs:\n\n‚Äãrhs (Self): The RHS value.\n\nReturns:\n\nThe value of pow(self, rhs).\n\n__lshift__\n\n__lshift__(self: Self, rhs: Self) -> Self\n\nReturn self << rhs.\n\nArgs:\n\n‚Äãrhs (Self): The value to shift with.\n\nReturns:\n\nself << rhs.\n\n__rshift__\n\n__rshift__(self: Self, rhs: Self) -> Self\n\nReturn self >> rhs.\n\nArgs:\n\n‚Äãrhs (Self): The value to shift with.\n\nReturns:\n\nself >> rhs.\n\n__and__\n\n__and__(self: Self, rhs: Self) -> Self\n\nReturn self & rhs.\n\nArgs:\n\n‚Äãrhs (Self): The RHS value.\n\nReturns:\n\nself & rhs.\n\n__or__\n\n__or__(self: Self, rhs: Self) -> Self\n\nReturn self | rhs.\n\nArgs:\n\n‚Äãrhs (Self): The RHS value.\n\nReturns:\n\nself | rhs.\n\n__xor__\n\n__xor__(self: Self, rhs: Self) -> Self\n\nReturn self ^ rhs.\n\nArgs:\n\n‚Äãrhs (Self): The RHS value.\n\nReturns:\n\nself ^ rhs.\n\n__radd__\n\n__radd__(self: Self, value: Self) -> Self\n\nReturn value + self.\n\nArgs:\n\n‚Äãvalue (Self): The other value.\n\nReturns:\n\nvalue + self.\n\n__rsub__\n\n__rsub__(self: Self, value: Self) -> Self\n\nReturn value - self.\n\nArgs:\n\n‚Äãvalue (Self): The other value.\n\nReturns:\n\nvalue - self.\n\n__rmul__\n\n__rmul__(self: Self, value: Self) -> Self\n\nReturn value * self.\n\nArgs:\n\n‚Äãvalue (Self): The other value.\n\nReturns:\n\nvalue * self.\n\n__rfloordiv__\n\n__rfloordiv__(self: Self, value: Self) -> Self\n\nReturn value // self.\n\nArgs:\n\n‚Äãvalue (Self): The other value.\n\nReturns:\n\nvalue // self.\n\n__rmod__\n\n__rmod__(self: Self, value: Self) -> Self\n\nReturn value % self.\n\nArgs:\n\n‚Äãvalue (Self): The other value.\n\nReturns:\n\nvalue % self.\n\n__rpow__\n\n__rpow__(self: Self, value: Self) -> Self\n\nReturn pow(value,self).\n\nArgs:\n\n‚Äãvalue (Self): The other value.\n\nReturns:\n\npow(value,self).\n\n__rlshift__\n\n__rlshift__(self: Self, value: Self) -> Self\n\nReturn value << self.\n\nArgs:\n\n‚Äãvalue (Self): The other value.\n\nReturns:\n\nvalue << self.\n\n__rrshift__\n\n__rrshift__(self: Self, value: Self) -> Self\n\nReturn value >> self.\n\nArgs:\n\n‚Äãvalue (Self): The other value.\n\nReturns:\n\nvalue >> self.\n\n__rand__\n\n__rand__(self: Self, value: Self) -> Self\n\nReturn value & self.\n\nArgs:\n\n‚Äãvalue (Self): The other value.\n\nReturns:\n\nvalue & self.\n\n__ror__\n\n__ror__(self: Self, value: Self) -> Self\n\nReturn value | self.\n\nArgs:\n\n‚Äãvalue (Self): The other value.\n\nReturns:\n\nvalue | self.\n\n__rxor__\n\n__rxor__(self: Self, value: Self) -> Self\n\nReturn value ^ self.\n\nArgs:\n\n‚Äãvalue (Self): The other value.\n\nReturns:\n\nvalue ^ self.\n\n__iadd__\n\n__iadd__(inout self: Self, rhs: Self)\n\nCompute self + rhs and save the result in self.\n\nArgs:\n\n‚Äãrhs (Self): The RHS value.\n__isub__\n\n__isub__(inout self: Self, rhs: Self)\n\nCompute self - rhs and save the result in self.\n\nArgs:\n\n‚Äãrhs (Self): The RHS value.\n__imul__\n\n__imul__(inout self: Self, rhs: Self)\n\nCompute self*rhs and save the result in self.\n\nArgs:\n\n‚Äãrhs (Self): The RHS value.\n__itruediv__\n\n__itruediv__(inout self: Self, rhs: Self)\n\nCompute self / rhs, convert to int, and save the result in self.\n\nSince floor(self / rhs) is equivalent to self // rhs, this yields the same as __ifloordiv__.\n\nArgs:\n\n‚Äãrhs (Self): The RHS value.\n__ifloordiv__\n\n__ifloordiv__(inout self: Self, rhs: Self)\n\nCompute self // rhs and save the result in self.\n\nArgs:\n\n‚Äãrhs (Self): The RHS value.\n__imod__\n\n__imod__(inout self: Self, rhs: Self)\n\nCompute self % rhs and save the result in self.\n\nArgs:\n\n‚Äãrhs (Self): The RHS value.\n__ipow__\n\n__ipow__(inout self: Self, rhs: Self)\n\nCompute pow(self, rhs) and save the result in self.\n\nArgs:\n\n‚Äãrhs (Self): The RHS value.\n__ilshift__\n\n__ilshift__(inout self: Self, rhs: Self)\n\nCompute self << rhs and save the result in self.\n\nArgs:\n\n‚Äãrhs (Self): The RHS value.\n__irshift__\n\n__irshift__(inout self: Self, rhs: Self)\n\nCompute self >> rhs and save the result in self.\n\nArgs:\n\n‚Äãrhs (Self): The RHS value.\n__iand__\n\n__iand__(inout self: Self, rhs: Self)\n\nCompute self & rhs and save the result in self.\n\nArgs:\n\n‚Äãrhs (Self): The RHS value.\n__ixor__\n\n__ixor__(inout self: Self, rhs: Self)\n\nCompute self ^ rhs and save the result in self.\n\nArgs:\n\n‚Äãrhs (Self): The RHS value.\n__ior__\n\n__ior__(inout self: Self, rhs: Self)\n\nCompute self|rhs and save the result in self.\n\nArgs:\n\n‚Äãrhs (Self): The RHS value.\n__int__\n\n__int__(self: Self) -> Self\n\nGets the integral value (this is an identity function for Int).\n\nReturns:\n\nThe value as an integer.\n\n__mlir_index__\n\n__mlir_index__(self: Self) -> index\n\nConvert to index.\n\nReturns:\n\nThe corresponding __mlir_type.index value.\n\n__index__\n\n__index__(self: Self) -> Self\n\nReturn self converted to an integer, if self is suitable for use as an index into a list.\n\nFor Int type this is simply the value.\n\nReturns:\n\nThe corresponding Int value.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - float_literal",
    "url": "https://docs.modular.com/mojo/stdlib/builtin/float_literal.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\nbool\nbuiltin_list\nbuiltin_slice\nconstrained\ncoroutine\ndebug_assert\ndtype\nerror\nfile\nfloat_literal\nint\nio\nlen\nobject\nrange\nrebind\nsimd\nstring\nstring_literal\nstringref\ntuple\ntype_aliases\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nFloatLiteral\n__init__\n__bool__\n__neg__\n__lt__\n__le__\n__eq__\n__ne__\n__gt__\n__ge__\n__add__\n__sub__\n__mul__\n__truediv__\n__floordiv__\n__mod__\n__pow__\n__radd__\n__rsub__\n__rmul__\n__rtruediv__\n__rfloordiv__\n__rmod__\n__rpow__\n__iadd__\n__isub__\n__imul__\n__itruediv__\n__ifloordiv__\n__imod__\n__ipow__\nto_int\n__int__\nfloat_literal\n\nModule\n\nImplements the FloatLiteral class.\n\nThese are Mojo built-ins, so you don‚Äôt need to import them.\n\nFloatLiteral\n\nMojo floating point literal type.\n\nAliases:\n\n‚Äãfp_type = scalar<f64>\n\nFields:\n\n‚Äãvalue (scalar<f64>): The underlying storage for the floating point value.\n\nFunctions:\n\n__init__\n\n__init__(value: Self) -> Self\n\nForwarding constructor.\n\nArgs:\n\n‚Äãvalue (Self): The double value.\n\nReturns:\n\nThe value.\n\n__init__(value: f64) -> Self\n\nCreate a double value from a builtin MLIR f64 value.\n\nArgs:\n\n‚Äãvalue (f64): The underlying MLIR value.\n\nReturns:\n\nA double value.\n\n__init__(value: Int) -> Self\n\nConvert an integer to a double value.\n\nArgs:\n\n‚Äãvalue (Int): The integer value.\n\nReturns:\n\nThe integer value as a double.\n\n__init__(value: IntLiteral) -> Self\n\nConvert an IntLiteral to a double value.\n\nArgs:\n\n‚Äãvalue (IntLiteral): The IntLiteral value.\n\nReturns:\n\nThe integer value as a double.\n\n__init__(value: scalar<f64>, /) -> Self\n\n__bool__\n\n__bool__(self: Self) -> Bool\n\nA double value is true if it is non-zero.\n\nReturns:\n\nTrue if non-zero.\n\n__neg__\n\n__neg__(self: Self) -> Self\n\nReturn the negation of the double value.\n\nReturns:\n\nThe negated double value.\n\n__lt__\n\n__lt__(self: Self, rhs: Self) -> Bool\n\nLess than comparison.\n\nArgs:\n\n‚Äãrhs (Self): The value to compare.\n\nReturns:\n\nTrue if this value is less than rhs.\n\n__le__\n\n__le__(self: Self, rhs: Self) -> Bool\n\nLess than or equal to comparison.\n\nArgs:\n\n‚Äãrhs (Self): The value to compare.\n\nReturns:\n\nTrue if this value is less than or equal to rhs.\n\n__eq__\n\n__eq__(self: Self, rhs: Self) -> Bool\n\nCompare for equality.\n\nArgs:\n\n‚Äãrhs (Self): The value to compare.\n\nReturns:\n\nTrue if they are equal.\n\n__ne__\n\n__ne__(self: Self, rhs: Self) -> Bool\n\nCompare for inequality.\n\nArgs:\n\n‚Äãrhs (Self): The value to compare.\n\nReturns:\n\nTrue if they are not equal.\n\n__gt__\n\n__gt__(self: Self, rhs: Self) -> Bool\n\nGreater than comparison.\n\nArgs:\n\n‚Äãrhs (Self): The value to compare.\n\nReturns:\n\nTrue if this value is greater than rhs.\n\n__ge__\n\n__ge__(self: Self, rhs: Self) -> Bool\n\nGreater than or equal to comparison.\n\nArgs:\n\n‚Äãrhs (Self): The value to compare.\n\nReturns:\n\nTrue if this value is greater than or equal to rhs.\n\n__add__\n\n__add__(self: Self, rhs: Self) -> Self\n\nAdd two doubles.\n\nArgs:\n\n‚Äãrhs (Self): The value to add.\n\nReturns:\n\nThe sum of the two values.\n\n__sub__\n\n__sub__(self: Self, rhs: Self) -> Self\n\nSubtract two doubles.\n\nArgs:\n\n‚Äãrhs (Self): The value to subtract.\n\nReturns:\n\nThe difference of the two values.\n\n__mul__\n\n__mul__(self: Self, rhs: Self) -> Self\n\nMultiply two doubles.\n\nArgs:\n\n‚Äãrhs (Self): The value to multiply.\n\nReturns:\n\nThe product of the two values.\n\n__truediv__\n\n__truediv__(self: Self, rhs: Self) -> Self\n\nDivide two doubles.\n\nArgs:\n\n‚Äãrhs (Self): The value to divide.\n\nReturns:\n\nThe quotient of the two values.\n\n__floordiv__\n\n__floordiv__(self: Self, rhs: Self) -> Self\n\nDivide two doubles and round towards negative infinity.\n\nArgs:\n\n‚Äãrhs (Self): The value to divide.\n\nReturns:\n\nThe quotient of the two values rounded towards negative infinity.\n\n__mod__\n\n__mod__(self: Self, rhs: Self) -> Self\n\nCompute the remainder of dividing by a value.\n\nArgs:\n\n‚Äãrhs (Self): The divisor.\n\nReturns:\n\nThe remainder of the division operation.\n\n__pow__\n\n__pow__(self: Self, rhs: Self) -> Self\n\nCompute the power.\n\nArgs:\n\n‚Äãrhs (Self): The exponent.\n\nReturns:\n\nThe current value raised to the exponent.\n\n__radd__\n\n__radd__(self: Self, rhs: Self) -> Self\n\nReversed addition operator.\n\nArgs:\n\n‚Äãrhs (Self): The value to add.\n\nReturns:\n\nThe sum of this and the given value.\n\n__rsub__\n\n__rsub__(self: Self, rhs: Self) -> Self\n\nReversed subtraction operator.\n\nArgs:\n\n‚Äãrhs (Self): The value to subtract from.\n\nReturns:\n\nThe result of subtracting this from the given value.\n\n__rmul__\n\n__rmul__(self: Self, rhs: Self) -> Self\n\nReversed multiplication operator.\n\nArgs:\n\n‚Äãrhs (Self): The value to multiply.\n\nReturns:\n\nThe product of the given number and this.\n\n__rtruediv__\n\n__rtruediv__(self: Self, rhs: Self) -> Self\n\nReversed division.\n\nArgs:\n\n‚Äãrhs (Self): The value to be divided by this.\n\nReturns:\n\nThe result of dividing the given value by this.\n\n__rfloordiv__\n\n__rfloordiv__(self: Self, rhs: Self) -> Self\n\nReversed floor division.\n\nArgs:\n\n‚Äãrhs (Self): The value to be floor-divided by this.\n\nReturns:\n\nThe result of dividing the given value by this, modulo any remainder.\n\n__rmod__\n\n__rmod__(self: Self, rhs: Self) -> Self\n\nReversed remainder.\n\nArgs:\n\n‚Äãrhs (Self): The divisor.\n\nReturns:\n\nThe remainder after dividing the given value by this.\n\n__rpow__\n\n__rpow__(self: Self, rhs: Self) -> Self\n\nReversed power.\n\nArgs:\n\n‚Äãrhs (Self): The number to be raised to the power of this.\n\nReturns:\n\nThe result of raising the given number by this value.\n\n__iadd__\n\n__iadd__(inout self: Self, rhs: Self)\n\nIn-place addition operator.\n\nArgs:\n\n‚Äãrhs (Self): The value to add.\n__isub__\n\n__isub__(inout self: Self, rhs: Self)\n\nIn-place subtraction operator.\n\nArgs:\n\n‚Äãrhs (Self): The value to subtract.\n__imul__\n\n__imul__(inout self: Self, rhs: Self)\n\nIn-place multiplication operator.\n\nArgs:\n\n‚Äãrhs (Self): The value to multiply.\n__itruediv__\n\n__itruediv__(inout self: Self, rhs: Self)\n\nIn-place division.\n\nArgs:\n\n‚Äãrhs (Self): The value to divide.\n__ifloordiv__\n\n__ifloordiv__(inout self: Self, rhs: Self)\n\nIn-place floor division.\n\nArgs:\n\n‚Äãrhs (Self): The value to divide.\n__imod__\n\n__imod__(inout self: Self, rhs: Self)\n\nIn-place remainder.\n\nArgs:\n\n‚Äãrhs (Self): The divisor.\n__ipow__\n\n__ipow__(inout self: Self, rhs: Self)\n\nIn-place power.\n\nArgs:\n\n‚Äãrhs (Self): The exponent.\nto_int\n\nto_int(self: Self) -> Int\n\nCasts to the floating point value to an Int. If there is a fractional component, then the value is truncated towards zero.\n\nReturns:\n\nThe value as an integer.\n\n__int__\n\n__int__(self: Self) -> Int\n\nCasts to the floating point value to an Int. If there is a fractional component, then the value is truncated towards zero.\n\nReturns:\n\nThe value as an integer.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - file",
    "url": "https://docs.modular.com/mojo/stdlib/builtin/file.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\nbool\nbuiltin_list\nbuiltin_slice\nconstrained\ncoroutine\ndebug_assert\ndtype\nerror\nfile\nfloat_literal\nint\nio\nlen\nobject\nrange\nrebind\nsimd\nstring\nstring_literal\nstringref\ntuple\ntype_aliases\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nFileHandle\n__init__\n__moveinit__\n__takeinit__\n__del__\nclose\nread\nwrite\n__enter__\nopen\nfile\n\nModule\n\nImplements the file based methods.\n\nThese are Mojo built-ins, so you don‚Äôt need to import them.\n\nFor example, here‚Äôs how to read a file:\n\nvar  f = open(\"my_file.txt\", \"r\")\nprint(f.read())\nf.close()\n\nOr use a with statement to close the file automatically:\n\nwith open(\"my_file.txt\", \"r\") as f:\n  print(f.read())\nFileHandle\n\nFile handle to an opened file.\n\nFields:\n\n‚Äãhandle (DTypePointer[invalid]): The underlying pointer to the file handle.\n\nFunctions:\n\n__init__\n\n__init__(inout self: Self)\n\nDefault constructor.\n\n__init__(inout self: Self, path: StringLiteral, mode: StringLiteral)\n\nConstruct the FileHandle using the file path and mode.\n\nArgs:\n\n‚Äãpath (StringLiteral): The file path.\n‚Äãmode (StringLiteral): The mode to open the file in (the mode can be ‚Äúr‚Äù or ‚Äúw‚Äù).\n\n__init__(inout self: Self, path: String, mode: String)\n\nConstruct the FileHandle using the file path and mode.\n\nArgs:\n\n‚Äãpath (String): The file path.\n‚Äãmode (String): The mode to open the file in (the mode can be ‚Äúr‚Äù or ‚Äúw‚Äù).\n\n__init__(inout self: Self, path: StringRef, mode: StringRef)\n\nConstruct the FileHandle using the file path and string.\n\nArgs:\n\n‚Äãpath (StringRef): The file path.\n‚Äãmode (StringRef): The mode to open the file in (the mode can be ‚Äúr‚Äù or ‚Äúw‚Äù).\n__moveinit__\n\n__moveinit__(inout self: Self, owned existing: Self)\n\nMoves constructor for the file handle.\n\nArgs:\n\n‚Äãexisting (Self): The existing file handle.\n__takeinit__\n\n__takeinit__(inout self: Self, inout existing: Self)\n\nMoves constructor for the file handle.\n\nArgs:\n\n‚Äãexisting (Self): The existing file handle.\n__del__\n\n__del__(owned self: Self)\n\nCloses the file handle.\n\nclose\n\nclose(inout self: Self)\n\nCloses the file handle.\n\nread\n\nread(self: Self) -> String\n\nReads the data from the file.\n\nReturns:\n\nThe contents of the file.\n\nwrite\n\nwrite(self: Self, data: StringLiteral)\n\nWrite the data to the file.\n\nArgs:\n\n‚Äãdata (StringLiteral): The data to write to the file.\n\nwrite(self: Self, data: String)\n\nWrite the data to the file.\n\nArgs:\n\n‚Äãdata (String): The data to write to the file.\n\nwrite(self: Self, data: StringRef)\n\nWrite the data to the file.\n\nArgs:\n\n‚Äãdata (StringRef): The data to write to the file.\n__enter__\n\n__enter__(owned self: Self) -> Self\n\nThe function to call when entering the context.\n\nopen\n\nopen(path: StringLiteral, mode: StringLiteral) -> FileHandle\n\nOpens the file specified by path using the mode provided, returning a FileHandle.\n\nArgs:\n\n‚Äãpath (StringLiteral): The path to the file to open.\n‚Äãmode (StringLiteral): The mode to open the file in (the mode can be ‚Äúr‚Äù or ‚Äúw‚Äù).\n\nReturns:\n\nA file handle.\n\nopen(path: StringRef, mode: StringRef) -> FileHandle\n\nOpens the file specified by path using the mode provided, returning a FileHandle.\n\nArgs:\n\n‚Äãpath (StringRef): The path to the file to open.\n‚Äãmode (StringRef): The mode to open the file in (the mode can be ‚Äúr‚Äù or ‚Äúw‚Äù).\n\nReturns:\n\nA file handle.\n\nopen(path: String, mode: String) -> FileHandle\n\nOpens the file specified by path using the mode provided, returning a FileHandle.\n\nArgs:\n\n‚Äãpath (String): The path to the file to open.\n‚Äãmode (String): The mode to open the file in.\n\nReturns:\n\nA file handle.\n\nopen(path: Path, mode: String) -> FileHandle\n\nOpens the file specified by path using the mode provided, returning a FileHandle.\n\nArgs:\n\n‚Äãpath (Path): The path to the file to open.\n‚Äãmode (String): The mode to open the file in (the mode can be ‚Äúr‚Äù or ‚Äúw‚Äù).\n\nReturns:\n\nA file handle.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - dtype",
    "url": "https://docs.modular.com/mojo/stdlib/builtin/dtype.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\nbool\nbuiltin_list\nbuiltin_slice\nconstrained\ncoroutine\ndebug_assert\ndtype\nerror\nfile\nfloat_literal\nint\nio\nlen\nobject\nrange\nrebind\nsimd\nstring\nstring_literal\nstringref\ntuple\ntype_aliases\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nDType\n__init__\n__eq__\n__ne__\n__str__\nget_value\nisa\nis_bool\nis_uint8\nis_int8\nis_uint16\nis_int16\nis_uint32\nis_int32\nis_uint64\nis_int64\nis_bfloat16\nis_float16\nis_float32\nis_float64\nis_index\nis_address\nis_unsigned\nis_signed\nis_integral\nis_floating_point\nsizeof\nbitwidth\ndispatch_integral\ndispatch_floating\ndispatch_arithmetic\ndtype\n\nModule\n\nImplements the DType class.\n\nThese are Mojo built-ins, so you don‚Äôt need to import them.\n\nDType\n\nRepresents DType and provides methods for working with it.\n\nAliases:\n\n‚Äãtype = dtype\n‚Äãinvalid = invalid: Represents an invalid or unknown data type.\n‚Äãbool = bool: Represents a boolean data type.\n‚Äãint8 = si8: Represents a signed integer type whose bitwidth is 8.\n‚Äãuint8 = ui8: Represents an unsigned integer type whose bitwidth is 8.\n‚Äãint16 = si16: Represents a signed integer type whose bitwidth is 16.\n‚Äãuint16 = ui16: Represents an unsigned integer type whose bitwidth is 16.\n‚Äãint32 = si32: Represents a signed integer type whose bitwidth is 32.\n‚Äãuint32 = ui32: Represents an unsigned integer type whose bitwidth is 32.\n‚Äãint64 = si64: Represents a signed integer type whose bitwidth is 64.\n‚Äãuint64 = ui64: Represents an unsigned integer type whose bitwidth is 64.\n‚Äãbfloat16 = bf16: Represents a brain floating point value whose bitwidth is 16.\n‚Äãfloat16 = f16: Represents an IEEE754-2008 binary16 floating point value.\n‚Äãfloat32 = f32: Represents an IEEE754-2008 binary32 floating point value.\n‚Äãfloat64 = f64: Represents an IEEE754-2008 binary64 floating point value.\n‚Äãindex = index: Represents an integral type whose bitwidth is the maximum integral value on the system.\n‚Äãaddress = address: Represents a pointer type whose bitwidth is the same as the bitwidth of the hardware‚Äôs pointer type (32-bit on 32-bit machines and 64-bit on 64-bit machines).\n\nFields:\n\n‚Äãvalue (dtype): The underlying storage for the DType value.\n\nFunctions:\n\n__init__\n\n__init__(value: dtype, /) -> Self\n\n__eq__\n\n__eq__(self: Self, rhs: Self) -> Bool\n\nCompares one DType to another for equality.\n\nArgs:\n\n‚Äãrhs (Self): The DType to compare against.\n\nReturns:\n\nTrue if the DTypes are the same and False otherwise.\n\n__ne__\n\n__ne__(self: Self, rhs: Self) -> Bool\n\nCompares one DType to another for non-equality.\n\nArgs:\n\n‚Äãrhs (Self): The DType to compare against.\n\nReturns:\n\nFalse if the DTypes are the same and True otherwise.\n\n__str__\n\n__str__(self: Self) -> StringLiteral\n\nGets the name of the DType.\n\nReturns:\n\nThe name of the dtype.\n\nget_value\n\nget_value(self: Self) -> dtype\n\nGets the associated internal kgen.dtype value.\n\nReturns:\n\nThe kgen.dtype value.\n\nisa\n\nisa[other: Self](self: Self) -> Bool\n\nChecks if this DType matches the other one, specified as a parameter.\n\nParameters:\n\n‚Äãother (Self): The DType to compare against.\n\nReturns:\n\nTrue if the DTypes are the same and False otherwise.\n\nis_bool\n\nis_bool(self: Self) -> Bool\n\nChecks if this DType is Bool.\n\nReturns:\n\nTrue if the DType is Bool and False otherwise.\n\nis_uint8\n\nis_uint8(self: Self) -> Bool\n\nChecks if this DType is UInt8.\n\nReturns:\n\nTrue if the DType is UInt8 and False otherwise.\n\nis_int8\n\nis_int8(self: Self) -> Bool\n\nChecks if this DType is Int8.\n\nReturns:\n\nTrue if the DType is Int8 and False otherwise.\n\nis_uint16\n\nis_uint16(self: Self) -> Bool\n\nChecks if this DType is UInt16.\n\nReturns:\n\nTrue if the DType is UInt16 and False otherwise.\n\nis_int16\n\nis_int16(self: Self) -> Bool\n\nChecks if this DType is Int16.\n\nReturns:\n\nTrue if the DType is Int16 and False otherwise.\n\nis_uint32\n\nis_uint32(self: Self) -> Bool\n\nChecks if this DType is UInt32.\n\nReturns:\n\nTrue if the DType is UInt32 and False otherwise.\n\nis_int32\n\nis_int32(self: Self) -> Bool\n\nChecks if this DType is Int32.\n\nReturns:\n\nTrue if the DType is Int32 and False otherwise.\n\nis_uint64\n\nis_uint64(self: Self) -> Bool\n\nChecks if this DType is UInt64.\n\nReturns:\n\nTrue if the DType is UInt64 and False otherwise.\n\nis_int64\n\nis_int64(self: Self) -> Bool\n\nChecks if this DType is Int64.\n\nReturns:\n\nTrue if the DType is Int64 and False otherwise.\n\nis_bfloat16\n\nis_bfloat16(self: Self) -> Bool\n\nChecks if this DType is BFloat16.\n\nReturns:\n\nTrue if the DType is BFloat16 and False otherwise.\n\nis_float16\n\nis_float16(self: Self) -> Bool\n\nChecks if this DType is Float16.\n\nReturns:\n\nTrue if the DType is Float16 and False otherwise.\n\nis_float32\n\nis_float32(self: Self) -> Bool\n\nChecks if this DType is Float32.\n\nReturns:\n\nTrue if the DType is Float32 and False otherwise.\n\nis_float64\n\nis_float64(self: Self) -> Bool\n\nChecks if this DType is Float64.\n\nReturns:\n\nTrue if the DType is Float64 and False otherwise.\n\nis_index\n\nis_index(self: Self) -> Bool\n\nChecks if this DType is Index.\n\nReturns:\n\nTrue if the DType is Index and False otherwise.\n\nis_address\n\nis_address(self: Self) -> Bool\n\nChecks if this DType is Address.\n\nReturns:\n\nTrue if the DType is Address and False otherwise.\n\nis_unsigned\n\nis_unsigned(self: Self) -> Bool\n\nReturns True if the type parameter is unsigned and False otherwise.\n\nReturns:\n\nReturns True if the input type parameter is unsigned.\n\nis_signed\n\nis_signed(self: Self) -> Bool\n\nReturns True if the type parameter is signed and False otherwise.\n\nReturns:\n\nReturns True if the input type parameter is signed.\n\nis_integral\n\nis_integral(self: Self) -> Bool\n\nReturns True if the type parameter is an integer and False otherwise.\n\nReturns:\n\nReturns True if the input type parameter is an integer.\n\nis_floating_point\n\nis_floating_point(self: Self) -> Bool\n\nReturns True if the type parameter is a floating-point and False otherwise.\n\nReturns:\n\nReturns True if the input type parameter is a floating-point.\n\nsizeof\n\nsizeof(self: Self) -> Int\n\nReturns the size in bytes of the current DType.\n\nReturns:\n\nReturns the size in bytes of the current DType and -1 if the size is unknown.\n\nbitwidth\n\nbitwidth(self: Self) -> Int\n\nReturns the size in bits of the current DType.\n\nReturns:\n\nReturns the size in bits of the current DType and -1 if the size is unknown.\n\ndispatch_integral\n\ndispatch_integral[func: fn[DType]() capturing -> None](self: Self)\n\nDispatches an integral function corresponding to the current DType.\n\nConstraints:\n\nDType must be integral.\n\nParameters:\n\n‚Äãfunc (fn[DType]() capturing -> None): A parametrized on dtype function to dispatch.\n\ndispatch_integral[func: fn[DType]() capturing -> None](self: Self, out_chain: OutputChainPtr)\n\nDispatches an integral function corresponding to the current DType.\n\nConstraints:\n\nDType must be integral.\n\nParameters:\n\n‚Äãfunc (fn[DType]() capturing -> None): A parametrized on dtype function to dispatch.\n\nArgs:\n\n‚Äãout_chain (OutputChainPtr): The output chain used to report errors.\ndispatch_floating\n\ndispatch_floating[func: fn[DType]() capturing -> None](self: Self)\n\nDispatches a floating-point function corresponding to the current DType.\n\nConstraints:\n\nDType must be floating-point.\n\nParameters:\n\n‚Äãfunc (fn[DType]() capturing -> None): A parametrized on dtype function to dispatch.\n\ndispatch_floating[func: fn[DType]() capturing -> None](self: Self, out_chain: OutputChainPtr)\n\nDispatches a floating-point function corresponding to the current DType.\n\nConstraints:\n\nDType must be floating-point or integral.\n\nParameters:\n\n‚Äãfunc (fn[DType]() capturing -> None): A parametrized on dtype function to dispatch.\n\nArgs:\n\n‚Äãout_chain (OutputChainPtr): The output chain used to report errors.\ndispatch_arithmetic\n\ndispatch_arithmetic[func: fn[DType]() capturing -> None](self: Self)\n\nDispatches a function corresponding to the current DType.\n\nParameters:\n\n‚Äãfunc (fn[DType]() capturing -> None): A parametrized on dtype function to dispatch.\n\ndispatch_arithmetic[func: fn[DType]() capturing -> None](self: Self, out_chain: OutputChainPtr)\n\nDispatches a function corresponding to the current DType.\n\nParameters:\n\n‚Äãfunc (fn[DType]() capturing -> None): A parametrized on dtype function to dispatch.\n\nArgs:\n\n‚Äãout_chain (OutputChainPtr): The output chain used to report errors.\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - error",
    "url": "https://docs.modular.com/mojo/stdlib/builtin/error.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\nbool\nbuiltin_list\nbuiltin_slice\nconstrained\ncoroutine\ndebug_assert\ndtype\nerror\nfile\nfloat_literal\nint\nio\nlen\nobject\nrange\nrebind\nsimd\nstring\nstring_literal\nstringref\ntuple\ntype_aliases\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nError\n__init__\n__copyinit__\n__del__\n__str__\n__repr__\nerror\n\nModule\n\nImplements the Error class.\n\nThese are Mojo built-ins, so you don‚Äôt need to import them.\n\nError\n\nThis type represents an Error.\n\nFields:\n\n‚Äãdata (DTypePointer[si8]): A pointer to the beginning of the string data being referenced.\n‚Äãloaded_length (Int): The length of the string being referenced. Error instances conditionally own their error message. To reduce the size of the error instance we use the sign bit of the length field to store the ownership value. When loaded_length is negative it indicates ownership and a free is executed in the destructor.\n\nFunctions:\n\n__init__\n\n__init__() -> Self\n\nDefault constructor.\n\nReturns:\n\nThe constructed Error object.\n\n__init__(value: StringLiteral) -> Self\n\nConstruct an Error object with a given string literal.\n\nArgs:\n\n‚Äãvalue (StringLiteral): The error message.\n\nReturns:\n\nThe constructed Error object.\n\n__init__(src: String) -> Self\n\nConstruct an Error object with a given string.\n\nArgs:\n\n‚Äãsrc (String): The error message.\n\nReturns:\n\nThe constructed Error object.\n\n__init__(src: StringRef) -> Self\n\nConstruct an Error object with a given string ref.\n\nArgs:\n\n‚Äãsrc (StringRef): The error message.\n\nReturns:\n\nThe constructed Error object.\n\n__copyinit__\n\n__copyinit__(existing: Self) -> Self\n\nCreates a deep copy of an existing error.\n\nReturns:\n\nThe copy of the original error.\n\n__del__\n\n__del__(owned self: Self)\n\nReleases memory if allocated.\n\n__str__\n\n__str__(self: Self) -> String\n\nConverts the Error to string representation.\n\nReturns:\n\nA String of the error message.\n\n__repr__\n\n__repr__(self: Self) -> String\n\nConverts the Error to printable representation.\n\nReturns:\n\nA printable representation of the error message.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - debug_assert",
    "url": "https://docs.modular.com/mojo/stdlib/builtin/debug_assert.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\nbool\nbuiltin_list\nbuiltin_slice\nconstrained\ncoroutine\ndebug_assert\ndtype\nerror\nfile\nfloat_literal\nint\nio\nlen\nobject\nrange\nrebind\nsimd\nstring\nstring_literal\nstringref\ntuple\ntype_aliases\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\ndebug_assert\ndebug_assert\n\nModule\n\nImplements a debug assert.\n\nThese are Mojo built-ins, so you don‚Äôt need to import them.\n\ndebug_assert\n\ndebug_assert(cond: Bool, msg: StringLiteral)\n\nAsserts that the condition is true.\n\nThe debug_assert is similar to assert in C++. It is a no-op in release builds.\n\nArgs:\n\n‚Äãcond (Bool): The bool value to assert.\n‚Äãmsg (StringLiteral): The message to display on failure.\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - coroutine",
    "url": "https://docs.modular.com/mojo/stdlib/builtin/coroutine.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\nbool\nbuiltin_list\nbuiltin_slice\nconstrained\ncoroutine\ndebug_assert\ndtype\nerror\nfile\nfloat_literal\nint\nio\nlen\nobject\nrange\nrebind\nsimd\nstring\nstring_literal\nstringref\ntuple\ntype_aliases\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nCoroutineContext\nCoroutine\nRaisingCoroutine\ncoroutine\n\nModule\n\nImplements classes and methods for coroutines.\n\nThese are Mojo built-ins, so you don‚Äôt need to import them.\n\nCoroutineContext\n\nRepresents a callback closure (fn_ptr + captures).\n\nCoroutine\n\nRepresents a coroutine.\n\nCoroutines can pause execution saving the state of the program (including values of local variables and the location of the next instruction to be executed). When the coroutine is resumed, execution continues from where it left off, with the saved state restored.\n\nParameters:\n\n‚Äãtype (AnyType): Type of value returned upon completion of the coroutine.\n\nFunctions:\n\n__init__\n\n__init__(handle: !pop.coroutine<() -> !kgen.paramref<*\"type\">>) -> Self\n\nConstruct a coroutine object from a handle.\n\nArgs:\n\n‚Äãhandle (!pop.coroutine<() -> !kgen.paramref<*\"type\">>): The init handle.\n\nReturns:\n\nThe constructed coroutine object.\n\n__del__\n\n__del__(owned self: Self)\n\nDestroy the coroutine object.\n\n__await__\n\n__await__(self: Self) -> *\"type\"\n\nSuspends the current coroutine until the coroutine is complete.\n\nReturns:\n\nThe coroutine promise.\n\nget_promise\n\nget_promise(self: Self) -> Pointer[*\"type\"]\n\nReturn the pointer to the beginning of the memory where the async function results are stored.\n\nReturns:\n\nThe coroutine promise.\n\nget\n\nget(self: Self) -> *\"type\"\n\nGet the value of the fulfilled coroutine promise.\n\nReturns:\n\nThe value of the fulfilled promise.\n\nget_ctx\n\nget_ctx[ctx_type: AnyType](self: Self) -> Pointer[ctx_type]\n\nReturns the pointer to the coroutine context.\n\nParameters:\n\n‚Äãctx_type (AnyType): The type of the coroutine context.\n\nReturns:\n\nThe coroutine context.\n\n__call__\n\n__call__(self: Self) -> *\"type\"\n\nExecute the coroutine synchronously.\n\nReturns:\n\nThe coroutine promise.\n\nRaisingCoroutine\n\nRepresents a coroutine that can raise.\n\nCoroutines can pause execution saving the state of the program (including values of local variables and the location of the next instruction to be executed). When the coroutine is resumed, execution continues from where it left off, with the saved state restored.\n\nParameters:\n\n‚Äãtype (AnyType): Type of value returned upon completion of the coroutine.\n\nFunctions:\n\n__init__\n\n__init__(handle: !pop.coroutine<() throws -> !pop.variant<!kgen.declref<_\"$builtin\"::_\"$error\"::_Error, !lit.metatype<_\"$builtin\"::_\"$error\"::_Error>>, *\"type\">>) -> Self\n\nConstruct a coroutine object from a handle.\n\nArgs:\n\n‚Äãhandle (!pop.coroutine<() throws -> !pop.variant<!kgen.declref<_\"$builtin\"::_\"$error\"::_Error, !lit.metatype<_\"$builtin\"::_\"$error\"::_Error>>, *\"type\">>): The init handle.\n\nReturns:\n\nThe constructed coroutine object.\n\n__del__\n\n__del__(owned self: Self)\n\nDestroy the coroutine object.\n\n__await__\n\n__await__(self: Self) -> *\"type\"\n\nSuspends the current coroutine until the coroutine is complete.\n\nReturns:\n\nThe coroutine promise.\n\nget_promise\n\nget_promise(self: Self) -> Pointer[Variant[Error, *\"type\"]]\n\nReturn the pointer to the beginning of the memory where the async function results are stored.\n\nReturns:\n\nThe coroutine promise.\n\nget\n\nget(self: Self) -> *\"type\"\n\nGet the value of the fulfilled coroutine promise.\n\nReturns:\n\nThe value of the fulfilled promise.\n\nget_ctx\n\nget_ctx[ctx_type: AnyType](self: Self) -> Pointer[ctx_type]\n\nReturns the pointer to the coroutine context.\n\nParameters:\n\n‚Äãctx_type (AnyType): The type of the coroutine context.\n\nReturns:\n\nThe coroutine context.\n\n__call__\n\n__call__(self: Self) -> *\"type\"\n\nExecute the coroutine synchronously.\n\nReturns:\n\nThe coroutine promise.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - constrained",
    "url": "https://docs.modular.com/mojo/stdlib/builtin/constrained.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\nbool\nbuiltin_list\nbuiltin_slice\nconstrained\ncoroutine\ndebug_assert\ndtype\nerror\nfile\nfloat_literal\nint\nio\nlen\nobject\nrange\nrebind\nsimd\nstring\nstring_literal\nstringref\ntuple\ntype_aliases\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nconstrained\nconstrained\n\nModule\n\nImplements compile time contraints.\n\nThese are Mojo built-ins, so you don‚Äôt need to import them.\n\nconstrained\n\nconstrained[cond: Bool, msg: StringLiteral]()\n\nCompile time checks that the condition is true.\n\nThe constrained is similar to static_assert in C++ and is used to introduce constraints on the enclosing function. In Mojo, the assert places a constraint on the function. The message is displayed when the assertion fails.\n\nParameters:\n\n‚Äãcond (Bool): The bool value to assert.\n‚Äãmsg (StringLiteral): The message to display on failure.\n\nconstrained[cond: Bool]()\n\nCompile time checks that the condition is true.\n\nThe constrained is similar to static_assert in C++ and is used to introduce constraints on the enclosing function. In Mojo, the assert places a constraint on the function.\n\nParameters:\n\n‚Äãcond (Bool): The bool value to assert.\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - builtin_slice",
    "url": "https://docs.modular.com/mojo/stdlib/builtin/builtin_slice.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\nbool\nbuiltin_list\nbuiltin_slice\nconstrained\ncoroutine\ndebug_assert\ndtype\nerror\nfile\nfloat_literal\nint\nio\nlen\nobject\nrange\nrebind\nsimd\nstring\nstring_literal\nstringref\ntuple\ntype_aliases\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nslice\n__init__\n__getitem__\n__eq__\n__ne__\n__len__\nbuiltin_slice\n\nModule\n\nImplements slice.\n\nThese are Mojo built-ins, so you don‚Äôt need to import them.\n\nslice\n\nRepresents a slice expression.\n\nObjects of this type are generated when slice syntax is used within square brackets, e.g.:\n\nlet msg: String = \"Hello Mojo\"\n\n# Both are equivalent and print \"Mojo\".\nprint(msg[6:])\nprint(msg.__getitem__(slice(6, len(msg))))\n\nFields:\n\n‚Äãstart (Int): The starting index of the slice.\n‚Äãend (Int): The end index of the slice.\n‚Äãstep (Int): The step increment value of the slice.\n\nFunctions:\n\n__init__\n\n__init__(end: Int) -> Self\n\nConstruct slice given the end value.\n\nArgs:\n\n‚Äãend (Int): The end value.\n\nReturns:\n\nThe constructed slice.\n\n__init__(start: Int, end: Int) -> Self\n\nConstruct slice given the start and end values.\n\nArgs:\n\n‚Äãstart (Int): The start value.\n‚Äãend (Int): The end value.\n\nReturns:\n\nThe constructed slice.\n\n__init__[T0: AnyType, T1: AnyType, T2: AnyType](start: T0, end: T1, step: T2) -> Self\n\nConstruct slice given the start, end and step values.\n\nParameters:\n\n‚ÄãT0 (AnyType): Type of the start value.\n‚ÄãT1 (AnyType): Type of the end value.\n‚ÄãT2 (AnyType): Type of the step value.\n\nArgs:\n\n‚Äãstart (T0): The start value.\n‚Äãend (T1): The end value.\n‚Äãstep (T2): The step value.\n\nReturns:\n\nThe constructed slice.\n\n__getitem__\n\n__getitem__(self: Self, idx: Int) -> Int\n\nGet the slice index.\n\nArgs:\n\n‚Äãidx (Int): The index.\n\nReturns:\n\nThe slice index.\n\n__eq__\n\n__eq__(self: Self, other: Self) -> Bool\n\nCompare this slice to the other.\n\nArgs:\n\n‚Äãother (Self): The slice to compare to.\n\nReturns:\n\nTrue if start, end, and step values of this slice match the corresponding values of the other slice and False otherwise.\n\n__ne__\n\n__ne__(self: Self, other: Self) -> Bool\n\nCompare this slice to the other.\n\nArgs:\n\n‚Äãother (Self): The slice to compare to.\n\nReturns:\n\nFalse if start, end, and step values of this slice match the corresponding values of the other slice and True otherwise.\n\n__len__\n\n__len__(self: Self) -> Int\n\nReturn the length of the slice.\n\nReturns:\n\nThe length of the slice.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - builtin_list",
    "url": "https://docs.modular.com/mojo/stdlib/builtin/builtin_list.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\nbool\nbuiltin_list\nbuiltin_slice\nconstrained\ncoroutine\ndebug_assert\ndtype\nerror\nfile\nfloat_literal\nint\nio\nlen\nobject\nrange\nrebind\nsimd\nstring\nstring_literal\nstringref\ntuple\ntype_aliases\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nListLiteral\n__init__\n__len__\nget\nVariadicList\nVariadicListMem\nbuiltin_list\n\nModule\n\nImplements the ListLiteral class.\n\nThese are Mojo built-ins, so you don‚Äôt need to import them.\n\nListLiteral\n\nThe type of a literal heterogenous list expression.\n\nA list consists of zero or more values, separated by commas.\n\nParameters:\n\n‚ÄãTs (*AnyType): The type of the elements.\n\nFields:\n\n‚Äãstorage (!kgen.pack<Ts>): The underlying storage for the list.\n\nFunctions:\n\n__init__\n\n__init__(args: !kgen.pack<Ts>) -> Self\n\nConstruct the list literal from the given values.\n\nArgs:\n\n‚Äãargs (!kgen.pack<Ts>): The init values.\n\nReturns:\n\nThe constructed ListLiteral.\n\n__len__\n\n__len__(self: Self) -> Int\n\nGet the list length.\n\nReturns:\n\nThe length of this ListLiteral.\n\nget\n\nget[i: Int, T: AnyType](self: Self) -> T\n\nGet a list element at the given index.\n\nParameters:\n\n‚Äãi (Int): The element index.\n‚ÄãT (AnyType): The element type.\n\nReturns:\n\nThe element at the given index.\n\nVariadicList\n\nA utility class to access variadic function arguments. Provides a ‚Äúlist‚Äù view of the function argument so that the size of the argument list and each individual argument can be accessed.\n\nParameters:\n\n‚Äãtype (AnyType): The type of the elements in the list.\n\nAliases:\n\n‚ÄãStorageType = variadic<*\"type\">\n\nFields:\n\n‚Äãvalue (variadic<*\"type\">): The underlying storage for the variadic list.\n\nFunctions:\n\n__init__\n\n__init__(*value: *\"type\") -> Self\n\nConstructs a VariadicList from a variadic list of arguments.\n\nArgs:\n\n‚Äãvalue (**\"type\"): The variadic argument list to construct the variadic list with.\n\nReturns:\n\nThe VariadicList constructed.\n\n__init__(*value: *\"type\") -> Self\n\nConstructs a VariadicList from a variadic argument type.\n\nArgs:\n\n‚Äãvalue (**\"type\"): The variadic argument to construct the list with.\n\nReturns:\n\nThe VariadicList constructed.\n\n__getitem__\n\n__getitem__(self: Self, index: Int) -> *\"type\"\n\nGets a single element on the variadic list.\n\nArgs:\n\n‚Äãindex (Int): The index of the element to access on the list.\n\nReturns:\n\nThe element on the list corresponding to the given index.\n\n__len__\n\n__len__(self: Self) -> Int\n\nGets the size of the list.\n\nReturns:\n\nThe number of elements on the variadic list.\n\nVariadicListMem\n\nA utility class to access variadic function arguments of memory-only types that may have ownership. It exposes pointers to the elements in a way that can be enumerated. Each element may be accessed with __get_address_as_lvalue.\n\nParameters:\n\n‚Äãtype (AnyType): The type of the elements in the list.\n\nAliases:\n\n‚ÄãStorageType = variadic<pointer<*\"type\">>\n\nFields:\n\n‚Äãvalue (variadic<pointer<*\"type\">>): The underlying storage, a variadic list of pointers to elements of the given type.\n\nFunctions:\n\n__init__\n\n__init__(*value: pointer<*\"type\">) -> Self\n\nConstructs a VariadicList from a variadic argument type.\n\nArgs:\n\n‚Äãvalue (*pointer<*\"type\">): The variadic argument to construct the list with.\n\nReturns:\n\nThe VariadicList constructed.\n\n__getitem__\n\n__getitem__(self: Self, index: Int) -> pointer<*\"type\">\n\nGets a single element on the variadic list.\n\nArgs:\n\n‚Äãindex (Int): The index of the element to access on the list.\n\nReturns:\n\nA low-level pointer to the element on the list corresponding to the given index.\n\n__len__\n\n__len__(self: Self) -> Int\n\nGets the size of the list.\n\nReturns:\n\nThe number of elements on the variadic list.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - bool",
    "url": "https://docs.modular.com/mojo/stdlib/builtin/bool.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\nbool\nbuiltin_list\nbuiltin_slice\nconstrained\ncoroutine\ndebug_assert\ndtype\nerror\nfile\nfloat_literal\nint\nio\nlen\nobject\nrange\nrebind\nsimd\nstring\nstring_literal\nstringref\ntuple\ntype_aliases\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nBool\n__init__\n__bool__\n__mlir_i1__\n__invert__\n__eq__\n__ne__\n__and__\n__or__\n__xor__\n__rand__\n__ror__\n__rxor__\nbool\n\nModule\n\nImplements the Bool class.\n\nThese are Mojo built-ins, so you don‚Äôt need to import them.\n\nBool\n\nThe primitive Bool scalar value used in Mojo.\n\nFields:\n\n‚Äãvalue (scalar<bool>): The underlying storage of the boolean value.\n\nFunctions:\n\n__init__\n\n__init__(value: i1) -> Self\n\nConstruct a Bool value given a __mlir_type.i1 value.\n\nArgs:\n\n‚Äãvalue (i1): The initial __mlir_type.i1 value.\n\nReturns:\n\nThe constructed Bool value.\n\n__init__(value: Self) -> Self\n\nConstruct a Bool value given a __mlir_type.i1 value.\n\nArgs:\n\n‚Äãvalue (Self): The initial __mlir_type.i1 value.\n\nReturns:\n\nThe constructed Bool value.\n\n__init__[width: Int](value: SIMD[bool, width]) -> Self\n\nConstruct a Bool value given a SIMD value.\n\nIf there is more than a single element in the SIMD value, then value is reduced using the and operator.\n\nArgs:\n\n‚Äãvalue (SIMD[bool, width]): The initial SIMD value.\n\nReturns:\n\nThe constructed Bool value.\n\n__init__(value: scalar<bool>, /) -> Self\n\n__bool__\n\n__bool__(self: Self) -> Self\n\nConvert to Bool.\n\nReturns:\n\nThis value.\n\n__mlir_i1__\n\n__mlir_i1__(self: Self) -> i1\n\nConvert this Bool to __mlir_type.i1.\n\nThis method is a special hook used by the compiler to test boolean objects in control flow conditions. It should be implemented by Bool but not other general boolean convertible types (they should implement __bool__ instead).\n\nReturns:\n\nThe underlying value for the Bool.\n\n__invert__\n\n__invert__(self: Self) -> Self\n\nInverts the Bool value.\n\nReturns:\n\nTrue if the object is false and False otherwise.\n\n__eq__\n\n__eq__(self: Self, rhs: Self) -> Self\n\nCompare this Bool to RHS.\n\nPerforms an equality comparison between the Bool value and the argument. This method gets invoked when a user uses the == infix operator.\n\nArgs:\n\n‚Äãrhs (Self): The rhs value of the equality statement.\n\nReturns:\n\nTrue if the two values match and False otherwise.\n\n__ne__\n\n__ne__(self: Self, rhs: Self) -> Self\n\nCompare this Bool to RHS.\n\nPerforms a non-equality comparison between the Bool value and the argument. This method gets invoked when a user uses the != infix operator.\n\nArgs:\n\n‚Äãrhs (Self): The rhs value of the non-equality statement.\n\nReturns:\n\nFalse if the two values do match and True otherwise.\n\n__and__\n\n__and__(self: Self, rhs: Self) -> Self\n\nCompute self & rhs.\n\nBitwise and‚Äôs the Bool value with the argument. This method gets invoked when a user uses the and infix operator.\n\nArgs:\n\n‚Äãrhs (Self): The rhs value of the and statement.\n\nReturns:\n\nself & rhs.\n\n__or__\n\n__or__(self: Self, rhs: Self) -> Self\n\nCompute self | rhs.\n\nBitwise or‚Äôs the Bool value with the argument. This method gets invoked when a user uses the or infix operator.\n\nArgs:\n\n‚Äãrhs (Self): The rhs value of the or statement.\n\nReturns:\n\nself | rhs.\n\n__xor__\n\n__xor__(self: Self, rhs: Self) -> Self\n\nCompute self ^ rhs.\n\nBitwise Xor‚Äôs the Bool value with the argument. This method gets invoked when a user uses the ^ infix operator.\n\nArgs:\n\n‚Äãrhs (Self): The rhs value of the xor statement.\n\nReturns:\n\nself ^ rhs.\n\n__rand__\n\n__rand__(self: Self, value: Self) -> Self\n\nReturn value & self.\n\nArgs:\n\n‚Äãvalue (Self): The other value.\n\nReturns:\n\nvalue & self.\n\n__ror__\n\n__ror__(self: Self, value: Self) -> Self\n\nReturn value | self.\n\nArgs:\n\n‚Äãvalue (Self): The other value.\n\nReturns:\n\nvalue | self.\n\n__rxor__\n\n__rxor__(self: Self, value: Self) -> Self\n\nReturn value ^ self.\n\nArgs:\n\n‚Äãvalue (Self): The other value.\n\nReturns:\n\nvalue ^ self.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - benchmark",
    "url": "https://docs.modular.com/mojo/stdlib/benchmark/benchmark.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nBatch\n__init__\nmean\nUnit\nReport\nrun\nclobber_memory\nkeep\nbenchmark\n\nModule\n\nImplements the benchmark module for runtime benchmarking.\n\nYou can import these APIs from the benchmark package. For example:\n\nimport benchmark\nfrom time import sleep\n\nYou can pass any fn as a parameter into benchmark.run[...](), it will return a Report where you can get the mean, duration, max, and more:\n\nfn sleeper():\n    sleep(.01)\n\nlet report = benchmark.run[sleeper]()\nprint(report.mean())\n0.012451871794871795\n\nYou can print a full report:\n\nreport.print()\n---------------------\nBenchmark Report (s)\n---------------------\nMean: 0.012314264957264957\nTotal: 1.440769\nIters: 117\nWarmup Mean: 0.0119335\nWarmup Total: 0.023866999999999999\nWarmup Iters: 2\nFastest Mean: 0.012227958333333334\nSlowest Mean: 0.012442699999999999\n\n\nOr all the batch runs:\n\nreport.print_full()\n---------------------\nBenchmark Report (ms)\n---------------------\nMean: 12.397538461538462\nTotal: 1450.5119999999999\nIters: 117\nWarmup Mean: 11.715\nWarmup Total: 23.43\nWarmup Iters: 2\nFastest Mean: 12.0754375\nSlowest Mean: 12.760265306122449\n\nBatch: 1\nIterations: 20\nMean: 12.2819\nDuration: 245.63800000000001\n\nBatch: 2\nIterations: 48\nMean: 12.0754375\nDuration: 579.62099999999998\n\nBatch: 3\nIterations: 49\nMean: 12.760265306122449\nDuration: 625.25300000000004\n\n\nIf you want to use a different time unit you can bring in the Unit and pass it in as a parameter:\n\nfrom benchmark import Unit\n\nreport.print[Unit.ms]()\n---------------------\nBenchmark Report (ms)\n---------------------\nMean: 12.474991228070174\nTotal: 1422.1489999999999\nIters: 114\nWarmup Mean: 11.976000000000001\nWarmup Total: 23.952000000000002\nWarmup Iters: 2\nFastest Mean: 12.297478260869564\nSlowest Mean: 12.6313125\n\n\nThe unit‚Äôs are just aliases for StringLiteral, so you can for example:\n\nprint(report.mean[\"ms\"]())\n12.199145299145298\n\nBenchmark.run takes four arguments to change the behaviour, to set warmup iterations to 5:\n\nr = benchmark.run[sleeper](5)\n0.012004808080808081\n\nTo set 1 warmup iteration, 2 max iterations, a min total time of 3 sec, and a max total time of 4 s:\n\nr = benchmark.run[sleeper](1, 2, 3, 4)\n\nNote that the min total time will take precedence over max iterations\n\nBatch\n\nA batch of benchmarks, the benchmark.run() function works out how many iterations to run in each batch based the how long the previous iterations took.\n\nFields:\n\n‚Äãduration (Int): Total duration of batch stored as nanoseconds.\n‚Äãiterations (Int): Total iterations in the batch.\n\nFunctions:\n\n__init__\n\n__init__(duration: Int, iterations: Int, /) -> Self\n\nmean\n\nmean[unit: StringLiteral](self: Self) -> SIMD[f64, 1]\n\nReturns the average duration of the batch.\n\nParameters:\n\n‚Äãunit (StringLiteral): The time unit to display for example: ns, ms, s (default s).\n\nReturns:\n\nThe average duration of the batch.\n\nUnit\n\nTime Unit used by Benchmark Report.\n\nAliases:\n\n‚Äãns = \"ns\": Nanoseconds\n‚Äãms = \"ms\": Milliseconds\n‚Äãs = \"s\": Seconds\nReport\n\nContains the average execution time, iterations, min and max of each batch.\n\nFields:\n\n‚Äãwarmup_iters (Int): The total warmup iterations.\n‚Äãwarmup_duration (Int): The total duration it took to warmup.\n‚Äãruns (DynamicVector[Batch]): A DynamicVector of benchmark runs.\n\nFunctions:\n\n__init__\n\n__init__(inout self: Self)\n\nDefault initializer for the Report.\n\nSets all values to 0\n\n__copyinit__\n\n__copyinit__(inout self: Self, existing: Self)\n\nCreates a shallow copy (it doesn‚Äôt copy the data).\n\nArgs:\n\n‚Äãexisting (Self): The Report to copy.\n__del__\n\n__del__(owned self: Self)\n\nDelets the Report object.\n\niters\n\niters(self: Self) -> Int\n\nThe total benchmark iterations.\n\nReturns:\n\nThe total benchmark iterations.\n\nduration\n\nduration[unit: StringLiteral](self: Self) -> SIMD[f64, 1]\n\nThe total duration it took to run all benchmarks.\n\nParameters:\n\n‚Äãunit (StringLiteral): The time unit to display for example: ns, ms, s (default s).\n\nReturns:\n\nThe total duration it took to run all benchmarks.\n\nmean\n\nmean[unit: StringLiteral](self: Self) -> SIMD[f64, 1]\n\nThe average duration of all benchmark runs.\n\nParameters:\n\n‚Äãunit (StringLiteral): The time unit to display for example: ns, ms, s (default s).\n\nReturns:\n\nThe average duration of all benchmark runs.\n\nmin\n\nmin[unit: StringLiteral](self: Self) -> SIMD[f64, 1]\n\nThe batch of benchmarks that was the fastest to run.\n\nParameters:\n\n‚Äãunit (StringLiteral): The time unit to display for example: ns, ms, s (default s).\n\nReturns:\n\nThe fastest duration out of all batches.\n\nmax\n\nmax[unit: StringLiteral](self: Self) -> SIMD[f64, 1]\n\nThe batch of benchmarks that was the slowest to run.\n\nParameters:\n\n‚Äãunit (StringLiteral): The time unit to display for example: ns, ms, s (default s).\n\nReturns:\n\nThe slowest duration out of all batches.\n\nprint\n\nprint[unit: StringLiteral](self: Self)\n\nPrints out the shortened version of the report.\n\nParameters:\n\n‚Äãunit (StringLiteral): The time unit to display for example: ns, ms, s (default s).\nprint_full\n\nprint_full[unit: StringLiteral](self: Self)\n\nPrints out the full version of the report with each batch of benchmark runs.\n\nParameters:\n\n‚Äãunit (StringLiteral): The time unit to display for example: ns, ms, s (default s).\nrun\n\nrun[func: fn() -> None](num_warmup: Int, max_iters: Int, min_time_secs: SIMD[f64, 1], max_time_secs: SIMD[f64, 1]) -> Report\n\nBenchmarks the function passed in as a parameter.\n\nBenchmarking continues until ‚Äòmin_time_ns‚Äô has elapsed and either max_time_ns OR max_iters is achieved.\n\nParameters:\n\n‚Äãfunc (fn() -> None): The function to benchmark.\n\nArgs:\n\n‚Äãnum_warmup (Int): Number of warmup iterations to run before starting benchmarking (default 2).\n‚Äãmax_iters (Int): Max number of iterations to run (default 100_000).\n‚Äãmin_time_secs (SIMD[f64, 1]): Upper bound on benchmarking time in secs (default 0.5).\n‚Äãmax_time_secs (SIMD[f64, 1]): Lower bound on benchmarking time in secs (default 1).\n\nReturns:\n\nAverage execution time of func in ns.\n\nrun[func: fn() capturing -> None](num_warmup: Int, max_iters: Int, min_time_secs: SIMD[f64, 1], max_time_secs: SIMD[f64, 1]) -> Report\n\nBenchmarks the function passed in as a parameter.\n\nBenchmarking continues until ‚Äòmin_time_ns‚Äô has elapsed and either max_time_ns OR max_iters is achieved.\n\nParameters:\n\n‚Äãfunc (fn() capturing -> None): The function to benchmark.\n\nArgs:\n\n‚Äãnum_warmup (Int): Number of warmup iterations to run before starting benchmarking (default 2).\n‚Äãmax_iters (Int): Max number of iterations to run (default 100_000).\n‚Äãmin_time_secs (SIMD[f64, 1]): Upper bound on benchmarking time in secs (default 0.5).\n‚Äãmax_time_secs (SIMD[f64, 1]): Lower bound on benchmarking time in secs (default 1).\n\nReturns:\n\nAverage execution time of func in ns.\n\nclobber_memory\n\nclobber_memory()\n\nForces all pending memory writes to be flushed to memory.\n\nThis ensures that the compiler does not optimize away memory writes if it deems them to be not neccessary. In effect, this operation acts a barrier to memory reads and writes.\n\nkeep\n\nkeep(val: Bool)\n\nProvides a hint to the compiler to not optimize the variable use away.\n\nThis is useful in benchmarking to avoid the compiler not deleting the code to be benchmarked because the variable is not used in a side-effecting manner.\n\nArgs:\n\n‚Äãval (Bool): The value to not optimize away.\n\nkeep(val: Int)\n\nProvides a hint to the compiler to not optimize the variable use away.\n\nThis is useful in benchmarking to avoid the compiler not deleting the code to be benchmarked because the variable is not used in a side-effecting manner.\n\nArgs:\n\n‚Äãval (Int): The value to not optimize away.\n\nkeep[type: DType, simd_width: Int](val: SIMD[type, simd_width])\n\nProvides a hint to the compiler to not optimize the variable use away.\n\nThis is useful in benchmarking to avoid the compiler not deleting the code to be benchmarked because the variable is not used in a side-effecting manner.\n\nParameters:\n\n‚Äãtype (DType): The dtype of the input and output SIMD vector.\n‚Äãsimd_width (Int): The width of the input and output SIMD vector.\n\nArgs:\n\n‚Äãval (SIMD[type, simd_width]): The value to not optimize away.\n\nkeep[type: DType](val: DTypePointer[type])\n\nProvides a hint to the compiler to not optimize the variable use away.\n\nThis is useful in benchmarking to avoid the compiler not deleting the code to be benchmarked because the variable is not used in a side-effecting manner.\n\nParameters:\n\n‚Äãtype (DType): The type of the input.\n\nArgs:\n\n‚Äãval (DTypePointer[type]): The value to not optimize away.\n\nkeep[type: AnyType](val: Pointer[*\"type\"])\n\nProvides a hint to the compiler to not optimize the variable use away.\n\nThis is useful in benchmarking to avoid the compiler not deleting the code to be benchmarked because the variable is not used in a side-effecting manner.\n\nParameters:\n\n‚Äãtype (AnyType): The type of the input.\n\nArgs:\n\n‚Äãval (Pointer[*\"type\"]): The value to not optimize away.\n\nkeep[type: AnyType](inout *val: \"type\")\n\nProvides a hint to the compiler to not optimize the variable use away.\n\nThis is useful in benchmarking to avoid the compiler not deleting the code to be benchmarked because the variable is not used in a side-effecting manner.\n\nParameters:\n\n‚Äãtype (AnyType): The type of the input.\n\nArgs:\n\n‚Äãval (*\"type\"): The value to not optimize away.\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - base64",
    "url": "https://docs.modular.com/mojo/stdlib/base64/base64.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nb64encode\nbase64\n\nModule\n\nProvides functions for base64 encoding strings.\n\nYou can import these APIs from the base64 package. For example:\n\nfrom base64 import b64encode\nb64encode\n\nb64encode(str: String) -> String\n\nPerforms base64 encoding on the input string.\n\nArgs:\n\n‚Äãstr (String): The input string.\n\nReturns:\n\nBase64 encoding of the input string.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - autotuning",
    "url": "https://docs.modular.com/mojo/stdlib/autotune/autotuning.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nautotuning\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nautotune\nautotune_fork\nsearch\ncost_of\nautotuning\n\nModule\n\nImplements the autotune functionality.\n\nYou can import these APIs from the autotune package. For example:\n\nfrom autotune import search\nautotune\n\nautotune[T: AnyType, *Ts: AnyType](value: T, values: !kgen.pack<Ts>) -> T\n\nForks compilation to evaluate each of the provided values.\n\nParameters:\n\n‚ÄãT (AnyType): The first value type.\n‚ÄãTs (*AnyType): The types of the rest of the parameters.\n\nArgs:\n\n‚Äãvalue (T): The first value in the pack.\n‚Äãvalues (!kgen.pack<Ts>): The tail values.\n\nReturns:\n\nThe value being used in the current compilation fork.\n\nautotune_fork\n\nautotune_fork[type: AnyType, *values: *\"type\"]()\n\nForks compilation to evaluate each of the provided values.\n\nReturn parameters: out: The value being used in the current compilation fork.\n\nParameters:\n\n‚Äãtype (AnyType): The type of the parameters to be evaluated.\n‚Äãvalues (**\"type\"): A list of parameters to be evaluated.\nsearch\n\nsearch[fn_type: AnyType, candidates: VariadicList[fn_type], evaluator: fn(Pointer[fn_type], Int, /) -> Int]()\n\nFinds the best implementation among all candidates.\n\nThe function runs the search among the list of candidates using the provided evaluator. The evaluator function needs to take two inputs: a pointer to array of all candidates and the size of that array - and return an index of the best candidate.\n\nReturn parameters: The best found candidate.\n\nParameters:\n\n‚Äãfn_type (AnyType): The signature type of the function.\n‚Äãcandidates (VariadicList[fn_type]): A list of candidates to search from.\n‚Äãevaluator (fn(Pointer[fn_type], Int, /) -> Int): The evaluator function.\ncost_of\n\ncost_of[fn_type: AnyType, func: fn_type]() -> Int\n\nCount the number of operations in a function.\n\nThis function takes a function reference and estimates the ‚Äúcost‚Äù of invoking the function by counting the number of MLIR operations in the function after elaboration.\n\nParameters:\n\n‚Äãfn_type (AnyType): The signature type of the function.\n‚Äãfunc (fn_type): The function to evaluate.\n\nReturns:\n\nThe number of post-elaboration operations in the function.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - sort",
    "url": "https://docs.modular.com/mojo/stdlib/algorithm/sort.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nfunctional\nreduction\nsort\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\npartition\nsort\nsort\n\nModule\n\nImplements sorting functions.\n\nYou can import these APIs from the algorithm package. For example:\n\nfrom algorithm.sort import sort\npartition\n\npartition[type: AnyType, cmp_fn: fn[AnyType]($0, $0, /) capturing -> Bool](buff: Pointer[*\"type\"], k: Int, size: Int)\n\nPartition the input vector inplace such that first k elements are the largest (or smallest if cmp_fn is <= operator) elements. The ordering of the first k elements is undefined.\n\nParameters:\n\n‚Äãtype (AnyType): DType of the underlying data.\n‚Äãcmp_fn (fn[AnyType]($0, $0, /) capturing -> Bool): Comparison functor of type, type) capturing -> Bool type.\n\nArgs:\n\n‚Äãbuff (Pointer[*\"type\"]): Input buffer.\n‚Äãk (Int): Index of the partition element.\n‚Äãsize (Int): The length of the buffer.\nsort\n\nsort(inout buff: Pointer[Int], len: Int)\n\nSort the vector inplace.\n\nThe function doesn‚Äôt return anything, the vector is updated inplace.\n\nArgs:\n\n‚Äãbuff (Pointer[Int]): Input buffer.\n‚Äãlen (Int): The length of the buffer.\n\nsort[type: DType](inout buff: Pointer[SIMD[type, 1]], len: Int)\n\nSort the vector inplace.\n\nThe function doesn‚Äôt return anything, the vector is updated inplace.\n\nParameters:\n\n‚Äãtype (DType): DType of the underlying data.\n\nArgs:\n\n‚Äãbuff (Pointer[SIMD[type, 1]]): Input buffer.\n‚Äãlen (Int): The length of the buffer.\n\nsort(inout v: DynamicVector[Int])\n\nSort the vector inplace.\n\nThe function doesn‚Äôt return anything, the vector is updated inplace.\n\nArgs:\n\n‚Äãv (DynamicVector[Int]): Input integer vector to sort.\n\nsort[type: DType](inout v: DynamicVector[SIMD[type, 1]])\n\nSort the vector inplace.\n\nThe function doesn‚Äôt return anything, the vector is updated inplace.\n\nParameters:\n\n‚Äãtype (DType): DType of the underlying data.\n\nArgs:\n\n‚Äãv (DynamicVector[SIMD[type, 1]]): Input vector to sort.\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - reduction",
    "url": "https://docs.modular.com/mojo/stdlib/algorithm/reduction.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nfunctional\nreduction\nsort\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nmap_reduce\nreduce\nreduce_boolean\nmax\nmin\nsum\nproduct\nmean\nvariance\nall_true\nany_true\nnone_true\nargmax\nargmin\nreduce_shape\ncumsum\nreduction\n\nModule\n\nImplements SIMD reductions.\n\nYou can import these APIs from the algorithm package. For example:\n\nfrom algorithm import map_reduce\nmap_reduce\n\nmap_reduce[simd_width: Int, size: Dim, type: DType, acc_type: DType, input_gen_fn: fn[DType, Int](Int, /) capturing -> SIMD[*(0,0), *(0,1)], reduce_vec_to_vec_fn: fn[DType, DType, Int](SIMD[*(0,0), *(0,2)], SIMD[*(0,1), *(0,2)], /) capturing -> SIMD[*(0,0), *(0,2)], reduce_vec_to_scalar_fn: fn[DType, Int](SIMD[*(0,0), *(0,1)], /) -> SIMD[*(0,0), 1]](dst: Buffer[size, type], init: SIMD[acc_type, 1]) -> SIMD[acc_type, 1]\n\nStores the result of calling input_gen_fn in dst and simultaneously reduce the result using a custom reduction function.\n\nParameters:\n\n‚Äãsimd_width (Int): The vector width for the computation.\n‚Äãsize (Dim): The buffer size.\n‚Äãtype (DType): The buffer elements dtype.\n‚Äãacc_type (DType): The dtype of the reduction accumulator.\n‚Äãinput_gen_fn (fn[DType, Int](Int, /) capturing -> SIMD[*(0,0), *(0,1)]): A function that generates inputs to reduce.\n‚Äãreduce_vec_to_vec_fn (fn[DType, DType, Int](SIMD[*(0,0), *(0,2)], SIMD[*(0,1), *(0,2)], /) capturing -> SIMD[*(0,0), *(0,2)]): A mapping function. This function is used to combine (accumulate) two chunks of input data: e.g.¬†we load two 8xfloat32 vectors of elements and need to reduce them into a single 8xfloat32 vector.\n‚Äãreduce_vec_to_scalar_fn (fn[DType, Int](SIMD[*(0,0), *(0,1)], /) -> SIMD[*(0,0), 1]): A reduction function. This function is used to reduce a vector to a scalar. E.g. when we got 8xfloat32 vector and want to reduce it to an float32 scalar.\n\nArgs:\n\n‚Äãdst (Buffer[size, type]): The output buffer.\n‚Äãinit (SIMD[acc_type, 1]): The initial value to use in accumulator.\n\nReturns:\n\nThe computed reduction value.\n\nreduce\n\nreduce[simd_width: Int, size: Dim, type: DType, acc_type: DType, reduce_fn: fn[DType, DType, Int](SIMD[*(0,0), *(0,2)], SIMD[*(0,1), *(0,2)], /) capturing -> SIMD[*(0,0), *(0,2)]](src: Buffer[size, type], init: SIMD[acc_type, 1]) -> SIMD[acc_type, 1]\n\nComputes a custom reduction of buffer elements.\n\nParameters:\n\n‚Äãsimd_width (Int): The vector width for the computation.\n‚Äãsize (Dim): The buffer size.\n‚Äãtype (DType): The buffer elements dtype.\n‚Äãacc_type (DType): The dtype of the reduction accumulator.\n‚Äãreduce_fn (fn[DType, DType, Int](SIMD[*(0,0), *(0,2)], SIMD[*(0,1), *(0,2)], /) capturing -> SIMD[*(0,0), *(0,2)]): The lambda implementing the reduction.\n\nArgs:\n\n‚Äãsrc (Buffer[size, type]): The input buffer.\n‚Äãinit (SIMD[acc_type, 1]): The initial value to use in accumulator.\n\nReturns:\n\nThe computed reduction value.\n\nreduce[simd_width: Int, rank: Int, input_shape: DimList, output_shape: DimList, type: DType, acc_type: DType, map_fn: fn[DType, DType, Int](SIMD[*(0,0), *(0,2)], SIMD[*(0,1), *(0,2)], /) capturing -> SIMD[*(0,0), *(0,2)], reduce_fn: fn[DType, Int](SIMD[*(0,0), *(0,1)], /) -> SIMD[*(0,0), 1], reduce_axis: Int](src: NDBuffer[rank, input_shape, type], dst: NDBuffer[rank, output_shape, acc_type], init: SIMD[acc_type, 1])\n\nPerforms a reduction across reduce_axis of an NDBuffer (src) and stores the result in an NDBuffer (dst).\n\nFirst src is reshaped into a 3D tensor. Without loss of generality, the three axes will be referred to as [H,W,C], where the axis to reduce across is W, the axes before the reduce axis are packed into H, and the axes after the reduce axis are packed into C. i.e.¬†a tensor with dims [D1, D2, ‚Ä¶, Di, ‚Ä¶, Dn] reducing across axis i gets packed into a 3D tensor with dims [H, W, C], where H=prod(D1,‚Ä¶,Di-1), W = Di, and C = prod(Di+1,‚Ä¶,Dn).\n\nParameters:\n\n‚Äãsimd_width (Int): The vector width for the computation.\n‚Äãrank (Int): The rank of the input/output buffers.\n‚Äãinput_shape (DimList): The input buffer shape.\n‚Äãoutput_shape (DimList): The output buffer shape.\n‚Äãtype (DType): The buffer elements dtype.\n‚Äãacc_type (DType): The dtype of the reduction accumulator.\n‚Äãmap_fn (fn[DType, DType, Int](SIMD[*(0,0), *(0,2)], SIMD[*(0,1), *(0,2)], /) capturing -> SIMD[*(0,0), *(0,2)]): A mapping function. This function is used when to combine (accumulate) two chunks of input data: e.g.¬†we load two 8xfloat32 vectors of elements and need to reduce them to a single 8xfloat32 vector.\n‚Äãreduce_fn (fn[DType, Int](SIMD[*(0,0), *(0,1)], /) -> SIMD[*(0,0), 1]): A reduction function. This function is used to reduce a vector to a scalar. E.g. when we got 8xfloat32 vector and want to reduce it to 1xfloat32.\n‚Äãreduce_axis (Int): The axis to reduce across.\n\nArgs:\n\n‚Äãsrc (NDBuffer[rank, input_shape, type]): The input buffer.\n‚Äãdst (NDBuffer[rank, output_shape, acc_type]): The output buffer.\n‚Äãinit (SIMD[acc_type, 1]): The initial value to use in accumulator.\nreduce_boolean\n\nreduce_boolean[simd_width: Int, size: Dim, type: DType, reduce_fn: fn[DType, Int](SIMD[*(0,0), *(0,1)], /) capturing -> Bool, continue_fn: fn(Bool, /) capturing -> Bool](src: Buffer[size, type], init: Bool) -> Bool\n\nComputes a bool reduction of buffer elements. The reduction will early exit if the continue_fn returns False.\n\nParameters:\n\n‚Äãsimd_width (Int): The vector width for the computation.\n‚Äãsize (Dim): The buffer size.\n‚Äãtype (DType): The buffer elements dtype.\n‚Äãreduce_fn (fn[DType, Int](SIMD[*(0,0), *(0,1)], /) capturing -> Bool): A boolean reduction function. This function is used to reduce a vector to a scalar. E.g. when we got 8xfloat32 vector and want to reduce it to a bool.\n‚Äãcontinue_fn (fn(Bool, /) capturing -> Bool): A function to indicate whether we want to continue processing the rest of the iterations. This takes the result of the reduce_fn and returns True to continue processing and False to early exit.\n\nArgs:\n\n‚Äãsrc (Buffer[size, type]): The input buffer.\n‚Äãinit (Bool): The initial value to use.\n\nReturns:\n\nThe computed reduction value.\n\nmax\n\nmax[size: Dim, type: DType](src: Buffer[size, type]) -> SIMD[type, 1]\n\nComputes the max element in a buffer.\n\nParameters:\n\n‚Äãsize (Dim): The buffer size.\n‚Äãtype (DType): The buffer elements dtype.\n\nArgs:\n\n‚Äãsrc (Buffer[size, type]): The buffer.\n\nReturns:\n\nThe maximum of the buffer elements.\n\nmax[rank: Int, input_shape: DimList, output_shape: DimList, type: DType, reduce_axis: Int](src: NDBuffer[rank, input_shape, type], dst: NDBuffer[rank, output_shape, type])\n\nComputes the max across reduce_axis of an NDBuffer.\n\nParameters:\n\n‚Äãrank (Int): The rank of the input/output buffers.\n‚Äãinput_shape (DimList): The input buffer shape.\n‚Äãoutput_shape (DimList): The output buffer shape.\n‚Äãtype (DType): The buffer elements dtype.\n‚Äãreduce_axis (Int): The axis to reduce across.\n\nArgs:\n\n‚Äãsrc (NDBuffer[rank, input_shape, type]): The input buffer.\n‚Äãdst (NDBuffer[rank, output_shape, type]): The output buffer.\nmin\n\nmin[size: Dim, type: DType](src: Buffer[size, type]) -> SIMD[type, 1]\n\nComputes the min element in a buffer.\n\nParameters:\n\n‚Äãsize (Dim): The buffer size.\n‚Äãtype (DType): The buffer elements dtype.\n\nArgs:\n\n‚Äãsrc (Buffer[size, type]): The buffer.\n\nReturns:\n\nThe minimum of the buffer elements.\n\nmin[rank: Int, input_shape: DimList, output_shape: DimList, type: DType, reduce_axis: Int](src: NDBuffer[rank, input_shape, type], dst: NDBuffer[rank, output_shape, type])\n\nComputes the min across reduce_axis of an NDBuffer.\n\nParameters:\n\n‚Äãrank (Int): The rank of the input/output buffers.\n‚Äãinput_shape (DimList): The input buffer shape.\n‚Äãoutput_shape (DimList): The output buffer shape.\n‚Äãtype (DType): The buffer elements dtype.\n‚Äãreduce_axis (Int): The axis to reduce across.\n\nArgs:\n\n‚Äãsrc (NDBuffer[rank, input_shape, type]): The input buffer.\n‚Äãdst (NDBuffer[rank, output_shape, type]): The output buffer.\nsum\n\nsum[size: Dim, type: DType](src: Buffer[size, type]) -> SIMD[type, 1]\n\nComputes the sum of buffer elements.\n\nParameters:\n\n‚Äãsize (Dim): The buffer size.\n‚Äãtype (DType): The buffer elements dtype.\n\nArgs:\n\n‚Äãsrc (Buffer[size, type]): The buffer.\n\nReturns:\n\nThe sum of the buffer elements.\n\nsum[rank: Int, input_shape: DimList, output_shape: DimList, type: DType, reduce_axis: Int](src: NDBuffer[rank, input_shape, type], dst: NDBuffer[rank, output_shape, type])\n\nComputes the sum across reduce_axis of an NDBuffer.\n\nParameters:\n\n‚Äãrank (Int): The rank of the input/output buffers.\n‚Äãinput_shape (DimList): The input buffer shape.\n‚Äãoutput_shape (DimList): The output buffer shape.\n‚Äãtype (DType): The buffer elements dtype.\n‚Äãreduce_axis (Int): The axis to reduce across.\n\nArgs:\n\n‚Äãsrc (NDBuffer[rank, input_shape, type]): The input buffer.\n‚Äãdst (NDBuffer[rank, output_shape, type]): The output buffer.\nproduct\n\nproduct[size: Dim, type: DType](src: Buffer[size, type]) -> SIMD[type, 1]\n\nComputes the product of the buffer elements.\n\nParameters:\n\n‚Äãsize (Dim): The buffer size.\n‚Äãtype (DType): The buffer elements dtype.\n\nArgs:\n\n‚Äãsrc (Buffer[size, type]): The buffer.\n\nReturns:\n\nThe product of the buffer elements.\n\nproduct[rank: Int, input_shape: DimList, output_shape: DimList, type: DType, reduce_axis: Int](src: NDBuffer[rank, input_shape, type], dst: NDBuffer[rank, output_shape, type])\n\nComputes the product across reduce_axis of an NDBuffer.\n\nParameters:\n\n‚Äãrank (Int): The rank of the input/output buffers.\n‚Äãinput_shape (DimList): The input buffer shape.\n‚Äãoutput_shape (DimList): The output buffer shape.\n‚Äãtype (DType): The buffer elements dtype.\n‚Äãreduce_axis (Int): The axis to reduce across.\n\nArgs:\n\n‚Äãsrc (NDBuffer[rank, input_shape, type]): The input buffer.\n‚Äãdst (NDBuffer[rank, output_shape, type]): The output buffer.\nmean\n\nmean[size: Dim, type: DType](src: Buffer[size, type]) -> SIMD[type, 1]\n\nComputes the mean value of the elements in a buffer.\n\nParameters:\n\n‚Äãsize (Dim): The size of the input buffer..\n‚Äãtype (DType): The type of the elements of the input buffer and output SIMD vector.\n\nArgs:\n\n‚Äãsrc (Buffer[size, type]): The buffer of elements for which the mean is computed.\n\nReturns:\n\nThe mean value of the elements in the given buffer.\n\nmean[rank: Int, input_shape: DimList, output_shape: DimList, type: DType, reduce_axis: Int](src: NDBuffer[rank, input_shape, type], dst: NDBuffer[rank, output_shape, type])\n\nComputes the mean across reduce_axis of an NDBuffer.\n\nParameters:\n\n‚Äãrank (Int): The rank of the input/output buffers.\n‚Äãinput_shape (DimList): The input buffer shape.\n‚Äãoutput_shape (DimList): The output buffer shape.\n‚Äãtype (DType): The buffer elements dtype.\n‚Äãreduce_axis (Int): The axis to reduce across.\n\nArgs:\n\n‚Äãsrc (NDBuffer[rank, input_shape, type]): The input buffer.\n‚Äãdst (NDBuffer[rank, output_shape, type]): The output buffer.\n\nmean[type: DType, rank: Int, single_thread_blocking_override: Bool, input_fn: fn[Int, Int](StaticIntTuple[*(0,1)], /) capturing -> SIMD[type, *(0,0)], output_fn: fn[Int, Int](StaticIntTuple[*(0,1)], SIMD[type, *(0,0)], /) capturing -> None, target: StringLiteral](input_shape: StaticIntTuple[rank], reduce_dim: Int, output_shape: StaticIntTuple[rank], out_chain: OutputChainPtr)\n\nComputes the mean across the input and output shape.\n\nThis performs the mean computation on the domain specified by input_shape, storing the results using theinput_0_fn. The results‚Äô domain is output_shape which are stored using the output_0_fn.\n\nParameters:\n\n‚Äãtype (DType): The type of the input and output.\n‚Äãrank (Int): The rank of the domain.\n‚Äãsingle_thread_blocking_override (Bool): Whether the operation is performed async.\n‚Äãinput_fn (fn[Int, Int](StaticIntTuple[*(0,1)], /) capturing -> SIMD[type, *(0,0)]): The function to load the input.\n‚Äãoutput_fn (fn[Int, Int](StaticIntTuple[*(0,1)], SIMD[type, *(0,0)], /) capturing -> None): The function to store the output.\n‚Äãtarget (StringLiteral): The target architecture.\n\nArgs:\n\n‚Äãinput_shape (StaticIntTuple[rank]): The input shape.\n‚Äãreduce_dim (Int): The axis to perform the mean on.\n‚Äãoutput_shape (StaticIntTuple[rank]): The output shape.\n‚Äãout_chain (OutputChainPtr): The output chain to use.\nvariance\n\nvariance[size: Dim, type: DType](src: Buffer[size, type], mean_value: SIMD[type, 1], correction: Int) -> SIMD[type, 1]\n\nGiven a mean, computes the variance of elements in a buffer.\n\nThe mean value is used to avoid a second pass over the data:\n\nvariance = sum((x - E(x))^2) / (size - correction)\n\nParameters:\n\n‚Äãsize (Dim): The buffer size.\n‚Äãtype (DType): The buffer elements dtype.\n\nArgs:\n\n‚Äãsrc (Buffer[size, type]): The buffer.\n‚Äãmean_value (SIMD[type, 1]): The mean value of the buffer.\n‚Äãcorrection (Int): Normalize variance by size - correction.\n\nReturns:\n\nThe variance value of the elements in a buffer.\n\nvariance[size: Dim, type: DType](src: Buffer[size, type], correction: Int) -> SIMD[type, 1]\n\nComputes the variance value of the elements in a buffer.\n\nvariance(src) = sum((x - E(x))^2) / (size - correction)\n\nParameters:\n\n‚Äãsize (Dim): The buffer size.\n‚Äãtype (DType): The buffer elements dtype.\n\nArgs:\n\n‚Äãsrc (Buffer[size, type]): The buffer.\n‚Äãcorrection (Int): Normalize variance by size - correction (Default=1).\n\nReturns:\n\nThe variance value of the elements in a buffer.\n\nall_true\n\nall_true[size: Dim, type: DType](src: Buffer[size, type]) -> Bool\n\nReturns True if all the elements in a buffer are True and False otherwise.\n\nParameters:\n\n‚Äãsize (Dim): The buffer size.\n‚Äãtype (DType): The buffer elements dtype.\n\nArgs:\n\n‚Äãsrc (Buffer[size, type]): The buffer.\n\nReturns:\n\nTrue if all of the elements of the buffer are True and False otherwise.\n\nany_true\n\nany_true[size: Dim, type: DType](src: Buffer[size, type]) -> Bool\n\nReturns True if any the elements in a buffer are True and False otherwise.\n\nParameters:\n\n‚Äãsize (Dim): The buffer size.\n‚Äãtype (DType): The buffer elements dtype.\n\nArgs:\n\n‚Äãsrc (Buffer[size, type]): The buffer.\n\nReturns:\n\nTrue if any of the elements of the buffer are True and False otherwise.\n\nnone_true\n\nnone_true[size: Dim, type: DType](src: Buffer[size, type]) -> Bool\n\nReturns True if none of the elements in a buffer are True and False otherwise.\n\nParameters:\n\n‚Äãsize (Dim): The buffer size.\n‚Äãtype (DType): The buffer elements dtype.\n\nArgs:\n\n‚Äãsrc (Buffer[size, type]): The buffer.\n\nReturns:\n\nTrue if none of the elements of the buffer are True and False otherwise.\n\nargmax\n\nargmax[type: DType, out_type: DType, rank: Int](input: NDBuffer[rank, create_unknown[$builtin::$int::Int][rank](), type], axis: Int, output: NDBuffer[rank, create_unknown[$builtin::$int::Int][rank](), out_type], out_chain: OutputChainPtr)\n\nFinds the indices of the maximum element along the specified axis.\n\nParameters:\n\n‚Äãtype (DType): Type of the input tensor.\n‚Äãout_type (DType): Type of the output tensor.\n‚Äãrank (Int): The rank of the input / output.\n\nArgs:\n\n‚Äãinput (NDBuffer[rank, create_unknown[$builtin::$int::Int][rank](), type]): The input tensor.\n‚Äãaxis (Int): The axis.\n‚Äãoutput (NDBuffer[rank, create_unknown[$builtin::$int::Int][rank](), out_type]): The output tensor.\n‚Äãout_chain (OutputChainPtr): The chain to attach results to.\n\nargmax[type: DType, out_type: DType, axis_type: DType, rank: Int](input: NDBuffer[rank, create_unknown[$builtin::$int::Int][rank](), type], axis_buf: NDBuffer[1, create_unknown[$builtin::$int::Int][1](), axis_type], output: NDBuffer[rank, create_unknown[$builtin::$int::Int][rank](), out_type], out_chain: OutputChainPtr)\n\nFinds the indices of the maximum element along the specified axis.\n\nParameters:\n\n‚Äãtype (DType): Type of the input tensor.\n‚Äãout_type (DType): Type of the output tensor.\n‚Äãaxis_type (DType): Type of the axis tensor.\n‚Äãrank (Int): The rank of the input / output.\n\nArgs:\n\n‚Äãinput (NDBuffer[rank, create_unknown[$builtin::$int::Int][rank](), type]): The input tensor.\n‚Äãaxis_buf (NDBuffer[1, create_unknown[$builtin::$int::Int][1](), axis_type]): The axis tensor.\n‚Äãoutput (NDBuffer[rank, create_unknown[$builtin::$int::Int][rank](), out_type]): The axis tensor.\n‚Äãout_chain (OutputChainPtr): The chain to attach results to.\nargmin\n\nargmin[type: DType, out_type: DType, rank: Int](input: NDBuffer[rank, create_unknown[$builtin::$int::Int][rank](), type], axis: Int, output: NDBuffer[rank, create_unknown[$builtin::$int::Int][rank](), out_type], out_chain: OutputChainPtr)\n\nFinds the indices of the maximum element along the specified axis.\n\nParameters:\n\n‚Äãtype (DType): Type of the input tensor.\n‚Äãout_type (DType): Type of the output tensor.\n‚Äãrank (Int): The rank of the input / output.\n\nArgs:\n\n‚Äãinput (NDBuffer[rank, create_unknown[$builtin::$int::Int][rank](), type]): The input tensor.\n‚Äãaxis (Int): The axis.\n‚Äãoutput (NDBuffer[rank, create_unknown[$builtin::$int::Int][rank](), out_type]): The output tensor.\n‚Äãout_chain (OutputChainPtr): The chain to attach results to.\n\nargmin[type: DType, out_type: DType, axis_type: DType, rank: Int](input: NDBuffer[rank, create_unknown[$builtin::$int::Int][rank](), type], axis_buf: NDBuffer[1, create_unknown[$builtin::$int::Int][1](), axis_type], output: NDBuffer[rank, create_unknown[$builtin::$int::Int][rank](), out_type], out_chain: OutputChainPtr)\n\nFinds the indices of the minimum element along the specified axis.\n\nParameters:\n\n‚Äãtype (DType): Type of the input tensor.\n‚Äãout_type (DType): Type of the output tensor.\n‚Äãaxis_type (DType): Type of the axis tensor.\n‚Äãrank (Int): The rank of the input / output.\n\nArgs:\n\n‚Äãinput (NDBuffer[rank, create_unknown[$builtin::$int::Int][rank](), type]): The input tensor.\n‚Äãaxis_buf (NDBuffer[1, create_unknown[$builtin::$int::Int][1](), axis_type]): The axis tensor.\n‚Äãoutput (NDBuffer[rank, create_unknown[$builtin::$int::Int][rank](), out_type]): The axis tensor.\n‚Äãout_chain (OutputChainPtr): The chain to attach results to.\nreduce_shape\n\nreduce_shape[input_rank: Int, input_type: DType, axis_type: DType, single_thread_blocking_override: Bool](input_buf: NDBuffer[input_rank, create_unknown[$builtin::$int::Int][input_rank](), input_type], axis_buf: NDBuffer[1, create_unknown[$builtin::$int::Int][1](), axis_type]) -> StaticIntTuple[input_rank]\n\nCompute the output shape of a pad operation, and assert the inputs are compatible.\n\nParameters:\n\n‚Äãinput_rank (Int): Input_rank of the input tensor.\n‚Äãinput_type (DType): Type of the input tensor.\n‚Äãaxis_type (DType): Type of the axis tensor.\n‚Äãsingle_thread_blocking_override (Bool): Whether this function can block.\n\nArgs:\n\n‚Äãinput_buf (NDBuffer[input_rank, create_unknown[$builtin::$int::Int][input_rank](), input_type]): The input tensor.\n‚Äãaxis_buf (NDBuffer[1, create_unknown[$builtin::$int::Int][1](), axis_type]): The axis tensor.\n\nReturns:\n\nThe output shape.\n\ncumsum\n\ncumsum[size: Int, type: DType](dst: Buffer[__init__(size), type], src: Buffer[__init__(size), type])\n\nComputes the cumulative sum of all elements in a buffer. dst[i] = src[i] + src[i-1] + ‚Ä¶ + src[0].\n\nParameters:\n\n‚Äãsize (Int): The size of the input and output buffers.\n‚Äãtype (DType): The type of the elements of the input and output buffers.\n\nArgs:\n\n‚Äãdst (Buffer[__init__(size), type]): The buffer that stores the result of cumulative sum operation.\n‚Äãsrc (Buffer[__init__(size), type]): The buffer of elements for which the cumulative sum is computed.\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - functional",
    "url": "https://docs.modular.com/mojo/stdlib/algorithm/functional.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nfunctional\nreduction\nsort\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nmap\nunroll\nvectorize\nvectorize_unroll\nasync_parallelize\nsync_parallelize\nparallelize\ntile\nunswitch\ntile_and_unswitch\nelementwise\nparallelize_over_rows\nstencil\nfunctional\n\nModule\n\nImplements higher-order functions.\n\nYou can import these APIs from the algorithm package. For example:\n\nfrom algorithm import map\n\nAliases:\n\n‚ÄãStatic1DTileUnitFunc = fn[Int](Int, /) capturing -> None: Signature of a 1d tiled function that performs some work with a static tile size and an offset. i.e.¬†func<tile_size: Int> (offset: Int)\n‚ÄãDynamic1DTileUnitFunc = fn(Int, Int, /) capturing -> None: Signature of a 1d tiled function that performs some work with a dynamic tile size and an offset. i.e.¬†func(offset: Int, tile_size: Int)\n‚ÄãBinaryTile1DTileUnitFunc = fn[Int](Int, Int, /) capturing -> None: Signature of a tiled function that performs some work with a dynamic tile size and a secondary static tile size.\n‚ÄãStatic2DTileUnitFunc = fn[Int, Int](Int, Int, /) capturing -> None: Signature of a 2d tiled function that performs some work with a static tile size and an offset. i.e.¬†func<tile_size_x: Int, tile_size_y: Int> (offset_x: Int, offset_y: Int)\n‚ÄãSwitchedFunction = fn[Bool]() capturing -> None\n‚ÄãSwitchedFunction2 = fn[Bool, Bool]() capturing -> None\n‚ÄãStatic1DTileUnswitchUnitFunc = fn[Int, Bool](Int, Int, /) capturing -> None: Signature of a tiled function that performs some work with a static tile size and an offset. i.e.¬†func<tile_size: Int> (offset: Int)\n‚ÄãDynamic1DTileUnswitchUnitFunc = fn[Bool](Int, Int, Int, /) capturing -> None\nmap\n\nmap[func: fn(Int, /) capturing -> None](size: Int)\n\nMaps a function over a range from 0 to size.\n\nParameters:\n\n‚Äãfunc (fn(Int, /) capturing -> None): Function to map.\n\nArgs:\n\n‚Äãsize (Int): The number of elements.\nunroll\n\nunroll[count: Int, func: fn[Int]() capturing -> None]()\n\nRepeatedly evaluates a function count times.\n\nParameters:\n\n‚Äãcount (Int): A number of repetitions.\n‚Äãfunc (fn[Int]() capturing -> None): The function to evaluate. The function should take a single Int argument.\n\nunroll[dim0: Int, dim1: Int, func: fn[Int, Int]() capturing -> None]()\n\nRepeatedly evaluates a 2D nested loop.\n\nParameters:\n\n‚Äãdim0 (Int): The first dimension size.\n‚Äãdim1 (Int): The second dimension size.\n‚Äãfunc (fn[Int, Int]() capturing -> None): The function to evaluate. The function should take two Int arguments.\n\nunroll[dim0: Int, dim1: Int, dim2: Int, func: fn[Int, Int, Int]() capturing -> None]()\n\nRepeatedly evaluates a 3D nested loop.\n\nParameters:\n\n‚Äãdim0 (Int): The first dimension size.\n‚Äãdim1 (Int): The second dimension size.\n‚Äãdim2 (Int): The second dimension size.\n‚Äãfunc (fn[Int, Int, Int]() capturing -> None): The function to evaluate. The function should take three Int arguments.\nvectorize\n\nvectorize[simd_width: Int, func: fn[Int](Int, /) capturing -> None](size: Int)\n\nMaps a function which is parametrized over a simd_width over a range from 0 to size in simd fashion.\n\nParameters:\n\n‚Äãsimd_width (Int): The SIMD vector width.\n‚Äãfunc (fn[Int](Int, /) capturing -> None): The function for the loop body.\n\nArgs:\n\n‚Äãsize (Int): The total loop count.\nvectorize_unroll\n\nvectorize_unroll[simd_width: Int, unroll_factor: Int, func: fn[Int](Int, /) capturing -> None](size: Int)\n\nMaps a function which is parametrized over a simd_width over a range from 0 to size in simd fashion and unroll the loop by unroll_factor.\n\nParameters:\n\n‚Äãsimd_width (Int): The SIMD vector width.\n‚Äãunroll_factor (Int): The unroll factor for the main loop.\n‚Äãfunc (fn[Int](Int, /) capturing -> None): The function for the loop body.\n\nArgs:\n\n‚Äãsize (Int): The total loop count.\nasync_parallelize\n\nasync_parallelize[func: fn(Int, /) capturing -> None](out_chain: OutputChainPtr, num_work_items: Int)\n\nExecutes func(0) ‚Ä¶ func(num_work_items-1) as sub-tasks in parallel and returns immediately. The out_chain will be marked as ready only when all sub-tasks have completed.\n\nExecute func(0) ‚Ä¶ func(num_work_items-1) as sub-tasks in parallel and mark out_chain as ready when all functions have returned. This function will return when the sub-tasks have been scheduled but not necessarily completed. The runtime may execute the sub-tasks in any order and with any degree of concurrency.\n\nAll free variables in func must be ‚Äúasync safe‚Äù. Currently this means: - The variable must be bound by a by-val function argument (ie no &), or let binding. - The variable‚Äôs type must be ‚Äúasync safe‚Äù, ie is marked as @register_passable and any internal pointers are to memory with lifetime at least until out_chain is ready. In practice, this means only pointers to buffers held alive by the runtime. Consider using sync_parallelize if this requirement is too onerous.\n\nIf num_work_items is 0 then the out_chain is marked as ready before async_parallelize returns. If num_work_items is 1 then func(0) may still be executed as a sub-task.\n\nParameters:\n\n‚Äãfunc (fn(Int, /) capturing -> None): The function to invoke.\n\nArgs:\n\n‚Äãout_chain (OutputChainPtr): Out chain onto which to signal completion.\n‚Äãnum_work_items (Int): Number of parallel tasks.\nsync_parallelize\n\nsync_parallelize[func: fn(Int, /) capturing -> None](out_chain: OutputChainPtr, num_work_items: Int)\n\nExecutes func(0) ‚Ä¶ func(num_work_items-1) as sub-tasks in parallel. Marks out_chain as ready and returns only when all sub-tasks have completed.\n\nExecute func(0) ‚Ä¶ func(num_work_items-1) as sub-tasks in parallel, and return only when they have all functions have returned. The runtime may execute the sub-tasks in any order and with any degree of concurrency. The out_chain will be marked as ready before returning.\n\nParameters:\n\n‚Äãfunc (fn(Int, /) capturing -> None): The function to invoke.\n\nArgs:\n\n‚Äãout_chain (OutputChainPtr): Out chain onto which to signal completion.\n‚Äãnum_work_items (Int): Number of parallel tasks.\nparallelize\n\nparallelize[func: fn(Int, /) capturing -> None]()\n\nExecutes func(0) ‚Ä¶ func(N-1) as sub-tasks in parallel and returns when all are complete. N is chosen to be the number of processors on the system.\n\nExecute func(0) ‚Ä¶ func(N-1) as sub-tasks in parallel. This function will return only after all the sub-tasks have completed.\n\nCAUTION: Creates and destroys a local runtime! Do not use from kernels!\n\nParameters:\n\n‚Äãfunc (fn(Int, /) capturing -> None): The function to invoke.\n\nparallelize[func: fn(Int, /) capturing -> None](num_work_items: Int)\n\nExecutes func(0) ‚Ä¶ func(num_work_items-1) as sub-tasks in parallel and returns when all are complete.\n\nExecute func(0) ‚Ä¶ func(num_work_items-1) as sub-tasks in parallel. This function will return only after all the sub-tasks have completed.\n\nCAUTION: Creates and destroys a local runtime! Do not use from kernels!\n\nParameters:\n\n‚Äãfunc (fn(Int, /) capturing -> None): The function to invoke.\n\nArgs:\n\n‚Äãnum_work_items (Int): Number of parallel tasks.\n\nparallelize[func: fn(Int, /) capturing -> None](num_work_items: Int, num_workers: Int)\n\nExecutes func(0) ‚Ä¶ func(num_work_items-1) as sub-tasks in parallel and returns when all are complete.\n\nExecute func(0) ‚Ä¶ func(num_work_items-1) as sub-tasks in parallel. This function will return only after all the sub-tasks have completed.\n\nParameters:\n\n‚Äãfunc (fn(Int, /) capturing -> None): The function to invoke.\n\nArgs:\n\n‚Äãnum_work_items (Int): Number of parallel tasks.\n‚Äãnum_workers (Int): The number of works to use for execution.\ntile\n\ntile[workgroup_function: fn[Int](Int, /) capturing -> None, tile_size_list: VariadicList[Int]](offset: Int, upperbound: Int)\n\nA generator that launches work groups in specified list of tile sizes.\n\nA workgroup function is a function that can process a configurable consecutive ‚Äútile‚Äù of workload. E.g. work_on[3](5) should launch computation on item 5,6,7, and should be semantically equivalent to work_on[1](5), work_on[1](6), work_on[1](7).\n\nThis generator will try to proceed with the given list of tile sizes on the listed order. E.g. tile[func, (3,2,1)](offset, upperbound) will try to call func[3] starting from offset until remaining work is less than 3 from upperbound and then try func[2], and then func[1], etc.\n\nParameters:\n\n‚Äãworkgroup_function (fn[Int](Int, /) capturing -> None): Workgroup function that processes one tile of workload.\n‚Äãtile_size_list (VariadicList[Int]): List of tile sizes to launch work.\n\nArgs:\n\n‚Äãoffset (Int): The initial index to start the work from.\n‚Äãupperbound (Int): The runtime upperbound that the work function should not exceed.\n\ntile[workgroup_function: fn(Int, Int, /) capturing -> None](offset: Int, upperbound: Int, tile_size_list: VariadicList[Int])\n\nA generator that launches work groups in specified list of tile sizes.\n\nThis is the version of tile generator for the case where work_group function can take the tile size as a runtime value.\n\nParameters:\n\n‚Äãworkgroup_function (fn(Int, Int, /) capturing -> None): Workgroup function that processes one tile of workload.\n\nArgs:\n\n‚Äãoffset (Int): The initial index to start the work from.\n‚Äãupperbound (Int): The runtime upperbound that the work function should not exceed.\n‚Äãtile_size_list (VariadicList[Int]): List of tile sizes to launch work.\n\ntile[secondary_tile_size_list: VariadicList[Int], secondary_cleanup_tile: Int, workgroup_function: fn[Int](Int, Int, /) capturing -> None](offset: Int, upperbound: Int, primary_tile_size_list: VariadicList[Int], primary_cleanup_tile: Int)\n\nA generator that launches work groups in specified list of tile sizes until the sum of primary_tile_sizes has exceeded the upperbound.\n\nParameters:\n\n‚Äãsecondary_tile_size_list (VariadicList[Int]): List of static tile sizes to launch work.\n‚Äãsecondary_cleanup_tile (Int): Last static tile to use when primary tile sizes don‚Äôt fit exactly within the upperbound.\n‚Äãworkgroup_function (fn[Int](Int, Int, /) capturing -> None): Workgroup function that processes one tile of workload.\n\nArgs:\n\n‚Äãoffset (Int): The initial index to start the work from.\n‚Äãupperbound (Int): The runtime upperbound that the work function should not exceed.\n‚Äãprimary_tile_size_list (VariadicList[Int]): List of dynamic tile sizes to launch work.\n‚Äãprimary_cleanup_tile (Int): Last dynamic tile to use when primary tile sizes don‚Äôt fit exactly within the upperbound.\n\ntile[workgroup_function: fn[Int, Int](Int, Int, /) capturing -> None, tile_sizes_x: VariadicList[Int], tile_sizes_y: VariadicList[Int]](offset_x: Int, offset_y: Int, upperbound_x: Int, upperbound_y: Int)\n\nLaunches workgroup_function using the largest tile sizes possible in each dimension, starting from the x and y offset, until the x and y upperbounds are reached.\n\nParameters:\n\n‚Äãworkgroup_function (fn[Int, Int](Int, Int, /) capturing -> None): Function that is invoked for each tile and offset.\n‚Äãtile_sizes_x (VariadicList[Int]): List of tile sizes to use for the first parameter of workgroup_function.\n‚Äãtile_sizes_y (VariadicList[Int]): List of tile sizes to use for the second parameter of workgroup_function.\n\nArgs:\n\n‚Äãoffset_x (Int): Initial x offset passed to workgroup_function.\n‚Äãoffset_y (Int): Initial y offset passed to workgroup_function.\n‚Äãupperbound_x (Int): Max offset in x dimension passed to workgroup function.\n‚Äãupperbound_y (Int): Max offset in y dimension passed to workgroup function.\nunswitch\n\nunswitch[switched_func: fn[Bool]() capturing -> None](dynamic_switch: Bool)\n\nPerforms a functional unswitch transformation.\n\nUnswitch is a simple pattern that is similar idea to loop unswitching pass but extended to functional patterns. The pattern facilitates the following code transformation that reduces the number of branches in the generated code\n\nBefore:\n\nfor i in range(...)\n    if i < xxx:\n        ...\n\nAfter:\n\nif i < ...\n    for i in range(...)\n        ...\nelse\n    for i in range(...)\n        if i < xxx:\n            ...\n\nThis unswitch function generalizes that pattern with the help of meta parameters and can be used to perform both loop unswitching and other tile predicate lifting like in simd and amx.\n\nTODO: Generalize to support multiple predicates. TODO: Once nested lambdas compose well should make unswitch compose with tile in an easy way.\n\nParameters:\n\n‚Äãswitched_func (fn[Bool]() capturing -> None): The function containing the inner loop logic that can be unswitched.\n\nArgs:\n\n‚Äãdynamic_switch (Bool): The dynamic condition that enables the unswitched code path.\n\nunswitch[switched_func: fn[Bool, Bool]() capturing -> None](dynamic_switch_a: Bool, dynamic_switch_b: Bool)\n\nPerforms a functional 2-predicates unswitch transformation.\n\nParameters:\n\n‚Äãswitched_func (fn[Bool, Bool]() capturing -> None): The function containing the inner loop logic that has 2 predicates which can be unswitched.\n\nArgs:\n\n‚Äãdynamic_switch_a (Bool): The first dynamic condition that enables the outer unswitched code path.\n‚Äãdynamic_switch_b (Bool): The second dynamic condition that enables the inner unswitched code path.\ntile_and_unswitch\n\ntile_and_unswitch[workgroup_function: fn[Int, Bool](Int, Int, /) capturing -> None, tile_size_list: VariadicList[Int]](offset: Int, upperbound: Int)\n\nPerforms time and unswitch functional transformation.\n\nA variant of static tile given a workgroup function that can be unswitched. This generator is a fused version of tile and unswitch, where the static unswitch is true throughout the ‚Äúinner‚Äù portion of the workload and is false only on the residue tile.\n\nParameters:\n\n‚Äãworkgroup_function (fn[Int, Bool](Int, Int, /) capturing -> None): Workgroup function that processes one tile of workload.\n‚Äãtile_size_list (VariadicList[Int]): List of tile sizes to launch work.\n\nArgs:\n\n‚Äãoffset (Int): The initial index to start the work from.\n‚Äãupperbound (Int): The runtime upperbound that the work function should not exceed.\n\ntile_and_unswitch[workgroup_function: fn[Bool](Int, Int, Int, /) capturing -> None](offset: Int, upperbound: Int, tile_size_list: VariadicList[Int])\n\nPerforms time and unswitch functional transformation.\n\nA variant of dynamic tile given a workgroup function that can be unswitched. This generator is a fused version of tile and unswitch, where the static unswitch is true throughout the ‚Äúinner‚Äù portion of the workload and is false only on the residue tile.\n\nParameters:\n\n‚Äãworkgroup_function (fn[Bool](Int, Int, Int, /) capturing -> None): Workgroup function that processes one tile of workload.\n\nArgs:\n\n‚Äãoffset (Int): The initial index to start the work from.\n‚Äãupperbound (Int): The runtime upperbound that the work function should not exceed.\n‚Äãtile_size_list (VariadicList[Int]): List of tile sizes to launch work.\nelementwise\n\nelementwise[rank: Int, simd_width: Int, func: fn[Int, Int](StaticIntTuple[*(0,1)], /) capturing -> None](shape: StaticIntTuple[rank], out_chain: OutputChainPtr)\n\nExecutes func[width, rank](indices) as sub-tasks for a suitable combination of width and indices so as to cover shape.\n\nParameters:\n\n‚Äãrank (Int): The rank of the buffer.\n‚Äãsimd_width (Int): The SIMD vector width to use.\n‚Äãfunc (fn[Int, Int](StaticIntTuple[*(0,1)], /) capturing -> None): The body function.\n\nArgs:\n\n‚Äãshape (StaticIntTuple[rank]): The shape of the buffer.\n‚Äãout_chain (OutputChainPtr): The output chain to attach results to.\nparallelize_over_rows\n\nparallelize_over_rows[rank: Int, func: fn(Int, Int, /) capturing -> None](shape: StaticIntTuple[rank], axis: Int, out_chain: OutputChainPtr, grain_size: Int)\n\nParallelize func over non-axis dims of shape.\n\nParameters:\n\n‚Äãrank (Int): Rank of shape.\n‚Äãfunc (fn(Int, Int, /) capturing -> None): Function to call on range of rows.\n\nArgs:\n\n‚Äãshape (StaticIntTuple[rank]): Shape to parallelize over.\n‚Äãaxis (Int): Rows are slices along the axis dimension of shape.\n‚Äãout_chain (OutputChainPtr): The out chain to attach results to.\n‚Äãgrain_size (Int): The minimum number of elements to warrant using an additional thread.\nstencil\n\nstencil[rank: Int, stencil_rank: Int, stencil_axis: StaticIntTuple[stencil_rank], simd_width: Int, type: DType, map_fn: fn(StaticIntTuple[stencil_rank], /) capturing -> Tuple[StaticIntTuple[stencil_rank], StaticIntTuple[stencil_rank]], map_strides: StaticIntTuple[stencil_rank], load_fn: fn[Int, DType](StaticIntTuple[rank], /) capturing -> SIMD[*(0,1), *(0,0)], compute_init_fn: fn[Int]() capturing -> SIMD[type, *(0,0)], compute_fn: fn[Int](StaticIntTuple[rank], SIMD[type, *(0,0)], SIMD[type, *(0,0)], /) capturing -> SIMD[type, *(0,0)], compute_finalize_fn: fn[Int](StaticIntTuple[rank], SIMD[type, *(0,0)], /) capturing -> None](shape: StaticIntTuple[rank], out_chain: OutputChainPtr)\n\nComputes stencil operation in parallel.\n\nComputes output as a function that processes input stencils, stencils are computed as a continuous region for each output point that is determined by map_fn : map_fn(y) -> lower_bound, upper_bound. The boundary conditions for regions that fail out of the input domain are handled by load_fn.\n\nParameters:\n\n‚Äãrank (Int): Input and output domain rank.\n‚Äãstencil_rank (Int): Rank of stencil subdomain slice.\n‚Äãstencil_axis (StaticIntTuple[stencil_rank]): Stencil subdomain axes.\n‚Äãsimd_width (Int): The SIMD vector width to use.\n‚Äãtype (DType): The input and output data type.\n‚Äãmap_fn (fn(StaticIntTuple[stencil_rank], /) capturing -> Tuple[StaticIntTuple[stencil_rank], StaticIntTuple[stencil_rank]]): A function that a point in the output domain to the input co-domain.\n‚Äãmap_strides (StaticIntTuple[stencil_rank]): A list of integers for the strides in each point in the co-domain.\n‚Äãload_fn (fn[Int, DType](StaticIntTuple[rank], /) capturing -> SIMD[*(0,1), *(0,0)]): A function that loads a vector of simd_width from input.\n‚Äãcompute_init_fn (fn[Int]() capturing -> SIMD[type, *(0,0)]): A function that initialzies vector compute over the stencil.\n‚Äãcompute_fn (fn[Int](StaticIntTuple[rank], SIMD[type, *(0,0)], SIMD[type, *(0,0)], /) capturing -> SIMD[type, *(0,0)]): A function the process the value computed for each point in the stencil.\n‚Äãcompute_finalize_fn (fn[Int](StaticIntTuple[rank], SIMD[type, *(0,0)], /) capturing -> None): A function that finalizes the computation of a point in the output domain given a stencil.\n\nArgs:\n\n‚Äãshape (StaticIntTuple[rank]): The shape of the buffer.\n‚Äãout_chain (OutputChainPtr): The our chain to attach results to.\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - Mojoüî• modules",
    "url": "https://docs.modular.com/mojo/lib.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nMojoüî• modules\n\nMojo is a very young language, so these are the only modules we‚Äôre making available at this time. There is much more to come!\n\nStandard library modules\narg\nImplements functions and variables for interacting with execution and system environment.\natomic\nImplements the Atomic class.\nautotuning\nImplements the autotune functionality.\nbase64\nProvides functions for base64 encoding strings.\nbenchmark\nImplements the benchmark module for runtime benchmarking.\nbit\nProvides functions for bit manipulation.\nbool\nImplements the Bool class.\nbuffer\nImplements the Buffer class.\nbuiltin_list\nImplements the ListLiteral class.\nbuiltin_slice\nImplements slice.\ncomplex\nImplements the Complex type.\nconstrained\nImplements compile time contraints.\ncoroutine\nImplements classes and methods for coroutines.\ndebug_assert\nImplements a debug assert.\ndtype\nImplements the DType class.\nenv\nImplements basic routines for working with the OS.\nerror\nImplements the Error class.\nfile\nImplements the file based methods.\nfloat_literal\nImplements the FloatLiteral class.\nfunctional\nImplements higher-order functions.\nindex\nImplements StaticIntTuple which is commonly used to represent N-D indices.\ninfo\nImplements methods for querying the host target info.\nint\nImplements the Int class.\nintrinsics\nDefines intrinsics.\nio\nProvides utilities for working with input/output.\nlen\nProvides the len function.\nlimit\nProvides interfaces to query numeric various numeric properties of types.\nlist\nProvides utilities for working with static and variadic lists.\nmath\nDefines math utilities.\nmemory\nDefines functions for memory manipulations.\nobject\nDefines the object type, which is used to represent untyped values.\nobject\nImplements PythonObject.\nparam_env\nImplements functions for retrieving compile-time defines.\npath\nAliases:\npolynomial\nProvides two implementations for evaluating polynomials.\npython\nImplements Python interoperability.\nrandom\nProvides functions for random numbers.\nrange\nImplements a ‚Äòrange‚Äô call.\nrebind\nImplements type rebind.\nreduction\nImplements SIMD reductions.\nsimd\nImplements SIMD struct.\nsort\nImplements sorting functions.\nstatic_tuple\nImplements StaticTuple, a statically-sized uniform container.\nstring\nImplements basic object methods for working with strings.\nstring_literal\nImplements the StringLiteral class.\nstringref\nImplements the StringRef class.\ntensor\nImplements the Tensor type.\ntensor_shape\nImplements the TensorShape type.\ntensor_spec\nImplements the TensorSpec type.\ntesting\nImplements various testing utils.\ntime\nImplements basic utils for working with time.\ntuple\nImplements the Tuple type.\ntype_aliases\nDefines some type aliases.\nunsafe\nImplements classes for working with unsafe pointers.\nvector\nDefines several vector-like classes.\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started"
  },
  {
    "title": "Modular Docs - Ray tracing in Mojo",
    "url": "https://docs.modular.com/mojo/notebooks/RayTracing.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nStep 1: Basic definitions\nStep 2: Ray tracing\nStep 3: More spheres\nStep 4: Add lighting\nStep 5: Add specular lighting\nStep 6: Add background\nNext steps\nRay tracing in Mojo\n\nThis tutorial about ray tracing is based on the popular tutorial Understandable RayTracing in C++. The mathematical explanations are well described in that tutorial, so we‚Äôll just point you to the appropriate sections for reference as we implement a basic ray tracer in Mojo.\n\nStep 1: Basic definitions\n\nWe‚Äôll start by defining a Vec3f struct, which will use to represent a vector in 3D space as well as RGB pixels. We‚Äôll use a SIMD representation for our vector to enable vectorized operations. Note that since the SIMD type only allows a power of 2, we always pad the underlying storage with a 0.\n\nfrom math import rsqrt\n\n\n@register_passable(\"trivial\")\nstruct Vec3f:\n    var data: SIMD[DType.float32, 4]\n\n    @always_inline\n    fn __init__(x: Float32, y: Float32, z: Float32) -> Self:\n        return Vec3f {data: SIMD[DType.float32, 4](x, y, z, 0)}\n\n    @always_inline\n    fn __init__(data: SIMD[DType.float32, 4]) -> Self:\n        return Vec3f {data: data}\n\n    @always_inline\n    @staticmethod\n    fn zero() -> Vec3f:\n        return Vec3f(0, 0, 0)\n\n    @always_inline\n    fn __sub__(self, other: Vec3f) -> Vec3f:\n        return self.data - other.data\n\n    @always_inline\n    fn __add__(self, other: Vec3f) -> Vec3f:\n        return self.data + other.data\n\n    @always_inline\n    fn __matmul__(self, other: Vec3f) -> Float32:\n        return (self.data * other.data).reduce_add()\n\n    @always_inline\n    fn __mul__(self, k: Float32) -> Vec3f:\n        return self.data * k\n\n    @always_inline\n    fn __neg__(self) -> Vec3f:\n        return self.data * -1.0\n\n    @always_inline\n    fn __getitem__(self, idx: Int) -> SIMD[DType.float32, 1]:\n        return self.data[idx]\n\n    @always_inline\n    fn cross(self, other: Vec3f) -> Vec3f:\n        let self_zxy = self.data.shuffle[2, 0, 1, 3]()\n        let other_zxy = other.data.shuffle[2, 0, 1, 3]()\n        return (self_zxy * other.data - self.data * other_zxy).shuffle[\n            2, 0, 1, 3\n        ]()\n\n    @always_inline\n    fn normalize(self) -> Vec3f:\n        return self.data * rsqrt(self @ self)\n\nWe now define our Image struct, which will store the RGB pixels of our images. It also contains a method to conver this Mojo struct into a numpy image, which will be used for implementing a straightforward displaying mechanism. We will also implement a function for loading PNG files from disk.\n\nFirst install the required libraries:\n\n%%python\nfrom importlib.util import find_spec\nimport shutil\nimport subprocess\n\nfix = \"\"\"\n-------------------------------------------------------------------------\nfix following the steps here:\n    https://github.com/modularml/mojo/issues/1085#issuecomment-1771403719\n-------------------------------------------------------------------------\n\"\"\"\n\ndef install_if_missing(name: str):\n    if find_spec(name):\n        return\n\n    print(f\"{name} not found, installing...\")\n    try:\n        if shutil.which('python3'): python = \"python3\"\n        elif shutil.which('python'): python = \"python\"\n        else: raise (\"python not on path\" + fix)\n        subprocess.check_call([python, \"-m\", \"pip\", \"install\", name])\n    except:\n        raise ImportError(f\"{name} not found\" + fix)\n\ninstall_if_missing(\"numpy\")\ninstall_if_missing(\"matplotlib\")\nfrom python import Python\nfrom python.object import PythonObject\n\nstruct Image:\n    # reference count used to make the object efficiently copyable\n    var rc: Pointer[Int]\n    # the two dimensional image is represented as a flat array\n    var pixels: Pointer[Vec3f]\n    var height: Int\n    var width: Int\n\n    fn __init__(inout self, height: Int, width: Int):\n        self.height = height\n        self.width = width\n        self.pixels = Pointer[Vec3f].alloc(self.height * self.width)\n        self.rc = Pointer[Int].alloc(1)\n        self.rc.store(1)\n\n    fn __copyinit__(inout self, other: Self):\n        other._inc_rc()\n        self.pixels = other.pixels\n        self.rc = other.rc\n        self.height = other.height\n        self.width = other.width\n\n    fn __del__(owned self):\n        self._dec_rc()\n\n    fn _get_rc(self) -> Int:\n        return self.rc.load()\n\n    fn _dec_rc(self):\n        let rc = self._get_rc()\n        if rc > 1:\n            self.rc.store(rc - 1)\n            return\n        self._free()\n\n    fn _inc_rc(self):\n        let rc = self._get_rc()\n        self.rc.store(rc + 1)\n\n    fn _free(self):\n        self.rc.free()\n        self.pixels.free()\n\n    @always_inline\n    fn set(self, row: Int, col: Int, value: Vec3f) -> None:\n        self.pixels.store(self._pos_to_index(row, col), value)\n\n    @always_inline\n    fn _pos_to_index(self, row: Int, col: Int) -> Int:\n        # Convert a (rol, col) position into an index in the underlying linear storage\n        return row * self.width + col\n\n    def to_numpy_image(self) -> PythonObject:\n        let np = Python.import_module(\"numpy\")\n        let plt = Python.import_module(\"matplotlib.pyplot\")\n\n        let np_image = np.zeros((self.height, self.width, 3), np.float32)\n\n        # We use raw pointers to efficiently copy the pixels to the numpy array\n        let out_pointer = Pointer(\n            __mlir_op.`pop.index_to_pointer`[\n                _type=__mlir_type[`!kgen.pointer<scalar<f32>>`]\n            ](\n                SIMD[DType.index, 1](\n                    np_image.__array_interface__[\"data\"][0].__index__()\n                ).value\n            )\n        )\n        let in_pointer = Pointer(\n            __mlir_op.`pop.index_to_pointer`[\n                _type=__mlir_type[`!kgen.pointer<scalar<f32>>`]\n            ](SIMD[DType.index, 1](self.pixels.__as_index()).value)\n        )\n\n        for row in range(self.height):\n            for col in range(self.width):\n                let index = self._pos_to_index(row, col)\n                for dim in range(3):\n                    out_pointer.store(\n                        index * 3 + dim, in_pointer[index * 4 + dim]\n                    )\n\n        return np_image\n\n\ndef load_image(fname: String) -> Image:\n    let np = Python.import_module(\"numpy\")\n    let plt = Python.import_module(\"matplotlib.pyplot\")\n\n    let np_image = plt.imread(fname)\n    let rows = np_image.shape[0].__index__()\n    let cols = np_image.shape[1].__index__()\n    let image = Image(rows, cols)\n\n    let in_pointer = Pointer(\n        __mlir_op.`pop.index_to_pointer`[\n            _type=__mlir_type[`!kgen.pointer<scalar<f32>>`]\n        ](\n            SIMD[DType.index, 1](\n                np_image.__array_interface__[\"data\"][0].__index__()\n            ).value\n        )\n    )\n    let out_pointer = Pointer(\n        __mlir_op.`pop.index_to_pointer`[\n            _type=__mlir_type[`!kgen.pointer<scalar<f32>>`]\n        ](SIMD[DType.index, 1](image.pixels.__as_index()).value)\n    )\n    for row in range(rows):\n        for col in range(cols):\n            let index = image._pos_to_index(row, col)\n            for dim in range(3):\n                out_pointer.store(\n                    index * 4 + dim, in_pointer[index * 3 + dim]\n                )\n    return image\n\nWe then add a function for quickly displaying an Image into the notebook. Our Python interop comes in quite handy.\n\ndef render(image: Image):\n    np = Python.import_module(\"numpy\")\n    plt = Python.import_module(\"matplotlib.pyplot\")\n    colors = Python.import_module(\"matplotlib.colors\")\n    dpi = 32\n    fig = plt.figure(1, [image.height // 10, image.width // 10], dpi)\n\n    plt.imshow(image.to_numpy_image())\n    plt.axis(\"off\")\n    plt.show()\n\nFinally, we test all our code so far with a simple image, which is the one rendered in the Step 1 of the C++ tutorial.\n\nlet image = Image(192, 256)\n\nfor row in range(image.height):\n    for col in range(image.width):\n        image.set(\n            row,\n            col,\n            Vec3f(Float32(row) / image.height, Float32(col) / image.width, 0),\n        )\n\nrender(image)\n\nStep 2: Ray tracing\n\nNow we‚Äôll perform ray tracing from a camera into a scene with a sphere. Before reading the code below, we suggest you read more about how this works conceptually from Step 2 of the C++ tutorial.\n\nWe first define the Material and Sphere structs, which are the new data structures we‚Äôll need.\n\nfrom math import sqrt\n\n\n@register_passable(\"trivial\")\nstruct Material:\n    var color: Vec3f\n    var albedo: Vec3f\n    var specular_component: Float32\n\n    fn __init__(color: Vec3f) -> Material:\n        return Material {\n            color: color, albedo: Vec3f(0, 0, 0), specular_component: 0\n        }\n\n    fn __init__(\n        color: Vec3f, albedo: Vec3f, specular_component: Float32\n    ) -> Material:\n        return Material {\n            color: color, albedo: albedo, specular_component: specular_component\n        }\n\n\nalias W = 1024\nalias H = 768\nalias bg_color = Vec3f(0.02, 0.02, 0.02)\nlet shiny_yellow = Material(Vec3f(0.95, 0.95, 0.4), Vec3f(0.7, 0.6, 0), 30.0)\nlet green_rubber = Material(Vec3f( 0.3,  0.7, 0.3), Vec3f(0.9, 0.1, 0), 1.0)\n\n\n@register_passable(\"trivial\")\nstruct Sphere:\n    var center: Vec3f\n    var radius: Float32\n    var material: Material\n\n    fn __init__(c: Vec3f, r: Float32, material: Material) -> Self:\n        return Sphere {center: c, radius: r, material: material}\n\n    @always_inline\n    fn intersects(self, orig: Vec3f, dir: Vec3f, inout dist: Float32) -> Bool:\n        \"\"\"This method returns True if a given ray intersects this sphere.\n        And if it does, it writes in the `dist` parameter the distance to the\n        origin of the ray.\n        \"\"\"\n        let L = orig - self.center\n        let a = dir @ dir\n        let b = 2 * (dir @ L)\n        let c = L @ L - self.radius * self.radius\n        let discriminant = b * b - 4 * a * c\n        if discriminant < 0:\n            return False\n        if discriminant == 0:\n            dist = -b / 2 * a\n            return True\n        let q = -0.5 * (b + sqrt(discriminant)) if b > 0 else -0.5 * (\n            b - sqrt(discriminant)\n        )\n        var t0 = q / a\n        let t1 = c / q\n        if t0 > t1:\n            t0 = t1\n        if t0 < 0:\n            t0 = t1\n            if t0 < 0:\n                return False\n\n        dist = t0\n        return True\n\nWe then define a cast_ray method, which will be used to figure out the color of a particular pixel in the image we‚Äôll produce. It basically works by identifying whether this ray intersects the sphere or not.\n\nfn cast_ray(orig: Vec3f, dir: Vec3f, sphere: Sphere) -> Vec3f:\n    var dist: Float32 = 0\n    if not sphere.intersects(orig, dir, dist):\n        return bg_color\n\n    return sphere.material.color\n\nLastly, we parallelize the ray tracing for every pixel row-wise.\n\nfrom math import tan, acos\nfrom algorithm import parallelize\n\n\nfn create_image_with_sphere(sphere: Sphere, height: Int, width: Int) -> Image:\n    let image = Image(height, width)\n\n    @parameter\n    fn _process_row(row: Int):\n        let y = -((2.0 * row + 1) / height - 1)\n        for col in range(width):\n            let x = ((2.0 * col + 1) / width - 1) * width / height\n            let dir = Vec3f(x, y, -1).normalize()\n            image.set(row, col, cast_ray(Vec3f.zero(), dir, sphere))\n\n    parallelize[_process_row](height)\n\n    return image\n\n\nrender(\n    create_image_with_sphere(Sphere(Vec3f(-3, 0, -16), 2, shiny_yellow), H, W)\n)\n\nStep 3: More spheres\n\nThis section corresponds to the Step 3 of the C++ tutorial.\n\nWe include here all the necessary changes:\n\nWe add 3 more spheres to the scene, 2 of them being of ivory material.\nWhen we intersect the ray with the sphere, we render the color of the closest sphere.\nfrom algorithm import parallelize\nfrom utils.vector import DynamicVector\nfrom math.limit import inf\n\n\nfn scene_intersect(\n    orig: Vec3f,\n    dir: Vec3f,\n    spheres: DynamicVector[Sphere],\n    background: Material,\n) -> Material:\n    var spheres_dist = inf[DType.float32]()\n    var material = background\n\n    for i in range(0, spheres.size):\n        var dist = inf[DType.float32]()\n        if spheres[i].intersects(orig, dir, dist) and dist < spheres_dist:\n            spheres_dist = dist\n            material = spheres[i].material\n\n    return material\n\n\nfn cast_ray(\n    orig: Vec3f, dir: Vec3f, spheres: DynamicVector[Sphere]\n) -> Material:\n    let background = Material(Vec3f(0.02, 0.02, 0.02))\n    return scene_intersect(orig, dir, spheres, background)\n\n\nfn create_image_with_spheres(\n    spheres: DynamicVector[Sphere], height: Int, width: Int\n) -> Image:\n    let image = Image(height, width)\n\n    @parameter\n    fn _process_row(row: Int):\n        let y = -((2.0 * row + 1) / height - 1)\n        for col in range(width):\n            let x = ((2.0 * col + 1) / width - 1) * width / height\n            let dir = Vec3f(x, y, -1).normalize()\n            image.set(row, col, cast_ray(Vec3f.zero(), dir, spheres).color)\n\n    parallelize[_process_row](height)\n\n    return image\n\nlet spheres = DynamicVector[Sphere]()\nspheres.push_back(Sphere(Vec3f(-3,      0, -16),   2, shiny_yellow))\nspheres.push_back(Sphere(Vec3f(-1.0, -1.5, -12), 1.8, green_rubber))\nspheres.push_back(Sphere(Vec3f( 1.5, -0.5, -18),   3, green_rubber))\nspheres.push_back(Sphere(Vec3f( 7,      5, -18),   4, shiny_yellow))\n\nrender(create_image_with_spheres(spheres, H, W))\n\nStep 4: Add lighting\n\nThis section corresponds to the Step 4 of the C++ tutorial. Please read that section for an explanation of the trick used to estimate the light intensity of pixel based on the angle of intersection between each ray and the spheres. The changes are minimal and are primarily about handling this intersection angle.\n\n@register_passable(\"trivial\")\nstruct Light:\n    var position: Vec3f\n    var intensity: Float32\n\n    fn __init__(p: Vec3f, i: Float32) -> Self:\n        return Light {position: p, intensity: i}\nfrom math import max\n\n\nfn scene_intersect(\n    orig: Vec3f,\n    dir: Vec3f,\n    spheres: DynamicVector[Sphere],\n    inout material: Material,\n    inout hit: Vec3f,\n    inout N: Vec3f,\n) -> Bool:\n    var spheres_dist = inf[DType.float32]()\n\n    for i in range(0, spheres.size):\n        var dist: Float32 = 0\n        if spheres[i].intersects(orig, dir, dist) and dist < spheres_dist:\n            spheres_dist = dist\n            hit = orig + dir * dist\n            N = (hit - spheres[i].center).normalize()\n            material = spheres[i].material\n\n    return (spheres_dist != inf[DType.float32]()).__bool__()\n\n\nfn cast_ray(\n    orig: Vec3f,\n    dir: Vec3f,\n    spheres: DynamicVector[Sphere],\n    lights: DynamicVector[Light],\n) -> Material:\n    var point = Vec3f.zero()\n    var material = Material(Vec3f.zero())\n    var N = Vec3f.zero()\n    if not scene_intersect(orig, dir, spheres, material, point, N):\n        return bg_color\n\n    var diffuse_light_intensity: Float32 = 0\n    for i in range(lights.size):\n        let light_dir = (lights[i].position - point).normalize()\n        diffuse_light_intensity += lights[i].intensity * max(0, light_dir @ N)\n\n    return material.color * diffuse_light_intensity\n\n\nfn create_image_with_spheres_and_lights(\n    spheres: DynamicVector[Sphere],\n    lights: DynamicVector[Light],\n    height: Int,\n    width: Int,\n) -> Image:\n    let image = Image(height, width)\n\n    @parameter\n    fn _process_row(row: Int):\n        let y = -((2.0 * row + 1) / height - 1)\n        for col in range(width):\n            let x = ((2.0 * col + 1) / width - 1) * width / height\n            let dir = Vec3f(x, y, -1).normalize()\n            image.set(\n                row, col, cast_ray(Vec3f.zero(), dir, spheres, lights).color\n            )\n\n    parallelize[_process_row](height)\n\n    return image\n\n\nlet lights = DynamicVector[Light]()\nlights.push_back(Light(Vec3f(-20, 20, 20), 1.0))\nlights.push_back(Light(Vec3f(20, -20, 20), 0.5))\n\nrender(create_image_with_spheres_and_lights(spheres, lights, H, W))\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\nStep 5: Add specular lighting\n\nThis section corresponds to the Step 5 of the C++ tutorial. The changes to the code are quite minimal, but the rendered picture looks much more realistic!\n\nfrom math import pow\n\n\nfn reflect(I: Vec3f, N: Vec3f) -> Vec3f:\n    return I - N * (I @ N) * 2.0\n\n\nfn cast_ray(\n    orig: Vec3f,\n    dir: Vec3f,\n    spheres: DynamicVector[Sphere],\n    lights: DynamicVector[Light],\n) -> Material:\n    var point = Vec3f.zero()\n    var material = Material(Vec3f.zero())\n    var N = Vec3f.zero()\n    if not scene_intersect(orig, dir, spheres, material, point, N):\n        return bg_color\n\n    var diffuse_light_intensity: Float32 = 0\n    var specular_light_intensity: Float32 = 0\n    for i in range(lights.size):\n        let light_dir = (lights[i].position - point).normalize()\n        diffuse_light_intensity += lights[i].intensity * max(0, light_dir @ N)\n        specular_light_intensity += (\n            pow(\n                max(0.0, -reflect(-light_dir, N) @ dir),\n                material.specular_component,\n            )\n            * lights[i].intensity\n        )\n\n    let result = material.color * diffuse_light_intensity * material.albedo.data[\n        0\n    ] + Vec3f(\n        1.0, 1.0, 1.0\n    ) * specular_light_intensity * material.albedo.data[\n        1\n    ]\n    let result_max = max(result[0], max(result[1], result[2]))\n    # Cap the resulting vector\n    if result_max > 1:\n        return result * (1.0 / result_max)\n    return result\n\n\nfn create_image_with_spheres_and_specular_lights(\n    spheres: DynamicVector[Sphere],\n    lights: DynamicVector[Light],\n    height: Int,\n    width: Int,\n) -> Image:\n    let image = Image(height, width)\n\n    @parameter\n    fn _process_row(row: Int):\n        let y = -((2.0 * row + 1) / height - 1)\n        for col in range(width):\n            let x = ((2.0 * col + 1) / width - 1) * width / height\n            let dir = Vec3f(x, y, -1).normalize()\n            image.set(\n                row, col, cast_ray(Vec3f.zero(), dir, spheres, lights).color\n            )\n\n    parallelize[_process_row](height)\n\n    return image\n\n\nrender(create_image_with_spheres_and_specular_lights(spheres, lights, H, W))\n\nStep 6: Add background\n\nAs a last step, let‚Äôs use an image for the background instead of a uniform fill. The only code that we need to change is the code where we used to return bg_color. Now we will determine a point in the background image to which the ray is directed and draw that.\n\nfrom math import abs\n\n\nfn cast_ray(\n    orig: Vec3f,\n    dir: Vec3f,\n    spheres: DynamicVector[Sphere],\n    lights: DynamicVector[Light],\n    bg: Image,\n) -> Material:\n    var point = Vec3f.zero()\n    var material = Material(Vec3f.zero())\n    var N = Vec3f.zero()\n    if not scene_intersect(orig, dir, spheres, material, point, N):\n        # Background\n        # Given a direction vector `dir` we need to find a pixel in the image\n        let x = dir[0]\n        let y = dir[1]\n\n        # Now map x from [-1,1] to [0,w-1] and do the same for y.\n        let w = bg.width\n        let h = bg.height\n        let col = ((1.0 + x) * 0.5 * (w - 1)).to_int()\n        let row = ((1.0 + y) * 0.5 * (h - 1)).to_int()\n        return Material(bg.pixels[bg._pos_to_index(row, col)])\n\n    var diffuse_light_intensity: Float32 = 0\n    var specular_light_intensity: Float32 = 0\n    for i in range(lights.size):\n        let light_dir = (lights[i].position - point).normalize()\n        diffuse_light_intensity += lights[i].intensity * max(0, light_dir @ N)\n        specular_light_intensity += (\n            pow(\n                max(0.0, -reflect(-light_dir, N) @ dir),\n                material.specular_component,\n            )\n            * lights[i].intensity\n        )\n\n    let result = material.color * diffuse_light_intensity * material.albedo.data[\n        0\n    ] + Vec3f(\n        1.0, 1.0, 1.0\n    ) * specular_light_intensity * material.albedo.data[\n        1\n    ]\n    let result_max = max(result[0], max(result[1], result[2]))\n    # Cap the resulting vector\n    if result_max > 1:\n        return result * (1.0 / result_max)\n    return result\n\n\nfn create_image_with_spheres_and_specular_lights(\n    spheres: DynamicVector[Sphere],\n    lights: DynamicVector[Light],\n    height: Int,\n    width: Int,\n    bg: Image,\n) -> Image:\n    let image = Image(height, width)\n\n    @parameter\n    fn _process_row(row: Int):\n        let y = -((2.0 * row + 1) / height - 1)\n        for col in range(width):\n            let x = ((2.0 * col + 1) / width - 1) * width / height\n            let dir = Vec3f(x, y, -1).normalize()\n            image.set(\n                row, col, cast_ray(Vec3f.zero(), dir, spheres, lights, bg).color\n            )\n\n    parallelize[_process_row](height)\n\n    return image\n\n\nlet bg = load_image(\"images/background.png\")\nrender(\n    create_image_with_spheres_and_specular_lights(spheres, lights, H, W, bg)\n)\n\nNext steps\n\nWe‚Äôve only explored the basics of ray tracing here, but you can add shadows, reflections and so much more! Fortunately these are explained in the C++ tutorial, and we leave the corresponding Mojo implementations as an exercise for you.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - Fast memset in Mojo",
    "url": "https://docs.modular.com/mojo/notebooks/Memset.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nHigh-level overview\nImplementation\nFast memset in Mojo\n\nIn this tutorial we will implement a memset version optimized for small sizes using Mojo‚Äôs autotuning feature.\n\nThe idea behind the implementation is based on Nadav Rotem‚Äôs work [1], and is also well-described in [2].\n\nWe briefly summarize the approach below.\n\nHigh-level overview\n\nFor the best memset performance we want to use the widest possible register width for the memory access. For instance, if we want to store 19 bytes, we want to use vector width 16 and use two overlapping stores. To store 9 bytes, we would want to use two 8-byte stores.\n\nHowever, before we get to actually doing stores, we need to perform size checks to make sure that we‚Äôre in the right range. I.e. we want to use 8 bytes stores for sizes 8-16, 16 bytes stores for sizes 16-32, etc.\n\nThe order in which we do the size checks significantly affects performance and ideally we would like to run as few checks as possible for the sizes that occur most often. I.e. if most of the sizes we see are 16-32, then we want to first check if it‚Äôs within that range before we check if it‚Äôs in 8-16 or some other range.\n\nThis results in a number of different comparison ‚Äútrees‚Äù that can be used to perform the size checks, and in this tutorial we use Mojo‚Äôs autotuning to pick the most optimal one given the distribution of input data.\n\nImplementation\n\nWe will start as we always start - with imports and type aliases.\n\nfrom autotune import autotune_fork, search\nfrom math import min, max\nfrom memory.unsafe import DTypePointer, Pointer\nfrom time import time_function\nfrom benchmark import keep\nfrom memory import memset as stdlib_memset\n\nalias type = UInt8\nalias ptr_type = DTypePointer[DType.uint8]\n\nalias fn_type = fn(ptr: ptr_type, value: type, count: Int, /) -> None\n\nNow let‚Äôs add some auxiliary functions. We will use them to benchmark various memset implementations and visualize results.\n\nfn measure_time(func: fn_type, size: Int, iters: Int, samples: Int) -> Int:\n    alias alloc_size = 1024 * 1024\n    let ptr = ptr_type.alloc(alloc_size)\n\n    var best = -1\n    for sample in range(samples):\n\n        @parameter\n        fn runner():\n            for iter in range(iters):\n                # Offset pointer to shake up cache a bit\n                let offset_ptr = ptr.offset((iter * 128) & 1024)\n\n                # memset, change the value we're filling with\n                let v = type(iter&255)\n\n                # Actually call the memset function\n                func(offset_ptr, v.value, size)\n\n                # Avoid compiler optimizing things away\n                keep(v)\n                keep(size)\n                keep(offset_ptr)\n\n        let ns = time_function[runner]()\n        if best < 0 or ns < best:\n            best = ns\n\n    ptr.free()\n    return best\n\nalias MULT = 2_000\n\nfn visualize_result(size: Int, result: Int):\n    print_no_newline(\"Size: \")\n    if size < 10:\n        print_no_newline(\" \")\n    print_no_newline(size, \"  |\")\n    for _ in range(result // MULT):\n        print_no_newline(\"*\")\n    print()\n\n\nfn benchmark(func: fn_type, title: StringRef):\n    print(\"\\n=====================\")\n    print(title)\n    print(\"---------------------\\n\")\n\n    alias benchmark_iterations = 30 * MULT\n    alias warmup_samples = 10\n    alias benchmark_samples = 1000\n\n    # Warmup\n    for size in range(35):\n        _ = measure_time(\n            func, size, benchmark_iterations, warmup_samples\n        )\n\n    # Actual run\n    for size in range(35):\n        let result = measure_time(\n            func, size, benchmark_iterations, benchmark_samples\n        )\n\n        visualize_result(size, result)\nReproducing results from the paper\n\nLet‚Äôs implement a memset version from the paper in Mojo and compare it against the system memset.\n\n@always_inline\nfn overlapped_store[\n    width: Int\n](ptr: ptr_type, value: type, count: Int):\n    let v = SIMD[DType.uint8, width].splat(value)\n    ptr.simd_store[width](v)\n    ptr.simd_store[width](count - width, v)\n\n\nfn memset_manual(ptr: ptr_type, value: type, count: Int):\n    if count < 32:\n        if count < 5:\n            if count == 0:\n                return\n            # 0 < count <= 4\n            ptr.store(0, value)\n            ptr.store(count - 1, value)\n            if count <= 2:\n                return\n            ptr.store(1, value)\n            ptr.store(count - 2, value)\n            return\n\n        if count <= 16:\n            if count >= 8:\n                # 8 <= count < 16\n                overlapped_store[8](ptr, value, count)\n                return\n            # 4 < count < 8\n            overlapped_store[4](ptr, value, count)\n            return\n\n        # 16 <= count < 32\n        overlapped_store[16](ptr, value, count)\n    else:\n        # 32 < count\n        memset_system(ptr, value, count)\n\n\nfn memset_system(ptr: ptr_type, value: type, count: Int):\n    stdlib_memset(ptr, value.value, count)\n\nLet‚Äôs benchmark our version of memset vs the standard memset.\n\nNote: We‚Äôre optimizing memset for tiniest sizes and benchmarking that properly is tricky. The notebook environment makes it even harder, and while we tried our best to tune the notebook to demonstrate the performance difference, it is hard to guarantee that the results will be stable from run to run.\n\nbenchmark(memset_manual, \"Manual memset\")\nbenchmark(memset_system, \"System memset\")\n\n=====================\nManual memset\n---------------------\n\nSize:  0   |******************************************\nSize:  1   |******************************************\nSize:  2   |******************************************\nSize:  3   |******************************************\nSize:  4   |******************************************\nSize:  5   |***************************************************\nSize:  6   |***************************************************\nSize:  7   |***************************************************\nSize:  8   |******************************************\nSize:  9   |******************************************\nSize: 10   |******************************************\nSize: 11   |******************************************\nSize: 12   |******************************************\nSize: 13   |******************************************\nSize: 14   |******************************************\nSize: 15   |******************************************\nSize: 16   |******************************************\nSize: 17   |************************************************************\nSize: 18   |************************************************************\nSize: 19   |************************************************************\nSize: 20   |************************************************************\nSize: 21   |************************************************************\nSize: 22   |************************************************************\nSize: 23   |************************************************************\nSize: 24   |************************************************************\nSize: 25   |************************************************************\nSize: 26   |************************************************************\nSize: 27   |************************************************************\nSize: 28   |************************************************************\nSize: 29   |************************************************************\nSize: 30   |************************************************************\nSize: 31   |************************************************************\nSize: 32   |********************************************************************\nSize: 33   |********************************************************************\nSize: 34   |********************************************************************\n\n=====================\nSystem memset\n---------------------\n\nSize:  0   |************************************************************\nSize:  1   |************************************************************\nSize:  2   |************************************************************\nSize:  3   |************************************************************\nSize:  4   |************************************************************\nSize:  5   |************************************************************\nSize:  6   |************************************************************\nSize:  7   |************************************************************\nSize:  8   |************************************************************\nSize:  9   |************************************************************\nSize: 10   |************************************************************\nSize: 11   |************************************************************\nSize: 12   |************************************************************\nSize: 13   |************************************************************\nSize: 14   |************************************************************\nSize: 15   |************************************************************\nSize: 16   |************************************************************\nSize: 17   |************************************************************\nSize: 18   |************************************************************\nSize: 19   |************************************************************\nSize: 20   |************************************************************\nSize: 21   |************************************************************\nSize: 22   |************************************************************\nSize: 23   |************************************************************\nSize: 24   |************************************************************\nSize: 25   |************************************************************\nSize: 26   |************************************************************\nSize: 27   |************************************************************\nSize: 28   |************************************************************\nSize: 29   |************************************************************\nSize: 30   |************************************************************\nSize: 31   |************************************************************\nSize: 32   |***************************************************\nSize: 33   |***************************************************\nSize: 34   |***************************************************\nTweaking the implementation for different sizes\n\nWe can see that it‚Äôs already much faster for small sizes. That version was specifically optimized for a certain input size distribution, e.g.¬†we can see that sizes 8-16 and 0-4 work fastest.\n\nBut what if in our use case the distribution is different? Let‚Äôs imagine that in our case the most common sizes are 16-32 - is this version the most optimal version we can use then? The answer is obviously ‚Äúno‚Äù, and we can easily tweak the implementation to work better for these sizes - we just need to move the corresponding check closer to the beginning of the function. E.g. like so:\n\nfn memset_manual_2(ptr: ptr_type, value: type, count: Int):\n    if count < 32:\n        if count >= 16:\n            # 16 <= count < 32\n            overlapped_store[16](ptr, value, count)\n            return\n\n        if count < 5:\n            if count == 0:\n                return\n            # 0 < count <= 4\n            ptr.store(0, value)\n            ptr.store(count - 1, value)\n            if count <= 2:\n                return\n            ptr.store(1, value)\n            ptr.store(count - 2, value)\n            return\n\n        if count >= 8:\n            # 8 <= count < 16\n            overlapped_store[8](ptr, value, count)\n            return\n        # 4 < count < 8\n        overlapped_store[4](ptr, value, count)\n\n    else:\n        # 32 < count\n        memset_system(ptr, value, count)\n\nLet‚Äôs check the performance of this version.\n\nbenchmark(memset_manual_2, \"Manual memset v2\")\nbenchmark(memset_system, \"Mojo system memset\")\n\n=====================\nManual memset v2\n---------------------\n\nSize:  0   |************************************************************\nSize:  1   |************************************************************\nSize:  2   |************************************************************\nSize:  3   |***************************************************\nSize:  4   |***************************************************\nSize:  5   |************************************************************\nSize:  6   |************************************************************\nSize:  7   |************************************************************\nSize:  8   |***************************************************\nSize:  9   |***************************************************\nSize: 10   |***************************************************\nSize: 11   |***************************************************\nSize: 12   |***************************************************\nSize: 13   |***************************************************\nSize: 14   |***************************************************\nSize: 15   |***************************************************\nSize: 16   |**********************************\nSize: 17   |**********************************\nSize: 18   |**********************************\nSize: 19   |**********************************\nSize: 20   |**********************************\nSize: 21   |**********************************\nSize: 22   |**********************************\nSize: 23   |**********************************\nSize: 24   |**********************************\nSize: 25   |**********************************\nSize: 26   |**********************************\nSize: 27   |**********************************\nSize: 28   |**********************************\nSize: 29   |**********************************\nSize: 30   |**********************************\nSize: 31   |**********************************\nSize: 32   |********************************************************************\nSize: 33   |********************************************************************\nSize: 34   |********************************************************************\n\n=====================\nMojo system memset\n---------------------\n\nSize:  0   |************************************************************\nSize:  1   |************************************************************\nSize:  2   |************************************************************\nSize:  3   |************************************************************\nSize:  4   |************************************************************\nSize:  5   |************************************************************\nSize:  6   |************************************************************\nSize:  7   |************************************************************\nSize:  8   |************************************************************\nSize:  9   |************************************************************\nSize: 10   |************************************************************\nSize: 11   |************************************************************\nSize: 12   |************************************************************\nSize: 13   |************************************************************\nSize: 14   |************************************************************\nSize: 15   |************************************************************\nSize: 16   |************************************************************\nSize: 17   |************************************************************\nSize: 18   |************************************************************\nSize: 19   |************************************************************\nSize: 20   |************************************************************\nSize: 21   |************************************************************\nSize: 22   |************************************************************\nSize: 23   |************************************************************\nSize: 24   |************************************************************\nSize: 25   |************************************************************\nSize: 26   |************************************************************\nSize: 27   |************************************************************\nSize: 28   |************************************************************\nSize: 29   |************************************************************\nSize: 30   |************************************************************\nSize: 31   |************************************************************\nSize: 32   |***************************************************\nSize: 33   |***************************************************\nSize: 34   |***************************************************\n\nThe performance is now much better on the 16-32 sizes!\n\nThe problem is that we had to manually re-write the code. Wouldn‚Äôt it be nice if it was done automatically?\n\nIn Mojo this is possible (and quite easy) - we can generate multiple implementations and let the compiler pick the fastest one for us evaluating them on sizes we want!\n\nMojo implementation\n\nLet‚Äôs dive into that.\n\nThe first thing we need to do is to generate all possible candidates. To do that we will need to iteratively generate size checks to understand what size for the overlapping store we can use. Once we localize the size interval, we just call the overlapping store of the corresponding size.\n\nTo express this we will implement an adaptive function memset_impl_layer two parameters designating the current interval of possible size values. When we generate a new size check, we split that interval into two parts and recursively call the same functions on those two parts. Once we reach the minimal intervals, we will call the corresponding overlapped_store function.\n\nThis first implementation covers minimal interval cases:\n\n@adaptive\n@always_inline\nfn memset_impl_layer[\n    lower: Int, upper: Int\n](ptr: ptr_type, value: type, count: Int):\n    @parameter\n    if lower == -100 and upper == 0:\n        pass\n    elif lower == 0 and upper == 4:\n        ptr.store(0, value)\n        ptr.store(count - 1, value)\n        if count <= 2:\n            return\n        ptr.store(1, value)\n        ptr.store(count - 2, value)\n    elif lower == 4 and upper == 8:\n        overlapped_store[4](ptr, value, count)\n    elif lower == 8 and upper == 16:\n        overlapped_store[8](ptr, value, count)\n    elif lower == 16 and upper == 32:\n        overlapped_store[16](ptr, value, count)\n    elif lower == 32 and upper == 100:\n        memset_system(ptr, value, count)\n    else:\n        constrained[False]()\n\nLet‚Äôs now add an implementation for the other case, where we need to generate a size check.\n\n@adaptive\n@always_inline\nfn memset_impl_layer[\n    lower: Int, upper: Int\n](ptr: ptr_type, value: type, count: Int):\n    alias cur: Int\n    autotune_fork[Int, 0, 4, 8, 16, 32 -> cur]()\n\n    constrained[cur > lower]()\n    constrained[cur < upper]()\n\n    if count > cur:\n        memset_impl_layer[max(cur, lower), upper](ptr, value, count)\n    else:\n        memset_impl_layer[lower, min(cur, upper)](ptr, value, count)\n\nHere we use autotune_fork to generate all possible at that point checks.\n\nWe will discard values beyond the current interval, and for the values within we will recursively call this function on the interval splits.\n\nThis is sufficient to generate multiple correct versions of memset, but to achieve the best performance we need to take into account one more factor: when we‚Äôre dealing with such small sizes, even the code location matters a lot. E.g. if we swap Then and Else branches and invert the condition, we might get a different performance of the final function.\n\nTo account for that, let‚Äôs add one more implementation of our function, but now with branches swapped:\n\n@adaptive\n@always_inline\nfn memset_impl_layer[\n    lower: Int, upper: Int\n](ptr: ptr_type, value: type, count: Int):\n    alias cur: Int\n    autotune_fork[Int, 0, 4, 8, 16, 32 -> cur]()\n\n    constrained[cur > lower]()\n    constrained[cur < upper]()\n\n    if count <= cur:\n        memset_impl_layer[lower, min(cur, upper)](ptr, value, count)\n    else:\n        memset_impl_layer[max(cur, lower), upper](ptr, value, count)\n\nWe defined building blocks for our implementation, now we need to add a top level entry-point that will kick off the recursion we‚Äôve just defined.\n\nWe will simply call our function with [-100,100] interval - -100 and 100 simply designate that no checks have been performed yet. This interval will be refined as we generate more and more check until we have enough to emit actual stores.\n\n@adaptive\nfn memset_autotune_impl(ptr: ptr_type, value: type, count: Int, /):\n    memset_impl_layer[-100, 100](ptr, value, count)\n\nOk, we‚Äôre done with our memset implementation, now we just need to plug it to autotuning infrastructure to let the Mojo compiler do the search and pick the best implementation.\n\nTo do that, we need to define an evaluator - this is a function that will take an array of function pointers to all implementations of our function and will need to return an index of the best candidate.\n\nThere are no limitations in how this function can be implemented - it can return the first or a random candidate, or it can actually benchmark all of them and pick the fastest - this is what we‚Äôre going to do for this example.\n\nfn memset_evaluator(funcs: Pointer[fn_type], size: Int) -> Int:\n    # This size is picked at random, in real code we could use a real size\n    # distribution here.\n    let size_to_optimize_for = 17\n\n    var best_idx: Int = -1\n    var best_time: Int = -1\n\n    alias eval_iterations = MULT\n    alias eval_samples = 500\n\n    # Find the function that's the fastest on the size we're optimizing for\n    for f_idx in range(size):\n        let func = funcs.load(f_idx)\n        let cur_time = measure_time(\n            func, size_to_optimize_for, eval_iterations, eval_samples\n        )\n        if best_idx < 0:\n            best_idx = f_idx\n            best_time = cur_time\n        if best_time > cur_time:\n            best_idx = f_idx\n            best_time = cur_time\n\n    return best_idx\n\nThe evaluator is ready, the last brush stroke is to add a function that will call the best candidate.\n\nThe search will be performed at compile time, and at runtime we will go directly to the best implementation.\n\nfn memset_autotune(ptr: ptr_type, value: type, count: Int):\n    # Get the set of all candidates\n    alias candidates = memset_autotune_impl.__adaptive_set\n\n    # Use the evaluator to select the best candidate.\n    alias best_impl: fn_type\n    search[fn_type, VariadicList(candidates), memset_evaluator -> best_impl]()\n\n    # Run the best candidate\n    return best_impl(ptr, value, count)\n\nWe are now ready to benchmark our function, let‚Äôs see how its performance looks!\n\nbenchmark(memset_manual, \"Mojo manual memset\")\nbenchmark(memset_manual_2, \"Mojo manual memset v2\")\nbenchmark(memset_system, \"Mojo system memset\")\nbenchmark(memset_autotune, \"Mojo autotune memset\")\n\n=====================\nMojo manual memset\n---------------------\n\nSize:  0   |******************************************\nSize:  1   |******************************************\nSize:  2   |******************************************\nSize:  3   |******************************************\nSize:  4   |******************************************\nSize:  5   |***************************************************\nSize:  6   |***************************************************\nSize:  7   |***************************************************\nSize:  8   |******************************************\nSize:  9   |******************************************\nSize: 10   |******************************************\nSize: 11   |******************************************\nSize: 12   |******************************************\nSize: 13   |******************************************\nSize: 14   |******************************************\nSize: 15   |******************************************\nSize: 16   |******************************************\nSize: 17   |************************************************************\nSize: 18   |************************************************************\nSize: 19   |************************************************************\nSize: 20   |************************************************************\nSize: 21   |************************************************************\nSize: 22   |************************************************************\nSize: 23   |************************************************************\nSize: 24   |************************************************************\nSize: 25   |************************************************************\nSize: 26   |************************************************************\nSize: 27   |************************************************************\nSize: 28   |************************************************************\nSize: 29   |************************************************************\nSize: 30   |************************************************************\nSize: 31   |************************************************************\nSize: 32   |********************************************************************\nSize: 33   |********************************************************************\nSize: 34   |********************************************************************\n\n=====================\nMojo manual memset v2\n---------------------\n\nSize:  0   |************************************************************\nSize:  1   |************************************************************\nSize:  2   |************************************************************\nSize:  3   |***************************************************\nSize:  4   |***************************************************\nSize:  5   |************************************************************\nSize:  6   |************************************************************\nSize:  7   |************************************************************\nSize:  8   |***************************************************\nSize:  9   |***************************************************\nSize: 10   |***************************************************\nSize: 11   |***************************************************\nSize: 12   |***************************************************\nSize: 13   |***************************************************\nSize: 14   |***************************************************\nSize: 15   |***************************************************\nSize: 16   |**********************************\nSize: 17   |**********************************\nSize: 18   |**********************************\nSize: 19   |**********************************\nSize: 20   |**********************************\nSize: 21   |**********************************\nSize: 22   |**********************************\nSize: 23   |**********************************\nSize: 24   |**********************************\nSize: 25   |**********************************\nSize: 26   |**********************************\nSize: 27   |**********************************\nSize: 28   |**********************************\nSize: 29   |**********************************\nSize: 30   |**********************************\nSize: 31   |**********************************\nSize: 32   |********************************************************************\nSize: 33   |********************************************************************\nSize: 34   |********************************************************************\n\n=====================\nMojo system memset\n---------------------\n\nSize:  0   |************************************************************\nSize:  1   |************************************************************\nSize:  2   |************************************************************\nSize:  3   |************************************************************\nSize:  4   |************************************************************\nSize:  5   |************************************************************\nSize:  6   |************************************************************\nSize:  7   |************************************************************\nSize:  8   |************************************************************\nSize:  9   |************************************************************\nSize: 10   |************************************************************\nSize: 11   |************************************************************\nSize: 12   |************************************************************\nSize: 13   |************************************************************\nSize: 14   |************************************************************\nSize: 15   |************************************************************\nSize: 16   |************************************************************\nSize: 17   |************************************************************\nSize: 18   |************************************************************\nSize: 19   |************************************************************\nSize: 20   |************************************************************\nSize: 21   |************************************************************\nSize: 22   |************************************************************\nSize: 23   |************************************************************\nSize: 24   |************************************************************\nSize: 25   |************************************************************\nSize: 26   |************************************************************\nSize: 27   |************************************************************\nSize: 28   |************************************************************\nSize: 29   |************************************************************\nSize: 30   |************************************************************\nSize: 31   |************************************************************\nSize: 32   |***************************************************\nSize: 33   |***************************************************\nSize: 34   |***************************************************\n\n=====================\nMojo autotune memset\n---------------------\n\nSize:  0   |************************************************************\nSize:  1   |********************************************************************\nSize:  2   |********************************************************************\nSize:  3   |************************************************************\nSize:  4   |************************************************************\nSize:  5   |***************************************************\nSize:  6   |***************************************************\nSize:  7   |***************************************************\nSize:  8   |***************************************************\nSize:  9   |***************************************************\nSize: 10   |***************************************************\nSize: 11   |***************************************************\nSize: 12   |***************************************************\nSize: 13   |***************************************************\nSize: 14   |***************************************************\nSize: 15   |***************************************************\nSize: 16   |***************************************************\nSize: 17   |**********************************\nSize: 18   |**********************************\nSize: 19   |**********************************\nSize: 20   |**********************************\nSize: 21   |**********************************\nSize: 22   |**********************************\nSize: 23   |**********************************\nSize: 24   |**********************************\nSize: 25   |**********************************\nSize: 26   |**********************************\nSize: 27   |**********************************\nSize: 28   |**********************************\nSize: 29   |**********************************\nSize: 30   |**********************************\nSize: 31   |**********************************\nSize: 32   |**********************************\nSize: 33   |********************************************************************\nSize: 34   |********************************************************************\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - Matrix multiplication in Mojo",
    "url": "https://docs.modular.com/mojo/notebooks/Matmul.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nPython Implementation\nImporting the Python implementation to Mojo\nAdding types to the Python implementation\nVectorizing the inner most loop\nParallelizing Matmul\nTiling Matmul\nSearching for the tile_factor\nTile and accumulate in registers\nMatrix multiplication in Mojo\n\nThis notebook describes how to write a matrix multiplication (matmul) algorithm in Mojo. We will start with a pure Python implementation, transition to a naive implementation that is essentially a copy of the Python one, then add types, then continue the optimizations by vectorizing, tiling, and parallelizing the implementation.\n\nFirst, let‚Äôs define matrix multiplication. Given two dense matrices \nùê¥\n and \nùêµ\n of dimensions \nùëÄ\n√ó\nùêæ\n and \nùêæ\n√ó\nùëÅ\n respectively, we want to compute their dot product \nùê∂\n=\nùê¥\n.\nùêµ\n (also known as matmul). The dot product \nùê∂\n+\n=\nùê¥\n.\nùêµ\n is defined by\n\n\n\nùê∂\nùëñ\n,\nùëó\n+\n=\n‚àë\nùëò\n‚àà\n[\n0\n‚ãØ\nùêæ\n)\nùê¥\nùëñ\n,\nùëò\nùêµ\nùëò\n,\nùëó\n\nPlease take look at our blog post on matmul and why it is important for ML and DL workloads.\n\nThe format of this notebook is to start with an implementation which is identical to that of Python (effectively renaming the file extension), then look at how adding types to the implementation helps performance before extending the implementation by leveraging the vectorization and parallelization capabilities available on modern hardware. Throughout the execution, we report the GFlops achieved.\n\nPython Implementation\n\nLet‚Äôs first implement matmul in Python directly from the definition.\n\n%%python\ndef matmul_python(C, A, B):\n    for m in range(C.rows):\n        for k in range(A.cols):\n            for n in range(C.cols):\n                C[m, n] += A[m, k] * B[k, n]\n\nLet‚Äôs benchmark our implementation using 128 by 128 square matrices and report the achieved GFLops.\n\nInstall numpy if it‚Äôs not already:\n\n%%python\nfrom importlib.util import find_spec\nimport shutil\nimport subprocess\n\nfix = \"\"\"\n-------------------------------------------------------------------------\nfix following the steps here:\n    https://github.com/modularml/mojo/issues/1085#issuecomment-1771403719\n-------------------------------------------------------------------------\n\"\"\"\n\ndef install_if_missing(name: str):\n    if find_spec(name):\n        return\n\n    print(f\"{name} not found, installing...\")\n    try:\n        if shutil.which('python3'): python = \"python3\"\n        elif shutil.which('python'): python = \"python\"\n        else: raise (\"python not on path\" + fix)\n        subprocess.check_call([python, \"-m\", \"pip\", \"install\", name])\n    except:\n        raise ImportError(f\"{name} not found\" + fix)\n\ninstall_if_missing(\"numpy\")\n%%python\nfrom timeit import timeit\nimport numpy as np\n\nclass Matrix:\n    def __init__(self, value, rows, cols):\n        self.value = value\n        self.rows = rows\n        self.cols = cols\n\n    def __getitem__(self, idxs):\n        return self.value[idxs[0]][idxs[1]]\n\n    def __setitem__(self, idxs, value):\n        self.value[idxs[0]][idxs[1]] = value\n\ndef benchmark_matmul_python(M, N, K):\n    A = Matrix(list(np.random.rand(M, K)), M, K)\n    B = Matrix(list(np.random.rand(K, N)), K, N)\n    C = Matrix(list(np.zeros((M, N))), M, N)\n    secs = timeit(lambda: matmul_python(C, A, B), number=2)/2\n    gflops = ((2*M*N*K)/secs) / 1e9\n    print(gflops, \"GFLOP/s\")\n    return gflops\npython_gflops = benchmark_matmul_python(128, 128, 128).to_float64()\n0.0018947946413032505 GFLOP/s\nImporting the Python implementation to Mojo\n\nUsing Mojo is as simple as Python. First, let‚Äôs include that modules from the Mojo stdlib that we are going to use:\n\nImport utilities and define Matrix (click to show/hide)\n\nThen, we can copy and paste our Python code. Mojo is a superset of Python, so the same Python code will run as Mojo code\n\n# This exactly the same Python implementation,\n# but is infact Mojo code!\ndef matmul_untyped(C, A, B):\n    for m in range(C.rows):\n        for k in range(A.cols):\n            for n in range(C.cols):\n                C[m, n] += A[m, k] * B[k, n]\n\nWe can then benchmark the implementation. As before we use a 128 by 128 matrix\n\nfn matrix_getitem(self: object, i: object) raises -> object:\n    return self.value[i]\n\n\nfn matrix_setitem(self: object, i: object, value: object) raises -> object:\n    self.value[i] = value\n    return None\n\n\nfn matrix_append(self: object, value: object) raises -> object:\n    self.value.append(value)\n    return None\n\n\nfn matrix_init(rows: Int, cols: Int) raises -> object:\n    let value = object([])\n    return object(\n        Attr(\"value\", value), Attr(\"__getitem__\", matrix_getitem), Attr(\"__setitem__\", matrix_setitem),\n        Attr(\"rows\", rows), Attr(\"cols\", cols), Attr(\"append\", matrix_append),\n    )\n\ndef benchmark_matmul_untyped(M: Int, N: Int, K: Int, python_gflops: Float64):\n    C = matrix_init(M, N)\n    A = matrix_init(M, K)\n    B = matrix_init(K, N)\n    for i in range(M):\n        c_row = object([])\n        b_row = object([])\n        a_row = object([])\n        for j in range(N):\n            c_row.append(0.0)\n            b_row.append(random_float64(-5, 5))\n            a_row.append(random_float64(-5, 5))\n        C.append(c_row)\n        B.append(b_row)\n        A.append(a_row)\n\n    @parameter\n    fn test_fn():\n        try:\n            _ = matmul_untyped(C, A, B)\n        except:\n            pass\n\n    let secs = benchmark.run[test_fn]().mean()\n    _ = (A, B, C)\n    let gflops = ((2*M*N*K)/secs) / 1e9\n    let speedup : Float64 = gflops / python_gflops\n    print(gflops, \"GFLOP/s, a\", speedup.value, \"x speedup over Python\")\nbenchmark_matmul_untyped(128, 128, 128, python_gflops)\n0.0092210218211624933 GFLOP/s, a 4.866501952327785 x speedup over Python\n\nNote the huge speedup with no effort that we have gotten.\n\nAdding types to the Python implementation\n\nThe above program, while achieving better performance than Python, is still not the best we can get from Mojo. If we tell Mojo the types of the inputs, it can optimize much of the code away and reduce dispatching costs (unlike Python, which only uses types for type checking, Mojo exploits type info for performance optimizations as well).\n\nTo do that, let‚Äôs first define a Matrix struct. The Matrix struct contains a data pointer along with size fields. While the Matrix struct can be parametrized on any data type, here we set the data type to be Float32 for conciseness.\n\nalias type = DType.float32\n\nstruct Matrix:\n    var data: DTypePointer[type]\n    var rows: Int\n    var cols: Int\n\n    # Initialize zeroeing all values\n    fn __init__(inout self, rows: Int, cols: Int):\n        self.data = DTypePointer[type].alloc(rows * cols)\n        memset_zero(self.data, rows * cols)\n        self.rows = rows\n        self.cols = cols\n\n    # Initialize taking a pointer, don't set any elements\n    fn __init__(inout self, rows: Int, cols: Int, data: DTypePointer[DType.float32]):\n        self.data = data\n        self.rows = rows\n        self.cols = cols\n\n    ## Initialize with random values\n    @staticmethod\n    fn rand(rows: Int, cols: Int) -> Self:\n        let data = DTypePointer[type].alloc(rows * cols)\n        rand(data, rows * cols)\n        return Self(rows, cols, data)\n\n    fn __getitem__(self, y: Int, x: Int) -> Float32:\n        return self.load[1](y, x)\n\n    fn __setitem__(self, y: Int, x: Int, val: Float32):\n        return self.store[1](y, x, val)\n\n    fn load[nelts: Int](self, y: Int, x: Int) -> SIMD[DType.float32, nelts]:\n        return self.data.simd_load[nelts](y * self.cols + x)\n\n    fn store[nelts: Int](self, y: Int, x: Int, val: SIMD[DType.float32, nelts]):\n        return self.data.simd_store[nelts](y * self.cols + x, val)\n\nNote that we implement getitem and setitem in terms of load and store. For the naive implementation of matmul it does not make a difference, but we will utilize this later in a more optimized vectorized version of matmul.\n\nWith the above Matrix type we can effectively copy and paste the Python implementation and just add type annotations:\n\n# Note that C, A, and B have types.\nfn matmul_naive(C: Matrix, A: Matrix, B: Matrix):\n    for m in range(C.rows):\n        for k in range(A.cols):\n            for n in range(C.cols):\n                C[m, n] += A[m, k] * B[k, n]\n\nWe are going to benchmark the implementations as we improve, so let‚Äôs write a helper function that will do that for us:\n\nalias M = 1024\nalias N = 1024\nalias K = 1024\n\n@always_inline\nfn bench[\n    func: fn (Matrix, Matrix, Matrix) -> None](base_gflops: Float64):\n    var C = Matrix(M, N)\n    var A = Matrix.rand(M, K)\n    var B = Matrix.rand(K, N)\n\n    @always_inline\n    @parameter\n    fn test_fn():\n        _ = func(C, A, B)\n\n    let secs = benchmark.run[test_fn]().mean()\n    # Prevent the matrices from being freed before the benchmark run\n    A.data.free()\n    B.data.free()\n    C.data.free()\n    let gflops = ((2 * M * N * K) / secs) / 1e9\n    let speedup: Float64 = gflops / base_gflops\n    # print(gflops, \"GFLOP/s\", speedup, \" speedup\")\n    print(gflops, \"GFLOP/s, a\", speedup.value, \"x speedup over Python\")\n\nBenchmarking shows significant speedups. We increase the size of the matrix to 512 by 512, since Mojo is much faster than Python.\n\nbench[matmul_naive](python_gflops)\n3.6469022982798753 GFLOP/s, a 1924.695277674796 x speedup over Python\n\nAdding type annotations gives a huge improvement compared to the original untyped version.\n\nVectorizing the inner most loop\n\nWe can do better than the above implementation by utilizing the vector instructions. Rather than assuming a vector width, we query the simd width of the specified dtype using simd_width. This makes our code portable as we transition to other hardware. Leverage SIMD instructions is as easy as:\n\n# Mojo has SIMD vector types, we can vectorize the Matmul code as follows.\n# nelts = number of float32 elements that can fit in SIMD register\nalias nelts = simdwidthof[DType.float32]()\nfn matmul_vectorized_0(C: Matrix, A: Matrix, B: Matrix):\n    for m in range(C.rows):\n        for k in range(A.cols):\n            for nv in range(0, C.cols, nelts):\n                C.store[nelts](m,nv, C.load[nelts](m,nv) + A[m,k] * B.load[nelts](k,nv))\n\n            # Handle remaining elements with scalars.\n            for n in range(nelts*(C.cols//nelts), C.cols):\n                C[m,n] += A[m,k] * B[k,n]\n\nWe can benchmark the above implementation. Note that many compilers can detect naive loops and perform optimizations on them. Mojo, however, allows you to be explicit and precisely control what optimizations are applied.\n\nbench[matmul_vectorized_0](python_gflops)\n12.535805674163893 GFLOP/s, a 6615.9178419154141 x speedup over Python\n\nVectorization is a common optimization, and Mojo provides a higher-order function that performs vectorization for you. The vectorize function takes a vector width and a function which is parametric on the vector width and is going to be evaluated in a vectorized manner.\n\n# Simplify the code by using the builtin vectorize function\nfrom algorithm import vectorize\nfn matmul_vectorized_1(C: Matrix, A: Matrix, B: Matrix):\n    for m in range(C.rows):\n        for k in range(A.cols):\n            @parameter\n            fn dot[nelts : Int](n : Int):\n                C.store[nelts](m,n, C.load[nelts](m,n) + A[m,k] * B.load[nelts](k,n))\n            vectorize[nelts, dot](C.cols)\n\nThere is only a slight difference in terms of performance between the two implementations:\n\nbench[matmul_vectorized_1](python_gflops)\n12.541864071124047 GFLOP/s, a 6619.1152316631433 x speedup over Python\nParallelizing Matmul\n\nWith Mojo we can easily run code in parallel with the parallelize function.\n\nLet‚Äôs modify our matmul implementation and make it multi-threaded (for simplicity, we only parallelize on the M dimension).\n\nIn parallelize below we‚Äôre overpartitioning by distributing the work more evenly among processors. This ensures they all have something to work on even if some tasks finish before others, or some processors are stragglers. Intel and Apple now have separate performance and efficiency cores and this mitigates the problems that can cause.\n\n# Parallelize the code by using the builtin parallelize function\nfrom algorithm import parallelize\nfn matmul_parallelized(C: Matrix, A: Matrix, B: Matrix):\n    @parameter\n    fn calc_row(m: Int):\n        for k in range(A.cols):\n            @parameter\n            fn dot[nelts : Int](n : Int):\n                C.store[nelts](m,n, C.load[nelts](m,n) + A[m,k] * B.load[nelts](k,n))\n            vectorize[nelts, dot](C.cols)\n    parallelize[calc_row](C.rows, C.rows)\n\nWe can benchmark the parallel matmul implementation.\n\nbench[matmul_parallelized](python_gflops)\n107.98687292023116 GFLOP/s, a 56991.333290850547 x speedup over Python\nTiling Matmul\n\nTiling is an optimization performed for matmul to increase cache locality. The idea is to keep sub-matrices resident in the cache and increase the reuse. The tile function itself can be written in Mojo as:\n\nfrom algorithm import Static2DTileUnitFunc as Tile2DFunc\n# Perform 2D tiling on the iteration space defined by end_x and end_y.\nfn tile[tiled_fn: Tile2DFunc, tile_x: Int, tile_y: Int](end_x: Int, end_y: Int):\n    # Note: this assumes that ends are multiples of the tiles.\n    for y in range(0, end_y, tile_y):\n        for x in range(0, end_x, tile_x):\n            tiled_fn[tile_x, tile_y](x, y)\n\nThe above will perform 2 dimensional tiling over a 2D iteration space defined to be between \n(\n[\n0\n,\nùëí\nùëõ\nùëë\nùë•\n]\n,\n[\n0\n,\nùëí\nùëõ\nùëë\nùë¶\n]\n)\n. Once we define it above, we can use it within our matmul kernel. For simplicity we choose 4 as the tile height and since we also want to vectorize we use 4 * nelts as the tile width (since we vectorize on the columns).\n\n# Use the above tile function to perform tiled matmul.\nfn matmul_tiled_parallelized(C: Matrix, A: Matrix, B: Matrix):\n    @parameter\n    fn calc_row(m: Int):\n        @parameter\n        fn calc_tile[tile_x: Int, tile_y: Int](x: Int, y: Int):\n            for k in range(y, y + tile_y):\n                @parameter\n                fn dot[nelts : Int,](n : Int):\n                    C.store[nelts](m,n + x, C.load[nelts](m,n+x) + A[m,k] * B.load[nelts](k,n+x))\n                vectorize[nelts, dot](tile_x)\n\n        # We hardcode the tile factor to be 4.\n        alias tile_size = 4\n        tile[calc_tile, nelts * tile_size, tile_size](A.cols, C.cols)\n\n    parallelize[calc_row](C.rows, C.rows)\n\nAgain, we can benchmark the tiled parallel matmul implementation:\n\nbench[matmul_tiled_parallelized](python_gflops)\n136.92271321866085 GFLOP/s, a 72262.560930869338 x speedup over Python\n\nOne source of overhead in the above implementation is the fact that the we are not unrolling the loops introduced by vectorize of the dot function. We can do that via the vectorize_unroll higher-order function in Mojo:\n\n# Unroll the vectorized loop by a constant factor.\nfrom algorithm import vectorize_unroll\nfn matmul_tiled_unrolled_parallelized(C: Matrix, A: Matrix, B: Matrix):\n    @parameter\n    fn calc_row(m: Int):\n        @parameter\n        fn calc_tile[tile_x: Int, tile_y: Int](x: Int, y: Int):\n            for k in range(y, y + tile_y):\n                @parameter\n                fn dot[nelts : Int,](n : Int):\n                    C.store[nelts](m,n+x, C.load[nelts](m,n+x) + A[m,k] * B.load[nelts](k,n+x))\n\n                # Vectorize by nelts and unroll by tile_x/nelts\n                # Here unroll factor is 4\n                vectorize_unroll[nelts, tile_x//nelts, dot](tile_x)\n\n        alias tile_size = 4\n        tile[calc_tile, nelts*tile_size, tile_size](A.cols, C.cols)\n\n    parallelize[calc_row](C.rows, C.rows)\n\nAgain, we can benchmark the new tiled parallel matmul implementation with unrolled and vectorized inner loop:\n\nbench[matmul_tiled_unrolled_parallelized](python_gflops)\n173.70727621843133 GFLOP/s, a 91676.043636557093 x speedup over Python\nSearching for the tile_factor\nfrom autotune import autotune, search\nfrom time import now\nfrom memory.unsafe import Pointer\n\nalias matmul_fn_sig_type = fn(C: Matrix, A: Matrix, B: Matrix, /) -> None\n\nThe choice of the tile factor can greatly impact the performance of the full matmul, but the optimal tile factor is highly hardware-dependent, and is influenced by the cache configuration and other hard-to-model effects. We want to write portable code without having to know everything about the hardware, so we can ask Mojo to automatically select the best tile factor using autotuning.\n\n# Autotune the tile size used in the matmul.\n@adaptive\nfn matmul_autotune_impl(C: Matrix, A: Matrix, B: Matrix, /):\n    @parameter\n    fn calc_row(m: Int):\n        @parameter\n        fn calc_tile[tile_x: Int, tile_y: Int](x: Int, y: Int):\n            for k in range(y, y + tile_y):\n                @parameter\n                fn dot[nelts : Int](n : Int):\n                    C.store[nelts](m,n+x, C.load[nelts](m,n+x) + A[m,k] * B.load[nelts](k,n+x))\n                vectorize_unroll[nelts, tile_x // nelts, dot](tile_x)\n\n        # Instead of hardcoding to tile_size = 4, search for the fastest\n        # tile size by evaluating this function as tile size varies.\n        alias tile_size = autotune(1, 2, 4, 8, 16, 32)\n        tile[calc_tile, nelts * tile_size, tile_size](A.cols, C.cols)\n\n    parallelize[calc_row](C.rows, C.rows)\n\nThis will generate multiple candidates for the matmul function. To teach Mojo how to find the best tile factor, we provide an evaluator function Mojo can use to assess each candidate.\n\nfn matmul_evaluator(funcs: Pointer[matmul_fn_sig_type], size: Int) -> Int:\n    print(\"matmul_evaluator, number of candidates: \", size)\n\n    let eval_begin: Int = now()\n\n    # This size is picked at random, in real code we could use a real size\n    # distribution here.\n    let M = 512\n    let N = 512\n    let K = 512\n    print(\"Optimizing for size:\", M, \"x\", N, \"x\", K)\n\n    var best_idx: Int = -1\n    var best_time: Int = -1\n\n    alias eval_iterations = 10\n    alias eval_samples = 10\n\n    var C = Matrix(M, N)\n    var A = Matrix(M, K)\n    var B = Matrix(K, N)\n    let Cptr = Pointer[Matrix].address_of(C).address\n    let Aptr = Pointer[Matrix].address_of(A).address\n    let Bptr = Pointer[Matrix].address_of(B).address\n\n    # Find the function that's the fastest on the size we're optimizing for\n    for f_idx in range(size):\n        let func = funcs.load(f_idx)\n\n        @always_inline\n        @parameter\n        fn wrapper():\n            func(C, A, B)\n        let cur_time = benchmark.run[wrapper](1, 100_000, 5, 10).mean[\"ns\"]().to_int()\n\n        if best_idx < 0:\n            best_idx = f_idx\n            best_time = cur_time\n        if best_time > cur_time:\n            best_idx = f_idx\n            best_time = cur_time\n\n    let eval_end: Int = now()\n    # Prevent matrices from being destroyed before we finished benchmarking them.\n    A.data.free()\n    B.data.free()\n    C.data.free()\n    print(\"Time spent in matmul_evaluator, ms:\", (eval_end - eval_begin) // 1000000)\n    print(\"Best candidate idx:\", best_idx)\n    return best_idx\n\nFinally, we need to define an entry function that would simply call the best candidate.\n\nfn matmul_autotune(C: Matrix, A: Matrix, B: Matrix):\n    alias best_impl: matmul_fn_sig_type\n    search[\n        matmul_fn_sig_type,\n        VariadicList(matmul_autotune_impl.__adaptive_set),\n        matmul_evaluator -> best_impl\n    ]()\n    # Run the best candidate\n    return best_impl(C, A, B)\n\nLet‚Äôs benchmark our new implementation:\n\nbench[matmul_autotune](python_gflops)\nmatmul_evaluator, number of candidates:  6\nOptimizing for size: 512 x 512 x 512\nTime spent in matmul_evaluator, ms: 8098\nBest candidate idx: 5\n201.48323262066052 GFLOP/s, a 106335.12900483991 x speedup over Python\n\nPerform 2D tiling on the iteration space defined by end_x and end_y, parallelizing over y.\n\nfn tile_parallel[\n    tiled_fn: Tile2DFunc, tile_x: Int, tile_y: Int\n](end_x: Int, end_y: Int):\n    # Note: this assumes that ends are multiples of the tiles.\n    @parameter\n    fn row(yo: Int):\n        let y = tile_y * yo\n        for x in range(0, end_x, tile_x):\n            tiled_fn[tile_x, tile_y](x, y)\n\n    parallelize[row](end_y // tile_y, 512)\n\nTile the output and accumulate in registers. This strategy means we can compute tile_i * tile_j values of output for only reading tile_i + tile_j input values.\n\nfrom memory import stack_allocation\n\nfn accumulate_registers(C: Matrix, A: Matrix, B: Matrix):\n    @parameter\n    fn calc_tile[tile_j: Int, tile_i: Int](jo: Int, io: Int):\n        # Allocate the tile of accumulators on the stack.\n        var accumulators = Matrix(tile_i, tile_j, stack_allocation[tile_i * tile_j, DType.float32]())\n\n        for k in range(0, A.cols):\n            @parameter\n            fn calc_tile_row[i: Int]():\n                @parameter\n                fn calc_tile_cols[nelts: Int](j: Int):\n                    accumulators.store[nelts](i, j, accumulators.load[nelts](i, j) + A[io + i, k] * B.load[nelts](k, jo + j))\n\n                vectorize_unroll[nelts, tile_j // nelts, calc_tile_cols](tile_j)\n\n            unroll[tile_i, calc_tile_row]()\n\n        # Copy the local tile to the output\n        for i in range(tile_i):\n            for j in range(tile_j):\n                C[io + i, jo + j] = accumulators[i, j]\n\n    alias tile_i = 4\n    alias tile_j = nelts*4\n    tile_parallel[calc_tile, tile_j, tile_i](C.cols, C.rows)\nbench[accumulate_registers](python_gflops)\n584.69820167517651 GFLOP/s, a 308581.30423728545 x speedup over Python\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - Mandelbrot in Mojo with Python plots",
    "url": "https://docs.modular.com/mojo/notebooks/Mandelbrot.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nVectorizing Mandelbrot\nParallelizing Mandelbrot\nBenchmarking\nMandelbrot in Mojo with Python plots\n\nNot only is Mojo great for writing high-performance code, but it also allows us to leverage the huge Python ecosystem of libraries and tools. With seamless Python interoperability, Mojo can use Python for what it‚Äôs good at, especially GUIs, without sacrificing performance in critical code. Let‚Äôs take the classic Mandelbrot set algorithm and implement it in Mojo.\n\nThis tutorial shows two aspects of Mojo. First, it shows that Mojo can be used to develop fast programs for irregular applications. It also shows how we can leverage Python for visualizing the results.\n\nCode\n\nFirst set some parameters, you can try changing these to see different results:\n\nalias width = 960\nalias height = 960\nalias MAX_ITERS = 200\n\nalias min_x = -2.0\nalias max_x = 0.6\nalias min_y = -1.5\nalias max_y = 1.5\n\nThe core Mandelbrot algorithm involves computing an iterative complex function for each pixel until it ‚Äúescapes‚Äù the complex circle of radius 2, counting the number of iterations to escape:\n\nùëß\nùëñ\n+\n1\n=\nùëß\nùëñ\n2\n+\nùëê\n\n# Compute the number of steps to escape.\ndef mandelbrot_kernel(c: ComplexFloat64) -> Int:\n    z = c\n    for i in range(MAX_ITERS):\n        z = z * z + c\n        if z.squared_norm() > 4:\n            return i\n    return MAX_ITERS\n\n\ndef compute_mandelbrot() -> Tensor[float_type]:\n    # create a matrix. Each element of the matrix corresponds to a pixel\n    t = Tensor[float_type](height, width)\n\n    dx = (max_x - min_x) / width\n    dy = (max_y - min_y) / height\n\n    y = min_y\n    for row in range(height):\n        x = min_x\n        for col in range(width):\n            t[Index(row, col)] = mandelbrot_kernel(ComplexFloat64(x, y))\n            x += dx\n        y += dy\n    return t\n\nPlotting the number of iterations to escape with some color gives us the canonical Mandelbrot set plot. To render it we can directly leverage Python‚Äôs matplotlib right from Mojo!\n\nFirst install the required libraries:\n\n%%python\nfrom importlib.util import find_spec\nimport shutil\nimport subprocess\n\nfix = \"\"\"\n-------------------------------------------------------------------------\nfix following the steps here:\n    https://github.com/modularml/mojo/issues/1085#issuecomment-1771403719\n-------------------------------------------------------------------------\n\"\"\"\n\ndef install_if_missing(name: str):\n    if find_spec(name):\n        return\n\n    print(f\"{name} not found, installing...\")\n    try:\n        if shutil.which('python3'): python = \"python3\"\n        elif shutil.which('python'): python = \"python\"\n        else: raise (\"python not on path\" + fix)\n        subprocess.check_call([python, \"-m\", \"pip\", \"install\", name])\n    except:\n        raise ImportError(f\"{name} not found\" + fix)\n\ninstall_if_missing(\"numpy\")\ninstall_if_missing(\"matplotlib\")\ndef show_plot(tensor: Tensor[float_type]):\n    alias scale = 10\n    alias dpi = 64\n\n    np = Python.import_module(\"numpy\")\n    plt = Python.import_module(\"matplotlib.pyplot\")\n    colors = Python.import_module(\"matplotlib.colors\")\n\n    numpy_array = np.zeros((height, width), np.float64)\n\n    for row in range(height):\n        for col in range(width):\n            numpy_array.itemset((col, row), tensor[col, row])\n\n    fig = plt.figure(1, [scale, scale * height // width], dpi)\n    ax = fig.add_axes([0.0, 0.0, 1.0, 1.0], False, 1)\n    light = colors.LightSource(315, 10, 0, 1, 1, 0)\n\n    image = light.shade(numpy_array, plt.cm.hot, colors.PowerNorm(0.3), \"hsv\", 0, 0, 1.5)\n    plt.imshow(image)\n    plt.axis(\"off\")\n    plt.show()\n\nshow_plot(compute_mandelbrot())\n\nVectorizing Mandelbrot\n\nWe showed a naive implementation of the Mandelbrot algorithm, but there are two things we can do to speed it up. We can early-stop the loop iteration when a pixel is known to have escaped, and we can leverage Mojo‚Äôs access to hardware by vectorizing the loop, computing multiple pixels simultaneously. To do that we will use the vectorize higher order generator.\n\nWe start by defining our main iteration loop in a vectorized fashion\n\nfn mandelbrot_kernel_SIMD[\n    simd_width: Int\n](c: ComplexSIMD[float_type, simd_width]) -> SIMD[float_type, simd_width]:\n    \"\"\"A vectorized implementation of the inner mandelbrot computation.\"\"\"\n    let cx = c.re\n    let cy = c.im\n    var x = SIMD[float_type, simd_width](0)\n    var y = SIMD[float_type, simd_width](0)\n    var y2 = SIMD[float_type, simd_width](0)\n    var iters = SIMD[float_type, simd_width](0)\n\n    var t: SIMD[DType.bool, simd_width] = True\n    for i in range(MAX_ITERS):\n        if not t.reduce_or():\n            break\n        y2 = y*y\n        y = x.fma(y + y, cy)\n        t = x.fma(x, y2) <= 4\n        x = x.fma(x, cx - y2)\n        iters = t.select(iters + 1, iters)\n    return iters\n\nThe above function is parameterized on the simd_width and processes simd_width pixels. It only escapes once all pixels within the vector lane are done. We can use the same iteration loop as above, but this time we vectorize within each row instead. We use the vectorize generator to make this a simple function call.\n\nfn vectorized():\n    let t = Tensor[float_type](height, width)\n\n    @parameter\n    fn worker(row: Int):\n        let scale_x = (max_x - min_x) / width\n        let scale_y = (max_y - min_y) / height\n\n        @parameter\n        fn compute_vector[simd_width: Int](col: Int):\n            \"\"\"Each time we oeprate on a `simd_width` vector of pixels.\"\"\"\n            let cx = min_x + (col + iota[float_type, simd_width]()) * scale_x\n            let cy = min_y + row * scale_y\n            let c = ComplexSIMD[float_type, simd_width](cx, cy)\n            t.data().simd_store[simd_width](row * width + col, mandelbrot_kernel_SIMD[simd_width](c))\n\n        # Vectorize the call to compute_vector where call gets a chunk of pixels.\n        vectorize[simd_width, compute_vector](width)\n\n\n    @parameter\n    fn bench[simd_width: Int]():\n        for row in range(height):\n            worker(row)\n\n    let vectorized = benchmark.run[bench[simd_width]]().mean[\"ms\"]()\n    print(\"Vectorized\", \":\", vectorized, \"ms\")\n\n    try:\n        _ = show_plot(t)\n    except e:\n        print(\"failed to show plot:\", e)\n\nvectorized()\nVectorized : 12.177345000000001 ms\n\nParallelizing Mandelbrot\n\nWhile the vectorized implementation above is efficient, we can get better performance by parallelizing on the cols. This again is simple in Mojo using the parallelize higher order function. Only the function that performs the invocation needs to change.\n\nfn parallelized():\n    let t = Tensor[float_type](height, width)\n\n    @parameter\n    fn worker(row: Int):\n        let scale_x = (max_x - min_x) / width\n        let scale_y = (max_y - min_y) / height\n\n        @parameter\n        fn compute_vector[simd_width: Int](col: Int):\n            \"\"\"Each time we oeprate on a `simd_width` vector of pixels.\"\"\"\n            let cx = min_x + (col + iota[float_type, simd_width]()) * scale_x\n            let cy = min_y + row * scale_y\n            let c = ComplexSIMD[float_type, simd_width](cx, cy)\n            t.data().simd_store[simd_width](row * width + col, mandelbrot_kernel_SIMD[simd_width](c))\n\n        # Vectorize the call to compute_vector where call gets a chunk of pixels.\n        vectorize[simd_width, compute_vector](width)\n\n\n    @parameter\n    fn bench_parallel[simd_width: Int]():\n        parallelize[worker](height, height)\n\n    let parallelized = benchmark.run[bench_parallel[simd_width]]().mean[\"ms\"]()\n    print(\"Parallelized:\", parallelized, \"ms\")\n\n    try:\n        _ = show_plot(t)\n    except e:\n        print(\"failed to show plot:\", e)\n\nparallelized()\nParallelized: 1.4245639999999999 ms\n\nBenchmarking\n\nIn this section we increase the size to 4096x4096 and run 1000 iterations for a larger test to stress the CPU\n\nfn compare():\n    let t = Tensor[float_type](height, width)\n\n    @parameter\n    fn worker(row: Int):\n        let scale_x = (max_x - min_x) / width\n        let scale_y = (max_y - min_y) / height\n\n        @parameter\n        fn compute_vector[simd_width: Int](col: Int):\n            \"\"\"Each time we oeprate on a `simd_width` vector of pixels.\"\"\"\n            let cx = min_x + (col + iota[float_type, simd_width]()) * scale_x\n            let cy = min_y + row * scale_y\n            let c = ComplexSIMD[float_type, simd_width](cx, cy)\n            t.data().simd_store[simd_width](row * width + col, mandelbrot_kernel_SIMD[simd_width](c))\n\n        # Vectorize the call to compute_vector where call gets a chunk of pixels.\n        vectorize[simd_width, compute_vector](width)\n\n\n    @parameter\n    fn bench[simd_width: Int]():\n        for row in range(height):\n            worker(row)\n\n    let vectorized = benchmark.run[bench[simd_width]]().mean[\"ms\"]()\n    print(\"Number of threads:\", num_cores())\n    print(\"Vectorized:\", vectorized, \"ms\")\n\n    # Parallelized\n    @parameter\n    fn bench_parallel[simd_width: Int]():\n        parallelize[worker](height, height)\n\n    let parallelized = benchmark.run[bench_parallel[simd_width]]().mean[\"ms\"]()\n    print(\"Parallelized:\", parallelized, \"ms\")\n    print(\"Parallel speedup:\", vectorized / parallelized)\n\n    _ = t # Make sure tensor isn't destroyed before benchmark is finished\ncompare()\nNumber of threads: 16\nVectorized: 12.171849 ms\nParallelized: 1.3043979999999999 ms\nParallel speedup: 9.3313919524562294\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - Low-level IR in Mojo",
    "url": "https://docs.modular.com/mojo/notebooks/BoolMLIR.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nWhat is MLIR?\nDefining the OurBool type\nLeveraging MLIR\nValue semantics in Mojo\nCompile-time constants\nImplementing __bool__\nAvoiding type conversion with __mlir_i1__\nAdding functionality with MLIR\nThe promise of modularity\nLow-level IR in Mojo\n\nMojo is a high-level programming language with an extensive set of modern features. Mojo also provides you, the programmer, access to all of the low-level primitives that you need to write powerful ‚Äì yet zero-cost ‚Äì abstractions.\n\nThese primitives are implemented in MLIR, an extensible intermediate representation (IR) format for compiler design. Many different programming languages and compilers translate their source programs into MLIR, and because Mojo provides direct access to MLIR features, this means Mojo programs can enjoy the benefits of each of these tools.\n\nGoing one step further, Mojo‚Äôs unique combination of zero-cost abstractions with MLIR interoperability means that Mojo programs can take full advantage of anything that interfaces with MLIR. While this isn‚Äôt something normal Mojo programmers may ever need to do, it‚Äôs an extremely powerful capability when extending a system to interface with a new datatype, or an esoteric new accelerator feature.\n\nTo illustrate these ideas, we‚Äôll implement a boolean type in Mojo below, which we‚Äôll call OurBool. We‚Äôll make extensive use of MLIR, so let‚Äôs begin with a short primer.\n\nWhat is MLIR?\n\nMLIR is an intermediate representation of a program, not unlike an assembly language, in which a sequential set of instructions operate on in-memory values.\n\nMore importantly, MLIR is modular and extensible. MLIR is composed of an ever-growing number of ‚Äúdialects.‚Äù Each dialect defines operations and optimizations: for example, the ‚Äòmath‚Äô dialect provides mathematical operations such as sine and cosine, the ‚Äòamdgpu‚Äô dialect provides operations specific to AMD processors, and so on.\n\nEach of MLIR‚Äôs dialects can interoperate with the others. This is why MLIR¬†is said to unlock heterogeneous compute: as newer, faster processors and architectures are developed, new MLIR dialects are implemented to generate optimal code for those environments. Any new MLIR dialect can be translated seamlessly into other dialects, so as more get added, all existing MLIR becomes more powerful.\n\nThis means that our own custom types, such as the OurBool type we‚Äôll create below, can be used to provide programmers with a high-level, Python-like interface. But ‚Äúunder the covers,‚Äù Mojo and MLIR will optimize our convenient, high-level types for each new processor that appears in the future.\n\nThere‚Äôs much more to write about why MLIR is such a revolutionary technology, but let‚Äôs get back to Mojo and defining the OurBool type. There will be opportunities to learn more about MLIR along the way.\n\nDefining the OurBool type\n\nWe can use Mojo‚Äôs struct keyword to define a new type OurBool:\n\nstruct OurBool:\n    var value: __mlir_type.i1\n\nA boolean can represent 0 or 1, ‚Äútrue‚Äù or ‚Äúfalse.‚Äù To store this information, OurBool has a single member, called value. Its type is represented directly in MLIR, using the MLIR builtin type i1. In fact, you can use any MLIR type in Mojo, by prefixing the type name with __mlir_type.\n\nAs we‚Äôll see below, representing our boolean value with i1 will allow us to utilize all of the MLIR operations and optimizations that interface with the i1 type ‚Äì and there are many of them!\n\nHaving defined OurBool, we can now declare a variable of this type:\n\nlet a: OurBool\nLeveraging MLIR\n\nNaturally, we might next try to create an instance of OurBool. Attempting to do so at this point, however, results in an error:\n\nlet a = OurBool() # error: 'OurBool' does not implement an '__init__' method\n\nAs in Python, __init__ is a special method that can be defined to customize the behavior of a type. We can implement an __init__ method that takes no arguments, and returns an OurBool with a ‚Äúfalse‚Äù value.\n\nstruct OurBool:\n    var value: __mlir_type.i1\n\n    fn __init__(inout self):\n        self.value = __mlir_op.`index.bool.constant`[\n            value=__mlir_attr.`false`,\n        ]()\n\nTo initialize the underlying i1 value, we use an MLIR operation from its ‚Äòindex‚Äô dialect, called index.bool.constant.\n\nMLIR‚Äôs ‚Äòindex‚Äô dialect provides us with operations for manipulating builtin MLIR types, such as the i1 we use to store the value of OurBool. The index.bool.constant operation takes a true or false compile-time constant as input, and produces a runtime output of type i1 with the given value.\n\nSo, as shown above, in addition to any MLIR type, Mojo also provides direct access to any MLIR operation via the __mlir_op prefix, and to any attribute via the __mlir_attr prefix. MLIR attributes are used to represent compile-time constants.\n\nAs you can see above, the syntax for interacting with MLIR isn‚Äôt always pretty: MLIR attributes are passed in between square brackets [...], and the operation is executed via a parentheses suffix (...), which can take runtime argument values. However, most Mojo programmers will not need to access MLIR directly, and for the few that do, this ‚Äúugly‚Äù syntax gives them superpowers: they can define high-level types that are easy to use, but that internally plug into MLIR and its powerful system of dialects.\n\nWe think this is very exciting, but let‚Äôs bring things back down to earth: having defined an __init__ method, we can now create an instance of our OurBool type:\n\nlet b = OurBool()\nValue semantics in Mojo\n\nWe can now instantiate OurBool, but using it is another story:\n\nlet a = OurBool()\nlet b = a # error: 'OurBool' does not implement the '__copyinit__' method\n\nMojo uses ‚Äúvalue semantics‚Äù by default, meaning that it expects to create a copy of a when assigning to b. However, Mojo doesn‚Äôt make any assumptions about how to copy OurBool, or its underlying i1 value. The error indicates that we should implement a __copyinit__ method, which would implement the copying logic.\n\nIn our case, however, OurBool is a very simple type, with only one ‚Äútrivially copyable‚Äù member. We can use a decorator to tell the Mojo compiler that, saving us the trouble of defining our own __copyinit__ boilerplate. Trivially copyable types must implement an __init__ method that returns an instance of themselves, so we must also rewrite our initializer slightly.\n\n@register_passable(\"trivial\")\nstruct OurBool:\n    var value: __mlir_type.i1\n\n    fn __init__() -> Self:\n        return Self {\n            value: __mlir_op.`index.bool.constant`[\n                value=__mlir_attr.`false`,\n            ]()\n        }\n\nWe can now copy OurBool as we please:\n\nlet c = OurBool()\nlet d = c\nCompile-time constants\n\nIt‚Äôs not very useful to have a boolean type that can only represent ‚Äúfalse.‚Äù Let‚Äôs define compile-time constants that represent true and false OurBool values.\n\nFirst, let‚Äôs define another __init__ constructor for OurBool that takes its i1 value as an argument:\n\n@register_passable(\"trivial\")\nstruct OurBool:\n    var value: __mlir_type.i1\n\n    # ...\n\n    fn __init__(value: __mlir_type.i1) -> Self:\n        return Self {value: value}\n\nThis allows us to define compile-time constant OurBool values, using the alias keyword. First, let‚Äôs define OurTrue:\n\nalias OurTrue = OurBool(__mlir_attr.`true`)\n\nHere we‚Äôre passing in an MLIR compile-time constant value of true, which has the i1 type that our new __init__ constructor expects. We can use a slightly different syntax for OurFalse:\n\nalias OurFalse: OurBool = __mlir_attr.`false`\n\nOurFalse is declared to be of type OurBool, and then assigned an i1 type ‚Äì in this case, the OurBool constructor we added is called implicitly.\n\nWith true and false constants, we can also simplify our original __init__ constructor for OurBool. Instead of constructing an MLIR value, we can simply return our OurFalse constant:\n\nalias OurTrue = OurBool(__mlir_attr.`true`)\nalias OurFalse: OurBool = __mlir_attr.`false`\n\n\n@register_passable(\"trivial\")\nstruct OurBool:\n    var value: __mlir_type.i1\n\n    # We can simplify our no-argument constructor:\n    fn __init__() -> Self:\n        return OurFalse\n\n    fn __init__(value: __mlir_type.i1) -> Self:\n        return Self {value: value}\n\nNote also that we can define OurTrue before we define OurBool. The Mojo compiler is smart enough to figure this out.\n\nWith these constants, we can now define variables with both true and false values of OurBool:\n\nlet e = OurTrue\nlet f = OurFalse\nImplementing __bool__\n\nOf course, the reason booleans are ubiquitous in programming is because they can be used for program control flow. However, if we attempt to use OurBool in this way, we get an error:\n\nlet a = OurTrue\nif a: print(\"It's true!\") # error: 'OurBool' does not implement the '__bool__' method\n\nWhen Mojo attempts to execute our program, it needs to be able to determine whether to print ‚ÄúIt‚Äôs true!‚Äù or not. It doesn‚Äôt yet know that OurBool represents a boolean value ‚Äì Mojo just sees a struct that is 1 bit in size. However, Mojo also provides interfaces that convey boolean¬†qualities, which are the same as those used by Mojo‚Äôs standard library types, like Bool. In practice, this means Mojo gives you full control: any type that‚Äôs packaged with the language‚Äôs standard library is one for which you could define your own version.\n\nIn the case of our error message, Mojo is telling us that implementing a __bool__ method on OurBool would signify that it has boolean qualities.\n\nThankfully, __bool__ is simple to implement: Mojo‚Äôs standard library and builtin types are all implemented on top of MLIR, and so the builtin Bool type also defines a constructor that takes an i1, just like OurBool:\n\nalias OurTrue = OurBool(__mlir_attr.`true`)\nalias OurFalse: OurBool = __mlir_attr.`false`\n\n\n@register_passable(\"trivial\")\nstruct OurBool:\n    var value: __mlir_type.i1\n\n    # ...\n\n    fn __init__(value: __mlir_type.i1) -> Self:\n        return Self {value: value}\n\n    # Our new method converts `OurBool` to `Bool`:\n    fn __bool__(self) -> Bool:\n        return Bool(self.value)\n\nNow we can use OurBool anywhere we can use the builtin Bool type:\n\nlet g = OurTrue\nif g: print(\"It's true!\")\nIt's true!\nAvoiding type conversion with __mlir_i1__\n\nThe OurBool type is looking great, and by providing a conversion to Bool, it can be used anywhere the builtin Bool type can. But we promised you ‚Äúfull control,‚Äù and the ability to define your own version of any type built into Mojo or its standard library. So, why do we depend on __bool__ to convert our type into Bool (the standard library type)? This is just the formal way for Mojo to evaluate a type as a boolean, which is useful for real-world scenarios. However, to define a boolean type from scratch, you have a more low-level option.\n\nWhen Mojo evaluates a conditional expression, it actually attempts to convert the expression to an MLIR i1 value, by searching for the special interface method __mlir_i1__. (The automatic conversion to Bool occurs because Bool is known to implement the __mlir_i1__ method.)\n\nThus, by implementing the __mlir_i1__ special methods in OurBool, we can create a type that can replaces Bool entirely:\n\nalias OurTrue = OurBool(__mlir_attr.`true`)\nalias OurFalse: OurBool = __mlir_attr.`false`\n\n\n@register_passable(\"trivial\")\nstruct OurBool:\n    var value: __mlir_type.i1\n\n    fn __init__(value: __mlir_type.i1) -> Self:\n        return Self {value: value}\n\n    # Our new method converts `OurBool` to `i1`:\n    fn __mlir_i1__(self) -> __mlir_type.i1:\n        return self.value\n\nWe can still use OurBool in conditionals just as we did before:\n\nlet h = OurTrue\nif h: print(\"No more Bool conversion!\")\nNo more Bool conversion!\n\nBut this time, no conversion to Bool occurs. You can try adding print statements to the __bool__ and __mlir_i1__ methods to see for yourself.\n\nAdding functionality with MLIR\n\nThere are many more ways we can improve OurBool. Many of those involve implementing special methods, some of which you may recognize from Python, and some which are specific to Mojo. For example, we can implement inversion of a OurBool value by adding a __invert__ method. We can also add an __eq__ method, which allows two OurBool to be compared with the == operator.\n\nWhat sets Mojo apart is the fact that we can implement each of these using MLIR. To implement __eq__, for example, we use the index.casts operation to cast our i1 values to the MLIR index dialect‚Äôs index type, and then the index.cmp operation to compare them for equality. And with the __eq__ method implemented, we can then implement __invert__ in terms of __eq__:\n\nalias OurTrue = OurBool(__mlir_attr.`true`)\nalias OurFalse: OurBool = __mlir_attr.`false`\n\n\n@register_passable(\"trivial\")\nstruct OurBool:\n    var value: __mlir_type.i1\n\n    fn __init__(value: __mlir_type.i1) -> Self:\n        return Self {value: value}\n\n    # ...\n\n    fn __mlir_i1__(self) -> __mlir_type.i1:\n        return self.value\n\n    fn __eq__(self, rhs: OurBool) -> Self:\n        let lhsIndex = __mlir_op.`index.casts`[_type=__mlir_type.index](\n            self.value\n        )\n        let rhsIndex = __mlir_op.`index.casts`[_type=__mlir_type.index](\n            rhs.value\n        )\n        return Self(\n            __mlir_op.`index.cmp`[\n                pred=__mlir_attr.`#index<cmp_predicate eq>`\n            ](lhsIndex, rhsIndex)\n        )\n\n    fn __invert__(self) -> Self:\n        return OurFalse if self == OurTrue else OurTrue\n\nThis allows us to use the ~ operator with OurBool:\n\nlet i = OurFalse\nif ~i: print(\"It's false!\")\nIt's false!\n\nThis extensible design is what allows even ‚Äúbuilt in‚Äù Mojo types like Bool, Int, and even Tuple to be implemented in the Mojo standard library in terms of MLIR, rather than hard-coded into the Mojo language. This also means that there‚Äôs almost nothing that those types can achieve that user-defined types cannot.\n\nBy extension, this means that the incredible performance that Mojo unlocks for machine learning workflows isn‚Äôt due to some magic being performed behind a curtain ‚Äì you can define your own high-level types that, in their implementation, use low-level MLIR to achieve unprecedented speed and control.\n\nThe promise of modularity\n\nAs we‚Äôve seen, Mojo‚Äôs integration with MLIR allows Mojo programmers to implement zero-cost abstractons on par with Mojo‚Äôs own builtin and standard library types.\n\nMLIR is open-source and extensible: new dialects are being added all the time, and those dialects then become available to use in Mojo. All the while, Mojo code gets more powerful and more optimized for new hardware ‚Äì with no additional work necessary by Mojo programmers.\n\nWhat this means is that your own custom types, whether those be OurBool or OurTensor, can be used to provide programmers with an easy-to-use and unchanging interface. But behind the scenes, MLIR will optimize those convenient, high-level types for the computing environments of tomorrow.\n\nIn other words: Mojo isn‚Äôt magic, it‚Äôs modular.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - Mojoüî• notebooks",
    "url": "https://docs.modular.com/mojo/notebooks/",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nMojoüî• notebooks\n\nThe following pages are rendered from the Jupyter notebooks that are available on GitHub and in the Mojo Playground.\n\n\n\n\nLow-level IR in Mojo\nLearn how to use low-level primitives to define your own boolean type in Mojo.\nMandelbrot in Mojo with Python plots\nLearn how to write high-performance Mojo code and import Python packages.\nMatrix multiplication in Mojo\nLearn how to leverage Mojo‚Äôs various functions to write a high-performance matmul.\nFast memset in Mojo\nLearn how to use Mojo‚Äôs autotuning to quickly write a memset function.\nRay tracing in Mojo\nLearn how to draw 3D graphics with ray-traced lighting using Mojo.\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - Mojoüî• programming manual",
    "url": "https://docs.modular.com/mojo/programming-manual.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nUsing the Mojo compiler\nBasic systems programming extensions\nArgument passing control and memory ownership\nPython integration\nParameterization: compile-time metaprogramming\n‚ÄúValue Lifecycle‚Äù: Birth, life and death of a value\nBehavior of destructors\nLifetimes\nType traits\nAdvanced/Obscure Mojo features\nMojoüî• programming manual\n\nMojo is a programming language that is as easy to use as Python but with the performance of C++ and Rust. Furthermore, Mojo provides the ability to leverage the entire Python library ecosystem.\n\nMojo achieves this feat by utilizing next-generation compiler technologies with integrated caching, multithreading, and cloud distribution technologies. Furthermore, Mojo‚Äôs autotuning and compile-time metaprogramming features allow you to write code that is portable to even the most exotic hardware.\n\nMore importantly, Mojo allows you to leverage the entire Python ecosystem so you can continue to use tools you are familiar with. Mojo is designed to become a superset of Python over time by preserving Python‚Äôs dynamic features while adding new primitives for systems programming. These new system programming primitives will allow Mojo developers to build high-performance libraries that currently require C, C++, Rust, CUDA, and other accelerator systems. By bringing together the best of dynamic languages and systems languages, we hope to provide a unified programming model that works across levels of abstraction, is friendly for novice programmers, and scales across many use cases from accelerators through to application programming and scripting.\n\nThis document is an introduction to the Mojo programming language, not a complete language guide. It assumes knowledge of Python and systems programming concepts. At the moment, Mojo is still a work in progress and the documentation is targeted to developers with systems programming experience. As the language grows and becomes more broadly available, we intend for it to be friendly and accessible to everyone, including beginner programmers. It‚Äôs just not there today.\n\nUsing the Mojo compiler\n\nWith the Mojo SDK, you can run a Mojo program from a terminal just like you can with Python. So if you have a file named hello.mojo (or hello.üî•‚Äîyes, the file extension can be an emoji!), just type mojo hello.mojo:\n\n$ cat hello.üî•\ndef main():\n    print(\"hello world\")\n    for x in range(9, 0, -3):\n        print(x)\n$ mojo hello.üî•\nhello world\n9\n6\n3\n$\n\nAgain, you can use either the .üî• or .mojo suffix.\n\nFor more details about the Mojo compiler tools, see the mojo CLI docs.\n\nBasic systems programming extensions\n\nGiven our goal of compatibility and Python‚Äôs strength with high-level applications and dynamic APIs, we don‚Äôt have to spend much time explaining how those portions of the language work. On the other hand, Python‚Äôs support for systems programming is mainly delegated to C, and we want to provide a single system that is great in that world. As such, this section breaks down each major component and feature and describes how to use them with examples.\n\nlet and var declarations\n\nInside a def in Mojo, you may assign a value to a name and it implicitly creates a function scope variable just like in Python. This provides a very dynamic and low-ceremony way to write code, but it is a challenge for two reasons:\n\nSystems programmers often want to declare that a value is immutable for type-safety and performance.\nThey may want to get an error if they mistype a variable name in an assignment.\n\nTo support this, Mojo provides scoped runtime value declarations: let is immutable, and var is mutable. These values use lexical scoping and support name shadowing:\n\ndef your_function(a, b):\n    let c = a\n    # Uncomment to see an error:\n    # c = b  # error: c is immutable\n\n    if c != b:\n        let d = b\n        print(d)\n\nyour_function(2, 3)\n3\n\nlet and var declarations support type specifiers as well as patterns, and late initialization:\n\ndef your_function():\n    let x: Int = 42\n    let y: Float64 = 17.0\n\n    let z: Float32\n    if x != 0:\n        z = 1.0\n    else:\n        z = foo()\n    print(z)\n\ndef foo() -> Float32:\n    return 3.14\n\nyour_function()\n1.0\n\nNote that let and var are completely optional when in a def function (you can instead use implicitly declared values, just like Python), but they‚Äôre required for all variables in an fn function.\n\nAlso beware that when using Mojo in a REPL environment (such as this notebook), top-level variables (variables that live outside a function or struct) are treated like variables in a def, so they allow implicit value type declarations (they do not require var or let declarations, nor type declarations). This matches the Python REPL behavior.\n\nstruct types\n\nMojo is based on MLIR and LLVM, which offer a cutting-edge compiler and code generation system used in many programming languages. This lets us have better control over data organization, direct access to data fields, and other ways to improve performance. An important feature of modern systems programming languages is the ability to build high-level and safe abstractions on top of these complex, low-level operations without any performance loss. In Mojo, this is provided by the struct type.\n\nA struct in Mojo is similar to a Python class: they both support methods, fields, operator overloading, decorators for metaprogramming, etc. Their differences are as follows:\n\nPython classes are dynamic: they allow for dynamic dispatch, monkey-patching (or ‚Äúswizzling‚Äù), and dynamically binding instance properties at runtime.\n\nMojo structs are static: they are bound at compile-time (you cannot add methods at runtime). Structs allow you to trade flexibility for performance while being safe and easy to use.\n\nHere‚Äôs a simple definition of a struct:\n\nstruct MyPair:\n    var first: Int\n    var second: Int\n\n    # We use 'fn' instead of 'def' here - we'll explain that soon\n    fn __init__(inout self, first: Int, second: Int):\n        self.first = first\n        self.second = second\n\n    fn __lt__(self, rhs: MyPair) -> Bool:\n        return self.first < rhs.first or\n              (self.first == rhs.first and\n               self.second < rhs.second)\n\nSyntactically, the biggest difference compared to a Python class is that all instance properties in a struct must be explicitly declared with a var or let declaration.\n\nIn Mojo, the structure and contents of a ‚Äústruct‚Äù are set in advance and can‚Äôt be changed while the program is running. Unlike in Python, where you can add, remove, or change attributes of an object on the fly, Mojo doesn‚Äôt allow that for structs. This means you can‚Äôt use del to remove a method or change its value in the middle of running the program.\n\nHowever, the static nature of struct has some great benefits! It helps Mojo run your code faster. The program knows exactly where to find the struct‚Äôs information and how to use it without any extra steps or delays.\n\nMojo‚Äôs structs also work really well with features you might already know from Python, like operator overloading (which lets you change how math symbols like + and - work with your own data). Furthermore, all the ‚Äústandard types‚Äù (like Int, Bool, String and even Tuple) are made using structs. This means they‚Äôre part of the standard set of tools you can use, rather than being hardwired into the language itself. This gives you more flexibility and control when writing your code.\n\nIf you‚Äôre wondering what the inout means on the self argument: this indicates that the argument is mutable and changes made inside the function are visible to the caller. For details, see below about inout arguments.\n\nInt vs int\n\nIn Mojo, you might notice that we use Int (with a capital ‚ÄúI‚Äù), which is different from Python‚Äôs int (with a lowercase ‚Äúi‚Äù). This difference is on purpose, and it‚Äôs actually a good thing!\n\nIn Python, the int type can handle really big numbers and has some extra features, like checking if two numbers are the same object. But this comes with some extra baggage that can slow things down. Mojo‚Äôs Int is different. It‚Äôs designed to be simple, fast, and tuned for your computer‚Äôs hardware to handle quickly.\n\nWe made this choice for two main reasons:\n\nWe want to give programmers who need to work closely with computer hardware (systems programmers) a transparent and reliable way to interact with hardware. We don‚Äôt want to rely on fancy tricks (like JIT compilers) to make things faster.\n\nWe want Mojo to work well with Python without causing any issues. By using a different name (Int instead of int), we can keep both types in Mojo without changing how Python‚Äôs int works.\n\nAs a bonus, Int follows the same naming style as other custom data types you might create in Mojo. Additionally, Int is a struct that‚Äôs included in Mojo‚Äôs standard set of tools.\n\nStrong type checking\n\nEven though you can still use flexible types like in Python, Mojo lets you use strict type checking. Type-checking can make your code more predictable, manageable, and secure.\n\nOne of the primary ways to employ strong type checking is with Mojo‚Äôs struct type. A struct definition in Mojo defines a compile-time-bound name, and references to that name in a type context are treated as a strong specification for the value being defined. For example, consider the following code that uses the MyPair struct shown above:\n\ndef pair_test() -> Bool:\n    let p = MyPair(1, 2)\n    # Uncomment to see an error:\n    # return p < 4 # gives a compile time error\n    return True\n\nIf you uncomment the first return statement and run it, you‚Äôll get a compile-time error telling you that 4 cannot be converted to MyPair, which is what the right-hand-side of __lt__() requires (in the MyPair definition).\n\nThis is a familiar experience when working with systems programming languages, but it‚Äôs not how Python works. Python has syntactically identical features for MyPy type annotations, but they are not enforced by the compiler: instead, they are hints that inform static analysis. By tying types to specific declarations, Mojo can handle both the classical type annotation hints and strong type specifications without breaking compatibility.\n\nType checking isn‚Äôt the only use-case for strong types. Since we know the types are accurate, we can optimize the code based on those types, pass values in registers, and be as efficient as C for argument passing and other low-level details. This is the foundation of the safety and predictability guarantees Mojo provides to systems programmers.\n\nOverloaded functions and methods\n\nLike Python, you can define functions in Mojo without specifying argument data types and Mojo will handle them dynamically. This is nice when you want expressive APIs that just work by accepting arbitrary inputs and let dynamic dispatch decide how to handle the data. However, when you want to ensure type safety, as discussed above, Mojo also offers full support for overloaded functions and methods.\n\nThis allows you to define multiple functions with the same name but with different arguments. This is a common feature seen in many languages, such as C++, Java, and Swift.\n\nWhen resolving a function call, Mojo tries each candidate and uses the one that works (if only one works), or it picks the closest match (if it can determine a close match), or it reports that the call is ambiguous if it can‚Äôt figure out which one to pick. In the latter case, you can resolve the ambiguity by adding an explicit cast on the call site.\n\nLet‚Äôs look at an example:\n\nstruct Complex:\n    var re: Float32\n    var im: Float32\n\n    fn __init__(inout self, x: Float32):\n        \"\"\"Construct a complex number given a real number.\"\"\"\n        self.re = x\n        self.im = 0.0\n\n    fn __init__(inout self, r: Float32, i: Float32):\n        \"\"\"Construct a complex number given its real and imaginary components.\"\"\"\n        self.re = r\n        self.im = i\n\nYou can overload methods in structs and classes and overload module-level functions.\n\nMojo doesn‚Äôt support overloading solely on result type, and doesn‚Äôt use result type or contextual type information for type inference, keeping things simple, fast, and predictable. Mojo will never produce an ‚Äúexpression too complex‚Äù error, because its type-checker is simple and fast by definition.\n\nAgain, if you leave your argument names without type definitions, then the function behaves just like Python with dynamic types. As soon as you define a single argument type, Mojo will look for overload candidates and resolve function calls as described above.\n\nAlthough we haven‚Äôt discussed parameters yet (they‚Äôre different from function arguments), you can also overload functions and methods based on parameters.\n\nfn definitions\n\nThe extensions above are the cornerstone that provides low-level programming and provide abstraction capabilities, but many systems programmers prefer more control and predictability than what def in Mojo provides. To recap, def is defined by necessity to be very dynamic, flexible and generally compatible with Python: arguments are mutable, local variables are implicitly declared on first use, and scoping isn‚Äôt enforced. This is great for high level programming and scripting, but is not always great for systems programming. To complement this, Mojo provides an fn declaration which is like a ‚Äústrict mode‚Äù for def.\n\nAlternative: instead of using a new keyword like fn, we could instead add a modifier or decorator like @strict def. However, we need to take new keywords anyway and there is little cost to doing so. Also, in practice in systems programming domains, fn is used all the time so it probably makes sense to make it first class.\n\nAs far as a caller is concerned, fn and def are interchangeable: there is nothing a def can provide that a fn cannot (and vice versa). The difference is that a fn is more limited and controlled on the inside of its body (alternatively: pedantic and strict). Specifically, fns have a number of limitations compared to def functions:\n\nArgument values default to being immutable in the body of the function (like a let), instead of mutable (like a var). This catches accidental mutations, and permits the use of non-copyable types as arguments.\n\nArgument values require a type specification (except for self in a method), catching accidental omission of type specifications. Similarly, a missing return type specifier is interpreted as returning None instead of an unknown return type. Note that both can be explicitly declared to return object, which allows one to opt-in to the behavior of a def if desired.\n\nImplicit declaration of local variables is disabled, so all locals must be declared. This catches name typos and dovetails with the scoping provided by let and var.\n\nBoth support raising exceptions, but this must be explicitly declared on a fn with the raises keyword.\n\nProgramming patterns will vary widely across teams, and this level of strictness will not be for everyone. We expect that folks who are used to C++ and already use MyPy-style type annotations in Python to prefer the use of fns, but higher level programmers and ML researchers to continue to use def. Mojo allows you to freely intermix def and fn declarations, e.g. implementing some methods with one and others with the other, and allows each team or programmer to decide what is best for their use-case.\n\nFor more about argument behavior in Mojo functions, see the section below about Argument passing control and memory ownership.\n\nThe __copyinit__, __moveinit__, and __takeinit__ special methods\n\nMojo supports full ‚Äúvalue semantics‚Äù as seen in languages like C++ and Swift, and it makes defining simple aggregates of fields very easy with the @value decorator.\n\nFor advanced use cases, Mojo allows you to define custom constructors (using Python‚Äôs existing __init__ special method), custom destructors (using the existing __del__ special method) and custom copy and move constructors using the __copyinit__, __moveinit__ and __takeinit__ special methods.\n\nThese low-level customization hooks can be useful when doing low level systems programming, e.g.¬†with manual memory management. For example, consider a dynamic string type that needs to allocate memory for the string data when constructed and destroy it when the value is destroyed:\n\nfrom memory.unsafe import Pointer\n\nstruct HeapArray:\n    var data: Pointer[Int]\n    var size: Int\n\n    fn __init__(inout self, size: Int, val: Int):\n        self.size = size\n        self.data = Pointer[Int].alloc(self.size)\n        for i in range(self.size):\n            self.data.store(i, val)\n\n    fn __del__(owned self):\n        self.data.free()\n\n    fn dump(self):\n        print_no_newline(\"[\")\n        for i in range(self.size):\n            if i > 0:\n                print_no_newline(\", \")\n            print_no_newline(self.data.load(i))\n        print(\"]\")\n\nThis array type is implemented using low level functions to show a simple example of how this works. However, if you try to copy an instance of HeapArray with the = operator, you might be surprised:\n\nvar a = HeapArray(3, 1)\na.dump()   # Should print [1, 1, 1]\n# Uncomment to see an error:\n# var b = a  # ERROR: Vector doesn't implement __copyinit__\n\nvar b = HeapArray(4, 2)\nb.dump()   # Should print [2, 2, 2, 2]\na.dump()   # Should print [1, 1, 1]\n[1, 1, 1]\n[2, 2, 2, 2]\n[1, 1, 1]\n\nIf you uncomment the line to copy a into b, you‚Äôll see that Mojo doesn‚Äôt allow you to make a copy of our array: HeapArray contains an instance of Pointer (which is equivalent to a low-level C pointer), and Mojo doesn‚Äôt know what kind of data it points to or how to copy it. More generally, some types (like atomic numbers) cannot be copied or moved around because their address provides an identity just like a class instance does.\n\nIn this case, we do want our array to be copyable. To enable this, we have to implement the __copyinit__ special method, which is conventionally implemented like this:\n\nstruct HeapArray:\n    var data: Pointer[Int]\n    var size: Int\n\n    fn __init__(inout self, size: Int, val: Int):\n        self.size = size\n        self.data = Pointer[Int].alloc(self.size)\n        for i in range(self.size):\n            self.data.store(i, val)\n\n    fn __copyinit__(inout self, existing: Self):\n        self.size = existing.size\n        self.data = Pointer[Int].alloc(self.size)\n        for i in range(self.size):\n            self.data.store(i, existing.data.load(i))\n\n    fn __del__(owned self):\n        self.data.free()\n\n    fn dump(self):\n        print_no_newline(\"[\")\n        for i in range(self.size):\n            if i > 0:\n                print_no_newline(\", \")\n            print_no_newline(self.data.load(i))\n        print(\"]\")\n\nWith this implementation, our code above works correctly and the b = a copy produces a logically distinct instance of the array with its own lifetime and data:\n\nvar a = HeapArray(3, 1)\na.dump()   # Should print [1, 1, 1]\n# This is no longer an error:\nvar b = a\n\nb.dump()   # Should print [1, 1, 1]\na.dump()   # Should print [1, 1, 1]\n[1, 1, 1]\n[1, 1, 1]\n[1, 1, 1]\n\nMojo also supports the __moveinit__ method which allows both Rust-style moves (which transfers a value from one place to another when the source lifetime ends) and the __takeinit__ method for C++-style moves (where the contents of a value is logically transfered out of the source, but its destructor is still run), and allows defining custom move logic. For more detail, see the Value Lifecycle section below.\n\nMojo provides full control over the lifetime of a value, including the ability to make types copyable, move-only, and not-movable. This is more control than languages like Swift and Rust offer, which require values to at least be movable. If you are curious how existing can be passed into the __copyinit__ method without itself creating a copy, check out the section on Borrowed arguments below.\n\nArgument passing control and memory ownership\n\nIn both Python and Mojo, much of the language revolves around function calls: a lot of the (apparently) built-in behaviors are implemented in the standard library with ‚Äúdunder‚Äù (double-underscore) methods. Inside these magic functions is where a lot of memory ownership is determined through argument passing.\n\nLet‚Äôs review some details about how Python and Mojo pass arguments:\n\nAll values passed into a Python def function use reference semantics. This means the function can modify mutable objects passed into it and those changes are visible outside the function. However, the behavior is sometimes surprising for the uninitiated, because you can change the object that an argument points to and that change is not visible outside the function.\n\nAll values passed into a Mojo def function use value semantics by default. Compared to Python, this is an important difference: A Mojo def function receives a copy of all arguments‚Äîit can modify arguments inside the function, but the changes are not visible outside the function.\n\nAll values passed into a Mojo fn function are immutable references by default. This means the function can read the original object (it is not a copy), but it cannot modify the object at all.\n\nThis convention for immutable argument passing in a Mojo fn is called ‚Äúborrowing.‚Äù In the following sections, we‚Äôll explain how you can change the argument passing behavior in Mojo, for both def and fn functions.\n\nWhy argument conventions are important\n\nIn Python, all fundamental values are references to objects‚Äîas described above, a Python function can modify the original object. Thus, Python developers are used to thinking about everything as reference semantic. However, at the CPython or machine level, you can see that the references themselves are actually passed by-copy‚ÄîPython copies a pointer and adjusts reference counts.\n\nThis Python approach provides a comfortable programming model for most people, but it requires all values to be heap-allocated (and results are occasionally surprising due to reference sharing). Mojo classes (TODO: will) follow the same reference-semantic approach for most objects, but this isn‚Äôt practical for simple types like integers in a systems programming context. In these scenarios, we want the values to live on the stack or even in hardware registers. As such, Mojo structs are always inlined into their container, whether that be as the field of another type or into the stack frame of the containing function.\n\nThis raises some interesting questions: How do you implement methods that need to mutate self of a structure type, such as __iadd__? How does let work, and how does it prevent mutation? How are the lifetimes of these values controlled to keep Mojo a memory-safe language?\n\nThe answer is that the Mojo compiler uses dataflow analysis and type annotations to provide full control over value copies, aliasing of references, and mutation control. These features are similar in many ways to features in the Rust language, but they work somewhat differently in order to make Mojo easier to learn, and they integrate better into the Python ecosystem without requiring a massive annotation burden.\n\nIn the following sections, you‚Äôll learn about how you can control memory ownership for objects passed into Mojo fn functions.\n\nImmutable arguments (borrowed)\n\nA borrowed object is an immutable reference to an object that a function receives, instead of receiving a copy of the object. So the callee function has full read-and-execute access to the object, but it cannot modify it (the caller still has exclusive ‚Äúownership‚Äù of the object).\n\nFor example, consider this struct that we don‚Äôt want to copy when passing around instances of it:\n\n# Don't worry about this code yet. It's just needed for the function below.\n# It's a type so expensive to copy around so it does not have a\n# __copyinit__ method.\nstruct SomethingBig:\n    var id_number: Int\n    var huge: HeapArray\n    fn __init__(inout self, id: Int):\n        self.huge = HeapArray(1000, 0)\n        self.id_number = id\n\n    # self is passed by-reference for mutation as described above.\n    fn set_id(inout self, number: Int):\n        self.id_number = number\n\n    # Arguments like self are passed as borrowed by default.\n    fn print_id(self):  # Same as: fn print_id(borrowed self):\n        print(self.id_number)\n\nWhen passing an instance of SomethingBig to a function, it‚Äôs necessary to pass a reference because SomethingBig cannot be copied (it has no __copyinit__ method). And, as mentioned above, fn arguments are immutable references by default, but you can explicitly define it with the borrowed keyword as shown in the use_something_big() function here:\n\nfn use_something_big(borrowed a: SomethingBig, b: SomethingBig):\n    \"\"\"'a' and 'b' are both immutable, because 'borrowed' is the default.\"\"\"\n    a.print_id()\n    b.print_id()\n\nlet a = SomethingBig(10)\nlet b = SomethingBig(20)\nuse_something_big(a, b)\n10\n20\n\nThis default applies to all arguments uniformly, including the self argument of methods. This is much more efficient when passing large values or when passing expensive values like a reference-counted pointer (which is the default for Python/Mojo classes), because the copy constructor and destructor don‚Äôt have to be invoked when passing the argument.\n\nBecause the default argument convention for fn functions is borrowed, Mojo has simple and logical code that does the right thing by default. For example, we don‚Äôt want to copy or move all of SomethingBig just to invoke the print_id() method, or when calling use_something_big().\n\nThis borrowed argument convention is similar in some ways to passing an argument by const& in C++, which avoids a copy of the value and disables mutability in the callee. However, the borrowed convention differs from const& in C++ in two important ways:\n\nThe Mojo compiler implements a borrow checker (similar to Rust) that prevents code from dynamically forming mutable references to a value when there are immutable references outstanding, and it prevents multiple mutable references to the same value. You are allowed to have multiple borrows (as the call to use_something_big does above) but you cannot pass something by mutable reference and borrow at the same time. (TODO: Not currently enabled).\n\nSmall values like Int, Float, and SIMD are passed directly in machine registers instead of through an extra indirection (this is because they are declared with the @register_passable decorator). This is a significant performance enhancement when compared to languages like C++ and Rust, and moves this optimization from every call site to being declarative on a type.\n\nSimilar to Rust, Mojo‚Äôs borrow checker enforces the exclusivity of invariants. The major difference between Rust and Mojo is that Mojo does not require a sigil on the caller side to pass by borrow. Also, Mojo is more efficient when passing small values, and Rust defaults to moving values instead of passing them around by borrow. These policy and syntax decisions allow Mojo to provide an easier-to-use programming model.\n\nMutable arguments (inout)\n\nOn the other hand, if you define an fn function and want an argument to be mutable, you must declare the argument as mutable with the inout keyword.\n\nTip: When you see inout, it means any changes made to the argument inside the function are visible outside the function.\n\nConsider the following example, in which the __iadd__ function (which implements the in-place add operation such as x += 2) tries to modify self:\n\nstruct MyInt:\n    var value: Int\n\n    fn __init__(inout self, v: Int):\n        self.value = v\n\n    fn __copyinit__(inout self, existing: MyInt):\n        self.value = existing.value\n\n    # self and rhs are both immutable in __add__.\n    fn __add__(self, rhs: MyInt) -> MyInt:\n        return MyInt(self.value + rhs.value)\n\n    # ... but this cannot work for __iadd__\n    # Uncomment to see the error:\n    #fn __iadd__(self, rhs: Int):\n    #    self = self + rhs  # ERROR: cannot assign to self!\n\nIf you uncomment the __iadd__() method, you‚Äôll get a compiler error.\n\nThe problem here is that self is immutable because this is a Mojo fn function, so it can‚Äôt change the internal state of the argument (the default argument convention is borrowed). The solution is to declare that the argument is mutable by adding the inout keyword on the self argument name:\n\nstruct MyInt:\n    var value: Int\n\n    fn __init__(inout self, v: Int):\n        self.value = v\n\n    fn __copyinit__(inout self, existing: MyInt):\n        self.value = existing.value\n\n    # self and rhs are both immutable in __add__.\n    fn __add__(self, rhs: MyInt) -> MyInt:\n        return MyInt(self.value + rhs.value)\n\n    # ... now this works:\n    fn __iadd__(inout self, rhs: Int):\n        self = self + rhs\n\nNow the self argument is mutable in the function and any changes are visible in the caller, so we can perform in-place addition with MyInt:\n\nvar x: MyInt = 42\nx += 1\nprint(x.value) # prints 43 as expected\n\n# However...\nlet y = x\n# Uncomment to see the error:\n# y += 1       # ERROR: Cannot mutate 'let' value\n43\n\nIf you uncomment the last line above, mutation of the let value fails because it isn‚Äôt possible to form a mutable reference to an immutable value (let makes the variable immutable).\n\nOf course, you can declare multiple inout arguments. For example, you can define and use a swap function like this:\n\nfn swap(inout lhs: Int, inout rhs: Int):\n    let tmp = lhs\n    lhs = rhs\n    rhs = tmp\n\nvar x = 42\nvar y = 12\nprint(x, y)  # Prints 42, 12\nswap(x, y)\nprint(x, y)  # Prints 12, 42\n42 12\n12 42\n\nA very important aspect of this system is that it all composes correctly.\n\nNotice that we don‚Äôt call this argument passing ‚Äúby reference.‚Äù Although the inout convention is conceptually the same, we don‚Äôt call it by-reference passing because the implementation may actually pass values using pointers.\n\nTransfer arguments (owned and ^)\n\nThe final argument convention that Mojo supports is the owned argument convention. This convention is used for functions that want to take exclusive ownership over a value, and it is often used with the postfixed ^ operator.\n\nFor example, imagine you‚Äôre working with a move-only type like a unique pointer:\n\n# This is not really a unique pointer, we just model its behavior here\n# to serve the examples below.\nstruct UniquePointer:\n    var ptr: Int\n\n    fn __init__(inout self, ptr: Int):\n        self.ptr = ptr\n\n    fn __moveinit__(inout self, owned existing: Self):\n        self.ptr = existing.ptr\n\n    fn __del__(owned self):\n        self.ptr = 0\n\nWhile the borrow convention makes it easy to work with this unique pointer without ceremony, at some point you might want to transfer ownership to some other function. This is a situation where you want to use the ^ ‚Äútransfer‚Äù operator with your movable type.\n\nThe ^ operator ends the lifetime of a value binding and transfers the value ownership to something else (in the following example, ownership is transferred to the take_ptr() function). To support this, you can define functions as taking owned arguments. For example, you can define take_ptr() to take ownership of an argument as follows:\n\nfn take_ptr(owned p: UniquePointer):\n    print(\"take_ptr\")\n    print(p.ptr)\n\nfn use_ptr(borrowed p: UniquePointer):\n    print(\"use_ptr\")\n    print(p.ptr)\n\nfn work_with_unique_ptrs():\n    let p = UniquePointer(100)\n    use_ptr(p)    # Pass to borrowing function.\n    take_ptr(p^)  # Pass ownership of the `p` value to another function.\n\n    # Uncomment to see an error:\n    # use_ptr(p) # ERROR: p is no longer valid here!\n\nwork_with_unique_ptrs()\nuse_ptr\n100\ntake_ptr\n100\n\nNotice that if you uncomment the second call to use_ptr(), you get an error because the p value has been transferred to the take_ptr() function and, thus, the p value is destroyed.\n\nBecause it is declared owned, the take_ptr() function knows it has unique access to the value. This is very important for things like unique pointers, and it‚Äôs useful when you want to avoid copies.\n\nFor example, you will notably see the owned convention on destructors and on consuming move initializers. For example, our HeapArray struct defined earlier uses owned in its __del__() method, because you need to own a value to destroy it (or to steal its parts, in the case of a move constructor).\n\nComparing def and fn argument passing\n\nMojo‚Äôs def function is essentially just sugaring for the fn function:\n\nA def argument without an explicit type annotation defaults to Object.\n\nA def argument without a convention keyword (such as inout or owned) is passed by implicit copy into a mutable var with the same name as the argument. (This requires that the type have a __copyinit__ method.)\n\nFor example, these two functions have the same behavior:\n\ndef example(inout a: Int, b: Int, c):\n    # b and c use value semantics so they're mutable in the function\n    ...\n\nfn example(inout a: Int, b_in: Int, c_in: Object):\n    # b_in and c_in are immutable references, so we make mutable shadow copies\n    var b = b_in\n    var c = c_in\n    ...\n\nThe shadow copies typically add no overhead, because references for small types like Object are cheap to copy. The expensive part is adjusting the reference count, but that‚Äôs eliminated by a move optimization.\n\nPython integration\n\nIt‚Äôs easy to use Python modules you know and love in Mojo. You can import any Python module into your Mojo program and create Python types from Mojo types.\n\nImporting Python modules\n\nTo import a Python module in Mojo, just call Python.import_module() with the module name:\n\nfrom python import Python\n\nfn use_array() raises:\n    # This is equivalent to Python's `import numpy as np`\n    let np = Python.import_module(\"numpy\")\n\n    # Now use numpy as if writing in Python\n    let array = np.array([1, 2, 3])\n    print(array)\nuse_array()\n[1 2 3]\n\nYes, this imports Python NumPy, and you can import any other Python module you have installed.\n\nA few things to note:\n\nCurrently, you cannot import individual members (such as a single Python class or function)‚Äîyou must import the whole Python module and then access members through the module name.\n\nMojo doesn‚Äôt yet support top-level code, so the import_module() call must be inside another method. This means you may need to import a module multiple times or pass around a reference to the module.\n\nimport_module() may raise an exception (for example, if the module isn‚Äôt installed). If you‚Äôre using it inside a fn function, you need to either handle errors (using a try/except clause), or add the raises keyword to the function signature. You‚Äôll also see this when calling Python functions that may raise exceptions. (Raising exceptions is much more common in Python code than in the Mojo standard library, which limits their use for performance reasons.)\n\nMojo types in Python\n\nMojo primitive types implicitly convert into Python objects. Today we support lists, tuples, integers, floats, booleans, and strings.\n\nFor example, given this Python function that prints Python types:\n\n%%python\ndef type_printer(my_list, my_tuple, my_int, my_string, my_float):\n    print(type(my_list))\n    print(type(my_tuple))\n    print(type(my_int))\n    print(type(my_string))\n    print(type(my_float))\n\nYou can pass the Python function Mojo types with no problem:\n\ntype_printer([0, 3], (False, True), 4, \"orange\", 3.4)\n<class 'list'>\n<class 'tuple'>\n<class 'int'>\n<class 'str'>\n<class 'float'>\n\nNotice that in a Jupyter notebook, the Python function declared above is automatically available to any Mojo code in following code cells.\n\nMojo doesn‚Äôt have a standard Dictionary yet, so it is not yet possible to create a Python dictionary from a Mojo dictionary. You can work with Python dictionaries in Mojo though! To create a Python dictionary, use the dict method:\n\nfrom python import Python\nfrom python.object import PythonObject\n\nfn use_dict() raises:\n    let dictionary = Python.dict()\n    dictionary[\"fruit\"] = \"apple\"\n    dictionary[\"starch\"] = \"potato\"\n\n    let keys: PythonObject = [\"fruit\", \"starch\", \"protein\"]\n    let N: Int = keys.__len__().__index__()\n    print(N, \"items\")\n\n    for i in range(N):\n        if Python.is_type(dictionary.get(keys[i]), Python.none()):\n            print(keys[i], \"is not in dictionary\")\n        else:\n            print(keys[i], \"is included\")\n\nThen call the use_dict() function to see the results:\n\nuse_dict()\n3 items\nfruit is included\nstarch is included\nprotein is not in dictionary\nImporting local Python modules\n\nIf you have some local Python code you want to use in Mojo, just add the directory to the Python path and then import the module.\n\nFor example, suppose you have a Python file named mypython.py:\n\nimport numpy as np\n\ndef my_algorithm(a, b):\n    array_a = np.random.rand(a, a)\n    return array_a + b\n\nHere‚Äôs how you can import it and use it in a Mojo file:\n\nfrom python import Python\n\nfn use_my_module() raises:\n    Python.add_to_path(\"path/to/module\")\n    let mypython = Python.import_module(\"mypython\")\n\n    let c = mypython.my_algorithm(2, 3)\n    print(c)\n\nThere‚Äôs no need to worry about memory management when using Python in Mojo. Everything just works because Mojo was designed for Python from the beginning.\n\nParameterization: compile-time metaprogramming\n\nOne of Python‚Äôs most amazing features is its extensible runtime metaprogramming features. This has enabled a wide range of libraries and provides a flexible and extensible programming model that Python programmers everywhere benefit from. Unfortunately, these features also come at a cost: because they are evaluated at runtime, they directly impact run-time efficiency of the underlying code. Because they are not known to the IDE, it is difficult for IDE features like code completion to understand them and use them to improve the developer experience.\n\nOutside the Python ecosystem, static metaprogramming is also an important part of development, enabling the development of new programming paradigms and advanced libraries. There are many examples of prior art in this space, with different tradeoffs, for example:\n\nPreprocessors (e.g.¬†C preprocessor, Lex/YACC, etc) are perhaps the heaviest handed. They are fully general but the worst in terms of developer experience and tools integration.\n\nSome languages (like Lisp and Rust) support (sometimes ‚Äúhygienic‚Äù) macro expansion features, enabling syntactic extension and boilerplate reduction with somewhat better tooling integration.\n\nSome older languages like C++ have very large and complex metaprogramming languages (templates) that are a dual to the runtime language. These are notably difficult to learn and have poor compile times and error messages.\n\nSome languages (like Swift) build many features into the core language in a first-class way to provide good ergonomics for common cases at the expense of generality.\n\nSome newer languages like Zig integrate a language interpreter into the compilation flow, and allow the interpreter to reflect over the AST as it is compiled. This allows many of the same features as a macro system with better extensibility and generality.\n\nFor Modular‚Äôs work in AI, high-performance machine learning kernels, and accelerators, we need high abstraction capabilities provided by advanced metaprogramming systems. We needed high-level zero-cost abstractions, expressive libraries, and large-scale integration of multiple variants of algorithms. We want library developers to be able to extend the system, just like they do in Python, providing an extensible developer platform.\n\nThat said, we are not willing to sacrifice developer experience (including compile times and error messages) nor are we interested in building a parallel language ecosystem that is difficult to teach. We can learn from these previous systems but also have new technologies to build on top of, including MLIR and fine-grained language-integrated caching technologies.\n\nAs such, Mojo supports compile-time metaprogramming built into the compiler as a separate stage of compilation‚Äîafter parsing, semantic analysis, and IR generation, but before lowering to target-specific code. It uses the same host language for runtime programs as it does for metaprograms, and leverages MLIR to represent and evaluate these programs predictably.\n\nLet‚Äôs take a look at some simple examples.\n\nAbout ‚Äúparameters‚Äù: Python developers use the words ‚Äúarguments‚Äù and ‚Äúparameters‚Äù fairly interchangeably for ‚Äúthings that are passed into functions.‚Äù We decided to reclaim ‚Äúparameter‚Äù and ‚Äúparameter expression‚Äù to represent a compile-time value in Mojo, and continue to use ‚Äúargument‚Äù and ‚Äúexpression‚Äù to refer to runtime values. This allows us to align around words like ‚Äúparameterized‚Äù and ‚Äúparametric‚Äù for compile-time metaprogramming.\n\nDefining parameterized types and functions\n\nYou can parameterize structs and functions by specifying parameter names and types in square brackets (using an extended version of the PEP695 syntax). Unlike argument values, parameter values are known at compile-time, which enables an additional level of abstraction and code reuse, plus compiler optimizations such as autotuning.\n\nFor instance, let‚Äôs look at a SIMD type, which represents a low-level vector register in hardware that holds multiple instances of a scalar data-type. Hardware accelerators are constantly introducing new vector data types, and even CPUs may have 512-bit or longer SIMD vectors. In order to access the SIMD instructions on these processors, the data must be shaped into the proper SIMD width (data type) and length (vector size).\n\nHowever, it‚Äôs not feasible to define all the different SIMD variations with Mojo‚Äôs built-in types. So, Mojo‚Äôs SIMD type (defined as a struct) exposes the common SIMD operations in its methods, and makes the SIMD data type and size values parametric. This allows you to directly map your data to the SIMD vectors on any hardware.\n\nHere is a cut-down (non-functional) version of Mojo‚Äôs SIMD type definition:\n\nstruct SIMD[type: DType, size: Int]:\n    var value: ‚Ä¶ # Some low-level MLIR stuff here\n\n    # Create a new SIMD from a number of scalars\n    fn __init__(inout self, *elems: SIMD[type, 1]):  ...\n\n    # Fill a SIMD with a duplicated scalar value.\n    @staticmethod\n    fn splat(x: SIMD[type, 1]) -> SIMD[type, size]: ...\n\n    # Cast the elements of the SIMD to a different elt type.\n    fn cast[target: DType](self) -> SIMD[target, size]: ...\n\n    # Many standard operators are supported.\n    fn __add__(self, rhs: Self) -> Self: ...\n\nDefining each SIMD variant with parameters is great for code reuse because the SIMD type can express all the different vector variants statically, instead of requiring the language to pre-define every variant.\n\nBecause SIMD is a parameterized type, the self argument in its functions carries those parameters‚Äîthe full type name is SIMD[type, size]. Although it‚Äôs valid to write this out (as shown in the return type of splat()), this can be verbose, so we recommend using the Self type (from PEP673) like the __add__ example does.\n\nOverloading on parameters\n\nFunctions and methods can be overloaded on their parameter signatures. The overload resolution logic filters for candidates according to the following rules, in order of precedence:\n\nCandidates with the minimal number of implicit conversions (in both arguments and parameters).\nCandidates without variadic arguments.\nCandidates without variadic parameters.\nCandidates with the shortest parameter signature.\nNon-@staticmethod candidates (over @staticmethod ones, if available).\n\nIf there is more than one candidate after applying these rules, the overload resolution fails. For example:\n\n@register_passable(\"trivial\")\nstruct MyInt:\n    \"\"\"A type that is implicitly convertible to `Int`.\"\"\"\n    var value: Int\n\n    @always_inline(\"nodebug\")\n    fn __init__(_a: Int) -> Self:\n        return Self {value: _a}\n\nfn foo[x: MyInt, a: Int]():\n    print(\"foo[x: MyInt, a: Int]()\")\n\nfn foo[x: MyInt, y: MyInt]():\n    print(\"foo[x: MyInt, y: MyInt]()\")\n\nfn bar[a: Int](b: Int):\n    print(\"bar[a: Int](b: Int)\")\n\nfn bar[a: Int](*b: Int):\n    print(\"bar[a: Int](*b: Int)\")\n\nfn bar[*a: Int](b: Int):\n    print(\"bar[*a: Int](b: Int)\")\n\nfn parameter_overloads[a: Int, b: Int, x: MyInt]():\n    # `foo[x: MyInt, a: Int]()` is called because it requires no implicit\n    # conversions, whereas `foo[x: MyInt, y: MyInt]()` requires one.\n    foo[x, a]()\n\n    # `bar[a: Int](b: Int)` is called because it does not have variadic\n    # arguments or parameters.\n    bar[a](b)\n\n    # `bar[*a: Int](b: Int)` is called because it has variadic parameters.\n    bar[a, a, a](b)\n\nparameter_overloads[1, 2, MyInt(3)]()\n\nstruct MyStruct:\n    fn __init__(inout self):\n        pass\n\n    fn foo(inout self):\n        print(\"calling instance menthod\")\n\n    @staticmethod\n    fn foo():\n        print(\"calling static menthod\")\n\nfn test_static_overload():\n    var a = MyStruct()\n    # `foo(inout self)` takes precedence over a static method.\n    a.foo()\nfoo[x: MyInt, a: Int]()\nbar[a: Int](b: Int)\nbar[*a: Int](b: Int)\nUsing parameterized types and functions\n\nYou can instantiate parametric types and functions by passing values to the parameters in square brackets. For example, for the SIMD type above, type specifies the data type and size specifies the length of the SIMD vector (it must be a power of 2):\n\n# Make a vector of 4 floats.\nlet small_vec = SIMD[DType.float32, 4](1.0, 2.0, 3.0, 4.0)\n\n# Make a big vector containing 1.0 in float16 format.\nlet big_vec = SIMD[DType.float16, 32].splat(1.0)\n\n# Do some math and convert the elements to float32.\nlet bigger_vec = (big_vec+big_vec).cast[DType.float32]()\n\n# You can write types out explicitly if you want of course.\nlet bigger_vec2 : SIMD[DType.float32, 32] = bigger_vec\n\nprint('small_vec type:', small_vec.element_type, 'length:', len(small_vec))\nprint('bigger_vec2 type:', bigger_vec2.element_type, 'length:', len(bigger_vec2))\nsmall_vec type: float32 length: 4\nbigger_vec2 type: float32 length: 32\n\nNote that the cast() method also needs a parameter to specify the type you want from the cast (the method definition above expects a target parametric value). Thus, just like how the SIMD struct is a generic type definition, the cast() method is a generic method definition that gets instantiated at compile-time instead of runtime, based on the parameter value.\n\nThe code above shows the use of concrete types (that is, it instantiates SIMD using known type values), but the major power of parameters comes from the ability to define parametric algorithms and types (code that uses the parameter values). For example, here‚Äôs how to define a parametric algorithm with SIMD that is type- and width-agnostic:\n\nfrom math import sqrt\n\nfn rsqrt[dt: DType, width: Int](x: SIMD[dt, width]) -> SIMD[dt, width]:\n    return 1 / sqrt(x)\n\nprint(rsqrt[DType.float16, 4](42))\n[0.154296875, 0.154296875, 0.154296875, 0.154296875]\n\n\nNotice that the x argument is actually a SIMD type based on the function parameters. The runtime program can use the value of parameters, because the parameters are resolved at compile-time before they are needed by the runtime program (but compile-time parameter expressions cannot use runtime values).\n\nThe Mojo compiler is also smart about type inference with parameters. Note that the above function is able to call the parametric sqrt[]() function without specifying the parameters‚Äîthe compiler infers its parameters based on the parametric x value passed into it, as if you wrote sqrt[dt, width](x) explicitly. Also note that rsqrt() chose to define its first parameter named width even though the SIMD type names it size, and there is no problem.\n\nOptional parameters and keyword parameters\n\nJust as you can specify optional arguments in function signatures, you can also define an optional parameter by giving it a default value. You can also pass parameters by keyword. For a function or struct with multiple optional parameters, using keywords allows you to pass only the parameters you want to specify, regardless of their position in the function signature.\n\nFor example, here‚Äôs a function with two parameters, each with a default value:\n\nfn speak[a: Int = 3, msg: StringLiteral = \"woof\"]():\n    print(msg, a)\n\nfn use_defaults() raises:\n    speak()             # prints 'woof 3'\n    speak[5]()          # prints 'woof 5'\n    speak[7, \"meow\"]()  # prints 'meow 7'\n    speak[msg=\"baaa\"]() # prints 'baaa 3'\n\nRecall that Mojo can infer parameter values in a parametric function, based on the parametric values attached to an argument value (see the rsqrt[]() example above). If the parametric function also has a default value defined, then the inferred parameter type takes precedence.\n\nFor example, in the following code, we update the parametric speak[]() function to take an argument with a parametric type. Although the function has a default parameter value for a, Mojo instead uses the inferred a parameter value from the bar argument (as written, the default a value can never be used, but this is just for demonstration purposes):\n\n@value\nstruct Bar[v: Int]:\n    pass\n\nfn foo[a: Int = 3, msg: StringLiteral = \"woof\"](bar: Bar[a]):\n    print(msg, a)\n\nfn use_inferred():\n    foo(Bar[9]())  # prints 'woof 9'\n\nAs mentioned above, you can also use optional parameters and keyword parameters in a struct:\n\nstruct KwParamStruct[greeting: String = \"Hello\", name: String = \"üî•mojoüî•\"]:\n    fn __init__(inout self):\n        print(greeting, name)\n\nfn use_kw_params():\n    let a = KwParamStruct[]()                 # prints 'Hello üî•mojoüî•'\n    let b = KwParamStruct[name=\"World\"]()     # prints 'Hello World'\n    let c = KwParamStruct[greeting=\"Hola\"]()  # prints 'Hola üî•mojoüî•'\n\nNote: Mojo currently includes only partial support for keyword parameters, so some features such as keyword-only parameters and variadic keyword parameters (for example, **kwparams) are not supported yet.\n\nAutomatic parameterization of functions\n\nMojo supports ‚Äúautomatic‚Äù parameterization of functions. If a function argument type is parametric but the function signature doesn‚Äôt specify the parameters, they are automatically added as input parameters on the function. This is easier to understand with an example:\n\nfn print_params(vec: SIMD):\n    print(vec.type)\n    print(vec.size)\n\nfn main():\n    let v = SIMD[DType.float64, 4](1.0, 2.0, 3.0, 4.0)\n    print_params(v)\n\nIn the above example, the print_params function is automatically parameterized. It takes a parameterized type (SIMD), but doesn‚Äôt specify parameter values for it. Instead, it treats the types‚Äô parameters as its own, as if you had written them explicitly:\n\nfn print_params[type: DType, size: Int](vec: SIMD[type, size]):\n    print(vec.type)\n    print(vec.size)\n\nWhen you pass print_params() a concrete instance of the SIMD type, it can access the original input parameters as attributes on the instance (for example, vec.type). This is necessary for an automatically parameterized function, since it doesn‚Äôt have any other way to access the parameters. But it actually works in any context. You can access the input parameters of a parameterized type as attributes on the type:\n\nfn main():\n    print(SIMD[DType.float32, 2].size) # prints 2\n\nOr as attributes on an instance of the type:\n\nfn main():\n    let x = SIMD[DType.int32, 2](4, 8)\n    print(x.type) # prints int32\nParameter expressions are just Mojo code\n\nA parameter expression is any code expression (such as a+b) that occurs where a parameter is expected. Parameter expressions support operators and function calls, just like runtime code, and all parameter types use the same type system as the runtime program (such as Int and DType).\n\nBecause parameter expressions use the same grammar and types as runtime Mojo code, you can use many ‚Äúdependent type‚Äù features. For example, you might want to define a helper function to concatenate two SIMD vectors:\n\nfn concat[ty: DType, len1: Int, len2: Int](\n        lhs: SIMD[ty, len1], rhs: SIMD[ty, len2]) -> SIMD[ty, len1+len2]:\n\n    var result = SIMD[ty, len1 + len2]()\n    for i in range(len1):\n        result[i] = SIMD[ty, 1](lhs[i])\n    for j in range(len2):\n        result[len1 + j] = SIMD[ty, 1](rhs[j])\n    return result\n\nlet a = SIMD[DType.float32, 2](1, 2)\nlet x = concat[DType.float32, 2, 2](a, a)\n\nprint('result type:', x.element_type, 'length:', len(x))\nresult type: float32 length: 4\n\nNote how the resulting length is the sum of the input vector lengths, and you can express that with a simple + operation. For a more complex example, take a look at the SIMD.shuffle() method in the standard library: it takes two input SIMD values, a vector shuffle mask as a list, and returns a SIMD that matches the length of the shuffle mask.\n\nPowerful compile-time programming\n\nWhile simple expressions are useful, sometimes you want to write imperative compile-time logic with control flow. For example, the isclose() function in the Mojo Math module uses exact equality for integers but ‚Äúclose‚Äù comparison for floating-point. You can even do compile-time recursion. For instance, here is an example ‚Äútree reduction‚Äù algorithm that sums all elements of a vector recursively into a scalar:\n\nfn slice[ty: DType, new_size: Int, size: Int](\n        x: SIMD[ty, size], offset: Int) -> SIMD[ty, new_size]:\n    var result = SIMD[ty, new_size]()\n    for i in range(new_size):\n        result[i] = SIMD[ty, 1](x[i + offset])\n    return result\n\nfn reduce_add[ty: DType, size: Int](x: SIMD[ty, size]) -> Int:\n    @parameter\n    if size == 1:\n        return x[0].to_int()\n    elif size == 2:\n        return x[0].to_int() + x[1].to_int()\n\n    # Extract the top/bottom halves, add them, sum the elements.\n    alias half_size = size // 2\n    let lhs = slice[ty, half_size, size](x, 0)\n    let rhs = slice[ty, half_size, size](x, half_size)\n    return reduce_add[ty, half_size](lhs + rhs)\n\nlet x = SIMD[DType.index, 4](1, 2, 3, 4)\nprint(x)\nprint(\"Elements sum:\", reduce_add[DType.index, 4](x))\n[1, 2, 3, 4]\nElements sum: 10\n\nThis makes use of the @parameter if feature, which is an if statement that runs at compile-time. It requires that its condition be a valid parameter expression, and ensures that only the live branch of the if statement is compiled into the program.\n\nMojo types are just parameter expressions\n\nWhile we‚Äôve shown how you can use parameter expressions within types, type annotations can themselves be arbitrary expressions (just like in Python). Types in Mojo have a special metatype type, allowing type-parametric algorithms and functions to be defined.\n\nFor example, we can create a simplified Array that supports arbitrary types of the elements (via the AnyType parameter):\n\nstruct Array[T: AnyType]:\n    var data: Pointer[T]\n    var size: Int\n\n    fn __init__(inout self, size: Int, value: T):\n        self.size = size\n        self.data = Pointer[T].alloc(self.size)\n        for i in range(self.size):\n            self.data.store(i, value)\n\n    fn __getitem__(self, i: Int) -> T:\n        return self.data.load(i)\n\n    fn __del__(owned self):\n        self.data.free()\n\nvar v = Array[Float32](4, 3.14)\nprint(v[0], v[1], v[2], v[3])\n3.1400001049041748 3.1400001049041748 3.1400001049041748 3.1400001049041748\n\nNotice that the T parameter is being used as the formal type for the value arguments and the return type of the __getitem__ function. Parameters allow the Array type to provide different APIs based on the different use-cases.\n\nThere are many other cases that benefit from more advanced use of parameters. For example, you can execute a closure N times in parallel, feeding in a value from the context, like this:\n\nfn parallelize[func: fn (Int) -> None](num_work_items: Int):\n    # Not actually parallel: see the 'algorithm' module for real implementation.\n    for i in range(num_work_items):\n        func(i)\n\nAnother example where this is important is with variadic generics, where an algorithm or data structure may need to be defined over a list of heterogeneous types such as for a tuple:\n\nstruct Tuple[*Ts: AnyType]:\n    var _storage : *Ts\n\nAnd although we don‚Äôt have enough metatype helpers in place yet, we should be able to write something like this in the future (though overloading is still a better way to handle this):\n\nstruct Array[T: AnyType]:\n    fn __getitem__[IndexType: AnyType](self, idx: IndexType)\n       -> (ArraySlice[T] if issubclass(IndexType, Range) else T):\n       ...\nalias: named parameter expressions\n\nIt is very common to want to name compile-time values. Whereas var defines a runtime value, and let defines a runtime constant, we need a way to define a compile-time temporary value. For this, Mojo uses an alias declaration.\n\nFor example, the DType struct implements a simple enum using aliases for the enumerators like this (the actual DType implementation details vary a bit):\n\nstruct DType:\n    var value : UI8\n    alias invalid = DType(0)\n    alias bool = DType(1)\n    alias int8 = DType(2)\n    alias uint8 = DType(3)\n    alias int16 = DType(4)\n    alias int16 = DType(5)\n    ...\n    alias float32 = DType(15)\n\nThis allows clients to use DType.float32 as a parameter expression (which also works as a runtime value) naturally. Note that this is invoking the runtime constructor for DType at compile-time.\n\nTypes are another common use for alias. Because types are compile-time expressions, it is handy to be able to do things like this:\n\nalias Float16 = SIMD[DType.float16, 1]\nalias UInt8 = SIMD[DType.uint8, 1]\n\nvar x : Float16   # FLoat16 works like a \"typedef\"\n\nLike var and let, aliases obey scope, and you can use local aliases within functions as you‚Äôd expect.\n\nBy the way, both None and AnyType are defined as type aliases.\n\nAutotuning / Adaptive compilation\n\nMojo parameter expressions allow you to write portable parametric algorithms like you can do in other languages, but when writing high-performance code you still have to pick concrete values to use for the parameters. For example, when writing high-performance numeric algorithms, you might want to use memory tiling to accelerate the algorithm, but the dimensions to use depend highly on the available hardware features, the sizes of the cache, what gets fused into the kernel, and many other fiddly details.\n\nEven vector length can be difficult to manage, because the vector length of a typical machine depends on the datatype, and some datatypes like bfloat16 don‚Äôt have full support on all implementations. Mojo helps by providing an autotune function in the standard library. For example if you want to write a vector-length-agnostic algorithm to a buffer of data, you might write it like this:\n\nimport benchmark\nfrom autotune import autotune, search\nfrom memory.unsafe import DTypePointer\nfrom algorithm import vectorize\n\nfn buffer_elementwise_add_impl[\n    dt: DType\n](lhs: DTypePointer[dt], rhs: DTypePointer[dt], result: DTypePointer[dt], N: Int):\n    \"\"\"Perform elementwise addition of N elements in RHS and LHS and store\n    the result in RESULT.\n    \"\"\"\n    @parameter\n    fn add_simd[size: Int](idx: Int):\n        let lhs_simd = lhs.simd_load[size](idx)\n        let rhs_simd = rhs.simd_load[size](idx)\n        result.simd_store[size](idx, lhs_simd + rhs_simd)\n\n    # Pick vector length for this dtype and hardware\n    alias vector_len = autotune(1, 4, 8, 16, 32)\n\n    # Use it as the vectorization length\n    vectorize[vector_len, add_simd](N)\n\nfn elementwise_evaluator[dt: DType](\n    fns: Pointer[fn (DTypePointer[dt], DTypePointer[dt], DTypePointer[dt], Int) -> None],\n    num: Int,\n) -> Int:\n    # Benchmark the implementations on N = 64.\n    alias N = 64\n    let lhs = DTypePointer[dt].alloc(N)\n    let rhs = DTypePointer[dt].alloc(N)\n    let result = DTypePointer[dt].alloc(N)\n\n    # Fill with ones.\n    for i in range(N):\n        lhs.store(i, 1)\n        rhs.store(i, 1)\n\n    # Find the fastest implementation.\n    var best_idx: Int = -1\n    var best_time: Int = -1\n    for i in range(num):\n        @parameter\n        fn wrapper():\n            fns.load(i)(lhs, rhs, result, N)\n        let cur_time = benchmark.run[wrapper](1).mean[\"ns\"]().to_int()\n        if best_idx < 0 or best_time > cur_time:\n            best_idx = i\n            best_time = cur_time\n        print(\"time[\", i, \"] =\", cur_time)\n    print(\"selected:\", best_idx)\n    return best_idx\n\nfn buffer_elementwise_add[\n    dt: DType\n](lhs: DTypePointer[dt], rhs: DTypePointer[dt], result: DTypePointer[dt], N: Int):\n    # Forward declare the result parameter.\n    alias best_impl: fn(DTypePointer[dt], DTypePointer[dt], DTypePointer[dt], Int) -> None\n\n    # Perform search!\n    search[\n      fn(DTypePointer[dt], DTypePointer[dt], DTypePointer[dt], Int) -> None,\n      buffer_elementwise_add_impl[dt],\n      elementwise_evaluator[dt] -> best_impl\n    ]()\n\n    # Call the select implementation\n    best_impl(lhs, rhs, result, N)\n\nWe can now call our function as usual:\n\nlet N = 32\nlet a = DTypePointer[DType.float32].alloc(N)\nlet b = DTypePointer[DType.float32].alloc(N)\nlet res = DTypePointer[DType.float32].alloc(N)\n# Initialize arrays with some values\nfor i in range(N):\n    a.store(i, 2.0)\n    b.store(i, 40.0)\n    res.store(i, -1)\n\nbuffer_elementwise_add[DType.float32](a, b, res, N)\nprint(a.load(10), b.load(10), res.load(10))\ntime[ 0 ] = 23\ntime[ 1 ] = 6\ntime[ 2 ] = 4\ntime[ 3 ] = 3\ntime[ 4 ] = 4\nselected: 3\n2.0 40.0 42.0\n\nWhen compiling instantiations of this code, Mojo forks compilation of this algorithm and decides which value to use by measuring what works best in practice for the target hardware. It evaluates the different values of the vector_len expression and picks the fastest one according to a user-defined performance evaluator. Because it measures and evaluates each option individually, it might pick a different vector length for float32 than for int8, for example. This simple feature is pretty powerful‚Äîgoing beyond simple integer constants‚Äîbecause functions and types are also parameter expressions.\n\nNotice that the search for the best vector length is performed by the search() function. search() takes an evaluator and a forked function and returns the fastest implementation selected by the evaluator as a parameter result. For a deeper dive on this topic, check out the notebooks about Matrix Multiplication and Fast Memset in Mojo.\n\nAutotuning is an inherently exponential technique that benefits from internal implementation details of the Mojo compiler stack (particularly MLIR, integrated caching, and distribution of compilation). This is also a power-user feature and needs continued development and iteration over time.\n\n‚ÄúValue Lifecycle‚Äù: Birth, life and death of a value\n\nAt this point, you should understand the core semantics and features for Mojo functions and types, so we can now discuss how they fit together to express new types in Mojo.\n\nMany existing languages express design points with different tradeoffs: C++, for example, is very powerful but often accused of ‚Äúgetting the defaults wrong‚Äù which leads to bugs and mis-features. Swift is easy to work with, but has a less predictable model that copies values a lot and is dependent on an ‚ÄúARC optimizer‚Äù for performance. Rust started with strong value ownership goals to satisfy its borrow checker, but relies on values being movable, which makes it challenging to express custom move constructors and can put a lot of stress on memcpy performance. In Python, everything is a reference to a class, so it never really faces issues with types.\n\nFor Mojo, we‚Äôve learned from these existing systems, and we aim to provide a model that‚Äôs very powerful while still easy to learn and understand. We also don‚Äôt want to require ‚Äúbest effort‚Äù and difficult-to-predict optimization passes built into a ‚Äúsufficiently smart‚Äù compiler.\n\nTo explore these issues, we look at different value classifications and the relevant Mojo features that go into expressing them, and build from the bottom-up. We use C++ as the primary comparison point in examples because it is widely known, but we occasionally reference other languages if they provide a better comparison point.\n\nTypes that cannot be instantiated\n\nThe most bare-bones type in Mojo is one that doesn‚Äôt allow you to create instances of it: these types have no initializer at all, and if they have a destructor, it will never be invoked (because there cannot be instances to destroy):\n\nstruct NoInstances:\n    var state: Int  # Pretty useless\n\n    alias my_int = Int\n\n    @staticmethod\n    fn print_hello():\n        print(\"hello world\")\n\nMojo types do not get default constructors, move constructors, member-wise initializers or anything else by default, so it is impossible to create an instance of this NoInstances type. In order to get them, you need to define an __init__ method or use a decorator that synthesizes an initializer. As shown, these types can be useful as ‚Äúnamespaces‚Äù because you can refer to static members like NoInstances.my_int or NoInstances.print_hello() even though you cannot instantiate an instance of the type.\n\nNon-movable and non-copyable types\n\nIf we take a step up the ladder of sophistication, we‚Äôll get to types that can be instantiated, but once they are pinned to an address in memory, they cannot be implicitly moved or copied. This can be useful to implement types like atomic operations (such as std::atomic in C++) or other types where the memory address of the value is its identity and is critical to its purpose:\n\nstruct Atomic:\n    var state: Int\n\n    fn __init__(inout self, state: Int = 0):\n        self.state = state\n\n    fn __iadd__(inout self, rhs: Int):\n        #...atomic magic...\n\n    fn get_value(self) -> Int:\n        return atomic_load_int(self.state)\n\nThis class defines an initializer but no copy or move constructors, so once it is initialized it can never be moved or copied. This is safe and useful because Mojo‚Äôs ownership system is fully ‚Äúaddress correct‚Äù - when this is initialized onto the stack or in the field of some other type, it never needs to move.\n\nNote that Mojo‚Äôs approach controls only the built-in move operations, such as a = b copies and the ^ transfer operator. One useful pattern you can use for your own types (like Atomic above) is to add an explicit copy() method (a non-‚Äúdunder‚Äù method). This can be useful to make explicit copies of an instance when it is known safe to the programmer.\n\nUnique ‚Äúmove-only‚Äù types\n\nIf we take one more step up the ladder of capabilities, we will encounter types that are ‚Äúunique‚Äù - there are many examples of this in C++, such as types like std::unique_ptr or even a FileDescriptor type that owns an underlying POSIX file descriptor. These types are pervasive in languages like Rust, where copying is discouraged, but ‚Äúmove‚Äù is free. In Mojo, you can implement these kinds of moves by defining the __moveinit__ method to take ownership of a unique type. For example:\n\n# This is a simple wrapper around POSIX-style fcntl.h functions.\nstruct FileDescriptor:\n    var fd: Int\n\n    # This is how we move our unique type.\n    fn __moveinit__(inout self, owned existing: Self):\n        self.fd = existing.fd\n\n    # This takes ownership of a POSIX file descriptor.\n    fn __init__(inout self, fd: Int):\n        self.fd = fd\n\n    fn __init__(inout self, path: String):\n        # Error handling omitted, call the open(2) syscall.\n        self = FileDescriptor(open(path, ...))\n\n    fn __del__(owned self):\n        close(self.fd)   # pseudo code, call close(2)\n\n    fn dup(self) -> Self:\n        # Invoke the dup(2) system call.\n        return Self(dup(self.fd))\n    fn read(...): ...\n    fn write(...): ...\n\nThe consuming move constructor (__moveinit__) takes ownership of an existing FileDescriptor, and moves its internal implementation details over to a new instance. This is because instances of FileDescriptor may exist at different locations, and they can be logically moved around‚Äîstealing the body of one value and moving it into another.\n\nHere is an egregious example that will invoke __moveinit__ multiple times:\n\nfn egregious_moves(owned fd1: FileDescriptor):\n    # fd1 and fd2 have different addresses in memory, but the\n    # transfer operator moves unique ownership from fd1 to fd2.\n    let fd2 = fd1^\n\n    # Do it again, a use of fd2 after this point will produce an error.\n    let fd3 = fd2^\n\n    # We can do this all day...\n    let fd4 = fd3^\n    fd4.read(...)\n    # fd4.__del__() runs here\n\nNote how ownership of the value is transferred between various values that own it, using the postfix-^ ‚Äútransfer‚Äù operator, which destroys a previous binding and transfer ownership to a new constant. If you are familiar with C++, the simple way to think about the transfer operator is like std::move, but in this case, we can see that it is able to move things without resetting them to a state that can be destroyed: in C++, if your move operator failed to change the old value‚Äôs fd instance, it would get closed twice.\n\nMojo tracks the liveness of values and allows you to define custom move constructors. This is rarely needed, but extremely powerful when it is. For example, some types like the llvm::SmallVector type use the ‚Äúinline storage‚Äù optimization technique, and they may want to be implemented with an ‚Äúinner pointer‚Äù into their instance. This is a well-known trick to reduce pressure on the malloc memory allocator, but it means that a ‚Äúmove‚Äù operation needs custom logic to update the pointer when that happens.\n\nWith Mojo, this is as simple as implementing a custom __moveinit__ method. This is something that is also easy to implement in C++ (though, with boilerplate in the cases where you don‚Äôt need custom logic) but is difficult to implement in other popular memory-safe languages.\n\nOne additional note is that while the Mojo compiler provides good predictability and control, it is also very sophisticated. It reserves the right to eliminate temporaries and the corresponding copy/move operations. If this is inappropriate for your type, you should use explicit methods like copy() instead of the dunder methods.\n\nTypes that support a ‚Äútaking move‚Äù\n\nOne challenge with memory-safe languages is that they need to provide a predictable programming model around what the compiler is able to track, and static analysis in a compiler is inherently limited. For example, while it is possible for a compiler to understand that the two array accesses in the first example below are to different array elements, it is (in general) impossible to reason about the second example (this is C++ code):\n\nstd::pair<T, T> getValues1(MutableArray<T> &array) {\n    return { std::move(array[0]), std::move(array[1]) };\n}\nstd::pair<T, T> getValues2(MutableArray<T> &array, size_t i, size_t j) {\n    return { std::move(array[i]), std::move(array[j]) };\n}\n\nThe problem here is that there is simply no way (looking at just the function body above) to know or prove that the dynamic values of i and j are not the same. While it is possible to maintain dynamic state to track whether individual elements of the array are live, this often causes significant runtime expense (even when move/transfers are not used), which is something that Mojo and other systems programming languages are not keen to do. There are a variety of ways to deal with this, including some pretty complicated solutions that aren‚Äôt always easy to learn.\n\nMojo takes a pragmatic approach to let Mojo programmers get their job done without having to work around its type system. As seen above, it doesn‚Äôt force types to be copyable, movable, or even constructable, but it does want types to express their full contract, and it wants to enable fluent design patterns that programmers expect from languages like C++. The (well known) observation here is that many objects have contents that can be ‚Äútaken away‚Äù without needing to disable their destructor, either because they have a ‚Äúnull state‚Äù (like an optional type or nullable pointer) or because they have a null value that is efficient to create and a no-op to destroy (e.g.¬†std::vector can have a null pointer for its data).\n\nTo support these use-cases, the ^ transfer operator supports arbitrary LValues, and when applied to one, it invokes the ‚Äútaking move constructor,‚Äù which is spelled __takeinit__. This constructor must set up the new value to be in a live state, and it can mutate the old value, but it must put the old value into a state where its destructor still works. For example, if we want to put our FileDescriptor into a vector and move out of it, we might choose to extend it to know that -1 is a sentinel which means that it is ‚Äúnull‚Äù. We can implement this like so:\n\n# This is a simple wrapper around POSIX-style fcntl.h functions.\nstruct FileDescriptor:\n    var fd: Int\n\n    # This is the new key capability.\n    fn __takeinit__(inout self, inout existing: Self):\n        self.fd = existing.fd\n        existing.fd = -1  # neutralize 'existing'.\n\n    fn __moveinit__(inout self, owned existing: Self): # as above\n    fn __init__(inout self, fd: Int): # as above\n    fn __init__(inout self, path: String): # as above\n\n    fn __del__(owned self):\n        if self.fd != -1:\n            close(self.fd)   # pseudo code, call close(2)\n\nNotice how the ‚Äústealing move‚Äù constructor takes the file descriptor from an existing value and mutates that value so that its destructor won‚Äôt do anything. This technique has tradeoffs and is not the best for every type. We can see that it adds one (inexpensive) branch to the destructor because it has to check for the sentinel case. It is also generally considered bad form to make types like this nullable because a more general feature like an Optional[T] type is a better way to handle this.\n\nFurthermore, we plan to implement Optional[T] in Mojo itself, and Optional needs this functionality. We also believe that the library authors understand their domain problem better than language designers do, and generally prefer to give library authors full power over that domain. As such you can choose (but don‚Äôt have to) to make your types participate in this behavior in an opt-in way.\n\nCopyable types\n\nThe next step up from movable types are copyable types. Copyable types are also very common - programmers generally expect things like strings and arrays to be copyable, and every Python Object reference is copyable - by copying the pointer and adjusting the reference count.\n\nThere are many ways to implement copyable types. One can implement reference semantic types like Python or Java, where you propagate shared pointers around, one can use immutable data structures that are easily shareable because they are never mutated once created, and one can implement deep value semantics through lazy copy-on-write as Swift does. Each of these approaches has different tradeoffs, and Mojo takes the opinion that while we want a few common sets of collection types, we can also support a wide range of specialized ones that focus on particular use cases.\n\nIn Mojo, you can do this by implementing the __copyinit__ method. Here is an example of that using a simple String (in pseudo-code):\n\nstruct MyString:\n    var data: Pointer[UI8]\n\n    # StringRef is a pointer + length and works with StringLiteral.\n    def __init__(inout self, input: StringRef):\n        self.data = ...\n\n    # Copy the string by deep copying the underlying malloc'd data.\n    def __copyinit__(inout self, existing: Self):\n        self.data = strdup(existing.data)\n\n    # This isn't required, but optimizes unneeded copies.\n    def __moveinit__(inout self, owned existing: Self):\n        self.data = existing.data\n\n    def __del__(owned self):\n        free(self.data.address)\n\n    def __add__(self, rhs: MyString) -> MyString: ...\n\nThis simple type is a pointer to a ‚Äúnull-terminated‚Äù string data allocated with malloc, using old-school C APIs for clarity. It implements the __copyinit__, which maintains the invariant that each instance of MyString owns its underlying pointer and frees it upon destruction. This implementation builds on tricks we‚Äôve seen above, and implements a __moveinit__ constructor, which allows it to completely eliminate temporary copies in some common cases. You can see this behavior in this code sequence:\n\nfn test_my_string():\n    var s1 = MyString(\"hello \")\n\n    var s2 = s1    # s2.__copyinit__(s1) runs here\n\n    print(s1)\n\n    var s3 = s1^   # s3.__moveinit__(s1) runs here\n\n    print(s2)\n    # s2.__del__() runs here\n    print(s3)\n    # s3.__del__() runs here\n\nIn this case, you can see both why a copy constructor is needed: without one, the duplication of the s1 value into s2 would be an error - because you cannot have two live instances of the same non-copyable type. The move constructor is optional but helps the assignment into s3: without it, the compiler would invoke the copy constructor from s1, then destroy the old s1 instance. This is logically correct but introduces extra runtime overhead.\n\nMojo destroys values eagerly, which allows it to transform copy+destroy pairs into single move operations, which can lead to much better performance than C++ without requiring the need for pervasive micromanagement of std::move.\n\nTrivial types\n\nThe most flexible types are ones that are just ‚Äúbags of bits‚Äù. These types are ‚Äútrivial‚Äù because they can be copied, moved, and destroyed without invoking custom code. Types like these are arguably the most common basic type that surrounds us: things like integers and floating point values are all trivial. From a language perspective, Mojo doesn‚Äôt need special support for these, it would be perfectly fine for type authors to implement these things as no-ops, and allow the inliner to just make them go away.\n\nThere are two reasons that approach would be suboptimal: one is that we don‚Äôt want the boilerplate of having to define a bunch of methods on trivial types, and second, we don‚Äôt want the compile-time overhead of generating and pushing around a bunch of function calls, only to have them inline away to nothing. Furthermore, there is an orthogonal concern, which is that many of these types are trivial in another way: they are tiny, and should be passed around in the registers of a CPU, not indirectly in memory.\n\nAs such, Mojo provides a struct decorator that solves all of these problems. You can implement a type with the @register_passable(\"trivial\") decorator, and this tells Mojo that the type should be copyable and movable but that it has no user-defined logic for doing this. It also tells Mojo to prefer to pass the value in CPU registers, which can lead to efficiency benefits.\n\nTODO: This decorator is due for reconsideration. Lack of custom logic copy/move/destroy logic and ‚Äúpassability in a register‚Äù are orthogonal concerns and should be split. This former logic should be subsumed into a more general @value(\"trivial\") decorator, which is orthogonal from @register_passable.\n\n@value decorator\n\nMojo‚Äôs value lifecycle provides simple and predictable hooks that give you the ability to express exotic low-level things like Atomic correctly. This is great for control and for a simple programming model, but most structs are simple aggregations of other types, and we don‚Äôt want to write a lot of boilerplate for them. To solve this, Mojo provides a @value decorator for structs that synthesizes a lot of boilerplate for you.\n\nYou can think of @value as an extension of Python‚Äôs @dataclass that also handles Mojo‚Äôs __moveinit__ and __copyinit__ methods.\n\nThe @value decorator takes a look at the fields of your type, and generates some members that are missing. For example, consider a simple struct like this:\n\n@value\nstruct MyPet:\n    var name: String\n    var age: Int\n\nMojo will notice that you do not have a member-wise initializer, a move constructor, or a copy constructor, and it will synthesize these for you as if you had written:\n\nstruct MyPet:\n    var name: String\n    var age: Int\n\n    fn __init__(inout self, owned name: String, age: Int):\n        self.name = name^\n        self.age = age\n\n    fn __copyinit__(inout self, existing: Self):\n        self.name = existing.name\n        self.age = existing.age\n\n    fn __moveinit__(inout self, owned existing: Self):\n        self.name = existing.name^\n        self.age = existing.age\n\nWhen you add the @value decorator, Mojo synthesizes each of these special methods only when it doesn‚Äôt exist. You can override the behavior of one or more by defining your own version. For example, it is fairly common to want a custom copy constructor but use the default member-wise and move constructor.\n\nThe arguments to__init__ are all passed as owned arguments since the struct takes ownership and stores the value. This is a useful micro-optimization and enables the use of move-only types. Trivial types like Int are also passed as owned values, but since that doesn‚Äôt mean anything for them, we elide the marker and the transfer operator (^) for clarity.\n\nNote: If your type contains any move-only fields, Mojo will not generate a copy constructor because it cannot copy those fields. Further, the @value decorator only works on types whose members are copyable and/or movable. If you have something like Atomic in your struct, then it probably isn‚Äôt a value type, and you don‚Äôt want these members anyway.\n\nAlso notice that the MyPet struct above doesn‚Äôt include the __del__() destructor‚ÄîMojo also synthesizes this, but it doesn‚Äôt require the @value decorator (see the section below about destructors).\n\nThere is no way to suppress the generation of specific methods or customize generation at this time, but we can add arguments to the @value generator to do this if there is demand.\n\nBehavior of destructors\n\nAny struct in Mojo can have a destructor (a __del__() method), which is automatically run when the value‚Äôs lifetime ends (typically the point at which the value is last used). For example, a simple string might look like this (in pseudo code):\n\n@value\nstruct MyString:\n    var data: Pointer[UInt8]\n\n    def __init__(inout self, input: StringRef): ...\n    def __add__(self, rhs: String) -> MyString: ...\n    def __del__(owned self):\n        free(self.data.address)\n\nMojo destroys values like MyString (it calls the __del__() destructor) using an ‚ÄúAs Soon As Possible‚Äù (ASAP) policy that runs after every call. Mojo does not wait until the end of the code block to destroy unused values. Even in an expression like a+b+c+d, Mojo destroys the intermediate expressions eagerly, as soon as they are no longer needed‚Äîit does not wait until the end of the statement.\n\nThe Mojo compiler automatically invokes the destructor when a value is dead and provides strong guarantees about when the destructor is run. Mojo uses static compiler analysis to reason about your code and decide when to insert calls to the destructor. For example:\n\nfn use_strings():\n    var a = String(\"hello a\")\n    let b = String(\"hello b\")\n    print(a)\n    # a.__del__() runs here for \"hello a\"\n\n\n    print(b)\n    # b.__del__() runs here\n\n    a = String(\"temporary a\")\n    # a.__del__() runs here because \"temporary a\" is never used\n\n    # Other stuff happens here\n\n    a = String(\"final a\")\n    print(a)\n    # a.__del__() runs again here for \"final a\"\n\nuse_strings()\nhello a\nhello b\nfinal a\n\nIn the code above, you‚Äôll see that the a and b values are created early on, and each initialization of a value is matched with a call to a destructor. Notice that a is destroyed multiple times‚Äîonce for each time it receives a new value.\n\nNow, this might be surprising to a C++ programmer, because it‚Äôs different from the RAII pattern in which C++ destroys values at the end of a scope. Mojo also follows the principle that values acquire resources in a constructor and release resources in a destructor, but eager destruction in Mojo has a number of strong advantages over scope-based destruction in C++:\n\nThe Mojo approach eliminates the need for types to implement re-assignment operators, like operator=(const T&) and operator=(T&&) in C++, making it easier to define types and eliminating a concept.\n\nMojo does not allow mutable references to overlap with other mutable references or with immutable borrows. One major way that it provides a predictable programming model is by making sure that references to objects die as soon as possible, avoiding confusing situations where the compiler thinks a value could still be alive and interfere with another value, but that isn‚Äôt clear to the user.\n\nDestroying values at last-use composes nicely with ‚Äúmove‚Äù optimization, which transforms a ‚Äúcopy+del‚Äù pair into a ‚Äúmove‚Äù operation, a generalization of C++ move optimizations like NRVO (named return value optimization).\n\nDestroying values at end-of-scope in C++ is problematic for some common patterns like tail recursion because the destructor calls happen after the tail call. This can be a significant performance and memory problem for certain functional programming patterns.\n\nImportantly, Mojo‚Äôs eager destruction also works well within Python-style def functions to provide destruction guarantees (without a garbage collector) at a fine-grain level‚Äîrecall that Python doesn‚Äôt really provide scopes beyond a function, so C++-style destruction in Mojo would be a lot less useful.\n\nNote: Mojo also supports the Python-style with statement, which provides more deliberately-scoped access to resources.\n\nThe Mojo approach is more similar to how Rust and Swift work, because they both have strong value ownership tracking and provide memory safety. One difference is that their implementations require the use of a dynamic ‚Äúdrop flag‚Äù‚Äîthey maintain hidden shadow variables to keep track of the state of your values to provide safety. These are often optimized away, but the Mojo approach eliminates this overhead entirely, making the generated code faster and avoiding ambiguity.\n\nField-sensitive lifetime management\n\nIn addition to Mojo‚Äôs lifetime analysis being fully control-flow aware, it is also fully field-sensitive (each field of a structure is tracked independently). That is, Mojo separately keeps track of whether a ‚Äúwhole object‚Äù is fully or only partially initialized/destroyed.\n\nFor example, consider this code:\n\n@value\nstruct TwoStrings:\n    var str1: String\n    var str2: String\n\nfn use_two_strings():\n    var ts = TwoStrings(\"foo\", \"bar\")\n    print(ts.str1)\n    # ts.str1.__del__() runs here\n\n    # Other stuff happens here\n\n    ts.str1 = String(\"hello\") # Overwrite ts.str1\n    print(ts.str1)\n    # ts.__del__() runs here\n\nuse_two_strings()\nfoo\nhello\n\nNote that the ts.str1 field is destroyed almost immediately, because Mojo knows that it will be overwritten down below. You can also see this when using the transfer operator, for example:\n\nfn consume(owned arg: String):\n    pass\n\nfn use(arg: TwoStrings):\n    print(arg.str1)\n\nfn consume_and_use_two_strings():\n    var ts = TwoStrings(\"foo\", \"bar\")\n    consume(ts.str1^)\n    # ts.str1.__moveinit__() runs here\n\n    # ts is now only partially initialized here!\n\n    ts.str1 = String(\"hello\")  # All together now\n    use(ts)                    # This is ok\n    # ts.__del__() runs here\n\nconsume_and_use_two_strings()\nhello\n\nNotice that the code transfers ownership of the str1 field: for the duration of other_stuff(), the str1 field is completely uninitialized because ownership was transferred to consume(). Then str1 is reinitialized before it is used by the use() function (if it weren‚Äôt, Mojo would reject the code with an uninitialized field error).\n\nMojo‚Äôs rule on this is powerful and intentionally straight-forward: fields can be temporarily transferred, but the ‚Äúwhole object‚Äù must be constructed with the aggregate type‚Äôs initializer and destroyed with the aggregate destructor. This means that it isn‚Äôt possible to create an object by initializing only its fields, nor is it possible to tear down an object by destroying only its fields. For example, this code does not compile:\n\nfn consume_and_use_two_strings():\n    let ts = TwoStrings(\"foo\", \"bar\") # ts is initialized\n    # Uncomment to see an error:\n    # consume(ts.str1^)\n    # Because `ts` is not used anymore, it should be destroyed here, but\n    # the object is not whole, preventing the overall value from being destroyed\n\n    let ts2 : TwoStrings # ts2 type is declared but not initialized\n    ts2.str1 = String(\"foo\")\n    ts2.str2 = String(\"bar\")  # Both the member are initalized\n    # Uncomment to see an error:\n    # use(ts2) # Error: 'ts2' isn't fully initialized\n\nWhile we could allow patterns like this to happen, we reject this because a value is more than a sum of its parts. Consider a FileDescriptor that contains a POSIX file descriptor as an integer value: there is a big difference between destroying the integer (a no-op) and destroying the FileDescriptor (it might call the close() system call). Because of this, we require all full-value initialization to go through initializers and be destroyed with their full-value destructor.\n\nFor what it‚Äôs worth, Mojo does internally have an equivalent of the Rust mem::forget function, which explicitly disables a destructor and has a corresponding internal feature for ‚Äúblessing‚Äù an object, but they aren‚Äôt exposed for user consumption at this point.\n\nField lifetimes in __init__\n\nThe behavior of an __init__ method works almost like any other method‚Äîthere is a small bit of magic: it knows that the fields of an object are uninitialized, but it believes the full object is initialized. This means that you can use self as a whole object as soon as all the fields are initialized:\n\nfn use(arg: TwoStrings2):\n    pass\n\nstruct TwoStrings2:\n    var str1: String\n    var str2: String\n\n    fn __init__(inout self, cond: Bool, other: String):\n        self.str1 = String()\n        if cond:\n            self.str2 = other\n            use(self)  # Safe to use immediately!\n            # self.str2.__del__(): destroyed because overwritten below.\n\n        self.str2 = self.str1\n        use(self)  # Safe to use immediately!\n\nSimilarly, it‚Äôs safe for initializers in Mojo to completely overwrite self, such as by delegating to other initializers:\n\nstruct TwoStrings3:\n    var str1: String\n    var str2: String\n\n    fn __init__(inout self):\n        self.str1 = String()\n        self.str2 = String()\n\n    fn __init__(inout self, one: String):\n        self = TwoStrings3()  # Delegate to the basic init\n        self.str1 = one\nField lifetimes of owned arguments in __moveinit__ and __del__\n\nA final bit of magic exists for the owned arguments of a __moveinit__() move initializer and a __del__() destructor. To recap, these method signatures look like this:\n\nstruct TwoStrings:\n    ...\n    fn __moveinit__(inout self, owned existing: Self):\n        # Initializes a new `self` by consuming the contents of `existing`\n    fn __del__(owned self):\n        # Destroys all resources in `self`\n\nThese methods face an interesting but obscure problem: both methods are in charge of dismantling the owned existing/self value. That is, __moveinit__() destroys sub-elements of existing in order to transfer ownership to a new instance, while __del__() implements the deletion logic for its self. As such, they both want to own and transform elements of the owned value, and they definitely don‚Äôt want the owned value‚Äôs destructor to also run (in the case of the __del__() method, that would turn into an infinite loop).\n\nTo solve this problem, Mojo handles these two methods specially by assuming that their whole values are destroyed upon reaching any return from the method. This means that the whole object may be used before the field values are transferred. For example, this works as you expect:\n\nfn consume(owned str: String):\n    print('Consumed', str)\n\nstruct TwoStrings4:\n    var str1: String\n    var str2: String\n\n    fn __init__(inout self, one: String):\n        self.str1 = one\n        self.str2 = String(\"bar\")\n\n    fn __moveinit__(inout self, owned existing: Self):\n        self.str1 = existing.str1\n        self.str2 = existing.str2\n\n    fn __del__(owned self):\n        self.dump() # Self is still whole here\n        # Mojo calls self.str2.__del__() since str2 isn't used anymore\n\n        consume(self.str1^)\n        # str1 has now been transferred;\n        # `self.__del__()` is not called (avoiding an infinite loop).\n\n    fn dump(inout self):\n        print('str1:', self.str1)\n        print('str2:', self.str2)\n\nfn use_two_strings():\n    let two_strings = TwoStrings4(\"foo\")\n\n# We use a function call to ensure the `two_strings` ownership is enforced\n# (Currently, ownership is not enforced for top-level code in notebooks)\nuse_two_strings()\nstr1: foo\nstr2: bar\nConsumed foo\n\nYou should not generally have to think about this, but if you have logic with inner pointers into members, you may need to keep them alive for some logic within the destructor or move initializer itself. You can do this by assigning to the _ ‚Äúdiscard‚Äù pattern:\n\nfn __del__(owned self):\n    self.dump() # Self is still whole here\n\n    consume(self.str1^)\n    _ = self.str2\n    # self.str2.__del__(): Mojo destroys str2 after its last use.\n\nIn this case, if consume() implicitly refers to some value in str2 somehow, this will ensure that str2 isn‚Äôt destroyed until the last use when it is accessed by the _ discard pattern.\n\nDefining the __del__ destructor\n\nYou should define the __del__() method to perform any kind of cleanup the type requires. Usually, that includes freeing memory for any fields that are not trivial or destructible‚ÄîMojo automatically destroys any trivial and destructible types as soon as they‚Äôre not used anymore.\n\nFor example, consider this struct:\n\nstruct MyPet:\n    var name: String\n    var age: Int\n\n    fn __init__(inout self, owned name: String, age: Int):\n        self.name = name^\n        self.age = age\n\nThere‚Äôs no need to define the __del__() method because String is a destructible (it has its own __del__() method) and Mojo destroys it as soon as it‚Äôs no longer used (which is exactly when the MyPet instance is no longer used), and Int is a trivial type and Mojo reclaims this memory also as soon as possible (although a little differently, without need for a __del__() method).\n\nWhereas, the following struct must define the __del__() method to free the memory allocated for its Pointer:\n\nstruct Array[Type: AnyType]:\n    var data: Pointer[Type]\n    var size: Int\n\n    fn __init__(inout self, size: Int, value: Type):\n        self.size = size\n        self.data = Pointer[Type].alloc(self.size)\n        for i in range(self.size):\n            self.data.store(i, value)\n\n    fn __del__(owned self):\n        self.data.free()\nLifetimes\n\nTODO: Explain how returning references work, tied into lifetimes which dovetail with parameters. This is not enabled yet.\n\nType traits\n\nThis is a feature very much like Rust traits or Swift protocols or Haskell type classes. Note, this is not implemented yet.\n\nAdvanced/Obscure Mojo features\n\nThis section describes power-user features that are important for building the bottom-est level of the standard library. This level of the stack is inhabited by narrow features that require experience with compiler internals to understand and utilize effectively.\n\n@register_passable struct decorator\n\nThe default model for working with values is they live in memory, so they have an identity, which means they are passed indirectly to and from functions (equivalently, they are passed ‚Äúby reference‚Äù at the machine level). This is great for types that cannot be moved, and is a safe default for large objects or things with expensive copy operations. However, it is inefficient for tiny things like a single integer or floating point number.\n\nTo solve this, Mojo allows structs to opt-in to being passed in a register instead of passing through memory with the @register_passable decorator. You‚Äôll see this decorator on types like Int in the standard library:\n\n@register_passable(\"trivial\")\nstruct Int:\n    var value: __mlir_type.`!pop.scalar<index>`\n\n    fn __init__(value: __mlir_type.`!pop.scalar<index>`) -> Self:\n        return Self {value: value}\n    ...\n\nThe basic @register_passable decorator does not change the fundamental behavior of a type: it still needs to have a __copyinit__ method to be copyable, may still have a __init__ and __del__ methods, etc. The major effect of this decorator is on internal implementation details: @register_passable types are typically passed in machine registers (subject to the details of the underlying architecture).\n\nThere are only a few observable effects of this decorator to the typical Mojo programmer:\n\n@register_passable types are not able to hold instances of types that are not themselves @register_passable.\n\nInstances of @register_passable types do not have predictable identity, and so the self pointer is not stable/predictable (e.g.¬†in hash tables).\n\n@register_passable arguments and result are exposed to C and C++ directly, instead of being passed by-pointer.\n\nThe __init__ and __copyinit__ methods of this type are implicitly static (like __new__ in Python) and return their results by-value instead of taking inout self.\n\nWe expect that this decorator will be used pervasively on core standard library types, but is safe to ignore for general application level code.\n\nThe Int example above actually uses the ‚Äútrivial‚Äù variant of this decorator. It changes the passing convention as described above but also disallows copy and move constructors and destructors (synthesizing them all trivially).\n\nTODO: Trivial needs to be decoupled to its own decorator since it applies to memory types as well.\n\n@always_inline decorator\n\n@always_inline(\"nodebug\"): same thing but without debug information so you don‚Äôt step into the + method on Int.\n\n@parameter decorator\n\nThe @parameter decorator can be placed on nested functions that capture runtime values to create ‚Äúparametric‚Äù capturing closures. This is an unsafe feature in Mojo, because we do not currently model the lifetimes of capture-by-reference. A particular aspect of this feature is that it allows closures that capture runtime values to be passed as parameter values.\n\nMagic operators\n\nC++ code has a number of magic operators that intersect with value lifecycle, things like ‚Äúplacement new‚Äù, ‚Äúplacement delete‚Äù and ‚Äúoperator=‚Äù that reassign over an existing value. Mojo is a safe language when you use all its language features and compose on top of safe constructs, but of any stack is a world of C-style pointers and rampant unsafety. Mojo is a pragmatic language, and since we are interested in both interoperating with C/C++ and in implementing safe constructs like String directly in Mojo itself, we need a way to express unsafe things.\n\nThe Mojo standard library Pointer[element_type] type is implemented with an underlying !kgen.pointer<element_type> type in MLIR, and we desire a way to implement these C++-equivalent unsafe constructs in Mojo. Eventually, these will migrate to all being methods on the Pointer type, but until then, some need to be exposed as built-in operators.\n\nDirect access to MLIR\n\nMojo provides full access to the MLIR dialects and ecosystem. Please take a look at the Low level IR in Mojo to learn how to use the __mlir_type, __mlir_op, and __mlir_type constructs. All of the built-in and standard library APIs are implemented by just calling the underlying MLIR constructs, and in doing so, Mojo effectively serves as syntax sugar on top of MLIR.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - Mojo modules and packages",
    "url": "https://docs.modular.com/mojo/manual/get-started/packages.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nMojo modules\nMojo packages\nMojo modules and packages\n\nMojo provides a packaging system that allows you to organize and compile code libraries into importables files. This page introduces the necessary concepts about how to organize your code into modules and packages (which is a lot like Python), and shows you how to create a packaged binary with the mojo package command.\n\nMojo modules\n\nTo understand Mojo packages, you first need to understand Mojo modules. A Mojo module is a single Mojo source file that includes code suitable for use by other files that import it. For example, you can create a module to define a struct such as this one:\n\nmymodule.mojo\nstruct MyPair:\n    var first: Int\n    var second: Int\n\n    fn __init__(inout self, first: Int, second: Int):\n        self.first = first\n        self.second = second\n\n    fn dump(self):\n        print(self.first, self.second)\n\nNotice that this code has no main() function, so you can‚Äôt execute mymodule.mojo. However, you can import this into another file with a main() function and use it there.\n\nFor example, here‚Äôs how you can import MyPair into a file named main.mojo that‚Äôs in the same directory as mymodule.mojo:\n\nmain.mojo\nfrom mymodule import MyPair\n\nfn main():\n    let mine = MyPair(2, 4)\n    mine.dump()\n\nAlternatively, you can import the whole module and then access its members through the module name. For example:\n\nmain.mojo\nimport mymodule\n\nfn main():\n    let mine = mymodule.MyPair(2, 4)\n    mine.dump()\n\nYou can also create an alias for an imported member with as, like this:\n\nmain.mojo\nimport mymodule as my\n\nfn main():\n    let mine = my.MyPair(2, 4)\n    mine.dump()\n\nIn this example, it only works when mymodule.mojo is in the same directory as main.mojo. Currently, you can‚Äôt import .mojo files as modules if they reside in other directories. That is, unless you treat the directory as a Mojo package, as described in the next section.\n\nNote: A Mojo module may include a main() function and may also be executable, but that‚Äôs generally not the practice and modules typically include APIs to be imported and used in other Mojo programs.\n\nMojo packages\n\nA Mojo package is just a collection of Mojo modules in a directory that includes an __init__.mojo file. By organizing modules together in a directory, you can then import all the modules together or individually. Optionally, you can also compile the package into a .mojopkg or .üì¶ file that‚Äôs easier to share.\n\nYou can import a package and its modules either directly from source files or from a compiled .mojopkg/.üì¶ file. It makes no real difference to Mojo which way you import a package. When importing from source files, the directory name works as the package name, whereas when importing from a compiled package, the filename is the package name (which you specify with the mojo package command‚Äîit can differ from the directory name).\n\nFor example, consider a project with these files:\n\nmain.mojo\nmypackage/\n    __init__.mojo\n    mymodule.mojo\n\nmymodule.mojo is the same code from examples above (with the MyPair struct) and __init__.mojo is empty.\n\nIn this case, the main.mojo file can now import MyPair through the package name like this:\n\nmain.mojo\nfrom mypackage.mymodule import MyPair\n\nfn main():\n    let mine = MyPair(2, 4)\n    mine.dump()\n\nNotice that the __init__.mojo is crucial here. If you delete it, then Mojo doesn‚Äôt recognize the directory as a package and it cannot import mymodule.\n\nThen, let‚Äôs say you don‚Äôt want the mypackage source code in the same location as main.mojo. So, you can compile it into a package file like this:\n\nmojo package mypackage -o mypack.mojopkg\n\nThen the mypackage source can be moved somewhere else, and the project files now look like this:\n\nmain.mojo\nmypack.mojopkg\n\nBecause we named the package file different from the directory, we need to fix the import statement and it all works the same:\n\nmain.mojo\nfrom mypack.mymodule import MyPair\n\nNote: If you want to rename your package, you cannot simply edit the .mojopkg or .üì¶ filename, because the package name is encoded in the file. You must instead run mojo package again to specify a new name.\n\nThe __init__ file\n\nAs mentioned above, the __init__.mojo file is required to indicate that a directory should be treated as a Mojo package, and it can be empty.\n\nCurrently, top-level code is not supported in .mojo files, so unlike Python, you can‚Äôt write code in __init__.mojo that executes upon import. You can, however, add structs and functions, which you can then import from the package name.\n\nHowever, instead of adding APIs in the __init__.mojo file, you can import module members, which has the same effect by making your APIs accessible from the package name, instead of requiring the <package_name>.<module_name> notation.\n\nFor example, again let‚Äôs say you have these files:\n\nmain.mojo\nmypackage/\n    __init__.mojo\n    mymodule.mojo\n\nLet‚Äôs now add the following line in __init__.mojo:\n\n__init__.mojo\nfrom .mymodule import MyPair\n\nThat‚Äôs all that‚Äôs in there. Now, we can simplify the import statement in main.mojo like this:\n\nmain.mojo\nfrom mypackage import MyPair\n\nThis feature explains why some members in the Mojo standard library can be imported from their package name, while others required the <package_name>.<module_name> notation. For example, the functional module resides in the algorithm package, so you can import members of that module (such as the map() function) like this:\n\nfrom algorithm.functional import map\n\nHowever, the algorithm/__init__.mojo file also includes these lines:\n\nalgorithm/__init__.mojo\nfrom .functional import *\nfrom .reduction import *\n\nSo you can actually import anything from functional or reduction simply by naming the package. That is, you can drop the functional name from the import statement, and it also works:\n\nfrom algorithm import map\n\nNote: Which modules in the standard library are imported to the package scope varies, and is subject to change. Refer to the documentation for each module to see how you can import its members.\n\nLanguage basics\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - Mojo language basics",
    "url": "https://docs.modular.com/mojo/manual/basics/",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nLanguage basics\nSyntax and semantics\nFunctions\nVariables\nFunction arguments and returns\nStructures\nPython integration\nNext steps\nMojo language basics\n\nMojo is a powerful programming language that‚Äôs primarily designed for high-performance systems programming, so it has a lot in common with other systems languages like Rust and C++. Yet, Mojo is also designed to become a superset of Python, so a lot of language features and concepts you might know from Python translate nicely to Mojo.\n\nFor example, if you‚Äôre in a REPL environment or Jupyter notebook (like this document), you can run top-level code just like Python:\n\nprint(\"Hello Mojo!\")\nHello Mojo!\n\nYou don‚Äôt normally see that with other systems programming languages.\n\nMojo preserves Python‚Äôs dynamic features and language syntax, and it even allows you to import and run code from Python packages. However, it‚Äôs important to know that Mojo is an entirely new language, not just a new implementation of Python with syntax sugar. Mojo takes the Python language to a whole new level, with systems programming features, strong type-checking, memory safety, next-generation compiler technologies, and more. Yet, it‚Äôs still designed to be a simple language that‚Äôs useful for general-purpose programming.\n\nThis page provides a gentle introduction to the Mojo language, and requires only a little programming experience. So let‚Äôs get started!\n\nIf you‚Äôre an experienced systems programmer and want a deep dive into the language, check out the Mojo programming manual.\n\nLanguage basics\n\nFirst and foremost, Mojo is a compiled language and a lot of its performance and memory-safety features are derived from that fact. Mojo code can be ahead-of-time (AOT) or just-in-time (JIT) compiled.\n\nLike other compiled languages, Mojo programs (.mojo or .üî• files) require a main() function as the entry point to the program. For example:\n\nfn main():\n    var x: Int = 1\n    x += 1\n    print(x)\n\nIf you know Python, you might have expected the function name to be def main() instead of fn main(). Both actually work in Mojo, but using fn behaves a bit differently, as we‚Äôll discuss below.\n\nOf course, if you‚Äôre building a Mojo module (an API library), not a Mojo program, then your file doesn‚Äôt need a main() function (because it will be imported by other programs that do have one).\n\nNote: When you‚Äôre writing code in a .mojo/.üî• file, you can‚Äôt run top-level code as shown on this page‚Äîall code in a Mojo program or module must be encased in a function or struct. However, top-level code does work in a REPL or Jupyter notebook (such as the notebook for this page).\n\nNow let‚Äôs explain the code in this main() function.\n\nSyntax and semantics\n\nThis is simple: Mojo supports (or will support) all of Python‚Äôs syntax and semantics. If you‚Äôre not familiar with Python syntax, there are a ton of great resources online that can teach you.\n\nFor example, like Python, Mojo uses line breaks and indentation to define code blocks (not curly braces), and Mojo supports all of Python‚Äôs control-flow syntax such as if conditions and for loops.\n\nHowever, Mojo is still a work in progress, so there are some things from Python that aren‚Äôt implemented in Mojo yet (see the Mojo roadmap). All the missing Python features will arrive in time, but Mojo already includes many features and capabilities beyond what‚Äôs available in Python.\n\nAs such, the following sections will focus on some of the language features that are unique to Mojo (compared to Python).\n\nFunctions\n\nMojo functions can be declared with either fn (shown above) or def (as in Python). The fn declaration enforces strongly-typed and memory-safe behaviors, while def provides Python-style dynamic behaviors.\n\nBoth fn and def functions have their value, and it‚Äôs important that you learn them both. However, for the purposes of this introduction, we‚Äôre going to focus on fn functions only. For much more detail about both, see the programming manual.\n\nIn the following sections, you‚Äôll learn how fn functions enforce strongly-typed and memory-safe behaviors in your code.\n\nVariables\n\nYou can declare variables (such as x in the above main() function) with var to create a mutable value, or with let to create an immutable value.\n\nIf you change var to let in the main() function above and run it, you‚Äôll get a compiler error like this:\n\nerror: Expression [15]:7:5: expression must be mutable for in-place operator destination\n    x += 1\n    ^\n\nThat‚Äôs because let makes the value immutable, so you can‚Äôt increment it.\n\nAnd if you delete var completely, you‚Äôll get an error because fn functions require explicit variable declarations (unlike Python-style def functions).\n\nFinally, notice that the x variable has an explicit Int type specification. Declaring the type is not required for variables in fn, but it is desirable sometimes. If you omit it, Mojo infers the type, as shown here:\n\nfn do_math():\n    let x: Int = 1\n    let y = 2\n    print(x + y)\n\ndo_math()\n3\nFunction arguments and returns\n\nAlthough types aren‚Äôt required for variables declared in the function body, they are required for arguments and return values for an fn function.\n\nFor example, here‚Äôs how to declare Int as the type for function arguments and the return value:\n\nfn add(x: Int, y: Int) -> Int:\n    return x + y\n\nz = add(1, 2)\nprint(z)\n3\nOptional arguments and keyword arguments\n\nYou can also specify argument default values (also known as optional arguments), and pass values with keyword argument names. For example:\n\nfn pow(base: Int, exp: Int = 2) -> Int:\n    return base ** exp\n\n# Uses default value for `exp`\nz = pow(3)\nprint(z)\n\n# Uses keyword argument names (with order reversed)\nz = pow(exp=3, base=2)\nprint(z)\n9\n8\n\nNote: Mojo currently includes only partial support for keyword arguments, so some features such as keyword-only arguments and variadic keyword arguments (e.g.¬†**kwargs) are not supported yet.\n\nArgument mutability and ownership\n\nMojo supports full value semantics and enforces memory safety with a robust value ownership model (similar to the Rust borrow checker). Essentially, that means Mojo allows you to share references to values (instead of making a copy every time you pass a value to a function), but doing so requires that you follow Mojo‚Äôs ownership rules (to ensure memory safety) as described in this section.\n\nNotice that, above, add() doesn‚Äôt modify x or y, it only reads the values. In fact, as written, the function cannot modify them because fn arguments are immutable references by default. This ensures memory safety (no surprise changes to the data) while also avoiding a copy (which could be a performance hit).\n\nIn terms of argument conventions, this is called ‚Äúborrowing,‚Äù and although it‚Äôs the default for fn functions, you can make it explicit with the borrowed declaration like this (this behaves exactly the same as the add() above):\n\nfn add(borrowed x: Int, borrowed y: Int) -> Int:\n    return x + y\n\nIf you want the arguments to be mutable, you need to declare each argument convention as inout. This means that changes made to the arguments inside the function are visible outside the function.\n\nFor example, this function is able to modify the original variables:\n\nfn add_inout(inout x: Int, inout y: Int) -> Int:\n    x += 1\n    y += 1\n    return x + y\n\nvar a = 1\nvar b = 2\nc = add_inout(a, b)\nprint(a)\nprint(b)\nprint(c)\n2\n3\n5\n\nAnother option is to declare the argument as owned, which provides the function full ownership of the value (it‚Äôs mutable and guaranteed unique). This way, the function can modify the value and not worry about affecting variables outside the function. For example:\n\nfn set_fire(owned text: String) -> String:\n    text += \"üî•\"\n    return text\n\nfn mojo():\n    let a: String = \"mojo\"\n    let b = set_fire(a)\n    print(a)\n    print(b)\n\nmojo()\nmojo\nmojoüî•\n\nIn this case, Mojo makes a copy of a and passes it as the text argument. The original a string is still alive and well.\n\nHowever, if you want to give the function ownership of the value and do not want to make a copy (which can be an expensive operation for some types), then you can add the ^ ‚Äútransfer‚Äù operator when you pass a to the function. The transfer operator effectively destroys the local variable name‚Äîany attempt to call upon it later causes a compiler error.\n\nTry it above by changing the call to set_fire() to look like this:\n\n    let b = set_fire(a^)\n\nYou‚Äôll now get an error because the transfer operator effectively destroys the a variable, so when the following print() function tries to use a, that variable isn‚Äôt initialized anymore.\n\nIf you delete print(a), then it works fine.\n\nThese argument conventions are designed to provide systems programmers with total control for memory optimizations while ensuring safe access and timely deallocations‚Äîthe Mojo compiler ensures that no two variables have mutable access to the same value at the same time, and the lifetime of each value is well-defined to strictly prevent any memory errors such as ‚Äúuse-after-free‚Äù and ‚Äúdouble-free.‚Äù\n\nNote: Currently, Mojo always makes a copy when a function returns a value.\n\nStructures\n\nYou can build high-level abstractions for types (or ‚Äúobjects‚Äù) in a struct. A struct in Mojo is similar to a class in Python: they both support methods, fields, operator overloading, decorators for metaprogramming, etc. However, Mojo structs are completely static‚Äîthey are bound at compile-time, so they do not allow dynamic dispatch or any runtime changes to the structure. (Mojo will also support classes in the future.)\n\nFor example, here‚Äôs a basic struct:\n\nstruct MyPair:\n    var first: Int\n    var second: Int\n\n    fn __init__(inout self, first: Int, second: Int):\n        self.first = first\n        self.second = second\n    \n    fn dump(self):\n        print(self.first, self.second)\n\nAnd here‚Äôs how you can use it:\n\nlet mine = MyPair(2, 4)\nmine.dump()\n2 4\n\nIf you‚Äôre familiar with Python, then the __init__() method and the self argument should be familiar to you. If you‚Äôre not familiar with Python, then notice that, when we call dump(), we don‚Äôt actually pass a value for the self argument. The value for self is automatically provided with the current instance of the struct (it‚Äôs used similar to the this name used in some other languages to refer to the current instance of the object/type).\n\nFor much more detail about structs and other special methods like __init__() (also known as ‚Äúdunder‚Äù methods), see the programming manual.\n\nPython integration\n\nAlthough Mojo is still a work in progress and is not a full superset of Python yet, we‚Äôve built a mechanism to import Python modules as-is, so you can leverage existing Python code right away. Under the hood, this mechanism uses the CPython interpreter to run Python code, and thus it works seamlessly with all Python modules today.\n\nFor example, here‚Äôs how you can import and use NumPy (you must have Python numpy installed):\n\nfrom python import Python\n\nlet np = Python.import_module(\"numpy\")\n\nar = np.arange(15).reshape(3, 5)\nprint(ar)\nprint(ar.shape)\n[[ 0  1  2  3  4]\n [ 5  6  7  8  9]\n [10 11 12 13 14]]\n(3, 5)\n\nNote: Mojo is not a feature-complete superset of Python yet. So, you can‚Äôt always copy Python code and run it in Mojo. For more details on our plans, please refer to the Mojo roadmap and sharp edges.\n\nCaution: When you install Mojo, the installer searches your system for a version of Python to use with Mojo, and adds the path to the modular.cfg config file. If you change your Python version or switch virtual environments, Mojo will then be looking at the wrong Python library, which can cause problems such as errors when you import Python packages (Mojo says only An error occurred in Python‚Äîthis is a separate known issue). The current solution is to override Mojo‚Äôs path to the Python library, using the MOJO_PYTHON_LIBRARY environment variable. For instructions on how to find and set this path, see this related issue.\n\nNext steps\n\nWe hope this page covered enough of the basics to get you started. It‚Äôs intentionally brief, so if you want more detail about any of the topics touched upon here, check out the Mojo programming manual.\n\nIf you want to package your code as a library, read about Mojo modules and packages.\n\nIf you want to explore some Mojo code, check out our code examples on GitHub.\n\nTo see all the available Mojo APIs, check out the Mojo standard library reference.\n\nNote: The Mojo SDK is still in early development. Some things are still rough, but you can expect constant changes and improvements to both the language and tools. Please see the known issues and report any other issues on GitHub.\n\nHello, world!\nModules and packages\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - Hello, world!",
    "url": "https://docs.modular.com/mojo/manual/get-started/hello-world.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nRun code in the REPL\nBuild and run Mojo source files\nNext steps\nHello, world!\n\nAfter you install Mojo, you can use the Mojo CLI to build and compile Mojo programs. So let‚Äôs create the classic starter program that prints ‚ÄúHello, world!‚Äù\n\nBefore you start:\n\nYou must set the MODULAR_HOME and PATH environment variables, as described in the output when you ran modular install mojo. For example, if you‚Äôre using bash or zsh, add the following lines to your configuration file (.bash_profile, .bashrc, or .zshrc):\n\nexport MODULAR_HOME=\"$HOME/.modular\"\nexport PATH=\"$MODULAR_HOME/pkg/packages.modular.com_mojo/bin:$PATH\"\n\nThen source the file you just updated, for example:\n\nsource ~/.bash_profile\n\nIf you have other issues during install, check our known issues.\n\nRun code in the REPL\n\nFirst, let‚Äôs try running some code in the Mojo REPL, which allows you to write and run Mojo code directly in a command prompt:\n\nTo start a REPL session, type mojo in your terminal and press Enter.\n\nThen type print(\"Hello, world!\") and press Enter twice (a blank line is required to indicate the end of an expression).\n\nThat‚Äôs it! For example:\n\n$ mojo\nWelcome to Mojo! üî•\n\nExpressions are delimited by a blank line.\nType `:quit` to exit the REPL and `:mojo help` for further assistance.\n\n1> print(\"Hello, world!\")\n2.\nHello, world!\n\nYou can write as much code as you want in the REPL. You can press Enter to start a new line and continue writing code, and when you want Mojo to evaluate the code, press Enter twice. If there‚Äôs something to print, Mojo prints it and then returns the prompt to you.\n\nThe REPL is primarily useful for short experiments because the code isn‚Äôt saved. So when you want to write a real program, you need to write the code in a .mojo source file.\n\nBuild and run Mojo source files\n\nNow let‚Äôs print ‚ÄúHello, world‚Äù with a source file. Mojo source files are identified with either the .mojo or .üî• file extension.\n\nYou can quickly execute a Mojo file by passing it to the mojo command, or you can build a compiled executable with the mojo build command. Let‚Äôs try both.\n\nRun a Mojo file\n\nFirst, write the Mojo code and execute it:\n\nCreate a file named hello.mojo (or hello.üî•) and add the following code:\n\nfn main():\n   print(\"Hello, world!\")\n\nThat‚Äôs all you need. Save the file and return to your terminal.\n\nNow run it with the mojo command:\n\nmojo hello.mojo\n\nIt should immediately print the message:\n\nHello, world!\n\nIf this didn‚Äôt work for you, double-check your code looks exactly like the code in step 1, and make sure you correctly installed Mojo.\n\nBuild an executable binary\n\nNow, build and run an executable:\n\nCreate a stand-alone executable with the build command:\n\nmojo build hello.mojo\n\nIt creates the executable with the same name as the .mojo file, but you can change that with the -o option.\n\nThen run the executable:\n\n./hello\n\nThe executable runs on your system like any C or C++ executable.\n\nNext steps\n\nIf you‚Äôre developing in VS Code, install the Mojo extension so you get syntax highlighting, code completion, diagnostics, and more.\n\nIf you‚Äôre new to Mojo, read the Mojo language basics.\n\nIf you want to package your code as a library, read about Mojo modules and packages.\n\nIf you want to explore some Mojo code, clone our repo to see some examples:\n\ngit clone https://github.com/modularml/mojo.git\n\nThen open the /examples directory in your IDE to try our examples:\n\nThe code examples offer a variety of demos with the standard library to help you learn Mojo‚Äôs features and start your own projects.\n\nThe Mojo notebooks are the same Jupyter notebooks we publish in the Mojo Playground, which demonstrate a variety of language features. Now with the Mojo SDK, you can also run them in VS Code or in JupyterLab.\n\nFor a deep dive into the language, check out the Mojo programming manual.\n\nTo see all the available Mojo APIs, check out the Mojo standard library reference.\n\nNote: The Mojo SDK is still in early development, but you can expect constant improvements to both the language and tools. Please see the known issues and report any other issues on GitHub.\n\nGet Mojo\nLanguage basics\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - Get started with Mojoüî•",
    "url": "https://docs.modular.com/mojo/manual/get-started/",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nGet the Mojo SDK\nSystem requirements\nInstall Mojo\nUpdate Mojo\nUpdate the Modular CLI\nDevelop in the Mojo Playground\nGet started with Mojoüî•\n\nMojo is now available for local development!\n\nDownload Now\n\nThe Mojo SDK is currently available for Ubuntu Linux systems and macOS systems running on Apple silicon. Support for Windows is coming soon. You can also develop from Windows or Intel macOS using a container or remote Linux system. Alternatively, you can also experiment with Mojo using our web-based Mojo Playground.\n\nGet the Mojo SDK\n\nThe Mojo SDK includes everything you need for local Mojo development, including the Mojo standard library and the Mojo command-line interface (CLI). The Mojo CLI can start a REPL programming environment, compile and run Mojo source files, format source files, and more.\n\nWe‚Äôve also published a Mojo extension for Visual Studio Code to provide a first-class developer experience with features like code completion, quick fixes, and hover help for Mojo APIs.\n\nSystem requirements\n\nTo use the Mojo SDK, you need a system that meets these specifications:\n\nLinux:\n\nUbuntu 20.04/22.04 LTS\nx86-64 CPU (with SSE4.2 or newer) and a minimum of 8 GiB memory\nPython 3.8 - 3.11\ng++ or clang++ C++ compiler\n\nMac:\n\nApple silicon (M1 or M2 processor)\nmacOS Monterey (12) or later\nPython 3.8 - 3.11\nCommand-line tools for Xcode, or Xcode\n\nSupport for Windows will be added in a future release.\n\nInstall Mojo\n\nThe Mojo SDK is available through the Modular CLI tool, which works like a package manager to install and update Mojo. Use the following link to log into the Modular developer console, where you can get the Modular CLI and then install Mojo:\n\nDownload Now\n\nThen get started with Hello, world!\n\nNote: To help us improve Mojo, we collect some basic system information and crash reports. Learn more.\n\nUpdate Mojo\n\nMojo is a work in progress and we will release regular updates to the Mojo language and SDK tools. For information about each release, see the Mojo changelog.\n\nTo check your current Mojo version, use the --version option:\n\nmojo --version\n\nTo update to the latest Mojo version, use the modular update command:\n\nmodular update mojo\nUpdate the Modular CLI\n\nWe may also release updates to the modular tool. Run the following commands to update the CLI on your system.\n\nLinux:\n\nsudo apt update\n\nsudo apt install modular\n\nMac:\n\nbrew update\n\nbrew upgrade modular\nDevelop in the Mojo Playground\n\nInstead of downloading the Mojo SDK, you can also experiment with Mojo in our hosted Jupyter notebook environment called Mojo Playground. This is a hosted version of JupyterLab that‚Äôs running our latest Mojo kernel.\n\nTo get access, just log in to the Mojo Playground here.\n\nWhat to expect\n\nThe Mojo Playground is a JupyterHub environment in which you get a private volume associated with your account, so you can create your own notebooks and they‚Äôll be saved across sessions.\n\nWe‚Äôve included a handful of notebooks to show you Mojo basics and demonstrate its capabilities.\n\nThe number of vCPU cores available in your cloud instance may vary, so baseline performance is not representative of the language. However, as you will see in the included Matmul.ipynb notebook, Mojo‚Äôs relative performance over Python is significant.\n\nThere might be some bugs. Please report issues and feedback on GitHub.\n\nTips\n\nIf you want to keep any edits to the included notebooks, rename the notebook files. These files will reset upon any server refresh or update, sorry. So if you rename the files, your changes will be safe.\n\nYou can use %%python at the top of a notebook cell and write normal Python code. Variables, functions, and imports defined in a Python cell are available for access in subsequent Mojo cells.\n\nCaveats\n\nDid we mention that the included notebooks will lose your changes?\nRename the files if you want to save your changes.\n\nThe Mojo environment does not have network access, so you cannot install other tools or Python packages. However, we‚Äôve included a variety of popular Python packages, such as numpy, pandas, and matplotlib (see how to import Python modules).\n\nRedefining implicit variables is not supported (variables without a let or var in front). If you‚Äôd like to redefine a variable across notebook cells, you must introduce the variable with var (let variables are immutable).\n\nYou can‚Äôt use global variables inside functions‚Äîthey‚Äôre only visible to other global variables.\n\nFor a longer list of things that don‚Äôt work yet or have pain-points, see the Mojo roadmap and sharp edges.\n\nHello, world!\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - Mojoüî•",
    "url": "https://docs.modular.com/mojo/",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nMojoüî•\n\nMojo is a new programming language that bridges the gap between research and production by combining the best of Python syntax with systems programming and metaprogramming. With Mojo, you can write portable code that‚Äôs faster than C and seamlessly inter-op with the Python ecosystem.\n\nMojo is now available for local development! üî•\n\nGet the Mojo SDK\n\nJoin our community\n\nDocs\nWhy Mojoüî•\nA backstory and rationale for why we created the Mojo language.\nMojoüî• programming manual\nA tour of major Mojo language features with code examples.\nMojoüî• modules\nA list of all modules in the current standard library.\nMojoüî• roadmap & sharp edges\nA summary of our Mojo plans, including upcoming features and things we need to fix.\nMojoüî• FAQ\nAnswers to questions we expect about Mojo.\nMojoüî• changelog\nA history of significant Mojo changes.\nMojoüî• community\nResources to share feedback, report issues, and chat.\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  },
  {
    "title": "Modular Docs - Why Mojoüî•",
    "url": "https://docs.modular.com/mojo/why-mojo.html",
    "html": "AI Engine\nMojoüî•\nGet Started\nOverview\nWhy Mojo\nGet started\nGet Mojo\nHello, world!\nLanguage basics\nModules and packages\nProgramming manual\nMojo notebooks\nOverview\nLow-level IR in Mojo\nMandelbrot in Mojo with Python plots\nMatrix multiplication in Mojo\nFast memset in Mojo\nRay tracing in Mojo\nMojo library\nModule index\nalgorithm\nautotune\nbase64\nbenchmark\nbuiltin\ncomplex\nmath\nmemory\nos\npathlib\npython\nrandom\nsys\ntensor\ntesting\ntime\nutils\nMojo CLI\nmojo\nmojo build\nmojo debug\nmojo demangle\nmojo doc\nmojo format\nmojo package\nmojo repl\nmojo run\nRoadmap & sharp edges\nChangelog\nFAQ\nCommunity\nOn this page\nA language for next-generation compiler technology\nA member of the Python family\nCompatibility with Python\nPython‚Äôs problems\nRelated work\nWhy Mojoüî•\n\nWhen we started Modular, we had no intention of building a new programming language. But as we were building our platform to unify the world‚Äôs ML/AI infrastructure, we realized that programming across the entire stack was too complicated. Plus, we were writing a lot of MLIR by hand and not having a good time.\n\nWhat we wanted was an innovative and scalable programming model that could target accelerators and other heterogeneous systems that are pervasive in the AI field. This meant a programming language with powerful compile-time metaprogramming, integration of adaptive compilation techniques, caching throughout the compilation flow, and other features that are not supported by existing languages.\n\nAnd although accelerators are important, one of the most prevalent and sometimes overlooked ‚Äúaccelerators‚Äù is the host CPU. Nowadays, CPUs have lots of tensor-core-like accelerator blocks and other AI acceleration units, but they also serve as the ‚Äúfallback‚Äù for operations that specialized accelerators don‚Äôt handle, such as data loading, pre- and post-processing, and integrations with foreign systems. So it was clear that we couldn‚Äôt lift AI with just an ‚Äúaccelerator language‚Äù that worked with only specific processors.\n\nApplied AI systems need to address all these issues, and we decided there was no reason it couldn‚Äôt be done with just one language. Thus, Mojo was born.\n\nA language for next-generation compiler technology\n\nWhen we realized that no existing language could solve the challenges in AI compute, we embarked on a first-principles rethinking of how a programming language should be designed and implemented to solve our problems. Because we require high-performance support for a wide variety of accelerators, traditional compiler technologies like LLVM and GCC were not suitable (and any languages and tools based on them would not suffice). Although they support a wide range of CPUs and some commonly used GPUs, these compiler technologies were designed decades ago and are unable to fully support modern chip architectures. Nowadays, the standard technology for specialized machine learning accelerators is MLIR.\n\nMLIR is a relatively new open-source compiler infrastructure started at Google (whose leads moved to Modular) that has been widely adopted across the machine learning accelerator community. MLIR‚Äôs strength is its ability to build domain specific compilers, particularly for weird domains that aren‚Äôt traditional CPUs and GPUs, such as AI ASICS, quantum computing systems, FPGAs, and custom silicon.\n\nGiven our goals at Modular to build a next-generation AI platform, we were already using MLIR for some of our infrastructure, but we didn‚Äôt have a programming language that could unlock MLIR‚Äôs full potential across our stack. While many other projects now use MLIR, Mojo is the first major language designed expressly for MLIR, which makes Mojo uniquely powerful when writing systems-level code for AI workloads.\n\nA member of the Python family\n\nOur core mission for Mojo includes innovations in compiler internals and support for current and emerging accelerators, but don‚Äôt see any need to innovate in language syntax or community. So we chose to embrace the Python ecosystem because it is so widely used, it is loved by the AI ecosystem, and because we believe it is a really nice language.\n\nThe Mojo language has lofty goals: we want full compatibility with the Python ecosystem, we want predictable low-level performance and low-level control, and we need the ability to deploy subsets of code to accelerators. Additionally, we don‚Äôt want to create a fragmented software ecosystem‚Äîwe don‚Äôt want Python users who adopt Mojo to draw comparisons to the painful migration from Python 2 to 3. These are no small goals!\n\nFortunately, while Mojo is a brand-new code base, we aren‚Äôt really starting from scratch conceptually. Embracing Python massively simplifies our design efforts, because most of the syntax is already specified. We can instead focus our efforts on building Mojo‚Äôs compilation model and systems programming features. We also benefit from tremendous lessons learned from other languages (such as Rust, Swift, Julia, Zig, Nim, etc.), from our prior experience migrating developers to new compilers and languages, and we leverage the existing MLIR compiler ecosystem.\n\nFurther, we decided that the right long-term goal for Mojo is to provide a superset of Python (that is, to make Mojo compatible with existing Python programs) and to embrace the CPython implementation for long-tail ecosystem support. If you‚Äôre a Python programmer, we hope that Mojo is immediately familiar, while also providing new tools to develop safe and performant systems-level code that would otherwise require C and C++ below Python.\n\nWe aren‚Äôt trying to convince the world that ‚Äústatic is best‚Äù or ‚Äúdynamic is best.‚Äù Rather, we believe that both are good when used for the right applications, so we designed Mojo to allow you, the programmer, to decide when to use static or dynamic.\n\nWhy we chose Python\n\nPython is the dominant force in ML and countless other fields. It‚Äôs easy to learn, known by important cohorts of programmers, has an amazing community, has tons of valuable packages, and has a wide variety of good tooling. Python supports the development of beautiful and expressive APIs through its dynamic programming features, which led machine learning frameworks like TensorFlow and PyTorch to embrace Python as a frontend to their high-performance runtimes implemented in C++.\n\nFor Modular today, Python is a non-negotiable part of our API surface stack‚Äîthis is dictated by our customers. Given that everything else in our stack is negotiable, it stands to reason that we should start from a ‚ÄúPython-first‚Äù approach.\n\nMore subjectively, we believe that Python is a beautiful language. It‚Äôs designed with simple and composable abstractions, it eschews needless punctuation that is redundant-in-practice with indentation, and it‚Äôs built with powerful (dynamic) metaprogramming features. All of which provide a runway for us to extend the language to what we need at Modular. We hope that people in the Python ecosystem see our direction for Mojo as taking Python ahead to the next level‚Äîcompleting it‚Äîinstead of competing with it.\n\nCompatibility with Python\n\nWe plan for full compatibility with the Python ecosystem, but there are actually two types of compatibility, so here‚Äôs where we currently stand on them both:\n\nIn terms of your ability to import existing Python modules and use them in a Mojo program, Mojo is 100% compatible because we use CPython for interoperability.\n\nIn terms of your ability to migrate any Python code to Mojo, it‚Äôs not fully compatible yet. Mojo already supports many core features from Python, including async/await, error handling, variadics, and so on. However, Mojo is still young and missing many other features from Python. Mojo doesn‚Äôt even support classes yet!\n\nThere is a lot of work to be done, but we‚Äôre confident we‚Äôll get there, and we‚Äôre guided by our team‚Äôs experience building other major technologies with their own compatibility journeys:\n\nThe journey to the Clang compiler (a compiler for C, C++, Objective-C, CUDA, OpenCL, and others), which is a ‚Äúcompatible replacement‚Äù for GCC, MSVC and other existing compilers. It is hard to make a direct comparison, but the complexity of the Clang problem appears to be an order of magnitude bigger than implementing a compatible replacement for Python.\n\nThe journey to the Swift programming language, which embraced the Objective-C runtime and language ecosystem, and progressively migrated millions of programmers (and huge amounts of code). With Swift, we learned lessons about how to be ‚Äúrun-time compatible‚Äù and cooperate with a legacy runtime.\n\nIn situations where you want to mix Python and Mojo code, we expect Mojo to cooperate directly with the CPython runtime and have similar support for integrating with CPython classes and objects without having to compile the code itself. This provides plug-in compatibility with a massive ecosystem of existing code, and it enables a progressive migration approach in which incremental migration to Mojo yields incremental benefits.\n\nOverall, we believe that by focusing on language design and incremental progress towards full compatibility with Python, we will get where we need to be in time.\n\nHowever, it‚Äôs important to understand that when you write pure Mojo code, there is nothing in the implementation, compilation, or runtime that uses any existing Python technologies. On its own, it is an entirely new language with an entirely new compilation and runtime system.\n\nIntentional differences from Python\n\nWhile Python compatibility and migratability are key to Mojo‚Äôs success, we also want Mojo to be a first-class language (meaning that it‚Äôs a standalone language rather than dependent upon another language). It should not be limited in its ability to introduce new keywords or grammar productions merely to maintain compatibility. As such, our approach to compatibility is two-fold:\n\nWe utilize CPython to run all existing Python 3 code without modification and use its runtime, unmodified, for full compatibility with the entire ecosystem. Running code this way provides no benefit from Mojo, but the sheer existence and availability of this ecosystem will rapidly accelerate the bring-up of Mojo, and leverage the fact that Python is really great for high-level programming already.\n\nWe will provide a mechanical migration tool that provides very good compatibility for people who want to migrate code from Python to Mojo. For example, to avoid migration errors with Python code that uses identifier names that match Mojo keywords, Mojo provides a backtick feature that allows any keyword to behave as an identifier.\n\nTogether, this allows Mojo to integrate well in a mostly-CPython world, but allows Mojo programmers to progressively move code (a module or file at a time) to Mojo. This is a proven approach from the Objective-C to Swift migration that Apple performed.\n\nIt will take some time to build the rest of Mojo and the migration support, but we are confident that this strategy allows us to focus our energies and avoid distractions. We also think the relationship with CPython can build in both directions‚Äîwouldn‚Äôt it be cool if the CPython team eventually reimplemented the interpreter in Mojo instead of C? üî•\n\nPython‚Äôs problems\n\nBy aiming to make Mojo a superset of Python, we believe we can solve many of Python‚Äôs existing problems.\n\nPython has some well-known problems‚Äîmost obviously, poor low-level performance and CPython implementation details like the global interpreter lock (GIL), which makes Python single-threaded. While there are many active projects underway to improve these challenges, the issues brought by Python go deeper and are particularly impactful in the AI field. Instead of talking about those technical limitations in detail, we‚Äôll talk about their implications here in 2023.\n\nNote that everywhere we refer to Python in this section is referring to the CPython implementation. We‚Äôll talk about other implementations later.\n\nThe two-world problem\n\nFor a variety of reasons, Python isn‚Äôt suitable for systems programming. Fortunately, Python has amazing strengths as a glue layer, and low-level bindings to C and C++ allow building libraries in C, C++ and many other languages with better performance characteristics. This is what has enabled things like NumPy, TensorFlow, PyTorch, and a vast number of other libraries in the ecosystem.\n\nUnfortunately, while this approach is an effective way to build high-performance Python libraries, it comes with a cost: building these hybrid libraries is very complicated. It requires low-level understanding of the internals of CPython, requires knowledge of C/C++ (or other) programming (undermining one of the original goals of using Python in the first place), makes it difficult to evolve large frameworks, and (in the case of ML) pushes the world towards ‚Äúgraph based‚Äù programming models, which have worse fundamental usability than ‚Äúeager mode‚Äù systems. Both TensorFlow and PyTorch have faced significant challenges in this regard.\n\nBeyond the fundamental nature of how the two-world problem creates system complexity, it makes everything else in the ecosystem more complicated. Debuggers generally can‚Äôt step across Python and C code, and those that can aren‚Äôt widely accepted. It‚Äôs painful that the Python package ecosystems has to deal with C/C++ code in addition to Python. Projects like PyTorch, with significant C++ investments, are intentionally trying to move more of their codebase to Python because they know it gains usability.\n\nThe three-world and N-world problem\n\nThe two-world problem is commonly felt across the Python ecosystem, but things are even worse for developers of machine learning frameworks. AI is pervasively accelerated, and those accelerators use bespoke programming languages like CUDA. While CUDA is a relative of C++, it has its own special problems and limitations, and it does not have consistent tools like debuggers or profilers. It is also effectively locked into a single hardware maker.\n\nThe AI world has an incredible amount of innovation on the hardware front, and as a consequence, complexity is spiraling out of control. There are now several attempts to build limited programming systems for accelerators (OpenCL, Sycl, OneAPI, and others). This complexity explosion is continuing to increase and none of these systems solve the fundamental fragmentation in the tools and ecosystem that is hurting the industry so badly‚Äîthey‚Äôre adding to the fragmentation.\n\nMobile and server deployment\n\nAnother challenge for the Python ecosystem is deployment. There are many facets to this, including how to control dependencies, how to deploy hermetically compiled ‚Äúa.out‚Äù files, and how to improve multi-threading and performance. These are areas where we would like to see the Python ecosystem take significant steps forward.\n\nRelated work\n\nWe are aware of many other efforts to improve Python, but they do not solve the fundamental problem we aim to solve with Mojo.\n\nSome ongoing efforts to improve Python include work to speed up Python and replace the GIL, to build languages that look like Python but are subsets of it, and to build embedded domain-specific languages (DSLs) that integrate with Python but which are not first-class languages. While we cannot provide an exhaustive list of all the efforts, we can talk about some challenges faced in these projects, and why they don‚Äôt solve the problems that Mojo does.\n\nImproving CPython and JIT compiling Python\n\nRecently, the community has spent significant energy on improving CPython performance and other implementation issues, and this is showing huge results. This work is fantastic because it incrementally improves the current CPython implementation. For example, Python 3.11 has increased performance 10-60% over Python 3.10 through internal improvements, and Python 3.12 aims to go further with a trace optimizer. Many other projects are attempting to tame the GIL, and projects like PyPy (among many others) have used JIT compilation and tracing approaches to speed up Python.\n\nWhile we are fans of these great efforts, and feel they are valuable and exciting to the community, they unfortunately do not satisfy our needs at Modular, because they do not help provide a unified language onto an accelerator. Many accelerators these days support very limited dynamic features, or do so with terrible performance. Furthermore, systems programmers don‚Äôt seek only ‚Äúperformance,‚Äù but they also typically want a lot of predictability and control over how a computation happens.\n\nWe are looking to eliminate the need to use C or C++ within Python libraries, we seek the highest performance possible, and we cannot accept dynamic features at all in some cases. Therefore, these approaches don‚Äôt help.\n\nPython subsets and other Python-like languages\n\nThere are many attempts to build a ‚Äúdeployable‚Äù Python, such as TorchScript from the PyTorch project. These are useful because they often provide low-dependency deployment solutions and sometimes have high performance. Because they use Python-like syntax, they can be easier to learn than a novel language.\n\nOn the other hand, these languages have not seen wide adoption‚Äîbecause they are a subset of Python, they generally don‚Äôt interoperate with the Python ecosystem, don‚Äôt have fantastic tooling (such as debuggers), and often change-out inconvenient behavior in Python unilaterally, which breaks compatibility and fragments the ecosystem further. For example, many of these change the behavior of simple integers to wrap instead of producing Python-compatible math.\n\nThe challenge with these approaches is that they attempt to solve a weak point of Python, but they aren‚Äôt as good at Python‚Äôs strong points. At best, these can provide a new alternative to C and C++, but without solving the dynamic use-cases of Python, they cannot solve the ‚Äútwo world problem.‚Äù This approach drives fragmentation, and incompatibility makes migration difficult to impossible‚Äîrecall how challenging it was to migrate from Python 2 to Python 3.\n\nPython supersets with C compatibility\n\nBecause Mojo is designed to be a superset of Python with improved systems programming capabilities, it shares some high-level ideas with other Python supersets like Pyrex and Cython. Like Mojo, these projects define their own language that also support the Python language. They allow you to write more performant extensions for Python that interoperate with both Python and C libraries.\n\nThese Python supersets are great for some kinds of applications, and they‚Äôve been applied to great effect by some popular Python libraries. However, they don‚Äôt solve Python‚Äôs two-world problem and because they rely on CPython for their core semantics, they can‚Äôt work without it, whereas Mojo uses CPython only when necessary to provide compatibility with existing Python code. Pure Mojo code does not use any pre-existing runtime or compiler technologies, it instead uses an MLIR-based infrastructure to enable high-performance execution on a wide range of hardware.\n\nEmbedded DSLs in Python\n\nAnother common approach is to build an embedded domain-specific languages (DSLs) in Python, typically installed with a Python decorator. There are many examples of this (the @tf.function decorator in TensorFlow, the @triton.jit in OpenAI‚Äôs Triton programming model, etc.). A major benefit of these systems is that they maintain compatibility with the Python ecosystem of tools, and integrate natively into Python logic, allowing an embedded mini language to co-exist with the strengths of Python for dynamic use cases.\n\nUnfortunately, the embedded mini-languages provided by these systems often have surprising limitations, don‚Äôt integrate well with debuggers and other workflow tooling, and do not support the level of native language integration that we seek for a language that unifies heterogeneous compute and is the primary way to write large-scale kernels and systems.\n\nWith Mojo, we hope to move the usability of the overall system forward by simplifying things and making it more consistent. Embedded DSLs are an expedient way to get demos up and running, but we are willing to put in the additional effort and work to provide better usability and predictability for our use-case.\n\nTo see all the features we‚Äôve built with Mojo so far, see the Mojo programming manual.\n\n¬© 2023 Modular Inc\ncookie\nModular.com\nTerms\nPrivacy\nGet started\nPlease accept our cookies\nWe use cookies to monitor visitor traffic and gain valuable insights that help us improve the website and documentation. Read more\nAccept\nReject"
  }
]